{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "from joblib import hash, dump, load\n",
    "import os\n",
    "\n",
    "from deer.default_parser import process_args\n",
    "from deer.agent import NeuralAgent\n",
    "from deer.learning_algos.CRAR_torch import CRAR\n",
    "from simple_maze_env import MyEnv as simple_maze_env\n",
    "import deer.experiment.base_controllers as bc\n",
    "\n",
    "from deer.policies import EpsilonGreedyPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Defaults:\n",
    "    # ----------------------\n",
    "    # Experiment Parameters\n",
    "    # ----------------------\n",
    "    steps_per_epoch = 5000\n",
    "    epochs = 50\n",
    "    steps_per_test = 1000\n",
    "    period_btw_summary_perfs = 1\n",
    "    \n",
    "    # ----------------------\n",
    "    # Environment Parameters\n",
    "    # ----------------------\n",
    "    frame_skip = 2\n",
    "\n",
    "    # ----------------------\n",
    "    # DQN Agent parameters:\n",
    "    # ----------------------\n",
    "    update_rule = 'rmsprop'\n",
    "    learning_rate = 5 * 1E-4 # 1E-4\n",
    "    learning_rate_decay = 0.9\n",
    "    discount = 0.9\n",
    "    discount_inc = 1\n",
    "    discount_max = 0.99\n",
    "    rms_decay = 0.9\n",
    "    rms_epsilon = 0.0001\n",
    "    momentum = 0\n",
    "    clip_norm = 1.0\n",
    "    epsilon_start = 1.0\n",
    "    epsilon_min = 1.0\n",
    "    epsilon_decay = 10000\n",
    "    update_frequency = 1\n",
    "    replay_memory_size = 1000000 #replacing with 200000 will works just fine (in case you dont have 18gb of memory)\n",
    "    batch_size = 32\n",
    "    freeze_interval = 1000\n",
    "    deterministic = False\n",
    "\n",
    "higher_dim_obs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters hash is: 62977be8e45d8a56a5537c11dfd5d2fd8dda69e0\n",
      "The parameters are: <__main__.Defaults object at 0x2ae487dc08b0>\n",
      "end gathering data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters = Defaults()\n",
    "if parameters.deterministic:\n",
    "    rng = np.random.RandomState(123456)\n",
    "else:\n",
    "    rng = np.random.RandomState()\n",
    "\n",
    "# --- Instantiate environment ---\n",
    "env = simple_maze_env(rng, higher_dim_obs=higher_dim_obs)\n",
    "\n",
    "# --- Instantiate learning_algo ---\n",
    "learning_algo = CRAR(\n",
    "    env,\n",
    "    parameters.rms_decay,\n",
    "    parameters.rms_epsilon,\n",
    "    parameters.momentum,\n",
    "    parameters.clip_norm,\n",
    "    parameters.freeze_interval,\n",
    "    parameters.batch_size,\n",
    "    parameters.update_rule,\n",
    "    rng,\n",
    "    high_int_dim=False,\n",
    "    internal_dim=2, lr=parameters.learning_rate)\n",
    "\n",
    "test_policy = EpsilonGreedyPolicy(learning_algo, env.nActions(), rng, 1.)\n",
    "\n",
    "# --- Instantiate agent ---\n",
    "agent = NeuralAgent(\n",
    "    env,\n",
    "    learning_algo,\n",
    "    parameters.replay_memory_size,\n",
    "    max(env.inputDimensions()[i][0] for i in range(len(env.inputDimensions()))),\n",
    "    parameters.batch_size,\n",
    "    rng,\n",
    "    test_policy=test_policy)\n",
    "\n",
    "# --- Create unique filename for FindBestController ---\n",
    "h = hash(vars(parameters), hash_name=\"sha1\")\n",
    "fname = \"test_\" + h\n",
    "print(\"The parameters hash is: {}\".format(h))\n",
    "print(\"The parameters are: {}\".format(parameters))\n",
    "\n",
    "# As for the discount factor and the learning rate, one can update periodically the parameter of the epsilon-greedy\n",
    "# policy implemented by the agent. This controllers has a bit more capabilities, as it allows one to choose more\n",
    "# precisely when to update epsilon: after every X action, episode or epoch. This parameter can also be reset every\n",
    "# episode or epoch (or never, hence the resetEvery='none').\n",
    "agent.attach(bc.EpsilonController(\n",
    "    initial_e=parameters.epsilon_start,\n",
    "    e_decays=parameters.epsilon_decay,\n",
    "    e_min=parameters.epsilon_min,\n",
    "    evaluate_on='action',\n",
    "    periodicity=1,\n",
    "    reset_every='none'))\n",
    "\n",
    "agent.run(10, 500)\n",
    "print(\"end gathering data\")\n",
    "\n",
    "# --- Bind controllers to the agent ---\n",
    "# Before every training epoch (periodicity=1), we want to print a summary of the agent's epsilon, discount and \n",
    "# learning rate as well as the training epoch number.\n",
    "agent.attach(bc.VerboseController(\n",
    "    evaluate_on='epoch', \n",
    "    periodicity=1))\n",
    "\n",
    "# Every epoch end, one has the possibility to modify the learning rate using a LearningRateController. Here we \n",
    "# wish to update the learning rate after every training epoch (periodicity=1), according to the parameters given.\n",
    "agent.attach(bc.LearningRateController(\n",
    "    initial_learning_rate=parameters.learning_rate, \n",
    "    learning_rate_decay=parameters.learning_rate_decay,\n",
    "    periodicity=1))\n",
    "\n",
    "# Same for the discount factor.\n",
    "agent.attach(bc.DiscountFactorController(\n",
    "    initial_discount_factor=parameters.discount, \n",
    "    discount_factor_growth=parameters.discount_inc, \n",
    "    discount_factor_max=parameters.discount_max,\n",
    "    periodicity=1))\n",
    "\n",
    "# During training epochs, we want to train the agent after every [parameters.update_frequency] action it takes.\n",
    "# Plus, we also want to display after each training episode (!= than after every training) the average bellman\n",
    "# residual and the average of the V values obtained during the last episode, hence the two last arguments.\n",
    "agent.attach(bc.TrainerController(\n",
    "    evaluate_on='action', \n",
    "    periodicity=parameters.update_frequency, \n",
    "    show_episode_avg_V_value=True, \n",
    "    show_avg_Bellman_residual=True))\n",
    "\n",
    "# We wish to discover, among all versions of our neural network (i.e., after every training epoch), which one \n",
    "# has the highest validation score.\n",
    "# To achieve this goal, one can use the FindBestController along with an InterleavedTestEpochControllers. It is \n",
    "# important that the validationID is the same than the id argument of the InterleavedTestEpochController.\n",
    "# The FindBestController will dump on disk the validation scores for each and every network, as well as the \n",
    "# structure of the neural network having the best validation score. These dumps can then used to plot the evolution \n",
    "# of the validation and test scores (see below) or simply recover the resulting neural network for your \n",
    "# application.\n",
    "agent.attach(bc.FindBestController(\n",
    "    validationID=simple_maze_env.VALIDATION_MODE,\n",
    "    testID=None,\n",
    "    unique_fname=fname))\n",
    "\n",
    "# All previous controllers control the agent during the epochs it goes through. However, we want to interleave a \n",
    "# \"validation epoch\" between each training epoch. For each validation epoch, we want also to display the sum of all \n",
    "# rewards obtained, hence the showScore=True. Finally, we want to call the summarizePerformance method of ALE_env \n",
    "# every [parameters.period_btw_summary_perfs] *validation* epochs.\n",
    "agent.attach(bc.InterleavedTestEpochController(\n",
    "    id=simple_maze_env.VALIDATION_MODE, \n",
    "    epoch_length=parameters.steps_per_test,\n",
    "    periodicity=1,\n",
    "    show_score=True,\n",
    "    summarize_every=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3075, -0.0738], device='cuda:0') tensor([-0.3935, -0.3524], device='cuda:0') tensor([-0.3075, -0.0738], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2149], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.03939761593192816 0.06175614380836487 1.1208807349205017 0.0 0.3985723863840103 0.0007902259081602097 0.0944376584906131\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5836, -0.9203], device='cuda:0') tensor([ 0.6992, -0.5662], device='cuda:0') tensor([ 0.8374, -0.4729], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2582], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.019770468425005676 0.12359020361304283 1.121973300933838 0.0 0.37130512318015096 0.0005640176087617874 0.061059341832064094\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1799, -0.9287], device='cuda:0') tensor([-0.0786, -0.9235], device='cuda:0') tensor([ 0.1799, -0.9287], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2702], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.015531838409602643 0.1855282192081213 1.1262276980876922 0.0 0.37075778633356093 0.0004164915904402733 0.05478172168321908\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9755, 0.2436], device='cuda:0') tensor([0.8941, 0.5510], device='cuda:0') tensor([0.9709, 0.6393], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2356], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.01493524963967502 0.2474083079993725 1.1255790145397186 0.0 0.36860829856991767 0.00030326097458601 0.057905500134453176\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0245, 0.3212], device='cuda:0') tensor([0.0151, 0.6104], device='cuda:0') tensor([-0.0262,  0.7165], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2189], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.014059623297303914 0.30939146226644515 1.125911684989929 0.0 0.37176535150408746 0.0003536386415362358 0.05418459502607584\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2915, -0.0945], device='cuda:0') tensor([-0.2722, -0.4442], device='cuda:0') tensor([-0.2915, -0.0945], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2546], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.013398410096764565 0.37118502757698296 1.125076869726181 0.0 0.37173338621854785 0.00029525277763605117 0.05523675377853215\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.4405, 0.9616], device='cuda:0') tensor([0.1345, 0.9807], device='cuda:0') tensor([-0.0142,  0.9616], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2611], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.012120192690752447 0.43276455108821393 1.1245315189361573 0.0 0.36697716522216794 0.0003591551259160042 0.0544772493802011\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1167,  0.1698], device='cuda:0') tensor([-0.0836,  0.4728], device='cuda:0') tensor([-0.0623,  0.6145], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2171], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.010026129917241633 0.4941618693843484 1.1258524687290192 0.0 0.37061456245183944 0.00029993318021297454 0.05654946191888303\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0448,  0.6841], device='cuda:0') tensor([-0.0572,  0.9115], device='cuda:0') tensor([-0.0607,  0.9992], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2164], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.008065609472338111 0.5555369528532028 1.1241880543231964 0.0 0.36847025391459465 0.00031088876724243164 0.05324288756307215\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9923,  0.9926], device='cuda:0') tensor([-0.8202,  1.0030], device='cuda:0') tensor([-0.6349,  1.0016], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2262], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.007546660067513585 0.6170435894504189 1.1265912499427795 0.0 0.36331345316767694 0.00023169004917144776 0.05394541093334555\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 1:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.3416, -0.0253],\n",
      "        [-0.3416, -0.0253],\n",
      "        [-0.3416, -0.0253],\n",
      "        ...,\n",
      "        [-0.6749, -0.1739],\n",
      "        [-0.6373, -0.5477],\n",
      "        [-0.6373, -0.5477]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6749, -0.1739], device='cuda:0') tensor([-0.6453,  0.2037], device='cuda:0') tensor([-0.6165,  0.2999], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2096], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00721187219908461 0.6784051927104592 1.126071973323822 0.0 0.36924794697761537 0.0002430214136838913 0.05153244132269174\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.5488, 0.3806], device='cuda:0') tensor([0.5429, 0.6510], device='cuda:0') tensor([0.5047, 0.7238], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2277], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.006782435566652566 0.739665833696723 1.1259139831066132 0.0 0.3621507062613964 0.0002458998262882233 0.05277685182541609\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9671, 0.6529], device='cuda:0') tensor([0.9980, 0.2834], device='cuda:0') tensor([0.9587, 0.3076], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2801], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.006517597775440663 0.8010619851946831 1.124820620536804 0.0 0.36790388652682304 0.00021417178213596345 0.05494956080429256\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 1.0000, -0.5403], device='cuda:0') tensor([ 1.0078, -0.5217], device='cuda:0') tensor([ 1.0000, -0.5403], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2675], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.005883220053976402 0.8625510400384665 1.1264215848445893 0.0 0.3635384317934513 0.00022730024158954622 0.05288260585581884\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.4039, 0.9956], device='cuda:0') tensor([-0.0121,  1.0403], device='cuda:0') tensor([-0.0963,  0.9966], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2605], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.005596291195834055 0.9241277429163456 1.1259426000118256 0.0 0.3648336213827133 0.00019469933956861495 0.0544125479478389\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9987, -0.5904], device='cuda:0') tensor([-1.0924, -0.5932], device='cuda:0') tensor([-0.9987, -0.5904], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2434], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.004839653304312378 0.9857159369513393 1.1253435294628142 0.0 0.36202846613526346 0.00022042980045080185 0.05394825206324458\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0199,  0.2794], device='cuda:0') tensor([-0.0864,  0.2685], device='cuda:0') tensor([-0.0199,  0.2794], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2601], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0038829914436209947 1.0474683815687895 1.1259131684303283 0.0 0.35863642793893813 0.00020265214145183562 0.05402933168504387\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9572, -1.0011], device='cuda:0') tensor([-0.9137, -0.6221], device='cuda:0') tensor([-0.9830, -0.6547], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2089], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0035498413273599 1.1090235043242573 1.1235901412963867 0.0 0.3583204120397568 0.00025904595106840134 0.049893021111376584\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.5857, 0.9507], device='cuda:0') tensor([0.9442, 0.9689], device='cuda:0') tensor([1.0053, 0.9395], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2546], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0033059484679251907 1.170819299556315 1.1259294080734252 0.0 0.3550165055692196 0.00025869309157133103 0.05206717714015394\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4420,  0.9830], device='cuda:0') tensor([-0.9090,  0.9406], device='cuda:0') tensor([-0.9808,  0.9779], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2497], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0031839834144338965 1.2324483529776336 1.1260409445762634 0.0 0.3579201200008392 0.00021103159338235855 0.05248258040845394\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 2:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.3029, -0.1043],\n",
      "        [-0.3029, -0.1043],\n",
      "        [-0.6333, -0.1863],\n",
      "        ...,\n",
      "        [-0.2082, -0.9906],\n",
      "        [-0.2082, -0.9906],\n",
      "        [-0.2082, -0.9906]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0446,  0.6119], device='cuda:0') tensor([-0.0370,  0.6560], device='cuda:0') tensor([-0.0446,  0.6119], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2577], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0030015448874328287 1.294117451198399 1.1255337076187133 0.0 0.35560623943805697 0.00019803528487682344 0.054517265439033506\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9752,  0.9720], device='cuda:0') tensor([-0.9678,  0.9525], device='cuda:0') tensor([-0.9752,  0.9720], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2405], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.002990917490446009 1.3559356985762716 1.12451246714592 0.0 0.3531511728465557 0.0001937522068619728 0.05235051140934229\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3178, -0.0775], device='cuda:0') tensor([-0.2994,  0.2585], device='cuda:0') tensor([-0.3178, -0.0775], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2147], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.002860337844584137 1.4176686100661755 1.1257159175872802 0.0 0.355618292093277 0.00020187918841838836 0.0543339478392154\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6150, -0.2661], device='cuda:0') tensor([-1.0153, -0.3104], device='cuda:0') tensor([-0.9884, -0.3490], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2514], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.002906643619411625 1.4794396535381675 1.1244153909683228 0.0 0.36094718807935716 0.00019121472537517547 0.054256623963825405\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5607, -0.2026], device='cuda:0') tensor([ 0.0472, -0.1786], device='cuda:0') tensor([ 0.0611, -0.2259], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2714], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.002713667873875238 1.54104569298774 1.1259513356685638 0.0 0.34829370433092116 0.00020659754425287247 0.05100840543396771\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0350,  0.6281], device='cuda:0') tensor([-0.0230,  0.2555], device='cuda:0') tensor([0.0471, 0.2938], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2592], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0027359795299125834 1.602853523015976 1.126291806936264 0.0 0.35818876677751543 0.0001870751976966858 0.05708203926682472\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9632,  0.5454], device='cuda:0') tensor([-0.9577,  0.5473], device='cuda:0') tensor([-0.9632,  0.5454], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2419], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0026523224944248794 1.6645419774502517 1.1247225008010864 0.0 0.35698442336916925 0.00020605307072401046 0.05434622247517109\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5597, -0.0877], device='cuda:0') tensor([ 0.9899, -0.0214], device='cuda:0') tensor([ 0.9977, -0.0107], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2578], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0025757634575711563 1.7263732657432556 1.12770258975029 0.0 0.36175254988670347 0.0001804076060652733 0.05235677236225456\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4795,  0.9869], device='cuda:0') tensor([-0.4792,  0.9687], device='cuda:0') tensor([-0.4795,  0.9869], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2356], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0025672582906554452 1.7880846824869514 1.1272538731098174 0.0 0.3573780494183302 0.00017063193023204805 0.05415627417434007\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6542, -0.2282], device='cuda:0') tensor([-0.9769, -0.2437], device='cuda:0') tensor([-0.9789, -0.2100], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2504], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.002356085963663645 1.8497375439405441 1.1272954423427581 0.0 0.353473502188921 0.0001781426891684532 0.05237634105421603\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 3:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.3352,  0.0271],\n",
      "        [ 0.0810, -0.1119],\n",
      "        [ 0.5764, -0.0914],\n",
      "        ...,\n",
      "        [-0.4684,  1.0000],\n",
      "        [-0.4684,  1.0000],\n",
      "        [-0.4914,  0.6230]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9472,  1.0025], device='cuda:0') tensor([-0.9059,  0.9741], device='cuda:0') tensor([-0.9472,  1.0025], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2014], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0023115290683927013 1.9114814739599824 1.1266026513576508 0.0 0.35422515311837194 0.00013620183616876603 0.05257123544532806\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0867, -0.1065], device='cuda:0') tensor([ 0.0279, -0.4619], device='cuda:0') tensor([-0.0795, -0.5223], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2637], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0023447938717436044 1.9730643092617393 1.1240734868049622 0.0 0.347754913687706 0.00015611047297716142 0.05522462922614068\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9874, -0.0206], device='cuda:0') tensor([0.9817, 0.3735], device='cuda:0') tensor([0.9848, 0.3560], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2369], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0023568252637051045 2.0347315671369435 1.1258195271492004 0.0 0.3527720060646534 0.00015353265404701233 0.05147250513639301\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2195, -0.9798], device='cuda:0') tensor([-0.1738, -0.9889], device='cuda:0') tensor([-0.2195, -0.9798], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2623], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0023087808535201476 2.096577880397439 1.1265467376708984 0.0 0.3573277403116226 0.00013925198465585708 0.053228097501210866\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0920, 0.2832], device='cuda:0') tensor([ 0.1256, -0.0616], device='cuda:0') tensor([ 0.1460, -0.1221], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2631], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0024196884979028254 2.158368332400918 1.1259669678211213 0.0 0.35389274471998217 0.00014509546011686326 0.05431949536455795\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9666,  0.9885], device='cuda:0') tensor([-0.4714,  0.9717], device='cuda:0') tensor([-0.4689,  0.9922], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2267], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.002186690649250522 2.2200722697898745 1.1259861974716185 0.0 0.35781736728549 0.00014464368671178817 0.05360184923186898\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5930, -0.1035], device='cuda:0') tensor([-0.5971, -0.4111], device='cuda:0') tensor([-0.4954, -0.5105], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2474], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.002019363724975847 2.281661891222 1.1243017401695252 0.0 0.3547336857020855 0.000146934375166893 0.05573547765798867\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9824, -0.9807], device='cuda:0') tensor([-0.9769, -0.5589], device='cuda:0') tensor([-0.9854, -0.5727], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2085], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.002065400888910517 2.3434317017644646 1.1252936673164369 0.0 0.3590202525854111 0.00014371761679649354 0.054157174037769436\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9909, -0.2764], device='cuda:0') tensor([-1.0079, -0.2814], device='cuda:0') tensor([-0.9909, -0.2764], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2430], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0020939068197039887 2.405200975045562 1.1260249881744384 0.0 0.3574643389284611 0.00014302346110343933 0.05568744093552232\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9976,  0.3134], device='cuda:0') tensor([-0.5428,  0.3200], device='cuda:0') tensor([-0.5463,  0.2964], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2257], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0020486766401445495 2.4669391233846545 1.125042257785797 0.0 0.35190053102374075 0.00013963159918785095 0.05261610970553011\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 4:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.2361, -0.0665],\n",
      "        [-0.6152, -0.1855],\n",
      "        [-0.9874, -0.2008],\n",
      "        ...,\n",
      "        [ 0.9960, -0.4802],\n",
      "        [ 0.9780, -0.9984],\n",
      "        [ 0.9780, -0.9984]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9867,  1.0015], device='cuda:0') tensor([-1.0051,  1.0090], device='cuda:0') tensor([-0.9867,  1.0015], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2402], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0018245916831074282 2.528501107878983 1.1271438550949098 0.0 0.34952265337109567 0.0001233583241701126 0.05523459839913994\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0456, -0.5467], device='cuda:0') tensor([-0.3037, -0.9731], device='cuda:0') tensor([-0.2943, -0.9914], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2609], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0017215596237801947 2.5902139995247127 1.126930285692215 0.0 0.3569768271446228 0.00012550003081560136 0.05326839341316372\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9784, -0.9855], device='cuda:0') tensor([ 0.9640, -0.9943], device='cuda:0') tensor([ 0.9784, -0.9855], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2852], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0016522205563960597 2.6519079056084154 1.1250717515945434 0.0 0.35492593958973884 0.00010499565303325653 0.053359958863817156\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3416, -0.9778], device='cuda:0') tensor([ 0.9705, -0.9586], device='cuda:0') tensor([ 0.9877, -0.9871], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2525], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0016258053740020842 2.7138005952090025 1.1280179085731505 0.0 0.3495377978682518 0.00013083668798208236 0.05236537432065234\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9928, 0.4278], device='cuda:0') tensor([0.5842, 0.3247], device='cuda:0') tensor([0.6041, 0.2612], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2700], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0015162652201834135 2.7756445549726485 1.1285718548297883 0.0 0.34913049775362015 0.00010738385468721389 0.05025410219281912\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4859, -0.5410], device='cuda:0') tensor([-0.9885, -0.5976], device='cuda:0') tensor([-0.9832, -0.6693], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2551], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0015706339745083823 2.8372686020061373 1.1259136090278625 0.0 0.35255659186840055 0.00012184825539588928 0.05396715157013386\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9970, -0.2581], device='cuda:0') tensor([-0.5116, -0.0991], device='cuda:0') tensor([-0.5748, -0.1668], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2252], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0015321226712549105 2.8989973256215453 1.1245508959293367 0.0 0.34816332459449767 0.00012532392889261245 0.05219018658343703\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1585,  0.9894], device='cuda:0') tensor([-0.1718,  0.9936], device='cuda:0') tensor([-0.1585,  0.9894], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2539], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.001457388230599463 2.9607443443015216 1.1249025840759277 0.0 0.3512106426358223 0.00011794087290763855 0.05339784841425717\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9863, 0.3946], device='cuda:0') tensor([0.5737, 0.2273], device='cuda:0') tensor([0.5376, 0.1662], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2703], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0014122796232113614 3.0226060065254567 1.127566326379776 0.0 0.35373381680250165 0.00011454083025455475 0.053223160272929816\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9796, -0.9891], device='cuda:0') tensor([ 0.9720, -0.9893], device='cuda:0') tensor([ 0.9796, -0.9891], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2853], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0014659074313240125 3.0843829780966043 1.126891638278961 0.0 0.3496379584670067 0.00012137588113546372 0.054617543113417925\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 5:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.2185,  0.0826],\n",
      "        [-0.2185,  0.0826],\n",
      "        [-0.6046, -0.1431],\n",
      "        ...,\n",
      "        [-0.4274,  0.6160],\n",
      "        [-0.4925,  0.2192],\n",
      "        [-0.9941,  0.1327]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9819,  0.9955], device='cuda:0') tensor([-0.9620,  1.0040], device='cuda:0') tensor([-0.9819,  0.9955], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2403], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0013077952087623998 3.1461189639419316 1.1284418795108795 0.0 0.3552364190816879 9.439931809902191e-05 0.053137013701722025\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1325,  0.9966], device='cuda:0') tensor([0.4503, 0.9535], device='cuda:0') tensor([0.4078, 0.9977], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2420], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.001302898380206898 3.2077542529702185 1.1260151145458221 0.0 0.3473049968481064 9.119734913110733e-05 0.05298203322291374\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9964, -0.3022], device='cuda:0') tensor([-0.5466, -0.1097], device='cuda:0') tensor([0.1496, 0.0028], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2252], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0012613664902746677 3.26947699341923 1.1267062618732453 0.0 0.35023712772130966 8.814913779497146e-05 0.05238260713685304\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9654,  0.9978], device='cuda:0') tensor([-1.0068,  0.5502], device='cuda:0') tensor([-0.9896,  0.6484], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2371], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.001250860490195919 3.3311637881249188 1.1261328678131104 0.0 0.34386192306876184 0.00010184632986783982 0.05202185435220599\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9912, -0.9991], device='cuda:0') tensor([ 0.2161, -0.9924], device='cuda:0') tensor([ 0.1881, -0.9914], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2825], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0012167724027531222 3.3928628700748087 1.127193338394165 0.0 0.35179518526792525 9.782011061906814e-05 0.051534758266992865\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1771, -0.9977], device='cuda:0') tensor([ 0.9562, -0.9956], device='cuda:0') tensor([ 0.9851, -0.9993], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2487], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0012237463945057243 3.4545970483198762 1.1274494442939758 0.0 0.3474681767821312 9.471080452203751e-05 0.050692837991751734\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5995, -0.8845], device='cuda:0') tensor([ 0.1932, -0.9992], device='cuda:0') tensor([ 0.1600, -0.9935], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2765], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.001212234525475651 3.516463657937944 1.1238845167160034 0.0 0.3424368833899498 0.00010135883092880249 0.052910665780305864\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5255,  0.3153], device='cuda:0') tensor([-0.9820,  0.1465], device='cuda:0') tensor([-0.9973,  0.1597], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2512], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0011803759349277242 3.5782526858523487 1.125680376291275 0.0 0.34146951833367345 8.831908553838729e-05 0.052622598502784966\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9989,  0.1210], device='cuda:0') tensor([-0.5798,  0.3071], device='cuda:0') tensor([-0.5649,  0.3100], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2255], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0011193399295443668 3.6399547431468964 1.1254400749206543 0.0 0.3422156766653061 7.587586343288422e-05 0.051050457094796005\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9911, -0.6948], device='cuda:0') tensor([-1.0050, -0.3000], device='cuda:0') tensor([-0.9936, -0.3378], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2072], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0011657927303458564 3.701667538046837 1.1260287356376648 0.0 0.3352019340991974 9.995704889297485e-05 0.054052273962646724\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 6:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.1853,  0.1663],\n",
      "        [-0.5985, -0.0976],\n",
      "        [-0.5314,  0.3085],\n",
      "        ...,\n",
      "        [ 0.9851, -0.9912],\n",
      "        [ 0.9851, -0.9912],\n",
      "        [ 0.1318, -0.9985]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3812,  0.9959], device='cuda:0') tensor([-0.3292,  1.0277], device='cuda:0') tensor([-0.3812,  0.9959], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2374], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0009801153781008906 3.7635037332624197 1.1251854200363158 0.0 0.3432532220482826 7.266171276569366e-05 0.051510337892919776\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1942,  0.1609], device='cuda:0') tensor([-0.6237, -0.1903], device='cuda:0') tensor([-0.5794, -0.1331], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2579], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.001014240883756429 3.825267079055309 1.1263820588588715 0.0 0.34485919815301896 7.10325986146927e-05 0.05285037160199135\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9912, -0.4187], device='cuda:0') tensor([ 1.0067, -0.4371], device='cuda:0') tensor([ 0.9912, -0.4187], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2672], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.001007249126327224 3.8869741953238846 1.1275472764968872 0.0 0.3464733908176422 7.949115335941314e-05 0.051742639151401815\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5341,  0.3261], device='cuda:0') tensor([-0.4637,  0.3346], device='cuda:0') tensor([-0.5341,  0.3261], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2348], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0009786812652600929 3.9486747244372964 1.1284708566665649 0.0 0.3428124870955944 9.173091500997544e-05 0.05255196781922132\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0081, 0.7215], device='cuda:0') tensor([0.0028, 0.6954], device='cuda:0') tensor([0.0081, 0.7215], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2578], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000892389187705703 4.010447541192174 1.1270737533569335 0.0 0.34258313839137555 7.12340995669365e-05 0.05108115982823074\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1149,  0.9949], device='cuda:0') tensor([-0.0810,  1.0154], device='cuda:0') tensor([-0.1149,  0.9949], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2544], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0008687835386372171 4.072296942524612 1.1267782046794892 0.0 0.3368063608407974 7.94193521142006e-05 0.05491905767284334\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9948,  0.0512], device='cuda:0') tensor([-0.9657, -0.3445], device='cuda:0') tensor([-0.9968, -0.3601], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2381], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0008673867626930587 4.1339856252372265 1.1254508216381074 0.0 0.3376533409655094 7.554683089256287e-05 0.05291712219221517\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4887, -0.4953], device='cuda:0') tensor([-0.5960, -0.9855], device='cuda:0') tensor([-0.6280, -0.9900], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2503], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0009357073286082596 4.1958556876257065 1.1273917415142058 0.0 0.3485578856766224 8.46085399389267e-05 0.05443538255058229\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2444, -0.1600], device='cuda:0') tensor([ 0.6487, -0.5092], device='cuda:0') tensor([ 0.6537, -0.5232], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2511], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000845314163074363 4.25761419146508 1.1275747709274293 0.0 0.3393351735472679 6.986173242330552e-05 0.053781270740553735\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.2109, 0.3379], device='cuda:0') tensor([ 0.5619, -0.0023], device='cuda:0') tensor([ 0.5489, -0.0390], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2499], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0008320811357698403 4.319420502521098 1.1272126910686493 0.0 0.33939118933677676 7.102151215076446e-05 0.05345175029989332\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 7:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.1392,  0.2365],\n",
      "        [-0.1392,  0.2365],\n",
      "        [ 0.2455, -0.1784],\n",
      "        ...,\n",
      "        [-0.9849,  0.9861],\n",
      "        [-0.4495,  0.9928],\n",
      "        [-0.4528,  0.6194]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4748, -0.4679], device='cuda:0') tensor([-0.9810, -0.6087], device='cuda:0') tensor([-0.9959, -0.6572], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2551], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007821764702675864 4.3811700055524705 1.1261335394382477 0.0 0.34062747672200205 6.723780930042266e-05 0.053362537678331136\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.5479, 0.5707], device='cuda:0') tensor([0.4448, 0.9914], device='cuda:0') tensor([0.4461, 0.9946], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2270], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007958465506089852 4.442965977109969 1.127725698709488 0.0 0.33937506315112115 6.987114995718002e-05 0.05351588736847043\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6671, -0.5284], device='cuda:0') tensor([0.6059, 0.0016], device='cuda:0') tensor([ 0.5932, -0.0010], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2332], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0008153408346115612 4.5047855127081275 1.1256117084026336 0.0 0.33965179005265234 7.427436113357544e-05 0.05270445203594863\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4159, -0.9983], device='cuda:0') tensor([-0.1123, -0.5164], device='cuda:0') tensor([-0.1245, -0.5386], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2166], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007380168248782865 4.566676008015871 1.1274381883144378 0.0 0.33919313874840734 6.577831506729126e-05 0.055526791673153636\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0562, 0.7707], device='cuda:0') tensor([0.2685, 0.4029], device='cuda:0') tensor([0.1994, 0.4085], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2608], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007386319352663122 4.628566442355513 1.1273595168590547 0.0 0.3413508716225624 6.990904361009597e-05 0.05327125203795731\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5001,  0.3197], device='cuda:0') tensor([-1.0068,  0.1150], device='cuda:0') tensor([-0.9777,  0.1332], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2516], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007482788974302821 4.690332696445286 1.1282561111450196 0.0 0.3359897278547287 7.545478641986848e-05 0.052548968041315675\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9949, -0.4290], device='cuda:0') tensor([ 1.0021, -1.0173], device='cuda:0') tensor([ 0.9984, -0.9928], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2851], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007595647667185403 4.752076522879302 1.1260541489124298 0.0 0.3361926508247852 6.678471714258193e-05 0.05301857292558998\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4093, -0.9974], device='cuda:0') tensor([ 0.0939, -1.0087], device='cuda:0') tensor([ 0.1105, -0.9966], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2359], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007777500689844601 4.813979501642287 1.1288010876178742 0.0 0.33677371111512183 7.461053878068924e-05 0.052880662327632305\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9950, 0.0273], device='cuda:0') tensor([1.0010, 0.3775], device='cuda:0') tensor([0.9962, 0.3839], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2368], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00078931535204174 4.8757349046170715 1.126789973974228 0.0 0.3353713984489441 6.164810806512833e-05 0.05339770500920713\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1433, -0.9947], device='cuda:0') tensor([ 0.1541, -1.0048], device='cuda:0') tensor([ 0.1433, -0.9947], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2654], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007845345324603841 4.937632361076772 1.1259207878112794 0.0 0.3397695169448853 7.304191589355469e-05 0.049589984081685544\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 8:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.1488,  0.2780],\n",
      "        [-0.1488,  0.2780],\n",
      "        [ 0.2495, -0.1007],\n",
      "        ...,\n",
      "        [ 0.6142, -0.9922],\n",
      "        [ 0.6381, -0.5237],\n",
      "        [ 0.6142, -0.9922]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5050, -0.4850], device='cuda:0') tensor([-0.9612, -0.6146], device='cuda:0') tensor([-0.9890, -0.6269], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2545], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0006886455815983936 4.999282288715244 1.1273780322074891 0.0 0.33351966363191604 6.394374370574951e-05 0.05307617162540555\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5106,  0.9933], device='cuda:0') tensor([-0.4847,  1.0105], device='cuda:0') tensor([-0.5106,  0.9933], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2350], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007396810100763105 5.060967220842838 1.1268903901576997 0.0 0.3356182109117508 7.110054790973663e-05 0.05585114048607647\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9966, -0.4780], device='cuda:0') tensor([ 1.0040, -0.5033], device='cuda:0') tensor([ 0.9966, -0.4780], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2674], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007621116014197469 5.122872676834464 1.1251568577289581 0.0 0.3378888991177082 4.963630437850952e-05 0.054143489866517486\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2683, -0.1196], device='cuda:0') tensor([0.2576, 0.4577], device='cuda:0') tensor([0.2497, 0.4539], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2247], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007177583003067412 5.184682488009334 1.1277319164276123 0.0 0.33702110990881917 5.787750333547592e-05 0.05114506379608065\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9958, -0.9927], device='cuda:0') tensor([-1.0178, -1.0112], device='cuda:0') tensor([-0.9958, -0.9927], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2441], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0008031965238042176 5.246508525334298 1.126399557352066 0.0 0.3387004556655884 4.9580954015254975e-05 0.0549295895807445\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2428, -0.1246], device='cuda:0') tensor([-0.0848, -0.5071], device='cuda:0') tensor([-0.0598, -0.4952], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2675], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0008011885258601978 5.308230395719409 1.1268956663608551 0.0 0.3334347647726536 5.098966509103775e-05 0.04936913408152759\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.1248, 0.8945], device='cuda:0') tensor([0.1164, 0.8471], device='cuda:0') tensor([0.1248, 0.8945], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2582], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007510728603811003 5.369910050250589 1.1262300169467927 0.0 0.34201986265182494 5.120255798101425e-05 0.05211774008534849\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5151, -0.0828], device='cuda:0') tensor([-0.9926, -0.2888], device='cuda:0') tensor([-1.0008, -0.2648], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2529], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007802675804705359 5.431654651023448 1.1267921574115753 0.0 0.3336277595460415 5.894838273525238e-05 0.05117834674101323\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5202,  0.9942], device='cuda:0') tensor([-0.4891,  0.6571], device='cuda:0') tensor([-0.4608,  0.6440], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2471], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007728165840962902 5.493489061869681 1.125314710378647 0.0 0.3345872298926115 6.0092754662036895e-05 0.051913022658787666\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9991, 0.0654], device='cuda:0') tensor([ 0.9896, -0.4099], device='cuda:0') tensor([ 0.9988, -0.4217], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2836], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007554423352121375 5.555397667087615 1.1262475945949555 0.0 0.3289991090595722 5.5086731910705566e-05 0.051519444233272225\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 9:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.1309,  0.3721],\n",
      "        [ 0.2222, -0.0307],\n",
      "        [ 0.6204, -0.5536],\n",
      "        ...,\n",
      "        [ 0.9964, -0.4209],\n",
      "        [ 0.6091, -0.9967],\n",
      "        [ 0.6204, -0.5536]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9885, -0.6410], device='cuda:0') tensor([-0.9675, -0.2568], device='cuda:0') tensor([-0.9916, -0.2870], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2070], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007204109826125204 5.617001368716359 1.1249602150917053 0.0 0.33833376376330854 4.4145114719867705e-05 0.05276603698870167\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5025, -0.5166], device='cuda:0') tensor([-0.4591, -0.4682], device='cuda:0') tensor([-0.5025, -0.5166], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2348], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000670504615176469 5.678849225960672 1.1258087918758393 0.0 0.3339050936996937 4.285946488380432e-05 0.049107022566720844\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1332, -0.9972], device='cuda:0') tensor([-0.4349, -0.9850], device='cuda:0') tensor([-0.4007, -0.9964], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2697], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007201741749886424 5.740673062928021 1.126880665540695 0.0 0.3315120936781168 5.079983174800873e-05 0.0519204579340294\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4914,  0.3271], device='cuda:0') tensor([-0.4600,  0.3546], device='cuda:0') tensor([-0.4914,  0.3271], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2357], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007593852537684143 5.802535764560103 1.1269593169689178 0.0 0.338854853361845 5.21470308303833e-05 0.05343221049197018\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3815, -0.9976], device='cuda:0') tensor([-0.3699, -0.9932], device='cuda:0') tensor([-0.3815, -0.9976], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2588], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000729389330430422 5.864308091029525 1.124322023153305 0.0 0.3399022522866726 4.701302945613861e-05 0.0539728211001493\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1311, -0.9955], device='cuda:0') tensor([-0.3430, -1.0176], device='cuda:0') tensor([-0.3829, -0.9958], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2696], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000704236876918003 5.926056229993701 1.1253694417476654 0.0 0.34202570402622223 4.4516660273075105e-05 0.053015300821512935\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0598, -0.4382], device='cuda:0') tensor([ 0.6079, -0.9917], device='cuda:0') tensor([ 0.6252, -0.9981], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2443], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0006670298771932721 5.987919906184077 1.1258622283935547 0.0 0.336615561068058 5.057913064956665e-05 0.05195474244002253\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9945, -0.9989], device='cuda:0') tensor([-0.9874, -0.6511], device='cuda:0') tensor([-0.9988, -0.6730], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2085], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0006885193960624747 6.049869105532766 1.125633962392807 0.0 0.3343557922244072 5.169276893138886e-05 0.05433976421039551\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9889,  0.9972], device='cuda:0') tensor([-0.9775,  0.5593], device='cuda:0') tensor([-0.9973,  0.5680], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2366], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0006450860839686357 6.111744564287364 1.125849760055542 0.0 0.3311404172182083 4.986315220594406e-05 0.0510382484626025\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9903, 0.7277], device='cuda:0') tensor([0.5144, 0.4674], device='cuda:0') tensor([0.5578, 0.4247], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2673], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0006306049005070235 6.173715506896377 1.1244698870182037 0.0 0.32935469307005405 5.295747518539429e-05 0.05221095979772508\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 10:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.1000,  0.4128],\n",
      "        [-0.1000,  0.4128],\n",
      "        [-0.1000,  0.4128],\n",
      "        ...,\n",
      "        [-0.4565,  0.6306],\n",
      "        [-0.5302,  0.9986],\n",
      "        [-0.5302,  0.9986]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2437, -0.0249], device='cuda:0') tensor([-0.0894,  0.3928], device='cuda:0') tensor([-0.1000,  0.4128], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2659], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005973416092747356 6.235621145941317 1.1270201704502105 0.0 0.33125979226827623 4.0727198123931884e-05 0.054192759522236886\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4740, -0.5460], device='cuda:0') tensor([-0.4223, -0.0895], device='cuda:0') tensor([-0.4873, -0.1198], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2140], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005927851110463962 6.29749034179002 1.1274856023788453 0.0 0.3422203229367733 4.269995540380478e-05 0.051039316489361226\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0341, -0.5005], device='cuda:0') tensor([ 0.6617, -1.0225], device='cuda:0') tensor([ 0.6147, -0.9874], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2448], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005518636438646354 6.359343543291092 1.125067890882492 0.0 0.3334377170354128 3.773735463619232e-05 0.05154789326991886\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4838,  0.2998], device='cuda:0') tensor([-0.4703, -0.0740], device='cuda:0') tensor([-0.4867, -0.1074], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2493], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005924264862260315 6.421261026993394 1.125513720035553 0.0 0.33545744109153747 5.138266086578369e-05 0.051373102507553996\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([1.0000, 0.3893], device='cuda:0') tensor([ 0.5975, -0.1312], device='cuda:0') tensor([ 0.5416, -0.1548], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2704], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005342748240218498 6.483106863588095 1.126929985523224 0.0 0.33975394958257676 3.7710048258304596e-05 0.05379100648313761\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9998, -0.9934], device='cuda:0') tensor([ 0.1453, -1.0073], device='cuda:0') tensor([ 0.1293, -0.9995], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2826], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005624521473946516 6.544921288155019 1.123749100446701 0.0 0.33619590717554093 4.044779390096664e-05 0.05156912556942552\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9984, -0.2676], device='cuda:0') tensor([-0.9891, -0.2395], device='cuda:0') tensor([-0.9984, -0.2676], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2428], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000538642538478598 6.606686564922333 1.1269739091396331 0.0 0.3354648907184601 4.172418266534805e-05 0.0521857927730307\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9930,  0.2063], device='cuda:0') tensor([-0.4810,  0.2989], device='cuda:0') tensor([-0.4838,  0.2830], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2257], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005792075867648237 6.668570860505104 1.1261845662593841 0.0 0.3321599320471287 4.645463824272156e-05 0.05360722425859422\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6214, -0.9972], device='cuda:0') tensor([ 0.1253, -0.9894], device='cuda:0') tensor([ 0.1302, -0.9959], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2770], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0004897044579556677 6.730425455763936 1.1267688934803008 0.0 0.33370769417285917 4.44594994187355e-05 0.051889924235641954\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 1.0010, -0.9953], device='cuda:0') tensor([ 1.0007, -0.9966], device='cuda:0') tensor([ 1.0010, -0.9953], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2676], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005201390200527385 6.7923840023055675 1.1240841987133026 0.0 0.3369763026237488 4.7638699412345883e-05 0.05432285233866423\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 11:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0964,  0.4546],\n",
      "        [-0.4704, -0.1259],\n",
      "        [-0.9927, -0.2597],\n",
      "        ...,\n",
      "        [ 0.9936, -0.0253],\n",
      "        [ 0.5587, -0.5790],\n",
      "        [ 0.5446, -0.1263]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9951,  0.1388], device='cuda:0') tensor([-0.9854, -0.2594], device='cuda:0') tensor([-0.9927, -0.2597], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2379], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005003206431283615 6.854288552567363 1.1248030023574829 0.0 0.3312476730644703 4.2681559920310976e-05 0.05642190799023956\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9972, -0.9980], device='cuda:0') tensor([ 0.1049, -0.9793], device='cuda:0') tensor([ 0.1334, -0.9981], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2826], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00046335614658892156 6.916124682895839 1.1235537605285644 0.0 0.3325230162441731 3.6119401454925534e-05 0.053255479076877235\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1551, -0.9998], device='cuda:0') tensor([ 0.9997, -0.9386], device='cuda:0') tensor([ 0.9975, -0.9956], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2482], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00045131689027766696 6.977973019778728 1.1279173903465272 0.0 0.33243445234000685 3.426793962717056e-05 0.0512956370478496\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0436, -0.4431], device='cuda:0') tensor([-0.3948, -1.0011], device='cuda:0') tensor([-0.4001, -0.9990], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2609], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00044973509121336975 7.03974951466173 1.1260473320484161 0.0 0.3373641046285629 3.849916160106659e-05 0.05313563652243465\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9949,  0.1578], device='cuda:0') tensor([-1.0240,  0.5816], device='cuda:0') tensor([-0.9955,  0.5788], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2037], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00045462816755753013 7.1017422181516885 1.1276670730113982 0.0 0.3336641185581684 3.917399793863297e-05 0.053166699538938704\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4055, -0.9999], device='cuda:0') tensor([-0.0395, -0.4518], device='cuda:0') tensor([-0.0578, -0.4277], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2168], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0004266075913328677 7.1636303361132745 1.1260116901397705 0.0 0.33302801349759104 3.560713678598404e-05 0.05067995041422546\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4707, -0.5091], device='cuda:0') tensor([-0.6403, -1.0239], device='cuda:0') tensor([-0.6699, -0.9981], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2507], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00043902186510968023 7.2255174937844275 1.1274495463371277 0.0 0.32365013800561426 4.011750966310501e-05 0.05083218451216817\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9918,  0.5537], device='cuda:0') tensor([-1.0083,  0.9794], device='cuda:0') tensor([-0.9883,  0.9975], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2023], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0004346478720544837 7.287328459106385 1.123696210861206 0.0 0.3322169626057148 4.389815777540207e-05 0.054419583145529034\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5280, -0.5848], device='cuda:0') tensor([0.2250, 0.0418], device='cuda:0') tensor([0.2114, 0.0237], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2738], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0004221565391635522 7.3492616770714525 1.126043590784073 0.0 0.33422365263104437 4.476895928382873e-05 0.05070962570887059\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6211, -0.9956], device='cuda:0') tensor([ 0.5385, -0.5604], device='cuda:0') tensor([ 0.5301, -0.5840], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2341], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0004142990393738728 7.411054750584066 1.127399761915207 0.0 0.3388318095505238 4.2164675891399386e-05 0.052488341849297286\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 12:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0905,  0.4953],\n",
      "        [-0.0905,  0.4953],\n",
      "        [ 0.2375,  0.0385],\n",
      "        ...,\n",
      "        [-0.4214, -0.9983],\n",
      "        [-0.4214, -0.9983],\n",
      "        [-0.4214, -0.9983]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9963, -0.9958], device='cuda:0') tensor([ 0.1184, -1.0050], device='cuda:0') tensor([ 0.1249, -0.9996], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2826], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00036800669771037064 7.472877452149987 1.1263760344982148 0.0 0.3349460007250309 3.675509989261627e-05 0.05223900036141276\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6658, -0.9981], device='cuda:0') tensor([-0.5094, -0.5309], device='cuda:0') tensor([-0.4880, -0.5587], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2129], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00036888420942705126 7.53477878062427 1.1270942959785462 0.0 0.3305379794538021 3.2764464616775514e-05 0.05223983835894615\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4310, -0.1205], device='cuda:0') tensor([-0.0952,  0.5142], device='cuda:0') tensor([-0.0775,  0.5024], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2367], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00041654963500332087 7.596554100550711 1.1259776313304901 0.0 0.3352847362756729 3.8427695631980895e-05 0.051546138771809635\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.5723, 0.3821], device='cuda:0') tensor([1.0181, 0.7195], device='cuda:0') tensor([0.9957, 0.7102], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2569], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00039091435336740686 7.658353773593903 1.126136280298233 0.0 0.3293952719271183 3.065736591815948e-05 0.05363055474497378\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.3195, 0.6144], device='cuda:0') tensor([0.2459, 0.0666], device='cuda:0') tensor([0.2460, 0.0524], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2673], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000402495897753397 7.7202092144340275 1.1274210720062257 0.0 0.3324355362951755 3.514943271875381e-05 0.05234979686141014\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0473, -0.4737], device='cuda:0') tensor([ 0.2468, -0.0085], device='cuda:0') tensor([ 0.2405, -0.0060], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2206], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003538312937307637 7.782051803290844 1.1283734438419342 0.0 0.33493928995728495 3.357753902673721e-05 0.049901973780244586\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6462, -0.9971], device='cuda:0') tensor([-0.4847, -0.5397], device='cuda:0') tensor([-0.4737, -0.5421], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2132], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00036537665146170185 7.843998097114265 1.1269987058639526 0.0 0.33289214004576206 3.5491086542606356e-05 0.05095515900291502\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4959,  0.6197], device='cuda:0') tensor([-0.4756,  0.2357], device='cuda:0') tensor([-0.4610,  0.2346], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2484], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0004160646945529152 7.905833426311612 1.1264211852550507 0.0 0.330717911452055 3.2183699309825894e-05 0.05086622394621372\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4380,  0.2814], device='cuda:0') tensor([-0.4047, -0.0700], device='cuda:0') tensor([-0.4019, -0.0971], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2504], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003761626088235062 7.967770920559764 1.1265239005088805 0.0 0.33069932597875595 3.525929898023605e-05 0.05146240498451516\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.5910, 0.3946], device='cuda:0') tensor([ 0.5217, -0.1773], device='cuda:0') tensor([ 0.5176, -0.1570], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2740], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003836406222253572 8.029486652001738 1.127556893348694 0.0 0.3302880271971226 3.8696274161338804e-05 0.04950565140461549\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 13:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0699,  0.5605],\n",
      "        [ 0.2281,  0.0813],\n",
      "        [ 0.5136, -0.5571],\n",
      "        ...,\n",
      "        [ 0.9950,  0.7477],\n",
      "        [ 0.9928,  0.9985],\n",
      "        [ 0.9928,  0.9985]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 1.0008, -0.9965], device='cuda:0') tensor([ 1.0067, -0.9967], device='cuda:0') tensor([ 1.0008, -0.9965], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2857], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00033131908666109665 8.091422293543816 1.127376171350479 0.0 0.33711891770362856 3.0044019222259522e-05 0.05377027974277735\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9984, 0.7186], device='cuda:0') tensor([1.0081, 0.7141], device='cuda:0') tensor([0.9984, 0.7186], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2626], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003479601017315872 8.153322785630822 1.1253911323547363 0.0 0.32974093928933146 2.9315605759620666e-05 0.05222171370964497\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9962, 0.3652], device='cuda:0') tensor([0.9981, 0.7262], device='cuda:0') tensor([0.9972, 0.7198], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2355], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003430946524604224 8.21527475516498 1.1293096487522125 0.0 0.3327274502813816 3.369397670030594e-05 0.052072633994743225\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9995,  0.9988], device='cuda:0') tensor([-0.9771,  1.0087], device='cuda:0') tensor([-0.9995,  0.9988], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2006], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003049371152592357 8.277102003030478 1.1266613290309906 0.0 0.3383467598855495 2.590867131948471e-05 0.05354610320646316\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9950, 0.3914], device='cuda:0') tensor([0.9863, 0.0194], device='cuda:0') tensor([0.9940, 0.0087], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2821], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000355438835802488 8.338958891570568 1.126211540222168 0.0 0.333508048415184 3.200411051511765e-05 0.0536692940723151\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9974, 0.9988], device='cuda:0') tensor([0.9975, 0.9968], device='cuda:0') tensor([0.9974, 0.9988], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2329], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003370271537278313 8.40088802266866 1.1266544060707093 0.0 0.3310382050573826 3.4656457602977756e-05 0.0536347922924906\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4429, -0.5370], device='cuda:0') tensor([-0.6189, -1.0030], device='cuda:0') tensor([-0.6363, -0.9989], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2514], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003442639551940374 8.462696591496467 1.1272170648574829 0.0 0.328944632768631 3.540787845849991e-05 0.05181506726099178\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.2265, 0.0255], device='cuda:0') tensor([ 0.4971, -0.6193], device='cuda:0') tensor([ 0.4893, -0.6245], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2507], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00032728620103443973 8.52451439037919 1.1258552873134613 0.0 0.33008656483888626 2.841789275407791e-05 0.05178749475069344\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2576,  1.0006], device='cuda:0') tensor([0.5409, 1.0094], device='cuda:0') tensor([0.5378, 0.9983], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2397], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003316682580480119 8.58626716788113 1.1248845953941344 0.0 0.3304742646217346 2.900143712759018e-05 0.052247825366444886\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4212,  0.2601], device='cuda:0') tensor([-0.4695,  0.6134], device='cuda:0') tensor([-0.4565,  0.5861], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2118], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003063502980512567 8.647956310085952 1.1263504014015198 0.0 0.3391070909500122 2.858354151248932e-05 0.053422675556503235\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 14:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0449,  0.5685],\n",
      "        [-0.3922, -0.1595],\n",
      "        [-0.4011,  0.2279],\n",
      "        ...,\n",
      "        [ 0.3312,  0.5859],\n",
      "        [ 0.2308,  0.0243],\n",
      "        [-0.0223, -0.4430]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 1.0002, -0.4493], device='cuda:0') tensor([ 0.6159, -0.9894], device='cuda:0') tensor([ 0.6606, -0.9971], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2780], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00029463074504747054 8.709807983152569 1.127690553188324 0.0 0.33226648753881455 2.9813066124916077e-05 0.051759881312958896\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1245, -0.9981], device='cuda:0') tensor([ 0.6472, -0.9977], device='cuda:0') tensor([ 0.6460, -1.0003], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2254], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002885873842606088 8.771596442192793 1.124583878517151 0.0 0.3260118579417467 2.6397764682769774e-05 0.05156307395733893\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5252, -0.1590], device='cuda:0') tensor([0.3592, 0.5673], device='cuda:0') tensor([0.3419, 0.5946], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2706], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002894843911781209 8.833358534723521 1.1245972907543182 0.0 0.3346820447444916 2.4534545838832855e-05 0.053336390747688714\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0317,  0.5853], device='cuda:0') tensor([0.2203, 0.0209], device='cuda:0') tensor([0.2345, 0.0394], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2447], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00030120175112097056 8.89517350320518 1.1272221171855927 0.0 0.3294627927094698 2.9234714806079865e-05 0.05408982947282493\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5543,  0.9995], device='cuda:0') tensor([-0.5761,  0.9799], device='cuda:0') tensor([-0.5543,  0.9995], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2071], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00028706825146218763 8.956955593638122 1.1237718849182128 0.0 0.32781469988822937 2.9141530394554138e-05 0.05132825247384608\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1357, -0.9996], device='cuda:0') tensor([ 0.9879, -0.9799], device='cuda:0') tensor([ 0.9953, -1.0000], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2477], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00030741353903431445 9.018810337759554 1.1256393480300904 0.0 0.33345459163188934 2.753278613090515e-05 0.05135430948995054\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9951, -0.6303], device='cuda:0') tensor([-0.9785, -0.2406], device='cuda:0') tensor([-0.9958, -0.2709], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2069], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00033051762520335616 9.080694400466978 1.1265159604549408 0.0 0.33286798429489134 2.815183997154236e-05 0.054645845820661634\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1533, -0.9957], device='cuda:0') tensor([ 0.9999, -0.9702], device='cuda:0') tensor([ 0.9933, -0.9932], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2481], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002883578683540691 9.14259343507886 1.1275803577899932 0.0 0.330600979834795 2.4807222187519073e-05 0.05199417510535568\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.2421, 0.0232], device='cuda:0') tensor([ 0.4800, -0.6427], device='cuda:0') tensor([ 0.4549, -0.6262], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2510], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002976552514301147 9.204477956689894 1.126699113368988 0.0 0.3364986698627472 3.122550249099731e-05 0.05041239537112415\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4319,  0.6334], device='cuda:0') tensor([-0.4242,  0.6305], device='cuda:0') tensor([-0.4319,  0.6334], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2368], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002937544459418859 9.26651984898746 1.126545606136322 0.0 0.33186591970920565 3.1314410269260404e-05 0.053221314349211755\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 15:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0254,  0.6108],\n",
      "        [ 0.2386,  0.0811],\n",
      "        [-0.0254,  0.6108],\n",
      "        ...,\n",
      "        [ 0.9987, -0.4165],\n",
      "        [ 0.6346, -0.9985],\n",
      "        [-0.0232, -0.4125]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9998, -0.2664], device='cuda:0') tensor([-0.9923, -0.2265], device='cuda:0') tensor([-0.9998, -0.2664], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2428], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002673024709802121 9.328303560301661 1.125468868970871 0.0 0.32512663048505785 2.7903996407985686e-05 0.05298878743778914\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9955, -0.9984], device='cuda:0') tensor([ 0.9967, -0.9935], device='cuda:0') tensor([ 0.9955, -0.9984], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2856], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002894949748297222 9.390119315341115 1.1272514576911927 0.0 0.33722870498895646 2.7565337717533112e-05 0.05322573591582477\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.2399, 0.9976], device='cuda:0') tensor([0.3583, 0.5603], device='cuda:0') tensor([0.3504, 0.6142], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2640], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002543657791102305 9.452125665344298 1.125436972618103 0.0 0.3383919483423233 2.8989605605602263e-05 0.05413068258576095\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9974, -0.4055], device='cuda:0') tensor([ 1.0073, -0.4007], device='cuda:0') tensor([ 0.9974, -0.4055], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2673], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002491826410405338 9.513912874341012 1.1263547110557557 0.0 0.33392605364322664 2.527310699224472e-05 0.050361874921247364\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9996, 0.9984], device='cuda:0') tensor([0.9981, 1.0031], device='cuda:0') tensor([0.9996, 0.9984], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2607], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002711025855387561 9.575801177285612 1.1277206485271454 0.0 0.32785949581861495 2.244146168231964e-05 0.05053619120549411\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9990, 0.0096], device='cuda:0') tensor([0.9885, 0.0038], device='cuda:0') tensor([0.9990, 0.0096], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2662], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002798028704855824 9.637603804655374 1.12632866024971 0.0 0.32894422082602975 2.7227900922298432e-05 0.052027385231107476\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9946, 0.4008], device='cuda:0') tensor([0.9970, 0.7415], device='cuda:0') tensor([0.9962, 0.7181], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2353], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00026287904307537247 9.699463273711503 1.124218321800232 0.0 0.3248348348289728 2.45232954621315e-05 0.05279063471686095\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9980, -0.9992], device='cuda:0') tensor([-0.9974, -0.9950], device='cuda:0') tensor([-0.9980, -0.9992], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2440], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002867922382283723 9.76140879546851 1.1262042105197907 0.0 0.3301931611895561 2.5814905762672426e-05 0.05280961951706559\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9982,  0.9978], device='cuda:0') tensor([-1.0006,  1.0083], device='cuda:0') tensor([-0.9982,  0.9978], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2400], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00025192105359747076 9.823306647129357 1.1270320386886596 0.0 0.3280498978495598 2.70208865404129e-05 0.05144483335968107\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5791,  0.9993], device='cuda:0') tensor([-0.4783,  0.5935], device='cuda:0') tensor([-0.4571,  0.5922], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2457], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002717704133829102 9.885133556306362 1.1257867171764373 0.0 0.3309364023506641 2.4881072342395784e-05 0.05154000880103558\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 16:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0379,  0.6009],\n",
      "        [-0.0379,  0.6009],\n",
      "        [-0.0379,  0.6009],\n",
      "        ...,\n",
      "        [ 0.6164,  0.3245],\n",
      "        [ 0.2319,  0.9997],\n",
      "        [ 0.6164,  0.3245]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2377,  0.9992], device='cuda:0') tensor([0.5807, 0.9952], device='cuda:0') tensor([0.5928, 0.9988], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2400], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00024849635538703297 9.946913719333708 1.1252140936851502 0.0 0.3343599790930748 2.5017671287059784e-05 0.05016198453772813\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3838, -0.1510], device='cuda:0') tensor([-0.0670,  0.6095], device='cuda:0') tensor([-0.0325,  0.5868], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2377], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000263335583236767 10.00881495642662 1.1257778792381286 0.0 0.3247970407307148 2.029866725206375e-05 0.051869359215721486\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9950,  0.5709], device='cuda:0') tensor([-1.0181,  0.9847], device='cuda:0') tensor([-0.9943,  0.9986], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2022], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002493006222503027 10.07077346663922 1.1282074191570282 0.0 0.3362166371941566 1.7542526125907898e-05 0.05049405427649617\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4251, -0.6110], device='cuda:0') tensor([0.2497, 0.0520], device='cuda:0') tensor([0.2432, 0.0583], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2725], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002546927854564274 10.132828727968038 1.1273261697292327 0.0 0.3327424079477787 2.009006589651108e-05 0.05406482501886785\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9973, -0.2248], device='cuda:0') tensor([-0.9798, -0.6084], device='cuda:0') tensor([-0.9970, -0.6024], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2385], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00024991818123089614 10.194852299787104 1.1249291591644288 0.0 0.3236753309071064 2.521178126335144e-05 0.0529661111542955\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2373,  0.9988], device='cuda:0') tensor([-0.2513,  1.0138], device='cuda:0') tensor([-0.2373,  0.9988], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2122], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00024793290563684424 10.256817989073694 1.1260087802410126 0.0 0.3383499876558781 2.174755185842514e-05 0.054221495087258514\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0275,  0.6207], device='cuda:0') tensor([-0.0314,  0.6192], device='cuda:0') tensor([-0.0275,  0.6207], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2169], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00023709232335386332 10.318725728951394 1.1259452781677246 0.0 0.33676725628972054 2.3036204278469087e-05 0.05148405125830322\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4626, -0.5412], device='cuda:0') tensor([-0.6509, -1.0089], device='cuda:0') tensor([-0.6679, -0.9990], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2509], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002383526814664947 10.3806023889035 1.1248444559574127 0.0 0.32821204417943955 2.4684704840183258e-05 0.05482023218087852\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0190,  0.6237], device='cuda:0') tensor([-0.0244,  0.6157], device='cuda:0') tensor([-0.0190,  0.6237], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2596], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00023485709917440544 10.442505495145918 1.127449387550354 0.0 0.33329562211036684 1.8696390092372896e-05 0.05192517574457452\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3827,  0.2255], device='cuda:0') tensor([-0.4464,  0.5743], device='cuda:0') tensor([-0.4522,  0.5981], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2125], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00023091464172466658 10.504458842977881 1.126809238910675 0.0 0.3306432890892029 2.5094211101531984e-05 0.05129882379993796\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 17:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0182,  0.6490],\n",
      "        [-0.0182,  0.6490],\n",
      "        [-0.3707, -0.1306],\n",
      "        ...,\n",
      "        [ 0.6249,  0.3350],\n",
      "        [ 0.5052, -0.1763],\n",
      "        [ 0.4163, -0.6200]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([9.9885e-01, 9.0645e-05], device='cuda:0') tensor([0.9919, 0.3822], device='cuda:0') tensor([0.9986, 0.3860], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2370], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00022771277610445396 10.566384330578149 1.1269272525310516 0.0 0.32958226472139357 1.7666429281234742e-05 0.054265123667195436\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.3715, 0.5873], device='cuda:0') tensor([0.2396, 0.0293], device='cuda:0') tensor([0.2236, 0.0430], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2685], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002374917047418421 10.628225248895586 1.1262440087795258 0.0 0.33270115053653715 2.0839720964431762e-05 0.052868590177502485\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5866,  0.9976], device='cuda:0') tensor([-0.6044,  0.9792], device='cuda:0') tensor([-0.5866,  0.9976], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2067], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00023450800406862982 10.69011986681074 1.1253325159549714 0.0 0.3265250653028488 2.2157542407512664e-05 0.055002497202716764\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4024, -0.6267], device='cuda:0') tensor([ 0.5508, -0.2132], device='cuda:0') tensor([ 0.5003, -0.2063], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2289], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00020872418506769462 10.75184318265319 1.126209819316864 0.0 0.3319202406108379 1.9070759415626526e-05 0.05340689207892865\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2476,  0.9972], device='cuda:0') tensor([0.2580, 0.9947], device='cuda:0') tensor([0.2522, 0.9978], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2533], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002149646252655657 10.813747281581163 1.1259767453670502 0.0 0.3296169488430023 2.0693525671958924e-05 0.053883963230066\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0002, -0.9995], device='cuda:0') tensor([-0.6724, -0.9969], device='cuda:0') tensor([-0.6578, -0.9988], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2244], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002228294331143843 10.8756043580845 1.1245230393409729 0.0 0.3337398270368576 1.889551430940628e-05 0.050656944708898664\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1091, -0.9980], device='cuda:0') tensor([ 1.0018, -0.9857], device='cuda:0') tensor([ 0.9995, -0.9989], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2471], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00021204791952914094 10.937339777238668 1.1255923075675964 0.0 0.3320208528935909 1.9663602113723756e-05 0.05164001696463674\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9994, -0.9964], device='cuda:0') tensor([-0.6608, -0.9915], device='cuda:0') tensor([-0.6508, -0.9975], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2244], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002197025397181278 10.999172012872993 1.125659560918808 0.0 0.328942952722311 2.1340228617191315e-05 0.05329420402832329\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3687, -0.1418], device='cuda:0') tensor([0.0430, 0.6547], device='cuda:0') tensor([-0.0088,  0.6441], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2380], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00022939497865445447 11.061113726697862 1.127286126613617 0.0 0.3346316614449024 1.8840402364730834e-05 0.04970168161205948\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5780,  0.9984], device='cuda:0') tensor([-0.9880,  0.9978], device='cuda:0') tensor([-0.9994,  0.9978], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2474], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00021589428595325443 11.12303326817602 1.126315129995346 0.0 0.3290190344452858 1.9268766045570374e-05 0.05244628329016268\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 18:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0259,  0.6479],\n",
      "        [ 0.2386,  0.0370],\n",
      "        [ 0.3845,  0.5699],\n",
      "        ...,\n",
      "        [ 0.9956,  0.3715],\n",
      "        [ 0.5032, -0.2084],\n",
      "        [ 0.9956,  0.3715]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:226: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1], c=colors[i], marker='x', edgecolors='k', alpha=0.5, s=100)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:269: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9981, -0.9993], device='cuda:0') tensor([ 0.9965, -0.4735], device='cuda:0') tensor([ 0.9977, -0.4615], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2408], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00020472394020180218 11.184885167099536 1.1258387310504914 0.0 0.32596287813782693 1.9441775977611542e-05 0.052152340402826666\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3804,  0.2128], device='cuda:0') tensor([-0.3848,  0.2136], device='cuda:0') tensor([-0.3804,  0.2128], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2379], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00020308264350751414 11.246705508686603 1.1268963692188263 0.0 0.3293692448437214 1.86162143945694e-05 0.05283158494904637\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4545, -0.5373], device='cuda:0') tensor([-0.4687, -0.5173], device='cuda:0') tensor([-0.4545, -0.5373], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2357], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00020092737275990657 11.308608791708947 1.1258776335716247 0.0 0.32901283249258995 1.8504895269870758e-05 0.05238140990026295\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4718, -0.5493], device='cuda:0') tensor([-1.0079, -0.6078], device='cuda:0') tensor([-0.9993, -0.6187], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2554], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00020660574750218074 11.370400318011642 1.1258645782470702 0.0 0.328604054659605 1.960216462612152e-05 0.05191053597815335\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9949, -0.0067], device='cuda:0') tensor([ 0.4214, -0.6282], device='cuda:0') tensor([ 0.3956, -0.6297], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2740], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00021403842291329057 11.432308363094926 1.1252243101596833 0.0 0.3279166815578938 1.9990310072898865e-05 0.05177565169520676\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1083, -0.9993], device='cuda:0') tensor([-0.4217, -1.0043], device='cuda:0') tensor([-0.4077, -0.9994], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2692], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00022938026713381987 11.494244112595915 1.1242625596523286 0.0 0.33383025228977203 1.7566271126270294e-05 0.05215041766595095\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9994,  0.1572], device='cuda:0') tensor([-1.0057, -0.2449], device='cuda:0') tensor([-0.9987, -0.2385], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2378], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000200641296163667 11.556209990918637 1.1267797694206239 0.0 0.32647274366021156 1.736310124397278e-05 0.05293722682446241\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.2530, 0.9980], device='cuda:0') tensor([0.6086, 0.2888], device='cuda:0') tensor([0.6180, 0.2900], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2488], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00021241669935989193 11.61809315290302 1.125929624557495 0.0 0.3305438648760319 1.831638067960739e-05 0.051331582051701845\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9979, -0.4647], device='cuda:0') tensor([ 1.0020, -0.9999], device='cuda:0') tensor([ 0.9986, -0.9996], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2852], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"params\")\n",
    "except Exception:\n",
    "    pass\n",
    "dump(vars(parameters), \"params/\" + fname + \".jldump\")\n",
    "agent.gathering_data=False\n",
    "agent.run(parameters.epochs, parameters.steps_per_epoch)\n",
    "\n",
    "# --- Show results ---\n",
    "basename = \"scores/\" + fname\n",
    "scores = load(basename + \"_scores.jldump\")\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
