{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "from joblib import hash, dump, load\n",
    "import os\n",
    "\n",
    "from deer.default_parser import process_args\n",
    "from deer.agent import NeuralAgent\n",
    "from deer.learning_algos.CRAR_torch import CRAR\n",
    "from simple_maze_env_3d import MyEnv as simple_maze_env\n",
    "import deer.experiment.base_controllers as bc\n",
    "\n",
    "from deer.policies import EpsilonGreedyPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Defaults:\n",
    "    # ----------------------\n",
    "    # Experiment Parameters\n",
    "    # ----------------------\n",
    "    steps_per_epoch = 5000\n",
    "    epochs = 50\n",
    "    steps_per_test = 1000\n",
    "    period_btw_summary_perfs = 1\n",
    "    \n",
    "    # ----------------------\n",
    "    # Environment Parameters\n",
    "    # ----------------------\n",
    "    frame_skip = 2\n",
    "\n",
    "    # ----------------------\n",
    "    # DQN Agent parameters:\n",
    "    # ----------------------\n",
    "    update_rule = 'rmsprop'\n",
    "    learning_rate = 5 * 1E-4 # 1E-4\n",
    "    learning_rate_decay = 0.9\n",
    "    discount = 0.9\n",
    "    discount_inc = 1\n",
    "    discount_max = 0.99\n",
    "    rms_decay = 0.9\n",
    "    rms_epsilon = 0.0001\n",
    "    momentum = 0\n",
    "    clip_norm = 1.0\n",
    "    epsilon_start = 1.0\n",
    "    epsilon_min = 1.0\n",
    "    epsilon_decay = 10000\n",
    "    update_frequency = 1\n",
    "    replay_memory_size = 1000000 #replacing with 200000 will works just fine (in case you dont have 18gb of memory)\n",
    "    batch_size = 32\n",
    "    freeze_interval = 1000\n",
    "    deterministic = False\n",
    "\n",
    "higher_dim_obs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters hash is: 62977be8e45d8a56a5537c11dfd5d2fd8dda69e0\n",
      "The parameters are: <__main__.Defaults object at 0x2b5f7b8d4760>\n",
      "end gathering data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters = Defaults()\n",
    "if parameters.deterministic:\n",
    "    rng = np.random.RandomState(123456)\n",
    "else:\n",
    "    rng = np.random.RandomState()\n",
    "\n",
    "# --- Instantiate environment ---\n",
    "env = simple_maze_env(rng, higher_dim_obs=higher_dim_obs)\n",
    "\n",
    "# --- Instantiate learning_algo ---\n",
    "learning_algo = CRAR(\n",
    "    env,\n",
    "    parameters.rms_decay,\n",
    "    parameters.rms_epsilon,\n",
    "    parameters.momentum,\n",
    "    parameters.clip_norm,\n",
    "    parameters.freeze_interval,\n",
    "    parameters.batch_size,\n",
    "    parameters.update_rule,\n",
    "    rng,\n",
    "    high_int_dim=False,\n",
    "    internal_dim=3, lr=parameters.learning_rate)\n",
    "\n",
    "test_policy = EpsilonGreedyPolicy(learning_algo, env.nActions(), rng, 1.)\n",
    "\n",
    "# --- Instantiate agent ---\n",
    "agent = NeuralAgent(\n",
    "    env,\n",
    "    learning_algo,\n",
    "    parameters.replay_memory_size,\n",
    "    max(env.inputDimensions()[i][0] for i in range(len(env.inputDimensions()))),\n",
    "    parameters.batch_size,\n",
    "    rng,\n",
    "    test_policy=test_policy)\n",
    "\n",
    "# --- Create unique filename for FindBestController ---\n",
    "h = hash(vars(parameters), hash_name=\"sha1\")\n",
    "fname = \"test_\" + h\n",
    "print(\"The parameters hash is: {}\".format(h))\n",
    "print(\"The parameters are: {}\".format(parameters))\n",
    "\n",
    "# As for the discount factor and the learning rate, one can update periodically the parameter of the epsilon-greedy\n",
    "# policy implemented by the agent. This controllers has a bit more capabilities, as it allows one to choose more\n",
    "# precisely when to update epsilon: after every X action, episode or epoch. This parameter can also be reset every\n",
    "# episode or epoch (or never, hence the resetEvery='none').\n",
    "agent.attach(bc.EpsilonController(\n",
    "    initial_e=parameters.epsilon_start,\n",
    "    e_decays=parameters.epsilon_decay,\n",
    "    e_min=parameters.epsilon_min,\n",
    "    evaluate_on='action',\n",
    "    periodicity=1,\n",
    "    reset_every='none'))\n",
    "\n",
    "agent.run(10, 500)\n",
    "print(\"end gathering data\")\n",
    "\n",
    "# --- Bind controllers to the agent ---\n",
    "# Before every training epoch (periodicity=1), we want to print a summary of the agent's epsilon, discount and \n",
    "# learning rate as well as the training epoch number.\n",
    "agent.attach(bc.VerboseController(\n",
    "    evaluate_on='epoch', \n",
    "    periodicity=1))\n",
    "\n",
    "# Every epoch end, one has the possibility to modify the learning rate using a LearningRateController. Here we \n",
    "# wish to update the learning rate after every training epoch (periodicity=1), according to the parameters given.\n",
    "agent.attach(bc.LearningRateController(\n",
    "    initial_learning_rate=parameters.learning_rate, \n",
    "    learning_rate_decay=parameters.learning_rate_decay,\n",
    "    periodicity=1))\n",
    "\n",
    "# Same for the discount factor.\n",
    "agent.attach(bc.DiscountFactorController(\n",
    "    initial_discount_factor=parameters.discount, \n",
    "    discount_factor_growth=parameters.discount_inc, \n",
    "    discount_factor_max=parameters.discount_max,\n",
    "    periodicity=1))\n",
    "\n",
    "# During training epochs, we want to train the agent after every [parameters.update_frequency] action it takes.\n",
    "# Plus, we also want to display after each training episode (!= than after every training) the average bellman\n",
    "# residual and the average of the V values obtained during the last episode, hence the two last arguments.\n",
    "agent.attach(bc.TrainerController(\n",
    "    evaluate_on='action', \n",
    "    periodicity=parameters.update_frequency, \n",
    "    show_episode_avg_V_value=True, \n",
    "    show_avg_Bellman_residual=True))\n",
    "\n",
    "# We wish to discover, among all versions of our neural network (i.e., after every training epoch), which one \n",
    "# has the highest validation score.\n",
    "# To achieve this goal, one can use the FindBestController along with an InterleavedTestEpochControllers. It is \n",
    "# important that the validationID is the same than the id argument of the InterleavedTestEpochController.\n",
    "# The FindBestController will dump on disk the validation scores for each and every network, as well as the \n",
    "# structure of the neural network having the best validation score. These dumps can then used to plot the evolution \n",
    "# of the validation and test scores (see below) or simply recover the resulting neural network for your \n",
    "# application.\n",
    "agent.attach(bc.FindBestController(\n",
    "    validationID=simple_maze_env.VALIDATION_MODE,\n",
    "    testID=None,\n",
    "    unique_fname=fname))\n",
    "\n",
    "# All previous controllers control the agent during the epochs it goes through. However, we want to interleave a \n",
    "# \"validation epoch\" between each training epoch. For each validation epoch, we want also to display the sum of all \n",
    "# rewards obtained, hence the showScore=True. Finally, we want to call the summarizePerformance method of ALE_env \n",
    "# every [parameters.period_btw_summary_perfs] *validation* epochs.\n",
    "agent.attach(bc.InterleavedTestEpochController(\n",
    "    id=simple_maze_env.VALIDATION_MODE, \n",
    "    epoch_length=parameters.steps_per_test,\n",
    "    periodicity=1,\n",
    "    show_score=True,\n",
    "    summarize_every=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3041, -0.2686,  0.0520], device='cuda:0') tensor([ 0.0486, -0.1000,  0.1473], device='cuda:0') tensor([ 0.3041, -0.2686,  0.0520], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0246], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.045375505048781635 0.00172343521239236 0.5153328900933266 0.0 0.39091637200117113 0.0005784320831298828 0.08760981340147554\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.7271, 0.1446, 0.9784], device='cuda:0') tensor([0.7067, 0.1152, 0.9301], device='cuda:0') tensor([ 0.9602, -0.1826,  0.8331], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0765], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0361452742703259 0.003649783253436908 0.5135328812003136 0.0 0.3604047100841999 0.0002394234910607338 0.05785818881075829\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.7575, -0.0543,  0.8857], device='cuda:0') tensor([0.4893, 0.0501, 0.6547], device='cuda:0') tensor([0.4388, 0.0142, 0.5577], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0829], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.01912647114135325 0.0055750516005791725 0.5100026924014092 0.0 0.34597234064340593 0.0004185580089688301 0.05439023857098073\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9719,  0.9177, -0.8755], device='cuda:0') tensor([-1.0811,  0.9615, -1.0893], device='cuda:0') tensor([-0.9719,  0.9177, -0.8755], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0102], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.014235317397862672 0.007423565477132797 0.5105641755461693 0.0 0.3394742150604725 0.0003473181426525116 0.05121932676713914\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9815, -0.9828,  0.2504], device='cuda:0') tensor([ 0.9234, -0.8538,  0.3173], device='cuda:0') tensor([ 0.9815, -0.9828,  0.2504], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0486], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.012541398039087654 0.009328865996329113 0.5106210528016091 0.0 0.3349946523308754 0.0002578039690852165 0.04934725484484807\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1407, -0.0820,  0.2186], device='cuda:0') tensor([-0.1073, -0.0820,  0.1898], device='cuda:0') tensor([-0.1407, -0.0820,  0.2186], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0501], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.011867055635899305 0.011248208676581271 0.5100922504067421 0.0 0.3320133416056633 0.00017356644570827484 0.04306033718306571\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3704, -0.2117, -0.1054], device='cuda:0') tensor([-0.0551, -0.4768, -0.1440], device='cuda:0') tensor([ 0.0923, -0.6042, -0.0383], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0292], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.01203476204816252 0.013207152049988508 0.5103571150302887 0.0 0.3248191978484392 0.00014826732873916625 0.044412256359122694\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0149, -0.6559,  0.0100], device='cuda:0') tensor([-0.3475, -0.2806, -0.1519], device='cuda:0') tensor([-0.3582, -0.3035, -0.0641], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0167], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.011813273704610765 0.015178094041068107 0.5097914350628853 0.0 0.3235062282830477 0.0001420704424381256 0.042403238458093254\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3361, -0.1633, -0.6010], device='cuda:0') tensor([-0.7388,  0.3150, -0.6023], device='cuda:0') tensor([-0.6871,  0.2092, -0.5586], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0043], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.01164249253552407 0.017176954388385637 0.5097386087179184 0.0 0.319124253898859 0.00011303289979696274 0.041369520034641026\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9406, -0.9589, -0.9883], device='cuda:0') tensor([ 0.4999, -0.7046, -0.8663], device='cuda:0') tensor([ 0.4700, -0.6942, -0.9777], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0142], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.01117736374028027 0.01924298360850662 0.5076758115291595 0.0 0.3211250612586737 0.00011480803042650222 0.04336084344610572\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 1:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0393,  0.0939,  0.2952],\n",
      "        [-0.3406, -0.2574,  0.0419],\n",
      "        [ 0.0680, -0.7057,  0.1959],\n",
      "        ...,\n",
      "        [-0.9717,  0.9713,  0.6783],\n",
      "        [-0.9717,  0.9713,  0.6783],\n",
      "        [-0.9717,  0.9713,  0.6783]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0731, -0.5977, -0.3837], device='cuda:0') tensor([ 0.0708, -0.4784, -0.8269], device='cuda:0') tensor([ 0.1258, -0.3885, -0.9260], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0099], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.01073353178333491 0.02133051643613726 0.5076456690430641 0.0 0.3187966531515121 8.650402724742889e-05 0.04269625455187634\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0676,  0.6945,  0.4900], device='cuda:0') tensor([-0.4580,  0.8535,  0.5168], device='cuda:0') tensor([-0.4935,  0.9435,  0.4327], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0827], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.010231924014165998 0.023415164474514312 0.5077607354521751 0.0 0.3245906144976616 0.00010023080557584763 0.04179432219453156\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0838, -0.3785, -0.9787], device='cuda:0') tensor([ 0.1306, -0.3461, -1.0657], device='cuda:0') tensor([ 0.0838, -0.3785, -0.9787], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0124], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.009757328810170293 0.025529422005056403 0.5065354502797127 0.0 0.31456190130114553 0.00011111538112163544 0.04412704720674083\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.3724, 0.1055, 0.9623], device='cuda:0') tensor([ 0.7439, -0.3564,  0.9487], device='cuda:0') tensor([ 0.7628, -0.3685,  0.9699], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0711], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00939031400065869 0.02766110105323605 0.5065711309313774 0.0 0.3138460589945316 8.704572916030884e-05 0.04310079095931724\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0059,  0.7816, -0.3644], device='cuda:0') tensor([-0.9749,  0.9042, -0.2683], device='cuda:0') tensor([-1.0059,  0.7816, -0.3644], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0177], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.008869966083206237 0.02984156374866143 0.5057044717669487 0.0 0.3055549488067627 0.00010539660602807999 0.04132281850394793\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0059, -0.6526,  0.3324], device='cuda:0') tensor([-0.4216, -0.3265,  0.2276], device='cuda:0') tensor([-0.3522, -0.2460,  0.2807], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0295], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00832800379442051 0.0320086457466241 0.5060414801836014 0.0 0.31226223741471765 9.607996791601181e-05 0.041222302456153555\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4798, -0.7572, -0.9865], device='cuda:0') tensor([ 0.4340, -0.8364, -0.2937], device='cuda:0') tensor([ 0.4928, -0.8858, -0.2679], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0628], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.007461762271821499 0.034185048489365724 0.5059109906554222 0.0 0.3128356257081032 8.065641671419144e-05 0.04298260855022818\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0781, -0.0974,  0.6933], device='cuda:0') tensor([-0.1324, -0.0086,  0.1013], device='cuda:0') tensor([-0.3466, -0.2117,  0.2845], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0628], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.006850955712608993 0.03641764470702037 0.5059689242243767 0.0 0.30600602459907533 0.00010091158002614975 0.043253984708106145\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3462, -0.2105,  0.2333], device='cuda:0') tensor([-0.3341, -0.1682, -0.4719], device='cuda:0') tensor([-0.3658, -0.1868, -0.3459], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0361], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.006185760316438973 0.038698357570916414 0.5048973731994629 0.0 0.31025665345788 8.58965590596199e-05 0.03734695317491423\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1074,  0.7255,  0.3330], device='cuda:0') tensor([-0.0708,  0.5967,  1.0233], device='cuda:0') tensor([-0.0556,  0.5833,  0.9878], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0058], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0058447258318774405 0.04097834410681389 0.5047600054740906 0.0 0.30402306506037713 8.092442154884339e-05 0.0401541029154323\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 2:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.1348, -0.0287,  0.8164],\n",
      "        [-0.3219, -0.2377,  0.3388],\n",
      "        [-0.7566,  0.1372,  0.4529],\n",
      "        ...,\n",
      "        [ 0.9754, -0.7018,  0.9742],\n",
      "        [ 0.9754, -0.7018,  0.9742],\n",
      "        [ 0.9754, -0.7018,  0.9742]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1760,  0.7437,  0.3088], device='cuda:0') tensor([-0.6002,  0.9112,  0.3239], device='cuda:0') tensor([-0.5563,  0.9711,  0.2321], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0747], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.005625246350187808 0.0432806845495943 0.5042021257281304 0.0 0.3080396408587694 6.742816418409348e-05 0.04070470316521824\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7719,  0.4087, -0.9900], device='cuda:0') tensor([-0.7978,  0.3004, -0.3477], device='cuda:0') tensor([-0.7763,  0.2424, -0.3181], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0486], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00552141148224473 0.04557678298465907 0.5043817023038865 0.0 0.30815944147109986 6.850001960992813e-05 0.037878833308583125\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9837,  0.9752,  0.8672], device='cuda:0') tensor([-0.9349,  1.0700,  0.7972], device='cuda:0') tensor([-0.9837,  0.9752,  0.8672], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0310], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.005455123075284064 0.04793732659122907 0.5039308549761772 0.0 0.30587127795815466 5.4654233157634735e-05 0.03977156195300631\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0986,  0.7293,  0.2734], device='cuda:0') tensor([-0.0890,  0.6770,  0.9512], device='cuda:0') tensor([-0.1035,  0.7343,  0.9444], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0036], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0054923302251845595 0.050327405015937986 0.5039306296110153 0.0 0.30415700206160545 6.255994737148285e-05 0.03862493888521567\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8215,  0.2275, -0.2794], device='cuda:0') tensor([-1.0210,  0.7739, -0.2904], device='cuda:0') tensor([-0.9801,  0.7836, -0.3112], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0112], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.005305556864012032 0.05271559057501145 0.50412739610672 0.0 0.3053463410437107 5.86145743727684e-05 0.038606909445719796\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4940, -0.3616, -0.2325], device='cuda:0') tensor([-0.8437,  0.2407, -0.2874], device='cuda:0') tensor([-0.8578,  0.2399, -0.2257], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0069], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.005148203108459711 0.055144529942190275 0.5034663410782814 0.0 0.3041273193210363 5.5938296020030976e-05 0.041312815580517054\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0750, -0.0955,  0.8677], device='cuda:0') tensor([-0.1377, -0.0276,  0.8571], device='cuda:0') tensor([-0.0750, -0.0955,  0.8677], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0588], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00497925391048193 0.05757088926015422 0.5028202062249184 0.0 0.29940233534574506 6.154849380254745e-05 0.0402389726821566\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9623, -0.9962,  0.7144], device='cuda:0') tensor([ 0.4682, -0.8654,  0.6894], device='cuda:0') tensor([ 0.4351, -0.9783,  0.7179], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0480], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.004677199512487277 0.060037538674427196 0.5029645119309425 0.0 0.29778654120862486 5.618338286876678e-05 0.03822636758536101\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.2874, 0.3253, 0.2004], device='cuda:0') tensor([0.0460, 0.1516, 0.6194], device='cuda:0') tensor([-0.1347,  0.0164,  0.8701], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0527], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0044586550970561805 0.06254122585919686 0.5016840350031853 0.0 0.2984252252280712 4.21956330537796e-05 0.04081947964103892\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6264, -0.4600, -0.1219], device='cuda:0') tensor([-0.5855, -0.4846,  0.6048], device='cuda:0') tensor([-0.5999, -0.4080,  0.6768], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0408], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0044362900748383255 0.06502019928814844 0.5029663655757904 0.0 0.3026344647705555 4.480784386396408e-05 0.04040424994472414\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 3:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.1300, -0.1477,  0.8656],\n",
      "        [ 0.4043,  0.2340,  0.1947],\n",
      "        [ 0.5133,  0.3675,  0.9828],\n",
      "        ...,\n",
      "        [-0.6286, -0.4486,  0.7520],\n",
      "        [-0.1300, -0.1477,  0.8656],\n",
      "        [ 0.4043,  0.2340,  0.1947]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1300, -0.1477,  0.8656], device='cuda:0') tensor([ 0.0206, -0.1651,  0.8694], device='cuda:0') tensor([-0.1300, -0.1477,  0.8656], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0791], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.004123851084616035 0.06752809581113979 0.501888462126255 0.0 0.29914637421071527 3.97854819893837e-05 0.03636895095300861\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8211, -0.0781,  0.9771], device='cuda:0') tensor([ 0.8163, -0.0716,  0.9751], device='cuda:0') tensor([ 0.8211, -0.0781,  0.9771], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0266], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0038960259987507015 0.07009083054587245 0.5013549631237983 0.0 0.30179560151696205 3.0957721173763274e-05 0.03928712525882293\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4818,  0.9677,  0.9922], device='cuda:0') tensor([-0.5294,  0.9797,  1.0112], device='cuda:0') tensor([-0.4818,  0.9677,  0.9922], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0377], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.003730146668618545 0.07267816816526465 0.5010975877046585 0.0 0.29962961581349373 2.800215780735016e-05 0.0409857592030894\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3453,  0.9930,  0.1133], device='cuda:0') tensor([-0.2790,  1.0117,  0.1520], device='cuda:0') tensor([-0.3453,  0.9930,  0.1133], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0571], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0036126440328080205 0.07523788181366399 0.501186479628086 0.0 0.2967604997009039 2.6914216578006743e-05 0.03547628121264279\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9415, -0.9918,  0.6307], device='cuda:0') tensor([ 0.9774, -0.9470,  0.7314], device='cuda:0') tensor([ 0.9415, -0.9918,  0.6307], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0023], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0035082147500943395 0.07781860111118294 0.5013608731031418 0.0 0.2988149530738592 2.1809078752994537e-05 0.037950369176687676\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2331, -0.9185,  0.9823], device='cuda:0') tensor([ 0.4567, -1.0023,  0.8986], device='cuda:0') tensor([ 0.4477, -0.9964,  0.8520], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0670], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0032576426176819952 0.08044804739486426 0.5016555528640747 0.0 0.2922723785191774 2.7629055082798006e-05 0.0376851448325906\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8823, -0.0129,  0.9696], device='cuda:0') tensor([ 0.8846, -0.0374,  0.9584], device='cuda:0') tensor([ 0.8823, -0.0129,  0.9696], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0286], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0030068225250579417 0.08305447478406132 0.502432776927948 0.0 0.29438770553469656 2.037515491247177e-05 0.03591253499686718\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9467,  0.0487, -0.0738], device='cuda:0') tensor([-0.8211, -0.6916,  0.0708], device='cuda:0') tensor([-0.8892, -0.6511,  0.1090], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0302], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00281938140001148 0.08561747457948514 0.502462378680706 0.0 0.294472736671567 2.0527422428131102e-05 0.037034147360129284\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8222,  0.9957,  0.2121], device='cuda:0') tensor([-0.9265,  0.9050,  0.9658], device='cuda:0') tensor([-0.9806,  0.9934,  0.9563], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0079], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0026258868970908227 0.08821190270828083 0.5022782896757125 0.0 0.29414427775144575 1.8950365483760833e-05 0.03775960869214032\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3505, -0.9776,  0.8236], device='cuda:0') tensor([ 0.3213, -0.9614, -0.0214], device='cuda:0') tensor([ 0.3395, -0.9678, -0.0542], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0614], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0024708602300379423 0.09077692884206771 0.5034941627979278 0.0 0.2943557090163231 2.6315130293369292e-05 0.03774215359531809\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 4:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.2157, -0.0779,  0.7485],\n",
      "        [-0.2157, -0.0779,  0.7485],\n",
      "        [-0.2157, -0.0779,  0.7485],\n",
      "        ...,\n",
      "        [ 0.7274,  0.6232,  0.9272],\n",
      "        [ 0.2714,  0.9633,  0.9426],\n",
      "        [-0.3999,  0.9689,  0.9758]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9930,  0.9666, -0.9833], device='cuda:0') tensor([-0.9408,  0.7842, -0.2498], device='cuda:0') tensor([-0.9939,  0.7508, -0.2781], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0310], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0022864353298209608 0.09335739556630142 0.5025636056661605 0.0 0.2865214288532734 1.778838038444519e-05 0.03714350513846148\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8412, -0.7166,  0.9778], device='cuda:0') tensor([-1.0010, -0.0561,  0.7924], device='cuda:0') tensor([-0.9795, -0.0378,  0.8185], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0498], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.002139749812427908 0.0959239879436791 0.5031646753549576 0.0 0.2878988574817777 1.7669782042503357e-05 0.03641186718503013\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9772, -0.7860,  0.0913], device='cuda:0') tensor([-0.7774, -0.7046,  0.9821], device='cuda:0') tensor([-0.8520, -0.7453,  0.9823], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0389], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0020114087469410152 0.09851933791697956 0.5031157884001732 0.0 0.28896896101534364 1.905117928981781e-05 0.0372159525048919\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9773,  0.0375, -0.1296], device='cuda:0') tensor([-1.0083,  0.1969, -1.0300], device='cuda:0') tensor([-0.9893,  0.1753, -0.9823], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0176], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0018823539516888558 0.10108552030776627 0.503729223370552 0.0 0.28822154194116595 1.8237583339214323e-05 0.0359895767722046\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9864, -0.9917, -0.9857], device='cuda:0') tensor([ 0.9928, -0.9950, -1.0049], device='cuda:0') tensor([ 0.9864, -0.9917, -0.9857], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0009], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0017589892116375268 0.10359390677302144 0.5050904655456543 0.0 0.29170353269577026 1.7337433993816376e-05 0.03787429520429578\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 1.0009,  0.0287, -0.1081], device='cuda:0') tensor([ 0.7135,  0.6293, -0.1137], device='cuda:0') tensor([ 0.6185,  0.5275, -0.1101], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0519], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0017122228344669565 0.10612814173381775 0.503860769033432 0.0 0.2907630743086338 1.9039064645767213e-05 0.03707859223487321\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4367,  0.9637,  0.9871], device='cuda:0') tensor([-0.4003,  1.0073,  1.0254], device='cuda:0') tensor([-0.4367,  0.9637,  0.9871], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0376], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0015128121976740658 0.10866991762514226 0.5038258862495423 0.0 0.292413128554821 2.168206125497818e-05 0.03677014672668884\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9730, -0.9858, -0.2948], device='cuda:0') tensor([ 0.9510, -1.0183,  0.5289], device='cuda:0') tensor([ 0.9715, -0.9906,  0.5436], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0333], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0014689656511181965 0.11121832967177034 0.5042319641709327 0.0 0.28133780654519797 1.8996886909008027e-05 0.03883346875634743\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9887, -0.5018,  0.0309], device='cuda:0') tensor([ 0.9571, -0.5230,  0.0085], device='cuda:0') tensor([ 0.9887, -0.5018,  0.0309], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0274], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.001316140487906523 0.11376072693103924 0.5047060539126396 0.0 0.2855800224393606 1.409558206796646e-05 0.03495199658855563\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9958,  0.0399, -0.1183], device='cuda:0') tensor([ 1.0047, -0.0059,  1.0104], device='cuda:0') tensor([0.9669, 0.0360, 0.9583], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0159], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0012735866402508692 0.11630995232099667 0.5049075743556023 0.0 0.2932051135450602 1.5157490968704224e-05 0.037279327319469306\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 5:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.1116, -0.0932,  0.6092],\n",
      "        [-0.1116, -0.0932,  0.6092],\n",
      "        [-0.1116, -0.0932,  0.6092],\n",
      "        ...,\n",
      "        [-0.8953,  0.9942,  0.2075],\n",
      "        [-0.8953,  0.9942,  0.2075],\n",
      "        [-0.8953,  0.9942,  0.2075]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9708, 0.0376, 0.9558], device='cuda:0') tensor([0.7752, 0.6859, 0.9123], device='cuda:0') tensor([0.8417, 0.7630, 0.8717], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0978], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.001168591639958322 0.11881998091400602 0.505470507144928 0.0 0.2863365162163973 1.5209555625915528e-05 0.03561378766794223\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9877,  0.9858, -0.9796], device='cuda:0') tensor([-0.9991,  0.9917, -0.9962], device='cuda:0') tensor([-0.9877,  0.9858, -0.9796], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0021], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0011111164723988623 0.12132701262156478 0.504481086075306 0.0 0.2853718234449625 1.3441070914268493e-05 0.03416806647292105\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9377,  0.9872,  0.1926], device='cuda:0') tensor([-1.0293,  0.8562,  1.0818], device='cuda:0') tensor([-0.9862,  0.9425,  0.9918], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0069], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0010346956008579582 0.12385484541812912 0.5045446724891662 0.0 0.28137079818546773 1.4390349388122559e-05 0.03484624523943057\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9789, -0.0758, -0.0932], device='cuda:0') tensor([-1.0582, -0.2334,  0.8006], device='cuda:0') tensor([-0.9989, -0.1931,  0.8016], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0331], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0010091276097809897 0.1263703269541729 0.5059131646752357 0.0 0.28421977105736734 1.3283863663673401e-05 0.03793173545203172\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9720, -0.9967, -0.3297], device='cuda:0') tensor([ 0.9550, -1.0389,  0.5016], device='cuda:0') tensor([ 0.9763, -0.9991,  0.5005], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0346], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0009435290931724012 0.12890087607176975 0.5053997249007225 0.0 0.28606589333713056 1.3611003756523132e-05 0.03695217557111755\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9835,  0.7491, -0.2628], device='cuda:0') tensor([-0.9529,  0.9611, -0.9356], device='cuda:0') tensor([-0.9925,  0.9884, -0.9866], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0288], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0008857447381597013 0.13138043848890812 0.5067697853446007 0.0 0.2920615273118019 1.1134766042232513e-05 0.035597070907941085\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9889,  0.1405, -0.2020], device='cuda:0') tensor([ 0.9719,  0.1173, -0.1975], device='cuda:0') tensor([ 0.9889,  0.1405, -0.2020], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0414], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000851114563527517 0.13385760964336804 0.5055864414572716 0.0 0.28760914563387635 1.0357089340686798e-05 0.03693787251942558\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2427,  0.9885, -0.3705], device='cuda:0') tensor([ 0.7541,  0.6982, -0.3841], device='cuda:0') tensor([ 0.7629,  0.7235, -0.4152], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0303], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0008363771148724482 0.13633574904152193 0.5059455437660217 0.0 0.2915313291847706 1.4511406421661378e-05 0.03610737378586782\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3359, -0.9985, -0.9775], device='cuda:0') tensor([-0.3566, -1.0001,  0.0289], device='cuda:0') tensor([-0.3132, -0.9956,  0.0187], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0700], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007502869174350053 0.1388432203065604 0.5061217383742332 0.0 0.2834438822120428 1.1203594505786896e-05 0.034861858248943466\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9813, 0.9906, 0.7113], device='cuda:0') tensor([0.9852, 0.1939, 0.9357], device='cuda:0') tensor([0.9795, 0.1880, 0.9299], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0872], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0007242199285537935 0.1412455323114991 0.506884950697422 0.0 0.28875370203703643 9.33443009853363e-06 0.03635581257473677\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 6:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0022, -0.0886,  0.4361],\n",
      "        [-0.9573, -0.9803,  0.9924],\n",
      "        [-0.3203, -0.9975,  0.9943],\n",
      "        ...,\n",
      "        [-0.3203, -0.9975,  0.9943],\n",
      "        [-0.9573, -0.9803,  0.9924],\n",
      "        [-0.9855, -0.2230,  0.8011]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0022, -0.0886,  0.4361], device='cuda:0') tensor([-0.9589, -0.9768,  0.9991], device='cuda:0') tensor([-0.9573, -0.9803,  0.9924], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0521], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0006576709795626811 0.1436564489842858 0.50698130351305 0.0 0.2914521096497774 7.293276488780975e-06 0.037123283612716475\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9885, -0.4582, -0.0110], device='cuda:0') tensor([ 1.0022,  0.1345, -0.2947], device='cuda:0') tensor([ 0.9905,  0.1520, -0.2951], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0464], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0006210049528745003 0.14605903027858586 0.507671923160553 0.0 0.28560815908014775 1.1538252234458923e-05 0.034855312285537364\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4069,  0.8818,  0.9279], device='cuda:0') tensor([0.3138, 0.9882, 0.7755], device='cuda:0') tensor([0.2973, 0.9665, 0.7852], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0763], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0006118419237318448 0.14847441906831227 0.5067672094702721 0.0 0.28832780551910403 1.1374741792678833e-05 0.034053178932750595\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.3074, 0.9776, 0.7321], device='cuda:0') tensor([-0.4210,  0.8836,  0.9117], device='cuda:0') tensor([-0.3964,  0.8873,  0.9074], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1039], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005399274590308778 0.15088341178232803 0.5073912502527237 0.0 0.2839246506989002 1.0829322040081025e-05 0.03574711072666105\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3669, -0.9491,  0.8622], device='cuda:0') tensor([ 0.3706, -0.9421, -0.0340], device='cuda:0') tensor([ 0.3657, -0.9514, -0.0407], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0635], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005595080556813627 0.15326143072685228 0.507327947795391 0.0 0.28676746958494187 1.2092471122741698e-05 0.03664723830472212\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3309, -0.9902, -0.9939], device='cuda:0') tensor([-0.9336, -0.8850, -0.9282], device='cuda:0') tensor([-0.9876, -0.9030, -0.9394], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0226], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005059239165857434 0.15565776156401262 0.5077216506004334 0.0 0.29092210242152217 8.354030549526215e-06 0.036214241251931525\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9761, 0.9911, 0.6104], device='cuda:0') tensor([0.9800, 0.2279, 0.9633], device='cuda:0') tensor([0.9876, 0.2122, 0.9770], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0825], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0005107487155473792 0.15800896618433763 0.5087365058660507 0.0 0.2835825530588627 1.2831866741180419e-05 0.032961818824056535\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9944, -0.9761, -0.9900], device='cuda:0') tensor([ 1.0108, -0.9793, -0.9767], device='cuda:0') tensor([ 0.9944, -0.9761, -0.9900], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0017], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0004881530698039569 0.1603327259774087 0.5084416191577912 0.0 0.28621115039288997 8.831210434436799e-06 0.036992037691990845\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2711,  0.9958, -0.6854], device='cuda:0') tensor([ 0.8896,  0.8664, -0.8996], device='cuda:0') tensor([ 0.9101,  0.9041, -0.8939], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0178], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0004757474590442143 0.16265405356988777 0.5085920417904853 0.0 0.2794989363104105 9.468428790569305e-06 0.03466227809147676\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9259,  0.9335, -0.9396], device='cuda:0') tensor([ 0.3215,  0.9970, -0.6838], device='cuda:0') tensor([ 0.2825,  0.9975, -0.6889], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0366], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00045782231670455075 0.16492711268819402 0.509777449131012 0.0 0.28757069578766825 1.1926725506782532e-05 0.033759594058123184\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 7:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0248, -0.0871,  0.3773],\n",
      "        [-0.9938, -0.9920,  0.9862],\n",
      "        [-0.3406, -0.9882,  0.9664],\n",
      "        ...,\n",
      "        [-0.3853,  0.9306, -0.2014],\n",
      "        [-0.9610,  0.9910,  0.2334],\n",
      "        [-0.9949,  0.9354,  0.9846]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9853, 0.2371, 0.9749], device='cuda:0') tensor([ 1.0175,  0.2745, -0.5455], device='cuda:0') tensor([ 0.9999,  0.2452, -0.5682], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0941], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00039953275601146743 0.16720929403335322 0.5098844120502471 0.0 0.2857254088446498 8.525736629962922e-06 0.03639048654783983\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3732, -0.9506,  0.8980], device='cuda:0') tensor([ 0.3790, -0.9488, -0.0212], device='cuda:0') tensor([ 0.3814, -0.9481, -0.0237], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0651], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003980548235704191 0.16945651033765172 0.509378142952919 0.0 0.29264484950900077 1.0441996157169342e-05 0.03491755563084735\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9813, 0.2591, 0.9629], device='cuda:0') tensor([ 0.9954, -0.5354,  0.9666], device='cuda:0') tensor([ 0.9848, -0.5388,  0.9540], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0811], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00038043407973600553 0.17173284263780805 0.5097730474472046 0.0 0.27922578287124633 8.678115904331208e-06 0.03509733936854172\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3804, -0.9499,  0.9059], device='cuda:0') tensor([ 0.9873, -1.0173,  0.5398], device='cuda:0') tensor([ 0.9933, -0.9960,  0.5217], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0694], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00034694997189217247 0.173977513793041 0.5099024537205696 0.0 0.2856110840290785 7.889494299888611e-06 0.03467986458307132\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3535,  0.9496, -0.1993], device='cuda:0') tensor([ 0.3115,  0.9861, -0.6982], device='cuda:0') tensor([ 0.3117,  0.9982, -0.7177], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0316], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000350103129807394 0.17626944374700543 0.5091854786872864 0.0 0.2816267677098513 6.995685398578644e-06 0.03627969344123266\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9955, 0.9982, 0.3606], device='cuda:0') tensor([1.0139, 1.0069, 0.3495], device='cuda:0') tensor([0.9955, 0.9982, 0.3606], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0265], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003413527216180228 0.1785482615166111 0.5101204112768173 0.0 0.2766604302972555 1.0685399174690247e-05 0.03401457597949775\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.3178, 0.9686, 0.5406], device='cuda:0') tensor([0.9940, 0.9903, 0.4000], device='cuda:0') tensor([0.9936, 0.9944, 0.3785], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0706], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00031596886634361 0.1808335006510606 0.5097737993001938 0.0 0.28299593494832515 9.276285767555236e-06 0.03333009754531668\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9658,  0.9958,  0.2927], device='cuda:0') tensor([-0.3536,  0.9490, -0.1563], device='cuda:0') tensor([-0.3453,  0.9479, -0.1873], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0464], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0003210448239406105 0.18309719788550866 0.5099147598147392 0.0 0.2811281451880932 9.517312049865723e-06 0.03629131879191846\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9940, -0.2140,  0.9322], device='cuda:0') tensor([-0.9958, -0.9874,  1.0310], device='cuda:0') tensor([-0.9899, -0.9817,  0.9918], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0703], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00031315914433798755 0.18536587241396774 0.5096195526719093 0.0 0.28254905995726587 7.39104300737381e-06 0.03511379105830565\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9690,  0.9946,  0.2463], device='cuda:0') tensor([-0.9533,  0.9298,  0.3170], device='cuda:0') tensor([-0.9690,  0.9946,  0.2463], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0690], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00029443622785038317 0.1877077342394041 0.5085098268389702 0.0 0.27724861292541025 7.830910384654999e-06 0.033398414037830663\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 8:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0092, -0.0551,  0.3952],\n",
      "        [-0.0092, -0.0551,  0.3952],\n",
      "        [-0.0092, -0.0551,  0.3952],\n",
      "        ...,\n",
      "        [ 0.3525, -0.9479, -0.9474],\n",
      "        [ 0.3814, -0.9572, -0.0049],\n",
      "        [-0.3141, -0.9937,  0.0201]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9991, -0.2287,  0.9537], device='cuda:0') tensor([-0.9806, -0.2207,  0.9608], device='cuda:0') tensor([-0.9991, -0.2287,  0.9537], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0017], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00027951776777626944 0.19000790377275553 0.5100173633098602 0.0 0.28536923784017565 7.827423512935638e-06 0.03472062071081018\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3261, -0.9828,  0.0325], device='cuda:0') tensor([-0.3279, -0.9727,  0.9795], device='cuda:0') tensor([-0.3503, -0.9856,  0.9963], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0389], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002624959007225698 0.1923064230886521 0.5104391201138496 0.0 0.2814968485534191 7.457748055458069e-06 0.03828110132250004\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9855, -0.9960,  0.9980], device='cuda:0') tensor([-0.9844, -0.9828,  0.0131], device='cuda:0') tensor([-0.9728, -0.9895,  0.0042], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0526], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00026062423393887 0.19462103486817794 0.50992404037714 0.0 0.28452827969193456 8.318834006786347e-06 0.03601946130010765\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3193, -0.9413, -0.9528], device='cuda:0') tensor([ 0.3249, -0.9276, -0.9561], device='cuda:0') tensor([ 0.3193, -0.9413, -0.9528], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0111], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002541988421289716 0.19687619443319274 0.5087082408070565 0.0 0.2819994304180145 7.3813572525978084e-06 0.03363785329504754\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9929, 0.3177, 0.9585], device='cuda:0') tensor([0.9975, 0.3329, 0.9439], device='cuda:0') tensor([0.9929, 0.3177, 0.9585], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0367], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00023612795436929446 0.1991926000317326 0.5091331642866135 0.0 0.28221286141872404 7.420755922794342e-06 0.03355083005939377\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3821, -0.9574,  0.0112], device='cuda:0') tensor([-0.3286, -0.9900,  0.0238], device='cuda:0') tensor([-0.3159, -0.9942,  0.0166], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0173], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00023108373787545134 0.2015168721670052 0.5087617274522781 0.0 0.28301438349485397 6.47357851266861e-06 0.038888996605383\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9961, -0.9935,  0.9961], device='cuda:0') tensor([-0.9650, -0.1952,  0.9875], device='cuda:0') tensor([-0.9936, -0.2057,  0.9961], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0474], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002456551365030464 0.2038390314617427 0.5085034661889076 0.0 0.28419952872395515 9.670808911323547e-06 0.035453278879635036\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3199, -0.9953, -0.9978], device='cuda:0') tensor([-0.9803, -0.9640, -0.9999], device='cuda:0') tensor([-0.9885, -0.9695, -0.9982], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0227], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00023054167762165889 0.2061754486745922 0.5091330061554908 0.0 0.2780165977627039 6.482847034931183e-06 0.03666689024225343\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3495,  0.9461,  0.8879], device='cuda:0') tensor([0.3624, 0.9942, 0.5317], device='cuda:0') tensor([0.3419, 0.9868, 0.5330], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0767], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0002168565200845478 0.20852325286983978 0.5077837640047074 0.0 0.28370196625590327 9.365282952785493e-06 0.03434614067792427\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9907,  0.9599,  0.9963], device='cuda:0') tensor([-0.3794,  0.9202,  0.8877], device='cuda:0') tensor([-0.3783,  0.9493,  0.8901], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0728], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00020965302470722235 0.21085498940886463 0.5102763253450394 0.0 0.2830109925866127 6.788276135921478e-06 0.03521882441555499\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 9:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0051, -0.0355,  0.3979],\n",
      "        [-0.0051, -0.0355,  0.3979],\n",
      "        [-0.0051, -0.0355,  0.3979],\n",
      "        ...,\n",
      "        [ 0.9983,  0.2864, -0.5062],\n",
      "        [ 0.9928,  0.9744, -0.9976],\n",
      "        [ 0.3281,  1.0001, -0.6847]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0051, -0.0355,  0.3979], device='cuda:0') tensor([ 0.9852,  0.9699, -0.9929], device='cuda:0') tensor([ 0.9928,  0.9744, -0.9976], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0102], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00020143249152170027 0.21319542100338731 0.5090062251091003 0.0 0.2863452959358692 6.669744849205017e-06 0.036606666790059535\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9476, -0.0472, -0.9886], device='cuda:0') tensor([-0.9228, -0.0452, -1.0000], device='cuda:0') tensor([-0.9476, -0.0472, -0.9886], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0171], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00018804418317449744 0.21557969701651017 0.5076689069271088 0.0 0.28510314857959745 5.7078748941421506e-06 0.036325874921050855\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9994, -0.9904, -0.9776], device='cuda:0') tensor([ 0.9961, -0.9922, -0.9805], device='cuda:0') tensor([ 0.9994, -0.9904, -0.9776], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0013], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00020932244714640547 0.2179114383776905 0.5080451367497444 0.0 0.28583751982450484 5.625903606414795e-06 0.03356863378500566\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9930, -0.4903,  0.9962], device='cuda:0') tensor([ 0.9961, -0.3876,  0.0095], device='cuda:0') tensor([ 0.9919, -0.3747,  0.0207], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0832], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00019097982236417012 0.2202569140883861 0.5074521925449371 0.0 0.284160001963377 6.320670247077942e-06 0.03477926362375729\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9942,  0.9710, -0.9959], device='cuda:0') tensor([ 0.9980,  0.2798, -0.4910], device='cuda:0') tensor([ 0.9880,  0.2822, -0.4848], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0100], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0001902904290764127 0.2226415751687018 0.5086246673464775 0.0 0.2797750537693501 6.3256099820137025e-06 0.035498591853072865\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3295,  0.9942, -0.6690], device='cuda:0') tensor([-0.3694,  0.9808, -0.1738], device='cuda:0') tensor([-0.3490,  0.9729, -0.1992], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0443], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00018847971221839542 0.2249892887462629 0.5080800535082817 0.0 0.2809614723622799 7.4134469032287595e-06 0.037957799456489735\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3103, -0.9781, -0.9912], device='cuda:0') tensor([-0.3145, -0.9940, -0.9796], device='cuda:0') tensor([-0.3103, -0.9781, -0.9912], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0211], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.000181286233724677 0.22730823176226114 0.5088186785578728 0.0 0.2833562420159578 4.934363067150116e-06 0.03586927690351149\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9960, -0.4720,  0.9892], device='cuda:0') tensor([ 0.9911, -0.4692,  0.9887], device='cuda:0') tensor([ 0.9960, -0.4720,  0.9892], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0672], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00019244602392427622 0.22963410499470774 0.5086531382203102 0.0 0.2828386991024017 6.968267261981964e-06 0.03640669983235421\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9967, 0.9944, 0.2048], device='cuda:0') tensor([ 0.9957,  0.9674, -1.0121], device='cuda:0') tensor([ 0.9915,  0.9767, -0.9927], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0751], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00017731069386354648 0.23198313792224506 0.5094366447925568 0.0 0.27712083925306796 4.7646090388298035e-06 0.037628188902745024\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3380,  0.9957, -0.6711], device='cuda:0') tensor([ 0.9856,  0.9696, -0.9942], device='cuda:0') tensor([ 0.9940,  0.9768, -0.9897], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0188], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00017312402346578891 0.23432756394986062 0.5090304089188575 0.0 0.285539104744792 5.112767219543457e-06 0.03469683557277312\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 10:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[-0.0017, -0.0283,  0.3778],\n",
      "        [-0.0017, -0.0283,  0.3778],\n",
      "        [-0.0017, -0.0283,  0.3778],\n",
      "        ...,\n",
      "        [-0.3445,  0.9838, -0.2032],\n",
      "        [-0.3445,  0.9838, -0.2032],\n",
      "        [-0.3381,  0.9752,  0.9135]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9885,  0.9985,  0.2663], device='cuda:0') tensor([-1.0196,  0.9693,  0.9841], device='cuda:0') tensor([-0.9972,  0.9673,  0.9973], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0099], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0001686312256133533 0.2366870545297861 0.5084854107499123 0.0 0.2820809602588415 7.451705634593963e-06 0.0354491137630539\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3873, -0.9504,  0.9823], device='cuda:0') tensor([ 1.0139, -1.0133,  0.6102], device='cuda:0') tensor([ 0.9991, -0.9937,  0.5941], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0727], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00015322280037798918 0.23904715744662097 0.5089193215370178 0.0 0.285555928632617 3.941178321838379e-06 0.03506999169359915\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3779, -0.9440, -0.9468], device='cuda:0') tensor([ 0.3770, -0.9340, -0.9561], device='cuda:0') tensor([ 0.3779, -0.9440, -0.9468], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0100], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0001547569370668498 0.2413907502903603 0.5093542781472206 0.0 0.2830749381929636 4.457831382751465e-06 0.034412438596016726\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3487,  0.9783,  0.9290], device='cuda:0') tensor([0.3578, 1.0024, 0.5418], device='cuda:0') tensor([0.3293, 0.9949, 0.5363], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0791], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0001512340153567493 0.24376698409137315 0.5078575649261474 0.0 0.28531488893926144 4.364222288131714e-06 0.035451698110904546\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9669, -0.0525, -0.9988], device='cuda:0') tensor([-0.9559, -0.0537, -1.0047], device='cuda:0') tensor([-0.9669, -0.0525, -0.9988], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0177], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00014967041130876168 0.24614606755250135 0.5082272437214851 0.0 0.28297172141075133 5.6751295924186705e-06 0.03766123048239388\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9896,  0.2929, -0.5045], device='cuda:0') tensor([ 0.9884,  0.9764, -1.0053], device='cuda:0') tensor([ 0.9967,  0.9773, -0.9989], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0399], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0001408973091383814 0.2484902211332228 0.5086703754663467 0.0 0.27977376960217953 5.617216229438781e-06 0.037442443659645504\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9956, -0.9944,  0.6204], device='cuda:0') tensor([ 0.9947, -0.9831,  0.6224], device='cuda:0') tensor([ 0.9956, -0.9944,  0.6204], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0635], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00014602688837476308 0.25084742136253046 0.5087810208201409 0.0 0.2807238571345806 6.23428076505661e-06 0.0322436427033972\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9910, -0.9774, -0.9984], device='cuda:0') tensor([ 0.9914, -0.9802, -0.9898], device='cuda:0') tensor([ 0.9910, -0.9774, -0.9984], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0021], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00013940539128088857 0.2532360873864964 0.5089197255969048 0.0 0.28516567358374595 5.850650370121002e-06 0.03455726093490375\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9954,  0.9908,  0.2647], device='cuda:0') tensor([-0.9698,  0.9486,  0.3117], device='cuda:0') tensor([-0.9954,  0.9908,  0.2647], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0693], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0001419207332583028 0.2556295550954528 0.50856422996521 0.0 0.28598907101154325 4.908397793769836e-06 0.035554827752523124\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3786, -0.9628,  0.0392], device='cuda:0') tensor([ 0.3749, -0.9498,  1.0055], device='cuda:0') tensor([ 0.3707, -0.9522,  0.9982], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0306], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0001285948088116129 0.2579795705913566 0.5089265460968018 0.0 0.28727071626484396 6.027370691299439e-06 0.03843196315411478\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 11:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[ 0.0157, -0.0325,  0.3679],\n",
      "        [ 0.9922,  0.9832, -0.9926],\n",
      "        [ 0.9895,  0.2962, -0.5085],\n",
      "        ...,\n",
      "        [ 0.3879, -0.9632,  0.0313],\n",
      "        [ 0.3478, -0.9416, -0.9523],\n",
      "        [ 0.3478, -0.9416, -0.9523]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.3333, 0.9941, 0.5435], device='cuda:0') tensor([-0.3719,  0.9876,  0.9383], device='cuda:0') tensor([-0.3422,  0.9900,  0.9652], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0966], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00012456496423692443 0.2603705366756767 0.5089312440752983 0.0 0.27713257414102554 5.499020218849182e-06 0.033489181817276406\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9989,  0.9853, -0.9959], device='cuda:0') tensor([ 0.0075, -0.0349,  0.3738], device='cuda:0') tensor([ 0.0122, -0.0347,  0.3711], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0237], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00012225965101242764 0.26272711680852806 0.5091379395723343 0.0 0.28321241956949234 5.483902990818024e-06 0.03629970293305814\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9975, -0.4475,  0.9872], device='cuda:0') tensor([1.0004, 0.4400, 0.9862], device='cuda:0') tensor([0.9995, 0.4411, 0.9847], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0888], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00012266158432612428 0.265089254995808 0.5094059985280037 0.0 0.27936241251230237 4.596307873725891e-06 0.03522098493704107\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9969,  0.4952,  0.6229], device='cuda:0') tensor([-0.9910,  0.5057,  0.6296], device='cuda:0') tensor([-0.9969,  0.4952,  0.6229], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0493], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0001189997104156646 0.2674854430682026 0.5089812573194504 0.0 0.2837312690913677 4.792273044586181e-06 0.03635266260406934\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9968,  0.9973,  0.2529], device='cuda:0') tensor([-0.3447,  0.9920, -0.2187], device='cuda:0') tensor([-0.3384,  0.9927, -0.2118], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0447], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00011779110237694112 0.2698644791254774 0.5085670618414879 0.0 0.28707136993110177 5.3600072860717775e-06 0.03552872646166361\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3995, -0.9578,  0.9929], device='cuda:0') tensor([ 0.3964, -0.9522,  0.9992], device='cuda:0') tensor([ 0.3995, -0.9578,  0.9929], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0079], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00011622319136222358 0.272174116312759 0.5092907812595368 0.0 0.28665738117694856 5.25212287902832e-06 0.03585011109203333\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0217, -0.0348,  0.3686], device='cuda:0') tensor([ 0.0214, -0.0265,  0.3608], device='cuda:0') tensor([ 0.0217, -0.0348,  0.3686], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0389], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00012036785639793379 0.27456628388585524 0.5088683144450188 0.0 0.2832658388018608 5.285166203975678e-06 0.03572657322016312\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9966, -0.9967,  0.9834], device='cuda:0') tensor([ 0.0314, -0.0312,  0.3582], device='cuda:0') tensor([ 0.0200, -0.0335,  0.3648], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0083], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00011311163671780377 0.27692955095297656 0.507866023004055 0.0 0.2833972471505404 4.288099706172943e-06 0.03421134225931018\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9957,  0.9915, -0.9991], device='cuda:0') tensor([ 0.0135, -0.0355,  0.3801], device='cuda:0') tensor([ 0.0175, -0.0369,  0.3705], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0236], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0001154796275368426 0.2793190918210894 0.508542852640152 0.0 0.28415102514624596 4.484497010707855e-06 0.03594821571611101\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9420, -0.1361, -0.0082], device='cuda:0') tensor([-0.9812, -1.0052,  0.0020], device='cuda:0') tensor([-0.9911, -0.9931,  0.0129], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0288], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.0001085327222608612 0.2816919833414722 0.5096016383767128 0.0 0.2823015640377998 4.218652844429016e-06 0.03435824416577816\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 12:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[ 0.0224, -0.0354,  0.3678],\n",
      "        [ 0.9965,  0.9944, -0.9935],\n",
      "        [ 0.0224, -0.0354,  0.3678],\n",
      "        ...,\n",
      "        [ 0.9942, -0.4316,  0.9970],\n",
      "        [ 0.9962,  0.4766,  0.9942],\n",
      "        [ 0.9962,  0.4766,  0.9942]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9965, -0.9981,  0.9860], device='cuda:0') tensor([-1.0011, -0.1935,  1.0006], device='cuda:0') tensor([-0.9919, -0.1789,  0.9922], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0470], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "9.873873816104606e-05 0.28406118108984085 0.5087641510367393 0.0 0.2827427857965231 4.275307059288025e-06 0.03399636653123889\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.3494, 0.9932, 0.5613], device='cuda:0') tensor([ 0.3142,  1.0042, -0.6946], device='cuda:0') tensor([ 0.3116,  0.9934, -0.6983], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0840], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00010247359205095563 0.2864548994214274 0.5089362334012986 0.0 0.2824131884276867 3.5420432686805723e-06 0.03442672664328711\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9986, -0.9969,  0.0096], device='cuda:0') tensor([-0.9463, -0.1415, -0.0172], device='cuda:0') tensor([-0.9446, -0.1401, -0.0090], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0102], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "9.706504196947208e-05 0.288827477727551 0.5096464094519615 0.0 0.28151394161581994 4.940256476402283e-06 0.035706634377740555\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9980,  0.9619,  0.9955], device='cuda:0') tensor([-1.0184,  1.0130,  0.9678], device='cuda:0') tensor([-0.9980,  0.9619,  0.9955], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0986], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "0.00010323844943195582 0.2911507214200683 0.5091915308237076 0.0 0.28435112473368646 3.857329487800598e-06 0.035635067054477984\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9984,  0.4865,  0.6133], device='cuda:0') tensor([-0.9931, -0.1831,  0.9942], device='cuda:0') tensor([-0.9944, -0.1852,  0.9902], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0713], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "9.520266873732908e-05 0.29356437594490126 0.5084336330294609 0.0 0.28256223203241826 4.787102341651917e-06 0.03648362148314482\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9974, -0.1849,  0.9969], device='cuda:0') tensor([-1.0029,  0.4778,  0.6126], device='cuda:0') tensor([-0.9967,  0.4816,  0.6180], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0549], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "9.947948918124894e-05 0.29591818449972196 0.5088676403164863 0.0 0.2856186889410019 3.6815032362937927e-06 0.03515668942700722\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9973, -0.9715, -0.9949], device='cuda:0') tensor([ 0.9997, -0.9893, -0.2382], device='cuda:0') tensor([ 0.9979, -0.9974, -0.2407], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0567], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "8.860076136625139e-05 0.2982844720243011 0.5096953849196434 0.0 0.28205293184518815 3.782391548156738e-06 0.03318481188599253\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3179, -0.9925,  0.9912], device='cuda:0') tensor([-0.3177, -0.9941,  0.9856], device='cuda:0') tensor([-0.3179, -0.9925,  0.9912], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0024], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "9.060400119051337e-05 0.3006273752201814 0.509074034512043 0.0 0.2812558188661933 4.580058157444e-06 0.03597238474187907\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9957, -0.9924, -0.9965], device='cuda:0') tensor([-1.0009, -0.9929, -0.9919], device='cuda:0') tensor([-0.9957, -0.9924, -0.9965], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0275], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "8.750057957513491e-05 0.3030007065734826 0.510075029194355 0.0 0.28246467868983743 3.1844750046730042e-06 0.03658526120526949\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9965,  0.9931, -0.9949], device='cuda:0') tensor([0.9996, 0.9950, 0.0481], device='cuda:0') tensor([0.9979, 0.9916, 0.0348], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0276], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "8.926473621977493e-05 0.305351815990638 0.5094423515200615 0.0 0.28153439520299434 4.432007670402527e-06 0.03490599826374091\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 13:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[ 0.0302, -0.0280,  0.3633],\n",
      "        [ 0.9954,  0.9924, -0.9913],\n",
      "        [ 0.0302, -0.0280,  0.3633],\n",
      "        ...,\n",
      "        [-0.9897,  0.7178, -0.2730],\n",
      "        [-0.9915,  0.9918, -0.9873],\n",
      "        [-0.9897,  0.7178, -0.2730]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3115, -0.9917,  0.0171], device='cuda:0') tensor([-0.3194, -0.9971, -0.9921], device='cuda:0') tensor([-0.3225, -0.9958, -0.9875], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0186], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "8.750334957585437e-05 0.3077255234248005 0.5096547036767006 0.0 0.2837944112867117 4.0508061647415165e-06 0.036281157095509116\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9965,  0.9959, -0.9991], device='cuda:0') tensor([0.9953, 0.9907, 0.0434], device='cuda:0') tensor([0.9965, 0.9939, 0.0295], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0277], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "8.086751386144897e-05 0.3100883570900187 0.5090529069900512 0.0 0.28549357295036315 3.227896988391876e-06 0.03486913301917957\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3169, -0.9945, -0.9963], device='cuda:0') tensor([-0.9936, -0.9931, -0.9950], device='cuda:0') tensor([-0.9916, -0.9965, -0.9921], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0227], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "8.387599148409209e-05 0.31244756521028466 0.5093740285038948 0.0 0.2859860444366932 2.819858491420746e-06 0.03381601410137955\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9978, -0.9685, -0.9991], device='cuda:0') tensor([ 1.0029, -0.9750, -0.9939], device='cuda:0') tensor([ 0.9978, -0.9685, -0.9991], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0012], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "8.008955881814472e-05 0.314793243738357 0.5086553164124489 0.0 0.2838627067953348 4.572972655296326e-06 0.03600112649484072\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3387, -0.9944, -0.9995], device='cuda:0') tensor([-0.3210, -0.9988,  0.0049], device='cuda:0') tensor([-0.3310, -0.9991,  0.0140], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0706], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "7.895475609984715e-05 0.31715843910793773 0.5089686176776886 0.0 0.2875301249474287 3.6780685186386107e-06 0.03628118685173103\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9953, -0.9954, -0.2568], device='cuda:0') tensor([ 0.3809, -0.9684,  0.0288], device='cuda:0') tensor([ 0.3858, -0.9774,  0.0357], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0126], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "7.68467542147846e-05 0.3195096058244817 0.509697117805481 0.0 0.28507722986489537 2.865999937057495e-06 0.03619146675523371\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9927, 0.5108, 0.9751], device='cuda:0') tensor([1.0052, 0.5200, 0.9669], device='cuda:0') tensor([0.9927, 0.5108, 0.9751], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0416], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "7.677455601515248e-05 0.32184329040593 0.5091832626461983 0.0 0.28126293314993384 3.5941824316978456e-06 0.03580094810400624\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3837, -0.9728,  0.0277], device='cuda:0') tensor([-0.3194, -0.9967,  0.0118], device='cuda:0') tensor([-0.3191, -0.9878,  0.0051], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0179], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "8.283766317617846e-05 0.3242156003148993 0.5093578293323516 0.0 0.284092055901885 2.819947898387909e-06 0.03460111590632005\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3410, -0.9358, -0.9587], device='cuda:0') tensor([ 0.9825, -0.9264, -1.0123], device='cuda:0') tensor([ 0.9981, -0.9654, -0.9985], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0108], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "7.966427357678185e-05 0.3265823023197008 0.5093682195544242 0.0 0.2817027347236872 3.5581141710281373e-06 0.034349022931652144\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9952, -0.0439, -0.9925], device='cuda:0') tensor([-0.9932,  0.9988, -0.9962], device='cuda:0') tensor([-0.9980,  0.9934, -0.9974], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0174], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "7.988527193811024e-05 0.3289717064035358 0.5083185337185859 0.0 0.2856485978066921 2.5651976466178895e-06 0.036833928000705785\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 14:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[ 0.0500, -0.0240,  0.3692],\n",
      "        [ 0.0500, -0.0240,  0.3692],\n",
      "        [ 0.9956,  0.9963, -0.9978],\n",
      "        ...,\n",
      "        [ 0.9977, -0.9672, -0.9976],\n",
      "        [ 0.3424, -0.9471, -0.9607],\n",
      "        [ 0.9977, -0.9672, -0.9976]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9967,  1.0002,  0.2276], device='cuda:0') tensor([-0.9931,  0.9690,  0.9874], device='cuda:0') tensor([-0.9980,  0.9589,  0.9969], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0086], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.941329077017144e-05 0.3313350370655535 0.509302232503891 0.0 0.28703993365168573 3.5502463579177854e-06 0.03414482753019547\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9972, -0.3991,  0.9893], device='cuda:0') tensor([ 0.9924, -0.3974,  0.9939], device='cuda:0') tensor([ 0.9972, -0.3991,  0.9893], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0686], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "7.291061904106754e-05 0.3336723522223765 0.5093706815838813 0.0 0.2811522247046232 3.2697170972824096e-06 0.0348124711754499\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3139, -0.9960,  0.0191], device='cuda:0') tensor([-0.3113, -0.9832,  0.9940], device='cuda:0') tensor([-0.2986, -0.9915,  0.9972], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0394], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "7.398455147631466e-05 0.3360171397215454 0.5087376891970634 0.0 0.28348252110183236 2.7832835912704466e-06 0.0347346157633001\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9993,  0.9592,  0.9981], device='cuda:0') tensor([-1.0052,  0.9697,  0.9983], device='cuda:0') tensor([-0.9993,  0.9592,  0.9981], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0353], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "7.307872378805768e-05 0.33835262144252193 0.5090164771080017 0.0 0.28787019693106414 2.6288628578186033e-06 0.03616762479097815\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9978,  0.2328, -0.6214], device='cuda:0') tensor([ 1.0003,  0.2288, -0.6279], device='cuda:0') tensor([ 0.9978,  0.2328, -0.6214], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0247], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "7.351706115150592e-05 0.3407072703448357 0.50920098477602 0.0 0.28525321844220164 3.338053822517395e-06 0.0361974721137085\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9850, -0.1697,  0.9761], device='cuda:0') tensor([-0.9497, -0.1391, -0.0075], device='cuda:0') tensor([-0.9490, -0.1345, -0.0011], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0631], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "7.464872473065043e-05 0.3430151590044843 0.5098623970150947 0.0 0.2817026276886463 3.190457820892334e-06 0.03723853021551622\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9918, -0.9972,  0.9867], device='cuda:0') tensor([-0.2977, -0.9896,  1.0133], device='cuda:0') tensor([-0.2964, -0.9913,  0.9921], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0581], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.706004703301005e-05 0.34538801217463333 0.5088348413705825 0.0 0.27832598526775837 3.063507378101349e-06 0.03523012612367165\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3199, -0.9889, -0.9952], device='cuda:0') tensor([-0.2981, -0.9986,  0.0084], device='cuda:0') tensor([-0.3110, -0.9946,  0.0125], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0703], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "7.383278829365735e-05 0.34775232945836615 0.5092656046152115 0.0 0.28005038933455945 3.82387638092041e-06 0.03645296638878062\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9920, -0.3932,  0.9919], device='cuda:0') tensor([ 0.9906, -0.3105,  0.0152], device='cuda:0') tensor([ 0.9916, -0.3107,  0.0242], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0846], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.683370602695504e-05 0.35007108065194914 0.509775562286377 0.0 0.28650061635673046 2.77739018201828e-06 0.03489526750688674\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9921, -0.9958,  0.5989], device='cuda:0') tensor([ 0.4017, -0.9612,  0.9843], device='cuda:0') tensor([ 0.4060, -0.9646,  0.9870], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0440], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.678280500636902e-05 0.35244178060942793 0.509698759675026 0.0 0.2816753886416554 3.7311017513275144e-06 0.03342814525205176\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 15:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[ 0.0518, -0.0185,  0.3630],\n",
      "        [ 0.9969,  0.9948, -0.9976],\n",
      "        [ 0.2834,  0.9958, -0.7833],\n",
      "        ...,\n",
      "        [-0.9950,  0.7130, -0.2839],\n",
      "        [-0.9953,  0.9957, -0.9978],\n",
      "        [-0.9953,  0.9957, -0.9978]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4131, -0.9679,  0.9994], device='cuda:0') tensor([ 0.4196, -0.9685,  0.9968], device='cuda:0') tensor([ 0.4131, -0.9679,  0.9994], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0083], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.520151831500698e-05 0.3548278743402334 0.5094552233815193 0.0 0.28157658007740977 2.8213635087013246e-06 0.036446621153038\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9981, -0.9975, -0.2581], device='cuda:0') tensor([ 0.3857, -0.9807,  0.0553], device='cuda:0') tensor([ 0.3784, -0.9841,  0.0601], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0126], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.392944447361514e-05 0.35722280278464313 0.5093762959241868 0.0 0.28188601963222026 2.7380064129829405e-06 0.03572210224036826\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9938,  0.7210, -0.2804], device='cuda:0') tensor([-0.9432, -0.1415, -0.0067], device='cuda:0') tensor([-0.9484, -0.1483, -0.0043], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0391], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.278236733123777e-05 0.3596020422236761 0.5095815562605858 0.0 0.280946188211441 3.2643601298332214e-06 0.03536722504868521\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9928,  0.9959, -0.9903], device='cuda:0') tensor([-0.9921, -0.0359, -1.0008], device='cuda:0') tensor([-0.9889, -0.0414, -0.9914], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0200], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.213957102227141e-05 0.36196365728450475 0.5096979030966758 0.0 0.2833552002310753 2.6313886046409605e-06 0.03725878582696896\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9973, 0.5566, 0.9988], device='cuda:0') tensor([ 0.9993,  0.2058, -0.6494], device='cuda:0') tensor([ 0.9951,  0.2040, -0.6522], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1008], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.149718842789298e-05 0.3643145386779215 0.5098836772441864 0.0 0.27902970257401466 2.91500985622406e-06 0.03589652816549642\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9977, -0.9600, -0.9986], device='cuda:0') tensor([ 1.0086, -0.9701, -0.9966], device='cuda:0') tensor([ 0.9977, -0.9600, -0.9986], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0019], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.297436790919165e-05 0.36665769258956427 0.5095309481620789 0.0 0.28426186050474644 3.050290048122406e-06 0.034354983699158764\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.3710, 0.9939, 0.4897], device='cuda:0') tensor([0.3724, 0.9874, 0.4835], device='cuda:0') tensor([0.3710, 0.9939, 0.4897], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0244], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.9393634503067e-05 0.3689874781740364 0.5101553923487663 0.0 0.28339577436447144 3.0404478311538696e-06 0.033742753798898774\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9912, -0.3767,  0.9982], device='cuda:0') tensor([0.9972, 0.5777, 0.9968], device='cuda:0') tensor([0.9939, 0.5671, 0.9983], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0907], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.126336267698207e-05 0.37134861313435247 0.5088603529334068 0.0 0.27682777227461336 2.6056990027427673e-06 0.035299875535303726\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9951, -0.9946, -0.9914], device='cuda:0') tensor([-0.9895, -0.0382, -0.9863], device='cuda:0') tensor([-0.9949, -0.0362, -0.9920], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0241], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.7640086048195374e-05 0.37366914852312766 0.5102296293377876 0.0 0.2883455557078123 2.996496856212616e-06 0.03558938477479387\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9975,  0.4814,  0.6102], device='cuda:0') tensor([-0.9984,  0.7125, -0.2698], device='cuda:0') tensor([-0.9942,  0.7135, -0.2863], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0590], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "6.404928586562164e-05 0.375998800839996 0.5100314956903458 0.0 0.2830376005619764 2.54705548286438e-06 0.03800264660897665\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 16:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[ 0.0574, -0.0143,  0.3730],\n",
      "        [ 0.9940,  0.9969, -0.9971],\n",
      "        [ 0.2679,  0.9955, -0.8080],\n",
      "        ...,\n",
      "        [-0.9986,  0.9965,  0.2349],\n",
      "        [-0.3300,  0.9931, -0.3087],\n",
      "        [-0.2627,  0.9969,  0.9983]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3431, -0.9484, -0.9605], device='cuda:0') tensor([ 0.3877, -0.9967,  0.0481], device='cuda:0') tensor([ 0.3909, -0.9849,  0.0612], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0642], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.639434271870414e-05 0.378356670926325 0.50990541690588 0.0 0.28137558509409427 2.6228129863739015e-06 0.0346616215746617\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9966, 0.5756, 0.9984], device='cuda:0') tensor([ 0.9970,  0.9973, -0.0414], device='cuda:0') tensor([ 0.9992,  0.9995, -0.0517], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1115], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.486800990183838e-05 0.38065273328032345 0.5105908208489418 0.0 0.28100612907111644 2.965159714221954e-06 0.036996521590743216\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9961, -0.9634, -0.9976], device='cuda:0') tensor([ 1.0009, -0.9752, -0.9920], device='cuda:0') tensor([ 0.9961, -0.9634, -0.9976], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0019], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.753875000664266e-05 0.3830178516404703 0.5102676204442977 0.0 0.28242526575922966 2.259157598018646e-06 0.032973040224751456\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9971,  0.4873,  0.6108], device='cuda:0') tensor([-0.9929,  0.7241, -0.2950], device='cuda:0') tensor([-0.9940,  0.7220, -0.2839], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0592], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.849673872216954e-05 0.385350438588066 0.5100930863618851 0.0 0.28695508977770806 3.187991678714752e-06 0.035288588805779\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3959, -0.9668,  0.9850], device='cuda:0') tensor([ 0.4043, -0.9712,  1.0009], device='cuda:0') tensor([ 0.3959, -0.9668,  0.9850], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0074], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.7693141341587765e-05 0.387716822888935 0.5097164261341095 0.0 0.28253349754214285 2.2466629743576048e-06 0.03481498643802479\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3932, -0.9898,  0.0767], device='cuda:0') tensor([ 0.4255, -0.9654,  0.9962], device='cuda:0') tensor([ 0.4314, -0.9717,  0.9976], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0291], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.830407648318214e-05 0.39006838893645907 0.5109919499158859 0.0 0.28082188642024997 2.439044415950775e-06 0.03436176802695263\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3885, -0.9900,  0.0741], device='cuda:0') tensor([ 0.3348, -0.9452, -0.9556], device='cuda:0') tensor([ 0.3378, -0.9460, -0.9574], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0310], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.912459286628291e-05 0.3924196640356677 0.5103341491222382 0.0 0.27862275241315365 2.590462565422058e-06 0.034173977805883625\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.3595, 0.9877, 0.4780], device='cuda:0') tensor([ 0.9828,  0.9878, -0.0594], device='cuda:0') tensor([ 0.9951,  0.9966, -0.0380], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0688], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.656428461225005e-05 0.3947579120468581 0.5102709736227989 0.0 0.2806043016463518 2.6433765888214112e-06 0.035522927068232096\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9989,  0.9989,  0.2393], device='cuda:0') tensor([-0.3078,  1.0010, -0.3028], device='cuda:0') tensor([-0.3297,  0.9991, -0.3235], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0442], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.304774838441517e-05 0.39707855206669773 0.5102694907784462 0.0 0.2800630116313696 2.4332702159881593e-06 0.03553790329291951\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9963,  0.9619,  0.9984], device='cuda:0') tensor([-0.2625,  0.9976,  0.9922], device='cuda:0') tensor([-0.2459,  0.9962,  0.9974], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0728], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.378947436838644e-05 0.3993907298211707 0.5104113429784775 0.0 0.2838458423167467 2.5343894958496096e-06 0.03365860919398256\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Average (on the epoch) training loss: 0.0\n",
      "Episode average V value: -1\n",
      "epoch 17:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "adjusting learning rate!!!\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n",
      "tensor([[ 0.0624, -0.0048,  0.3790],\n",
      "        [ 0.0624, -0.0048,  0.3790],\n",
      "        [-0.9984, -0.9983,  0.9908],\n",
      "        ...,\n",
      "        [-0.9962,  0.7245, -0.2882],\n",
      "        [-0.9962,  0.7245, -0.2882],\n",
      "        [-0.9982,  0.9988, -0.9917]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:211: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env_3d.py:252: RuntimeWarning: divide by zero encountered in log\n",
      "  plt.plot(np.log(learning_algo.tracked_disamb1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3277,  0.9960, -0.3241], device='cuda:0') tensor([ 0.2604,  0.9958, -0.8227], device='cuda:0') tensor([ 0.2545,  0.9973, -0.8232], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0280], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.2400474171008684e-05 0.40171826199407223 0.5098661727905274 0.0 0.28385318349301814 2.4770200252532957e-06 0.03391457209968939\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3044, -0.9983,  0.0266], device='cuda:0') tensor([-0.2888, -0.9881,  1.0102], device='cuda:0') tensor([-0.2852, -0.9957,  0.9957], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0390], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.471004881474073e-05 0.4040835312750423 0.5093928397297859 0.0 0.28253357197344303 3.070928156375885e-06 0.03604953064152505\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9943,  0.9617,  0.9994], device='cuda:0') tensor([-1.0072,  0.9904,  0.2427], device='cuda:0') tensor([-0.9922,  0.9951,  0.2448], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0870], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.312179701286368e-05 0.40644532698474356 0.5102750500440597 0.0 0.2864092414826155 2.3312419652938843e-06 0.034787967179203405\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9995, -0.9940,  0.9923], device='cuda:0') tensor([-1.0032, -0.9980,  0.0164], device='cuda:0') tensor([-0.9950, -0.9936,  0.0132], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0523], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.282862309468328e-05 0.408788867117255 0.5095691857933998 0.0 0.2798767305240035 2.2008568048477173e-06 0.036768049345526375\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9980,  0.9968, -0.9982], device='cuda:0') tensor([0.0611, 0.0035, 0.3757], device='cuda:0') tensor([ 0.0611, -0.0044,  0.3817], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0238], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "self.loss_T/500., self.lossR/500., self.loss_gamma/500., self.loss_Q/500., self.loss_disentangle_t/500., self.loss_disambiguate1/500., self.loss_disambiguate2/500.\n",
      "5.097158327043871e-05 0.41108814323483966 0.5107670958042145 0.0 0.28366282111406327 2.2176280617713927e-06 0.034721862622565824\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9974,  0.9634,  0.9953], device='cuda:0') tensor([-1.0074,  0.9703,  1.0014], device='cuda:0') tensor([-0.9974,  0.9634,  0.9953], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0354], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"params\")\n",
    "except Exception:\n",
    "    pass\n",
    "dump(vars(parameters), \"params/\" + fname + \".jldump\")\n",
    "agent.gathering_data=False\n",
    "agent.run(parameters.epochs, parameters.steps_per_epoch)\n",
    "\n",
    "# --- Show results ---\n",
    "basename = \"scores/\" + fname\n",
    "scores = load(basename + \"_scores.jldump\")\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
