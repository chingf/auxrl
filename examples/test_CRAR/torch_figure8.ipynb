{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import hash, dump, load\n",
    "import os\n",
    "\n",
    "from deer.default_parser import process_args\n",
    "from deer.agent import NeuralAgent\n",
    "from deer.learning_algos.CRAR_torch import CRAR\n",
    "from figure8_env import MyEnv as figure8_env\n",
    "import deer.experiment.base_controllers as bc\n",
    "\n",
    "from deer.policies import EpsilonGreedyPolicy, FixedFigure8Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure8_give_rewards = True\n",
    "nn_yaml = 'network_noconv.yaml'\n",
    "higher_dim_obs = False\n",
    "internal_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Defaults:\n",
    "    # ----------------------\n",
    "    # Experiment Parameters\n",
    "    # ----------------------\n",
    "    steps_per_epoch = 5000\n",
    "    epochs = 50\n",
    "    steps_per_test = 1000\n",
    "    period_btw_summary_perfs = 1\n",
    "\n",
    "    # ----------------------\n",
    "    # Temporal Processing Parameters\n",
    "    # ----------------------\n",
    "    nstep = 20\n",
    "    nstep_decay = 0.8\n",
    "    encoder_type = 'variational'\n",
    "    \n",
    "    # ----------------------\n",
    "    # Environment Parameters\n",
    "    # ----------------------\n",
    "    frame_skip = 2\n",
    "    show_rewards = False\n",
    "\n",
    "    # ----------------------\n",
    "    # DQN Agent parameters:\n",
    "    # ----------------------\n",
    "    update_rule = 'rmsprop'\n",
    "    learning_rate = 1 * 1E-4\n",
    "    learning_rate_decay = 0.9\n",
    "    discount = 0.9\n",
    "    discount_inc = 1\n",
    "    discount_max = 0.99\n",
    "    rms_decay = 0.9\n",
    "    rms_epsilon = 0.0001\n",
    "    momentum = 0\n",
    "    clip_norm = 1.0\n",
    "    epsilon_start = 1.0\n",
    "    epsilon_min = 1.0\n",
    "    epsilon_decay = 1000\n",
    "    update_frequency = 1\n",
    "    replay_memory_size = 100000 #50000 #replacing with 200000 will works just fine (in case you dont have 18gb of memory)\n",
    "    batch_size = 64 #32\n",
    "    freeze_interval = 1000\n",
    "    deterministic = False\n",
    "    \n",
    "    # ----------------------\n",
    "    # Learning algo parameters\n",
    "    # ----------------------\n",
    "    #loss_weights = [5E-3, 1E-3, 5E-3, 5E-3, 5E-3, 5E-3, 1.]\n",
    "    #loss_weights = [0, 0, 0, 0, 0, 0, 1.]\n",
    "    loss_weights = [5E-3, 5E-3, 5E-3, 0, 5E-3, 1E-3, 1., 1E-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters hash is: 62977be8e45d8a56a5537c11dfd5d2fd8dda69e0\n",
      "The parameters are: <__main__.Defaults object at 0x13a4bb9d0>\n",
      "end gathering data\n"
     ]
    }
   ],
   "source": [
    "parameters = Defaults()\n",
    "if parameters.deterministic:\n",
    "    rng = np.random.RandomState(123456)\n",
    "else:\n",
    "    rng = np.random.RandomState()\n",
    "\n",
    "# --- Instantiate environment ---\n",
    "env = figure8_env(\n",
    "    give_rewards=figure8_give_rewards,\n",
    "    intern_dim=internal_dim,\n",
    "    higher_dim_obs=higher_dim_obs,\n",
    "    show_rewards=parameters.show_rewards,\n",
    "    nstep=parameters.nstep, nstep_decay=parameters.nstep_decay\n",
    "    )\n",
    "\n",
    "# --- Instantiate learning_algo ---\n",
    "learning_algo = CRAR(\n",
    "    env,\n",
    "    parameters.rms_decay,\n",
    "    parameters.rms_epsilon,\n",
    "    parameters.momentum,\n",
    "    parameters.clip_norm,\n",
    "    parameters.freeze_interval,\n",
    "    parameters.batch_size,\n",
    "    parameters.update_rule,\n",
    "    rng,\n",
    "    high_int_dim=False,\n",
    "    internal_dim=internal_dim, lr=parameters.learning_rate,\n",
    "    nn_yaml=nn_yaml, double_Q=True,\n",
    "    loss_weights=parameters.loss_weights,\n",
    "    nstep=parameters.nstep, nstep_decay=parameters.nstep_decay,\n",
    "    encoder_type=parameters.encoder_type\n",
    "    )\n",
    "\n",
    "if figure8_give_rewards:\n",
    "    train_policy = EpsilonGreedyPolicy(\n",
    "        learning_algo, env.nActions(), rng, 0.2,\n",
    "        consider_valid_transitions=False\n",
    "        )\n",
    "    test_policy = EpsilonGreedyPolicy(\n",
    "        learning_algo, env.nActions(), rng, 0.\n",
    "        )\n",
    "else:\n",
    "    train_policy = FixedFigure8Policy.FixedFigure8Policy(\n",
    "        learning_algo, env.nActions(), rng, epsilon=0.2,\n",
    "        height=env.HEIGHT, width=env.WIDTH\n",
    "        )\n",
    "    test_policy = FixedFigure8Policy.FixedFigure8Policy(\n",
    "        learning_algo, env.nActions(), rng,\n",
    "        height=env.HEIGHT, width=env.WIDTH\n",
    "        )\n",
    "\n",
    "# --- Instantiate agent ---\n",
    "agent = NeuralAgent(\n",
    "    env,\n",
    "    learning_algo,\n",
    "    parameters.replay_memory_size,\n",
    "    1,\n",
    "    parameters.batch_size,\n",
    "    rng,\n",
    "    train_policy=train_policy,\n",
    "    test_policy=test_policy)\n",
    "\n",
    "agent.setNetwork('saved')\n",
    "\n",
    "# --- Create unique filename for FindBestController ---\n",
    "h = hash(vars(parameters), hash_name=\"sha1\")\n",
    "fname = \"test_\" + h\n",
    "print(\"The parameters hash is: {}\".format(h))\n",
    "print(\"The parameters are: {}\".format(parameters))\n",
    "\n",
    "# As for the discount factor and the learning rate, one can update periodically the parameter of the epsilon-greedy\n",
    "# policy implemented by the agent. This controllers has a bit more capabilities, as it allows one to choose more\n",
    "# precisely when to update epsilon: after every X action, episode or epoch. This parameter can also be reset every\n",
    "# episode or epoch (or never, hence the resetEvery='none').\n",
    "agent.attach(bc.EpsilonController(\n",
    "    initial_e=parameters.epsilon_start,\n",
    "    e_decays=parameters.epsilon_decay,\n",
    "    e_min=parameters.epsilon_min,\n",
    "    evaluate_on='episode',\n",
    "    periodicity=1,\n",
    "    reset_every='none'))\n",
    "\n",
    "agent.run(10, 500)\n",
    "print(\"end gathering data\")\n",
    "\n",
    "# --- Bind controllers to the agent ---\n",
    "# Before every training epoch (periodicity=1), we want to print a summary of the agent's epsilon, discount and \n",
    "# learning rate as well as the training epoch number.\n",
    "agent.attach(bc.VerboseController(\n",
    "    evaluate_on='epoch', \n",
    "    periodicity=1))\n",
    "\n",
    "# Every epoch end, one has the possibility to modify the learning rate using a LearningRateController. Here we \n",
    "# wish to update the learning rate after every training epoch (periodicity=1), according to the parameters given.\n",
    "agent.attach(bc.LearningRateController(\n",
    "    initial_learning_rate=parameters.learning_rate, \n",
    "    learning_rate_decay=parameters.learning_rate_decay,\n",
    "    periodicity=1))\n",
    "\n",
    "# Same for the discount factor.\n",
    "agent.attach(bc.DiscountFactorController(\n",
    "    initial_discount_factor=parameters.discount, \n",
    "    discount_factor_growth=parameters.discount_inc, \n",
    "    discount_factor_max=parameters.discount_max,\n",
    "    periodicity=1))\n",
    "\n",
    "# During training epochs, we want to train the agent after every [parameters.update_frequency] action it takes.\n",
    "# Plus, we also want to display after each training episode (!= than after every training) the average bellman\n",
    "# residual and the average of the V values obtained during the last episode, hence the two last arguments.\n",
    "agent.attach(bc.TrainerController(\n",
    "    evaluate_on='action', \n",
    "    periodicity=parameters.update_frequency, \n",
    "    show_episode_avg_V_value=True, \n",
    "    show_avg_Bellman_residual=True))\n",
    "\n",
    "# We wish to discover, among all versions of our neural network (i.e., after every training epoch), which one \n",
    "# has the highest validation score.\n",
    "# To achieve this goal, one can use the FindBestController along with an InterleavedTestEpochControllers. It is \n",
    "# important that the validationID is the same than the id argument of the InterleavedTestEpochController.\n",
    "# The FindBestController will dump on disk the validation scores for each and every network, as well as the \n",
    "# structure of the neural network having the best validation score. These dumps can then used to plot the evolution \n",
    "# of the validation and test scores (see below) or simply recover the resulting neural network for your \n",
    "# application.\n",
    "agent.attach(bc.FindBestController(\n",
    "    validationID=figure8_env.VALIDATION_MODE,\n",
    "    testID=None,\n",
    "    unique_fname=fname))\n",
    "\n",
    "# All previous controllers control the agent during the epochs it goes through. However, we want to interleave a \n",
    "# \"validation epoch\" between each training epoch. For each validation epoch, we want also to display the sum of all \n",
    "# rewards obtained, hence the showScore=True. Finally, we want to call the summarizePerformance method of ALE_env \n",
    "# every [parameters.period_btw_summary_perfs] *validation* epochs.\n",
    "agent.attach(bc.InterleavedTestEpochController(\n",
    "    id=figure8_env.VALIDATION_MODE, \n",
    "    epoch_length=parameters.steps_per_test,\n",
    "    periodicity=1,\n",
    "    show_score=True,\n",
    "    summarize_every=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7025, -0.4656,  1.6450,  1.3993, -0.7933, -0.1965, -0.0157, -0.6956,\n",
      "         0.4271,  0.1160]) tensor([-0.1674, -0.5055,  1.6059,  1.3400, -0.7545, -0.1851, -0.0030, -0.7231,\n",
      "         0.7229,  0.1217]) tensor([-0.4830, -0.4513,  1.6309,  1.3870, -0.8058, -0.2255,  0.0095, -0.6919,\n",
      "         0.7994,  0.1073])\n",
      "R[0]\n",
      "tensor([-0.0048], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.030352426677942277 0.004225414296251983 0.027583783397218214 0.011717409119009972 0.07549799115210772 0.9459268748760223 0.015321112579666079 53.36420378112793\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0076, -1.0156,  1.1520,  0.1336,  0.0376, -0.0362,  0.0283, -0.8130,\n",
      "         0.3749,  0.4306]) tensor([-0.4009, -1.0005,  1.1698,  0.1883,  0.0560, -0.0056,  0.0320, -0.8164,\n",
      "         0.4256,  0.1624]) tensor([-0.3752, -0.9602,  1.0740,  0.0591,  0.1414, -0.0069,  0.0784, -0.8246,\n",
      "         0.3584, -0.0221])\n",
      "R[0]\n",
      "tensor([0.0037], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.03878197740018368 0.0037917914531353744 0.02075294778193347 0.00879412890598178 0.05350057913735509 0.8551802442073823 0.011467975246254355 52.33580683135986\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0929, -0.5399,  1.4834,  1.3790, -0.6645,  0.0224, -0.1268, -0.7769,\n",
      "         0.5387,  0.0571]) tensor([-0.2187, -0.5557,  1.4614,  1.3713, -0.6586,  0.0479, -0.1335, -0.8014,\n",
      "         0.7014,  0.1648]) tensor([-0.3242, -0.5978,  1.4251,  1.2741, -0.6941, -0.0501, -0.0098, -0.8643,\n",
      "         1.0630,  0.2195])\n",
      "R[0]\n",
      "tensor([0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.045944883853197095 0.0038586225777544315 0.012606669584056363 0.007867456602863967 0.04191091213747859 0.7506345653533936 0.009550994765944778 51.35488594055176\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8192, -0.7050,  1.2243,  1.2007, -0.7543, -0.0850, -0.0165, -0.8817,\n",
      "        -0.2264, -0.5349]) tensor([-0.2273, -0.7258,  1.2623,  1.1604, -0.7333, -0.1019, -0.0304, -0.8808,\n",
      "         0.4593,  0.0135]) tensor([-0.3524, -0.6919,  1.1939,  1.1327, -0.7180, -0.1259,  0.0394, -0.8472,\n",
      "         0.5001, -0.0412])\n",
      "R[0]\n",
      "tensor([-0.0085], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.04906932104378939 0.003498292824275268 0.010342184494133107 0.007303494303487241 0.038218212001025674 0.7415359649658203 0.00934018380055204 51.29610272979736\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8214, -0.7311,  1.3212,  1.0185, -0.7185, -0.0940,  0.2628, -1.1833,\n",
      "         0.8275,  0.2644]) tensor([-0.0648, -0.7196,  1.3256,  1.0007, -0.6914, -0.0521,  0.1794, -1.1655,\n",
      "         0.6787,  0.1002]) tensor([ 0.1222, -0.8050,  1.4573,  1.0162, -0.8072, -0.0984,  0.2271, -1.2665,\n",
      "         0.7221,  0.9054])\n",
      "R[0]\n",
      "tensor([0.0034], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.051752405092120174 0.0035099293478742764 0.008918220995954471 0.007263349711894989 0.035821191638708116 0.7103622705936432 0.009053961384110153 50.95495907592773\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9373, -0.7834,  1.0063,  0.8810, -0.7736, -0.0355,  0.2416, -1.4239,\n",
      "         0.0069,  0.4262]) tensor([-0.2048, -0.7453,  1.0456,  0.8564, -0.7401, -0.0632,  0.2465, -1.3425,\n",
      "         0.4078,  0.0135]) tensor([-0.0671, -0.6488,  1.0163,  0.9683, -0.8261, -0.1131,  0.1766, -1.2500,\n",
      "         0.2788, -0.0425])\n",
      "R[0]\n",
      "tensor([-0.0056], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05209719858318567 0.003443000880517502 0.007678968901920598 0.0068022655895911156 0.03561751229688525 0.7062009787559509 0.009080463712569327 50.86255773925781\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1531, -0.5698,  1.0999,  1.2720, -0.5062, -0.0023,  0.0857, -0.6925,\n",
      "        -0.0888,  0.2092]) tensor([-0.2586, -0.5927,  1.0960,  1.2103, -0.4754,  0.0024,  0.0955, -0.6977,\n",
      "         0.4263,  0.0185]) tensor([-0.2392, -0.5734,  1.0520,  1.2162, -0.4681, -0.0314,  0.1643, -0.6838,\n",
      "         0.2535,  0.0889])\n",
      "R[0]\n",
      "tensor([-0.0058], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05195494062453508 0.0033330428959889103 0.007471795595134608 0.007123867847025394 0.035410751644521954 0.6967003657817841 0.009110905338544398 50.49632012939453\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5799, -0.5610,  1.3566,  1.4405, -0.5198,  0.2279, -0.2741, -0.7107,\n",
      "         0.2425, -0.1935]) tensor([-0.1449, -0.6033,  1.3289,  1.3819, -0.5015,  0.2359, -0.2666, -0.7475,\n",
      "         0.6206,  0.1627]) tensor([-0.3006, -0.4658,  1.3634,  1.6079, -0.3919,  0.3786, -0.4197, -0.5344,\n",
      "         0.3042, -0.1820])\n",
      "R[0]\n",
      "tensor([-0.0061], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05245746160298586 0.003377857442395907 0.006608171409607166 0.007060875092167408 0.034744334749877454 0.6847402338981629 0.009010835734196008 50.19495608520508\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2616, -0.6434,  1.0707,  1.1599, -0.5655, -0.0791,  0.1889, -0.7899,\n",
      "        -0.1427,  0.2143]) tensor([-0.1798, -0.6592,  1.0952,  1.1307, -0.5841, -0.1053,  0.1753, -0.7959,\n",
      "         0.4233, -0.0275]) tensor([-0.6194, -0.6169,  0.9553,  1.1268, -0.5954,  0.1138, -0.0420, -1.0466,\n",
      "         0.2171, -0.1638])\n",
      "R[0]\n",
      "tensor([0.0055], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05231893035024405 0.0032436247563109644 0.0063367220115178495 0.0073881392562761905 0.03564029063284397 0.6854545112848281 0.009456888677552342 50.056897117614746\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1576, -0.4977,  1.2345,  0.9990, -0.8114, -0.3937,  0.5495, -0.9885,\n",
      "         0.8500, -0.6084]) tensor([-0.0748, -0.5067,  1.2246,  1.0043, -0.8296, -0.3898,  0.5160, -1.0128,\n",
      "         0.4151, -0.0836]) tensor([-0.4559, -0.4955,  1.2447,  1.0053, -0.8130, -0.3956,  0.5510, -0.9855,\n",
      "         0.3637,  0.1819])\n",
      "R[0]\n",
      "tensor([0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052471534475684166 0.0029533410819640267 0.0062885175750707276 0.006986455421894789 0.03521111333742738 0.6869440047740937 0.009376107954885811 49.91359848022461\n",
      "Average (on the epoch) training loss: 0.007830744185019285\n",
      "Episode average V value: 0\n",
      "epoch 1:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/miniforge3/envs/auxrl/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 2.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 1.9998000199980002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:279: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  abs_states[i:i+1], torch.as_tensor([action_encoding])\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0442, -0.1661,  1.4172,  1.4498, -0.7383, -0.2926, -0.0364, -0.3251,\n",
      "         0.3037,  0.1873]) tensor([-0.1036, -0.2485,  1.4099,  1.4063, -0.7471, -0.3041,  0.0411, -0.4222,\n",
      "         0.4491,  0.0308]) tensor([-0.4967, -0.3210,  1.5247,  1.5180, -0.7102, -0.0712, -0.2419, -0.4681,\n",
      "         0.4894,  0.0689])\n",
      "R[0]\n",
      "tensor([0.0022], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05199839198589325 0.002694318709329309 0.00655076961251325 0.00753559243073687 0.03532428617961705 0.678129638671875 0.009760236552916466 49.87619654083252\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1997, -0.5711,  1.0916,  1.2171, -0.4866, -0.0295,  0.1489, -0.6954,\n",
      "         0.3748, -0.1243]) tensor([-0.2222, -0.6083,  1.1236,  1.1845, -0.5067, -0.0399,  0.1476, -0.7317,\n",
      "         0.3907,  0.0466]) tensor([-0.4636, -0.6077,  1.0654,  1.1724, -0.5542, -0.1016,  0.1964, -0.7393,\n",
      "         0.2738,  0.0255])\n",
      "R[0]\n",
      "tensor([-0.0127], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053143586426973345 0.0027876238433673277 0.006330066554699442 0.006929231063462794 0.035328193068504335 0.6569881926774979 0.009672539731021971 49.61223990631103\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1093, -0.7182,  1.3142,  1.3558, -0.6668,  0.1153, -0.2651, -0.8232,\n",
      "         0.7962, -0.0977]) tensor([-0.2019, -0.7375,  1.3154,  1.2854, -0.6305,  0.0801, -0.1785, -0.8108,\n",
      "         0.5166,  0.1208]) tensor([ 0.0392, -0.7997,  1.1874,  1.2393, -0.6873,  0.0877, -0.2041, -0.9275,\n",
      "         0.6637,  0.5320])\n",
      "R[0]\n",
      "tensor([0.0017], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05285825172066688 0.0031521894268789767 0.006003971500133048 0.007419602393638342 0.035475258596241475 0.6704986844062805 0.009996750814840197 49.541968536376956\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6625, -0.6775,  1.2438,  1.1556, -0.7129, -0.1582,  0.0897, -0.8218,\n",
      "         0.7024,  0.0485]) tensor([-0.1273, -0.6795,  1.2242,  1.1359, -0.7053, -0.1680,  0.1001, -0.8240,\n",
      "         0.4205,  0.0017]) tensor([ 0.0249, -0.6752,  1.1838,  1.1452, -0.7090, -0.2040,  0.1625, -0.8119,\n",
      "         0.3882,  0.1689])\n",
      "R[0]\n",
      "tensor([-0.0056], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053110330909490584 0.002841824403636565 0.005911323145352071 0.007055343319429084 0.035054567702114584 0.6821469490528107 0.009773092209361494 49.57380099487305\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0699, -0.5893,  1.4349,  1.0679, -0.9330, -0.2877,  0.2527, -1.0862,\n",
      "         0.4914,  0.0762]) tensor([-0.0374, -0.5844,  1.3602,  1.0300, -0.8762, -0.2637,  0.2819, -1.0754,\n",
      "         0.4929, -0.0091]) tensor([ 0.5624, -0.5522,  1.3302,  1.0581, -0.9141, -0.2984,  0.2675, -1.0794,\n",
      "         0.7333, -0.7154])\n",
      "R[0]\n",
      "tensor([0.0018], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05406111659109592 0.003345392377654207 0.004929179661776289 0.007944600882939995 0.03444552344083786 0.7116396239995957 0.009381535514257848 49.584556434631345\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1948, -0.5256,  0.9703,  0.8420, -0.6631, -0.2794,  0.5960, -1.0032,\n",
      "        -0.0676, -0.6843]) tensor([-0.0997, -0.5207,  0.9913,  0.8425, -0.6493, -0.2597,  0.5745, -0.9984,\n",
      "         0.2108, -0.1423]) tensor([-0.0675, -0.5329,  0.9532,  0.7858, -0.6561, -0.1823,  0.4780, -1.1336,\n",
      "        -0.0925, -0.5985])\n",
      "R[0]\n",
      "tensor([-0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05331600246578455 0.0037957744756258764 0.005267719699171721 0.008091849395073951 0.03529389187321067 0.7466821637153626 0.009797560840379447 49.352722694396974\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1067, -0.6399,  1.1187,  1.1074, -0.6795, -0.2515,  0.2545, -0.7718,\n",
      "         0.8639, -0.0371]) tensor([-0.1614, -0.6473,  1.1493,  1.1106, -0.6939, -0.2527,  0.2339, -0.7873,\n",
      "         0.2954, -0.0419]) tensor([ 0.2245, -0.6375,  1.1289,  1.1111, -0.6925, -0.2595,  0.2525, -0.7668,\n",
      "         0.2911,  0.4854])\n",
      "R[0]\n",
      "tensor([0.0027], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053197074338793754 0.0035470005467032025 0.0051511918828909984 0.008275753531139345 0.03545977616682649 0.7557914073467255 0.009793095584027469 49.11297673034668\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5725, -0.6319,  1.4056,  1.0389, -0.8558, -0.2540,  0.4008, -1.1807,\n",
      "         0.5874, -0.0843]) tensor([ 0.0099, -0.5981,  1.3754,  1.0340, -0.8270, -0.2189,  0.3578, -1.1423,\n",
      "         0.5045, -0.0234]) tensor([ 0.0215, -0.5903,  1.3725,  1.0168, -0.8492, -0.2859,  0.4342, -1.1401,\n",
      "         0.2008,  0.2271])\n",
      "R[0]\n",
      "tensor([-0.0038], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05331113977730274 0.003089451541931339 0.004691143568532425 0.007952004316728562 0.03492972476780415 0.7806016149520874 0.00950705175101757 49.24942517089844\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3672, -0.5811,  1.2855,  0.9109, -0.7141, -0.1755,  0.4135, -1.0923,\n",
      "        -0.1043, -0.7183]) tensor([ 0.0229, -0.5692,  1.2856,  0.9382, -0.7112, -0.1446,  0.3850, -1.0926,\n",
      "         0.3818, -0.1107]) tensor([-5.4323e-04, -5.4018e-01,  1.1905e+00,  9.3662e-01, -6.3938e-01,\n",
      "        -1.4861e-01,  3.9871e-01, -9.7800e-01,  2.6279e-01, -1.6347e-01])\n",
      "R[0]\n",
      "tensor([5.1007e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05386829088628292 0.0034839686630621144 0.004517111842462327 0.0077049738266505305 0.03400390883535147 0.8072119072675705 0.009221443253103643 49.231245262146\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0037, -0.4928,  1.3255,  1.2214, -0.7410, -0.3145,  0.1869, -0.6429,\n",
      "         0.9177, -0.0942]) tensor([-0.1270, -0.5049,  1.3080,  1.1861, -0.7048, -0.2910,  0.1851, -0.6556,\n",
      "         0.3663, -0.0302]) tensor([ 0.4155, -0.4918,  1.3208,  1.2299, -0.7408, -0.3181,  0.1853, -0.6363,\n",
      "        -0.1001, -0.0813])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053572740234434604 0.0030946229390883674 0.004352937586343615 0.0075777067407034335 0.03491682012379169 0.8196001831293106 0.00942441586125642 48.96794416809082\n",
      "Average (on the epoch) training loss: 0.007648665790050291\n",
      "Episode average V value: 0\n",
      "epoch 2:\n",
      "Learning rate: 9e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 2.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 1.9998000199980002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4606, -0.4164,  1.3281,  1.0229, -0.7756, -0.4201,  0.5831, -0.9080,\n",
      "         0.5238,  0.3308]) tensor([ 0.0046, -0.4263,  1.3256,  1.0482, -0.8122, -0.3993,  0.5256, -0.9492,\n",
      "         0.3322, -0.0997]) tensor([ 0.2888, -0.4453,  1.3543,  1.0515, -0.7943, -0.4023,  0.5392, -0.9313,\n",
      "        -0.0319, -0.1637])\n",
      "R[0]\n",
      "tensor([0.0036], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05351440098136664 0.0030754895334466708 0.00546531065783347 0.0077868165918625895 0.03474021206796169 0.8323102221488953 0.009228115730918944 48.86151324462891\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1716, -0.5537,  1.5512,  1.3300, -0.6913, -0.0556, -0.1674, -0.6359,\n",
      "         0.8451, -0.5142]) tensor([-0.1385, -0.5729,  1.4919,  1.2897, -0.6543, -0.0396, -0.1323, -0.6641,\n",
      "         0.5751,  0.0617]) tensor([-1.8774e-01, -5.1646e-01,  1.4414e+00,  1.2820e+00, -7.2745e-01,\n",
      "        -1.8052e-01, -1.2858e-03, -6.3669e-01,  9.3877e-01, -1.6475e-01])\n",
      "R[0]\n",
      "tensor([-9.3788e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.054182470254600046 0.0030446111760029453 0.005035608786580269 0.007844034153036774 0.0348434769436717 0.8498309794664383 0.009332275775726885 48.78817206573486\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3361, -0.7324,  1.2289,  0.8064, -0.1840,  0.0104,  0.1903, -0.6152,\n",
      "        -0.1462,  0.0017]) tensor([-0.2624, -0.7457,  1.2216,  0.8030, -0.1872,  0.0289,  0.1681, -0.6365,\n",
      "         0.4044,  0.0179]) tensor([-0.0222, -0.9763,  1.3905,  0.3966,  0.1349,  0.1379, -0.0252, -0.6504,\n",
      "         0.7342, -0.0596])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05330364833027124 0.0032940246991202 0.005027872372316779 0.007848086030688137 0.03563102438673377 0.8438108443021775 0.009272962451446801 48.65082237243652\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0561, -0.6367,  1.4913,  1.1779, -0.7855, -0.1402,  0.0379, -0.9043,\n",
      "         0.9824,  0.5172]) tensor([-0.0237, -0.6484,  1.4462,  1.1152, -0.7493, -0.1531,  0.0937, -0.8966,\n",
      "         0.5231,  0.0210]) tensor([-0.9163, -0.5286,  1.4576,  1.2837, -0.7041, -0.1532,  0.0247, -0.7044,\n",
      "        -0.0380, -0.2872])\n",
      "R[0]\n",
      "tensor([-0.0058], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05332381311058998 0.0036366915985599916 0.004286887392212521 0.007816278255078942 0.03592487151548267 0.8439468098878861 0.009518797942902894 48.54840921020508\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4944, -0.6147,  1.1642,  1.0683, -0.7243, -0.2581,  0.2990, -0.8485,\n",
      "         0.4869, -0.2303]) tensor([-0.0516, -0.6052,  1.2045,  1.1020, -0.7489, -0.2543,  0.2638, -0.8502,\n",
      "         0.3295, -0.0610]) tensor([ 0.2455, -0.5821,  1.1713,  1.0547, -0.7525, -0.2974,  0.3400, -0.8637,\n",
      "        -0.0174,  0.6247])\n",
      "R[0]\n",
      "tensor([-0.0047], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052639738492667676 0.003296901235042242 0.004246843777269533 0.007569715738296508 0.035370759665966034 0.8375843274593353 0.009250902616418899 48.582985977172854\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2076, -0.5737,  1.0768,  0.9494, -0.5415, -0.2910,  0.3909, -0.6864,\n",
      "         0.1102,  0.1792]) tensor([-0.1256, -0.5730,  1.1549,  1.0075, -0.5663, -0.2501,  0.3378, -0.7121,\n",
      "         0.3098, -0.0672]) tensor([ 0.1805, -0.5825,  1.1796,  1.0624, -0.6390, -0.2682,  0.2834, -0.7050,\n",
      "         0.0256, -0.0803])\n",
      "R[0]\n",
      "tensor([0.0024], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052834843926131726 0.0032169258568028455 0.0035997794228460407 0.007326499928254634 0.03513210411369801 0.8252881696224212 0.008929698484949768 48.51648201751709\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2730, -1.0190,  1.2091,  0.0577, -0.1268,  0.1324,  0.3456, -1.6129,\n",
      "         0.5387,  0.2317]) tensor([-0.0599, -0.9409,  1.2118,  0.1933, -0.2140,  0.0769,  0.3724, -1.5543,\n",
      "         0.3936,  0.0915]) tensor([ 0.5075, -0.8897,  1.3166,  0.5260, -0.3565, -0.0445,  0.5602, -1.3302,\n",
      "         0.3359, -0.0318])\n",
      "R[0]\n",
      "tensor([-0.0056], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05303763743489981 0.002933548575703753 0.004080255302738806 0.00719180301297456 0.03553813851624727 0.7936983772516251 0.009078291226644069 48.22262728881836\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-7.2127e-04, -5.6535e-01,  1.2892e+00,  9.9751e-01, -8.4050e-01,\n",
      "        -3.0866e-01,  4.5358e-01, -1.0975e+00,  1.6576e-01,  1.6099e-01]) tensor([-0.0038, -0.5469,  1.2431,  0.9681, -0.7947, -0.2774,  0.4413, -1.0735,\n",
      "         0.3456, -0.0553]) tensor([-0.1523, -0.5153,  1.0764,  0.8590, -0.6531, -0.2889,  0.6518, -0.9993,\n",
      "         0.0534, -0.4075])\n",
      "R[0]\n",
      "tensor([-0.0053], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05310525981336832 0.003646666013793947 0.003664949980287929 0.007368557948619127 0.03504691804200411 0.7976051309108734 0.009149636105634271 48.18125052642822\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7615, -0.5402,  1.2441,  1.1102, -0.6251, -0.2153,  0.0896, -0.5556,\n",
      "         0.1652,  0.0899]) tensor([-7.4062e-02, -5.6823e-01,  1.2813e+00,  1.1327e+00, -6.4948e-01,\n",
      "        -2.0915e-01,  6.9230e-02, -6.0185e-01,  3.4545e-01, -4.2903e-04]) tensor([ 0.6428, -0.5570,  1.2077,  1.0508, -0.5953, -0.2261,  0.1196, -0.5404,\n",
      "         0.2506, -0.6336])\n",
      "R[0]\n",
      "tensor([-0.0133], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053173477239906786 0.003561815032098821 0.0033917122607599595 0.00730303696426563 0.03509183494001627 0.7815324944257737 0.009422239227220417 48.11626918029785\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3222, -0.8119,  1.0851,  0.8410, -0.7572, -0.0077,  0.3357, -1.5095,\n",
      "         0.1059,  0.5652]) tensor([ 0.0204, -0.7698,  1.0982,  0.8440, -0.7468, -0.0570,  0.3566, -1.4272,\n",
      "         0.3167, -0.0444]) tensor([ 0.3290, -0.8148,  1.0876,  0.8484, -0.7570, -0.0349,  0.3768, -1.4768,\n",
      "         0.7002, -0.2585])\n",
      "R[0]\n",
      "tensor([0.0009], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053052251994609834 0.003454926612026611 0.003656933411846694 0.00749812502367422 0.03601066211611032 0.7672143456935883 0.009144586098380387 47.93818123626709\n",
      "Average (on the epoch) training loss: 0.007555295364675112\n",
      "Episode average V value: 0\n",
      "epoch 3:\n",
      "Learning rate: 8.1e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 14.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 13.998600139986001 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2590, -0.6452,  1.3061,  1.0378, -0.6222, -0.1865,  0.1096, -0.6731,\n",
      "         0.1829,  0.1592]) tensor([-0.1039, -0.6589,  1.2860,  1.0579, -0.6451, -0.1841,  0.1111, -0.7102,\n",
      "         0.4185, -0.0035]) tensor([-0.1297, -0.6326,  1.2572,  1.0285, -0.6151, -0.2158,  0.1566, -0.6490,\n",
      "         0.1639,  0.1455])\n",
      "R[0]\n",
      "tensor([-0.0048], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052606833927333355 0.003407142484680662 0.004325878029674641 0.007192716043908149 0.03525588376075029 0.762849146604538 0.009110903750173748 47.89295104217529\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6630, -0.9089,  0.9464,  0.6169, -0.1692,  0.1039,  0.1370, -0.7955,\n",
      "         1.0198, -0.1051]) tensor([-0.2432, -0.8960,  1.0628,  0.7444, -0.2784,  0.0893,  0.0841, -0.8251,\n",
      "         0.2922,  0.0289]) tensor([-0.3590, -0.7177,  0.9690,  0.8381, -0.1448,  0.1828,  0.0644, -0.6329,\n",
      "         0.3444, -0.3384])\n",
      "R[0]\n",
      "tensor([-0.0100], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052792210653424265 0.002933495630612015 0.0041652821337629575 0.007055322197033092 0.03582242793589831 0.7622430555820465 0.009131390628870577 47.75682587432861\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4701, -0.6310,  1.4516,  1.2507, -0.7439, -0.0710, -0.0926, -0.8005,\n",
      "        -0.0053,  0.3586]) tensor([-0.0335, -0.6342,  1.4178,  1.2319, -0.7082, -0.0505, -0.0757, -0.8048,\n",
      "         0.4525,  0.0716]) tensor([ 0.0818, -0.6389,  1.4821,  1.3210, -0.7067,  0.0505, -0.2291, -0.7985,\n",
      "         0.4577,  0.5161])\n",
      "R[0]\n",
      "tensor([-0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052936581835150716 0.0034160486522359862 0.004242972934989666 0.007235641228267923 0.034975805919617416 0.765266698718071 0.009412667234428226 47.74901677703858\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1283, -0.4845,  1.4047,  1.2780, -0.7022, -0.1473,  0.0144, -0.6696,\n",
      "         0.0270,  0.2995]) tensor([-0.0559, -0.5153,  1.3583,  1.2516, -0.7108, -0.1511,  0.0205, -0.7079,\n",
      "         0.4444,  0.0359]) tensor([-0.9055, -0.6668,  1.4384,  1.1678, -0.7666, -0.1078, -0.0136, -0.8757,\n",
      "         0.9392,  0.7401])\n",
      "R[0]\n",
      "tensor([-0.0009], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05268406803905964 0.003730084206596075 0.0033886522257380422 0.007028151669539511 0.03525979717075825 0.7490581976175308 0.009071372585371136 47.7040050201416\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1970, -0.5778,  1.2930,  1.1884, -0.5265, -0.0070,  0.0360, -0.6437,\n",
      "         0.4550,  0.2151]) tensor([-0.1024, -0.6066,  1.2873,  1.1643, -0.5486, -0.0224,  0.0525, -0.6762,\n",
      "         0.4126,  0.0379]) tensor([ 0.1170, -0.5549,  1.4416,  1.3792, -0.6122,  0.0693, -0.1976, -0.6419,\n",
      "         0.7274, -0.1889])\n",
      "R[0]\n",
      "tensor([-0.0024], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0522558476626873 0.002974127251673053 0.0034866636677397763 0.006619845611276105 0.03550454350188374 0.744616211771965 0.009552333774510771 47.684019439697266\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3379, -0.6300,  1.2596,  1.0007, -0.8443, -0.2645,  0.4450, -1.1739,\n",
      "         0.4327, -0.2243]) tensor([ 0.0452, -0.6362,  1.2381,  0.9633, -0.8282, -0.2644,  0.4336, -1.1694,\n",
      "         0.2541, -0.0215]) tensor([-0.2257, -0.6124,  1.2711,  0.9963, -0.8452, -0.2705,  0.4491, -1.1721,\n",
      "         0.6867,  0.4496])\n",
      "R[0]\n",
      "tensor([-0.0069], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05278563342988491 0.003255473678033013 0.0031599709269066805 0.006511843090178445 0.035299928724765776 0.753146469116211 0.009553972962778061 47.65496332550049\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2282, -0.5946,  1.3128,  1.0834, -0.7191, -0.2599,  0.1569, -0.6991,\n",
      "         0.6723,  0.1735]) tensor([-0.0527, -0.6155,  1.3164,  1.0646, -0.7110, -0.2590,  0.1717, -0.7229,\n",
      "         0.2826,  0.0057]) tensor([ 0.0809, -0.5899,  1.2920,  1.0446, -0.6949, -0.2877,  0.2417, -0.6970,\n",
      "         0.3281,  0.1416])\n",
      "R[0]\n",
      "tensor([1.4924e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053209294736385346 0.003834561879060857 0.003394542001289665 0.00667852023569867 0.03509215002134442 0.7396538406610489 0.009837058454751968 47.596330993652344\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1269, -1.0926,  1.0417,  0.1935, -0.0675, -0.0394,  0.2689, -0.8140,\n",
      "         0.4823,  0.4080]) tensor([-0.2735, -1.0701,  1.1358,  0.3855, -0.1870, -0.0069,  0.1760, -0.8746,\n",
      "         0.3144,  0.0754]) tensor([ 0.0187, -0.9432,  1.0192,  0.3381, -0.1182, -0.0577,  0.2535, -0.6912,\n",
      "         0.0091,  0.3307])\n",
      "R[0]\n",
      "tensor([-0.0101], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05410005396604538 0.0035300629142257095 0.002946452804178989 0.006408392807003111 0.03440692198649049 0.7461095073223114 0.009677020024508237 47.56753887176514\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6512, -0.6283,  1.2513,  0.9866, -0.7933, -0.2323,  0.4970, -1.1934,\n",
      "         0.1042,  0.0632]) tensor([ 0.0495, -0.6365,  1.2337,  0.9595, -0.7975, -0.2361,  0.4748, -1.1930,\n",
      "         0.2826, -0.0153]) tensor([-0.1130, -0.6497,  1.2024,  0.9814, -0.8164, -0.2179,  0.4743, -1.2250,\n",
      "         0.4824, -0.8674])\n",
      "R[0]\n",
      "tensor([-0.0070], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05306008660048246 0.0036119263522887196 0.0027011303254694213 0.006579405773896724 0.034804013904184104 0.7275266293287277 0.009600801314692944 47.47995171356201\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2209, -0.6339,  1.2207,  0.9944, -0.8043, -0.2044,  0.3481, -1.1313,\n",
      "         0.6976, -1.0013]) tensor([-0.0099, -0.6285,  1.2350,  0.9600, -0.7810, -0.2052,  0.3305, -1.1042,\n",
      "         0.3095, -0.0980]) tensor([ 0.0371, -0.6221,  1.3095,  0.9951, -0.7898, -0.2285,  0.4604, -1.1743,\n",
      "         0.3420,  0.2447])\n",
      "R[0]\n",
      "tensor([-0.0018], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053431300796568396 0.0037236194488014006 0.002606324575488543 0.006539385946467519 0.0349058095626533 0.7153312335014343 0.00979944083886221 47.24159185028076\n",
      "Average (on the epoch) training loss: 0.006784922460326925\n",
      "Episode average V value: 0\n",
      "epoch 4:\n",
      "Learning rate: 7.290000000000001e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 7.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 6.999300069993001 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4001, -0.5041,  1.3490,  1.2146, -0.7346, -0.2152,  0.0597, -0.6470,\n",
      "         1.0009,  0.8121]) tensor([-0.0354, -0.5415,  1.3426,  1.1619, -0.7121, -0.2231,  0.1092, -0.6788,\n",
      "         0.3722,  0.0912]) tensor([ 0.2104, -0.4843,  1.3150,  1.1872, -0.7400, -0.2574,  0.1142, -0.6314,\n",
      "        -0.1334,  0.1354])\n",
      "R[0]\n",
      "tensor([-0.0037], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05344015694409609 0.004110423419091603 0.0033335831182339463 0.006944776912219822 0.034880387097597124 0.7053435447216034 0.010222952811513097 47.23030869293213\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0309, -0.7432,  1.2116,  0.9453, -0.8626, -0.1673,  0.3222, -1.2887,\n",
      "        -0.4030,  0.1618]) tensor([ 0.0618, -0.7203,  1.2004,  0.9399, -0.8492, -0.1838,  0.3233, -1.2423,\n",
      "         0.3147,  0.0019]) tensor([-0.0492, -0.7419,  1.0520,  0.9060, -0.7944, -0.1578,  0.4754, -1.3243,\n",
      "        -0.0916, -0.2636])\n",
      "R[0]\n",
      "tensor([-0.0009], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053476209588348866 0.00393399443211274 0.003380100574915559 0.0067200906707439575 0.03487098854407668 0.6995743517875671 0.010265755313448609 47.09954669189453\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5142, -0.6832,  1.1328,  1.0422, -0.5591, -0.0415,  0.0635, -0.7803,\n",
      "        -0.2244,  0.3375]) tensor([-0.0886, -0.6906,  1.1785,  1.0363, -0.5484, -0.0330,  0.0552, -0.7781,\n",
      "         0.2864,  0.0256]) tensor([-0.2905, -0.6477,  1.1463,  1.0360, -0.4404,  0.0116,  0.0479, -0.7042,\n",
      "         1.2332, -0.3899])\n",
      "R[0]\n",
      "tensor([0.0046], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05415058799088001 0.003976278821099186 0.0032098555311968085 0.006611376979621128 0.034151973597705367 0.6823394891619682 0.010122112152166664 46.99929148101807\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0508, -0.9005,  0.9742,  0.4546, -0.2070,  0.0496,  0.0699, -0.8923,\n",
      "         0.2901, -0.1863]) tensor([-0.2250, -0.8859,  1.0606,  0.5812, -0.2816,  0.0370,  0.0696, -0.9104,\n",
      "         0.2325,  0.1133]) tensor([-0.7485, -0.9348,  0.9921,  0.4607, -0.2168,  0.0126,  0.1202, -0.8490,\n",
      "         0.2146, -0.4469])\n",
      "R[0]\n",
      "tensor([-0.0175], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05340386086702347 0.003502891137581173 0.0035963240806740943 0.006417343833949417 0.03445443058758974 0.6829800465703011 0.010552627163007856 47.1464912033081\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9876, -0.7570,  1.1051,  0.7495, -0.2445,  0.0482,  0.0998, -0.6695,\n",
      "         0.6106,  0.0353]) tensor([-0.1776, -0.7647,  1.1045,  0.7348, -0.2388,  0.0702,  0.0647, -0.6838,\n",
      "         0.3031,  0.0416]) tensor([-0.2269, -0.8211,  1.0906,  0.6158, -0.2167, -0.0086,  0.1637, -0.6745,\n",
      "        -0.2253,  0.0540])\n",
      "R[0]\n",
      "tensor([-0.0047], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05369996006786823 0.0034708096354188456 0.003230936475436465 0.006606737511465326 0.03437302547320724 0.6899785276651382 0.010163765349425376 46.8873450012207\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 1.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4246, -0.1522,  0.7839,  0.8904, -0.6492, -0.3019,  0.1409, -0.4471,\n",
      "        -0.0892, -0.1784]) tensor([-0.0383, -0.2435,  0.9437,  1.0056, -0.7569, -0.3063,  0.1727, -0.6047,\n",
      "         0.0222, -0.1315]) tensor([-0.2845, -0.6672,  1.1430,  1.0653, -0.7407, -0.1078,  0.0298, -0.8656,\n",
      "         0.8823, -0.0067])\n",
      "R[0]\n",
      "tensor([0.0062], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05415001825988293 0.0037349769572811056 0.0028682768194776146 0.006624982181470842 0.03465489121899009 0.6777851228713989 0.010416101080365479 46.939271614074705\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3622, -0.7437,  1.2295,  0.9284, -0.5967, -0.1407,  0.0525, -0.7608,\n",
      "         0.1697, -0.3274]) tensor([-0.0442, -0.7510,  1.2292,  0.9331, -0.5839, -0.1309,  0.0713, -0.7760,\n",
      "         0.2953,  0.0818]) tensor([ 0.9992, -0.7220,  1.1397,  0.8999, -0.5930, -0.1646,  0.1240, -0.7615,\n",
      "        -0.3063,  0.2869])\n",
      "R[0]\n",
      "tensor([0.0027], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05491218686848879 0.004062358533392398 0.0028677472031267827 0.007096425225492566 0.03383934363350272 0.6934624485969544 0.010038826727773995 47.03743310546875\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 3.5689e-02, -7.2635e-01,  1.4929e+00,  1.2250e+00, -7.3450e-01,\n",
      "        -4.9085e-05, -2.2293e-01, -7.9180e-01,  6.0352e-01, -4.6283e-01]) tensor([ 3.9180e-04, -7.2687e-01,  1.4121e+00,  1.1870e+00, -7.1062e-01,\n",
      "        -2.7726e-02, -1.4173e-01, -7.9223e-01,  4.4550e-01,  1.0889e-01]) tensor([ 0.2250, -0.7181,  1.3626,  1.1012, -0.7372, -0.1314, -0.0143, -0.7912,\n",
      "         0.5228,  0.4495])\n",
      "R[0]\n",
      "tensor([-0.0024], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.054957621440291406 0.003725415239619906 0.002769569792846596 0.006772208088077605 0.03428863033093512 0.6797760446071625 0.010105343528557569 47.12988745880127\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0510, -0.7393,  1.1167,  0.8876, -0.7651, -0.0808,  0.3827, -1.4099,\n",
      "         0.5746,  0.7558]) tensor([ 0.0796, -0.7124,  1.1151,  0.8342, -0.7143, -0.0884,  0.3862, -1.3365,\n",
      "         0.2592, -0.0170]) tensor([-0.4997, -0.7220,  0.9343,  0.5009, -0.1872, -0.1531,  0.4193, -0.6326,\n",
      "        -0.3184, -0.1801])\n",
      "R[0]\n",
      "tensor([0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0547546573728323 0.004159702657932939 0.0032229546452363137 0.006965204558102414 0.03393643368408084 0.6869250911474228 0.010202856180723757 46.91120510101318\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7135, -0.4740,  0.9949,  0.6920, -0.4376, -0.1174,  0.0470, -0.7938,\n",
      "         0.2911,  0.1984]) tensor([-0.0332, -0.5126,  1.0495,  0.7710, -0.4899, -0.1094,  0.0603, -0.8803,\n",
      "         0.1257, -0.0311]) tensor([-0.2035, -0.6081,  1.2418,  1.2249, -0.7539, -0.1207, -0.0589, -0.7221,\n",
      "         0.0922, -0.0341])\n",
      "R[0]\n",
      "tensor([0.0232], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.054629834100604055 0.003909615274889802 0.002505502190964762 0.006889237402006984 0.033898162834346296 0.6729945522546769 0.009787149173673243 46.96391261291504\n",
      "Average (on the epoch) training loss: 0.006764838336315006\n",
      "Episode average V value: 0\n",
      "epoch 5:\n",
      "Learning rate: 6.561000000000002e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 50.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 49.99500049995 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2369, -0.6599,  1.1558,  1.0261, -0.6580, -0.1943,  0.1802, -0.7442,\n",
      "         0.3511, -0.2240]) tensor([-0.0607, -0.6814,  1.1873,  1.0426, -0.6716, -0.1923,  0.1869, -0.7772,\n",
      "         0.2349,  0.0075]) tensor([ 0.9743, -0.6304,  1.0475,  0.9908, -0.6159, -0.2370,  0.2831, -0.7068,\n",
      "         0.1296,  0.1150])\n",
      "R[0]\n",
      "tensor([0.0021], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05465754283964634 0.004287948152003083 0.0037573764743865467 0.007231499769957736 0.03370983035117388 0.6834487912654876 0.010145923571661115 46.65123282623291\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6985, -0.6738,  1.1544,  1.0488, -0.8145, -0.2276,  0.2404, -0.9635,\n",
      "        -0.5785,  0.1770]) tensor([-0.0188, -0.6718,  1.2091,  1.0096, -0.7637, -0.2327,  0.2293, -0.9085,\n",
      "         0.1437, -0.0174]) tensor([ 1.0466, -0.6822,  1.3198,  1.1162, -0.7491, -0.1623,  0.0694, -0.8222,\n",
      "         0.4422, -0.2809])\n",
      "R[0]\n",
      "tensor([0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.054241251230239866 0.0040786468063743085 0.0032385951951036988 0.006520539902150631 0.034025922633707524 0.6786530075073243 0.009753738150931895 46.51821115875244\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6520, -0.6519,  1.2252,  0.9413, -0.7819, -0.1752,  0.4366, -1.2509,\n",
      "         0.3075, -0.6350]) tensor([ 0.0890, -0.6291,  1.2064,  0.9089, -0.7371, -0.1620,  0.4041, -1.2032,\n",
      "         0.2627, -0.0201]) tensor([-0.0819, -0.5934,  1.1199,  0.9244, -0.7231, -0.2159,  0.5395, -1.1979,\n",
      "         0.8311, -0.1452])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.054509659186005595 0.004325223381292744 0.003158589226412005 0.006723485665163025 0.03416602250933647 0.6975511510372162 0.009596163899172097 46.562914710998534\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1316, -0.8011,  1.1945,  0.7236, -0.3366,  0.0023,  0.0900, -0.7322,\n",
      "        -0.0708, -0.3027]) tensor([-0.1030, -0.8222,  1.1952,  0.7644, -0.3751,  0.0280,  0.0604, -0.7954,\n",
      "         0.3642,  0.0959]) tensor([ 0.6106, -0.9342,  1.2655,  0.5761, -0.3135, -0.0180,  0.0911, -0.8050,\n",
      "         0.2616, -0.2889])\n",
      "R[0]\n",
      "tensor([0.0021], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05424436026066542 0.004063653682855147 0.003354920954472618 0.0067653740488458425 0.03505575647577643 0.687992216706276 0.00961179052432999 46.50877040863037\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1175, -0.6644,  1.3431,  1.1372, -0.7244, -0.1371,  0.0281, -0.7828,\n",
      "         0.2001, -0.2935]) tensor([-0.0233, -0.6572,  1.3356,  1.1334, -0.6905, -0.1091,  0.0301, -0.7800,\n",
      "         0.3577,  0.0832]) tensor([-0.3008, -0.6942,  1.4445,  1.1967, -0.7351, -0.0288, -0.1174, -0.8455,\n",
      "         0.3468, -0.1157])\n",
      "R[0]\n",
      "tensor([-0.0035], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05407919120788574 0.003982429587227671 0.002698811308851873 0.006183941284194589 0.0348389480561018 0.6847157940268517 0.009674745167139918 46.326248840332035\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5278, -0.6244,  1.3433,  1.0065, -0.8556, -0.2565,  0.4189, -1.1671,\n",
      "        -0.3146,  0.6496]) tensor([ 0.0551, -0.6187,  1.3449,  0.9748, -0.8302, -0.2677,  0.4082, -1.1285,\n",
      "         0.1422,  0.0692]) tensor([-0.2770, -0.6019,  1.2755,  1.0093, -0.8332, -0.2713,  0.4677, -1.1408,\n",
      "         0.6902,  0.1185])\n",
      "R[0]\n",
      "tensor([-0.0019], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.054125480353832245 0.004193889178017343 0.0032260401142775665 0.006324219970963895 0.034445937007665635 0.6532096886634826 0.00953317599091679 46.213001167297364\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3961, -0.6632,  1.0792,  0.9649, -0.4169,  0.0756,  0.0611, -0.7417,\n",
      "         0.6364, -0.2062]) tensor([-0.0609, -0.6740,  1.0963,  0.9559, -0.4177,  0.0942,  0.0339, -0.7598,\n",
      "         0.2754,  0.0391]) tensor([ 0.6079, -0.6690,  1.1906,  0.8637, -0.5054, -0.0563,  0.0861, -0.7647,\n",
      "        -0.0335, -0.3712])\n",
      "R[0]\n",
      "tensor([6.4820e-06], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053995409660041335 0.0036500792334372817 0.0023004485886267503 0.005864127183333039 0.03506376202777028 0.6549425671100616 0.009747147935442627 46.22465887451172\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1887, -0.7375,  1.2991,  1.0006, -0.3985,  0.1013, -0.1779, -0.6938,\n",
      "         0.4334,  0.3900]) tensor([-0.1060, -0.7602,  1.2645,  0.9554, -0.3940,  0.0775, -0.1315, -0.7111,\n",
      "         0.3570,  0.0807]) tensor([ 0.0993, -0.7385,  1.1948,  1.0597, -0.5432,  0.0475, -0.1041, -0.7852,\n",
      "         0.8412,  0.0033])\n",
      "R[0]\n",
      "tensor([-0.0034], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0541983550041914 0.004023743711321004 0.003149677525558218 0.006004624102264643 0.03441981128230691 0.6597062598466873 0.009467770107090474 46.15668635559082\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1256, -0.6453,  1.1636,  1.0020, -0.8594, -0.2769,  0.4836, -1.1833,\n",
      "         0.7621,  0.0319]) tensor([ 0.1223, -0.6168,  1.1829,  1.0068, -0.8330, -0.2470,  0.4354, -1.1460,\n",
      "         0.1864, -0.0201]) tensor([-0.1796, -0.5727,  1.2906,  1.1150, -1.0304, -0.3523,  0.2139, -1.0264,\n",
      "        -0.2318, -0.0670])\n",
      "R[0]\n",
      "tensor([-0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05453140687197447 0.0037248169438680633 0.003112985718966229 0.005641883396776393 0.03431088402122259 0.6602823173999787 0.009214623815380036 46.06174645233154\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1512, -0.6398,  1.4059,  1.2806, -0.7986, -0.0355, -0.2513, -0.7640,\n",
      "         0.1811, -0.4205]) tensor([ 0.0389, -0.6470,  1.3445,  1.2566, -0.7826, -0.0578, -0.1757, -0.7762,\n",
      "         0.3869,  0.0816]) tensor([-0.3629, -0.7192,  1.2288,  1.1364, -0.7546, -0.1075, -0.0347, -0.8382,\n",
      "         0.3444,  0.1063])\n",
      "R[0]\n",
      "tensor([-0.0070], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05471793595701456 0.0038199748041715794 0.0026311243390446178 0.0057866494373884055 0.033596224542707206 0.6601062960624695 0.009082836952991783 46.08955996704101\n",
      "Average (on the epoch) training loss: 0.0063046344761038195\n",
      "Episode average V value: 0\n",
      "epoch 6:\n",
      "Learning rate: 5.904900000000002e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 26.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 25.997400259974004 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4906, -1.2077,  1.7338,  0.4944, -0.2838,  0.0784,  0.2049, -1.2376,\n",
      "         1.4229,  0.4229]) tensor([-0.0206, -1.1535,  1.6416,  0.5212, -0.2790,  0.1162,  0.1825, -1.2231,\n",
      "         0.7576,  0.2808]) tensor([ 0.0746, -1.3307,  1.7914,  0.3676, -0.1924,  0.1205,  0.1970, -1.3048,\n",
      "         0.7278,  0.2200])\n",
      "R[0]\n",
      "tensor([-5.0046e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05499792963266373 0.0036458955029775096 0.003639038102242921 0.0060910001888405535 0.033907878648489716 0.6472731496095657 0.008565362791065127 45.902900154113766\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0698, -0.7018,  1.4727,  1.2591, -0.8007,  0.0486, -0.3318, -0.8668,\n",
      "         0.3478,  0.1265]) tensor([ 0.0130, -0.6992,  1.3974,  1.2055, -0.7543,  0.0119, -0.2092, -0.8462,\n",
      "         0.3972,  0.0734]) tensor([-0.2516, -0.8581,  1.6086,  1.2424, -0.7614,  0.1990, -0.4866, -0.9943,\n",
      "        -0.2843, -0.2267])\n",
      "R[0]\n",
      "tensor([3.1702e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05491480223834515 0.003609601545103942 0.0028070340070989915 0.005907794028520584 0.03376552136614919 0.622496064722538 0.008818040128331631 45.55972649383545\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2785, -0.7099,  1.2001,  1.1358, -0.6870, -0.0341, -0.0915, -0.8079,\n",
      "         0.3154,  0.3347]) tensor([-0.0134, -0.7138,  1.1939,  1.1078, -0.6596, -0.0576, -0.0286, -0.7919,\n",
      "         0.2477, -0.0128]) tensor([ 0.1324, -0.7266,  1.1600,  1.0486, -0.6673, -0.0741, -0.0257, -0.8015,\n",
      "         0.4367,  0.3824])\n",
      "R[0]\n",
      "tensor([-0.0024], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.055251918412745 0.0038924135200832095 0.0031724653626442885 0.005947134392801672 0.03326955528929829 0.6135471270084382 0.008314908143598585 45.24758915710449\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1504, -0.6865,  1.3557,  1.3235, -0.6355,  0.2129, -0.3586, -0.8604,\n",
      "         0.4320,  0.3848]) tensor([-0.0206, -0.6846,  1.2919,  1.2454, -0.5824,  0.2057, -0.3274, -0.8378,\n",
      "         0.4128,  0.0487]) tensor([ 0.2435, -0.7763,  1.4641,  1.1807, -0.7953,  0.0131, -0.1885, -0.9738,\n",
      "         0.8874,  0.2996])\n",
      "R[0]\n",
      "tensor([0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.055243295289576055 0.0037320116498012795 0.0026467283907986713 0.005610993913142011 0.033797210806980726 0.5955727114081383 0.008362646393943579 44.92729730987549\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0373, -0.6564,  1.4703,  1.3179, -0.7312,  0.1016, -0.3726, -0.7796,\n",
      "         0.5334,  0.2058]) tensor([-0.0041, -0.6561,  1.4038,  1.2748, -0.6869,  0.1081, -0.3247, -0.7846,\n",
      "         0.4241,  0.0739]) tensor([ 0.0150, -0.4068,  1.5862,  1.4028, -0.6901,  0.1856, -0.5300, -0.7328,\n",
      "         0.6641,  0.0988])\n",
      "R[0]\n",
      "tensor([-0.0041], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05500795708596706 0.00398892516880369 0.002304638213630824 0.0058403695703018454 0.03334783848747611 0.5870887340307236 0.008533808081410825 44.63797811126709\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0482, -0.7472,  1.5564,  1.0444, -0.8653, -0.1504,  0.2957, -1.2851,\n",
      "         0.1327,  0.0617]) tensor([ 0.1123, -0.7126,  1.4394,  0.9677, -0.8116, -0.1602,  0.3340, -1.2307,\n",
      "         0.3860,  0.0640]) tensor([-0.0675, -0.8128,  1.5585,  1.1072, -0.8722, -0.0455, -0.0290, -1.1575,\n",
      "        -0.4073, -0.0867])\n",
      "R[0]\n",
      "tensor([-0.0032], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.054820885106921194 0.004648049755480315 0.0028138082208242847 0.005906157846562564 0.033778089316561816 0.5725921040177345 0.008493366509675979 44.44588034820556\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1053, -0.5513,  1.2419,  1.1382, -0.6702, -0.1880,  0.1079, -0.6712,\n",
      "         0.6180, -0.1618]) tensor([-0.0158, -0.5640,  1.2162,  1.1389, -0.6819, -0.1861,  0.1118, -0.7060,\n",
      "         0.1509,  0.0014]) tensor([-0.5604, -0.5507,  1.2069,  1.1258, -0.6689, -0.2109,  0.1380, -0.6783,\n",
      "         0.0665, -0.0072])\n",
      "R[0]\n",
      "tensor([-0.0083], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.054387995906174186 0.003820795873143652 0.0024878196300815035 0.005591423184610903 0.033652171947062014 0.5684705914258957 0.008437983811832965 44.151033882141114\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0526, -0.4991,  1.1489,  0.9650, -0.7923, -0.3119,  0.5191, -1.0748,\n",
      "         0.1797,  0.0654]) tensor([ 0.0983, -0.5040,  1.1408,  0.9434, -0.7885, -0.3106,  0.5130, -1.0784,\n",
      "         0.1104, -0.0760]) tensor([ 0.1270, -0.4244,  1.0074,  0.9506, -0.7701, -0.3274,  0.5379, -0.9844,\n",
      "        -0.2997, -0.5234])\n",
      "R[0]\n",
      "tensor([0.0016], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.054639253683388234 0.004221350255464131 0.0029034374542134173 0.005702586836647242 0.03346906407177448 0.5675059599876404 0.008424725515767933 43.99087815093994\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6625, -0.8087,  1.3806,  1.0452, -0.6812,  0.0049, -0.1313, -0.9141,\n",
      "         0.2095, -0.4793]) tensor([-0.0354, -0.7772,  1.3264,  1.0052, -0.6142,  0.0061, -0.0998, -0.8528,\n",
      "         0.3642,  0.0597]) tensor([-0.3378, -0.7132,  1.5416,  1.0176, -0.6952, -0.0194, -0.1381, -0.9585,\n",
      "         0.6225,  0.0406])\n",
      "R[0]\n",
      "tensor([-0.0029], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05413441253453493 0.0042265032521281685 0.0025328111499911756 0.006125175196444616 0.0344012145884335 0.5670416507124901 0.008472994198091327 43.9527159576416\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0935, -0.7312,  1.2784,  1.1543, -0.7221, -0.0055, -0.1513, -0.8325,\n",
      "         0.5132, -0.0311]) tensor([-0.0422, -0.7346,  1.2479,  1.1109, -0.6859, -0.0365, -0.0698, -0.8091,\n",
      "         0.2701,  0.0179]) tensor([-0.2019, -0.7273,  1.1188,  1.0422, -0.6777, -0.0877,  0.0361, -0.8270,\n",
      "         0.0560, -0.3207])\n",
      "R[0]\n",
      "tensor([0.0053], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05388123881071806 0.004103205843566684 0.0024291852932219627 0.0058581046499311925 0.0337460600733757 0.5649018489718437 0.008550278156064451 43.80643515777588\n",
      "Average (on the epoch) training loss: 0.005858073980780318\n",
      "Episode average V value: 0\n",
      "epoch 7:\n",
      "Learning rate: 5.314410000000002e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 64.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 63.993600639936005 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2755, -1.1637,  1.0123,  0.0260,  0.0697, -0.0471,  0.4730, -0.9172,\n",
      "         0.4305,  0.4304]) tensor([-2.4340e-01, -1.1130e+00,  1.0956e+00,  2.2806e-01, -4.5176e-02,\n",
      "        -8.8833e-05,  3.6179e-01, -9.4774e-01,  2.2437e-01,  6.2476e-02]) tensor([-0.7514, -0.9706,  1.0495,  0.4186, -0.2382, -0.0628,  0.3256, -0.9042,\n",
      "         0.0371,  0.4421])\n",
      "R[0]\n",
      "tensor([0.0072], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053540505811572076 0.0035099637223102035 0.003254573781901854 0.00573328065732494 0.03417489617317915 0.5404889825582504 0.007992826852481812 43.574907363891604\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3569, -0.5724,  1.0507,  0.8670, -0.7308, -0.2228,  0.5535, -1.2151,\n",
      "         0.3281,  0.2682]) tensor([ 0.0642, -0.5400,  1.0452,  0.8459, -0.6957, -0.2053,  0.5129, -1.1596,\n",
      "         0.0800, -0.0683]) tensor([ 0.3068, -0.5821,  1.0673,  0.8768, -0.7443, -0.2052,  0.5084, -1.2737,\n",
      "         0.4705,  0.3662])\n",
      "R[0]\n",
      "tensor([0.0014], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05354849214851856 0.004595148312255333 0.002819722952961456 0.0061347622545436025 0.03414999819546938 0.5366147733330726 0.008234130886383355 43.5615477142334\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0042, -0.7726,  1.2201,  1.1096, -0.6939, -0.0213, -0.0748, -0.8537,\n",
      "         0.6031,  0.0384]) tensor([-0.0276, -0.7498,  1.1809,  1.0981, -0.6690, -0.0410, -0.0358, -0.8170,\n",
      "         0.2288,  0.0036]) tensor([ 0.4799, -0.7450,  1.0977,  1.0594, -0.6928, -0.0456, -0.0192, -0.8585,\n",
      "         0.0086, -0.2741])\n",
      "R[0]\n",
      "tensor([-0.0040], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05362787038832903 0.003967387519052863 0.0033769045500594073 0.006043036691145971 0.03403279735147953 0.53999427485466 0.00821532631944865 43.328227310180665\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4842, -0.6948,  0.9987,  0.6873, -0.6704, -0.0667,  0.4385, -1.4705,\n",
      "        -0.3241,  0.0112]) tensor([ 0.0381, -0.6437,  0.9786,  0.6505, -0.6088, -0.0615,  0.4089, -1.3677,\n",
      "         0.1625, -0.0113]) tensor([ 0.4948, -0.6482,  0.9718,  0.6873, -0.6815, -0.0374,  0.3516, -1.4985,\n",
      "        -0.2762, -0.1078])\n",
      "R[0]\n",
      "tensor([0.0010], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053445848673582076 0.004361196023288358 0.0026772003999358278 0.006212974473368376 0.03407345137372613 0.5345222536325455 0.008310875329189003 43.24334588623047\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0958, -0.6608,  1.1974,  0.9289, -0.8001, -0.2113,  0.4848, -1.2702,\n",
      "         0.3455, -0.1649]) tensor([ 0.0792, -0.6434,  1.1595,  0.8958, -0.7807, -0.2209,  0.4892, -1.2333,\n",
      "         0.1802, -0.0342]) tensor([-0.2088, -0.7416,  1.0881,  0.8296, -0.7520, -0.0971,  0.4080, -1.4430,\n",
      "         0.2354, -0.0978])\n",
      "R[0]\n",
      "tensor([0.0008], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05310190144181252 0.0045889400429405215 0.002623587532554666 0.006380460065323859 0.03479701682552695 0.5350364184975624 0.00831214307108894 43.20728929901123\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1064, -1.1350,  1.1030,  0.1014, -0.1786, -0.0728, -0.0388, -0.7710,\n",
      "         0.1509, -0.4239]) tensor([-0.2559, -1.0870,  1.1466,  0.2232, -0.1559, -0.0220, -0.0500, -0.7473,\n",
      "         0.2573,  0.1157]) tensor([ 0.2754, -0.8048,  0.9439,  0.4528, -0.3315, -0.1507, -0.1987, -0.3784,\n",
      "        -0.0180, -0.1425])\n",
      "R[0]\n",
      "tensor([0.0060], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05299706285446882 0.004177938534103305 0.0029125410985907365 0.005931134919635952 0.034527946151793006 0.5077216728329659 0.008328737147618085 43.10111415100098\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3574, -0.6551,  1.1135,  0.8959, -0.5018, -0.1181, -0.0385, -0.5322,\n",
      "        -0.1499,  0.3502]) tensor([-0.1039, -0.6700,  1.1281,  0.9440, -0.5293, -0.1167, -0.0205, -0.5796,\n",
      "         0.1914, -0.0483]) tensor([ 0.8349, -0.6266,  1.1078,  0.9546, -0.4962, -0.1027, -0.0430, -0.5211,\n",
      "         0.0061, -0.1459])\n",
      "R[0]\n",
      "tensor([-0.0171], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05297848215699196 0.003875110973345727 0.0023499781294995044 0.005671452293405309 0.03470994654670358 0.5343995127081871 0.008334517731331289 43.223867561340334\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4925, -0.7075,  1.1472,  0.8014, -0.7498, -0.0090,  0.3008, -1.5271,\n",
      "        -0.3231,  0.1670]) tensor([ 0.0635, -0.6738,  1.1422,  0.7530, -0.6909, -0.0182,  0.2910, -1.4308,\n",
      "         0.2073,  0.0346]) tensor([ 0.1232, -0.6884,  1.0804,  0.7595, -0.6953, -0.0264,  0.3879, -1.5270,\n",
      "         0.4966,  0.3899])\n",
      "R[0]\n",
      "tensor([-0.0021], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052621201813220976 0.0038790054078999673 0.0024826278131040453 0.005649384669959545 0.034832687016576526 0.5209187704920769 0.008422052313573658 43.21052236938477\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2244, -0.7359,  1.0921,  0.8609, -0.7649, -0.1152,  0.4496, -1.4218,\n",
      "         0.1759, -0.4739]) tensor([ 0.0496, -0.7000,  1.0763,  0.8533, -0.7518, -0.1386,  0.4413, -1.3503,\n",
      "         0.1341,  0.0053]) tensor([ 0.5983, -0.6977,  1.2343,  0.9604, -0.8190, -0.1905,  0.4350, -1.2934,\n",
      "         0.9294,  0.2813])\n",
      "R[0]\n",
      "tensor([0.0078], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05306671107560396 0.0037537694420752814 0.002761622107533185 0.005721996060572564 0.034026072572916746 0.510290749013424 0.008486450978554785 43.00667765045166\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3680, -0.7011,  1.1156,  0.8382, -0.7600, -0.0520,  0.3140, -1.4546,\n",
      "        -0.0542,  0.3683]) tensor([ 0.0371, -0.6677,  1.0969,  0.7988, -0.7039, -0.0450,  0.2931, -1.3811,\n",
      "         0.1724, -0.0075]) tensor([ 0.3760, -0.6706,  1.1754,  0.8179, -0.7541, -0.0527,  0.3140, -1.4399,\n",
      "         0.4373,  0.0368])\n",
      "R[0]\n",
      "tensor([0.0013], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0526433689892292 0.003746023748699372 0.002557996427618491 0.005527289149118588 0.034809267159551384 0.5175019124150276 0.008530420030932873 43.15331703948975\n",
      "Average (on the epoch) training loss: 0.005900577123439871\n",
      "Episode average V value: 0\n",
      "epoch 8:\n",
      "Learning rate: 4.782969000000002e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 99.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 98.99010098990101 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1173, -0.5101,  1.1152,  0.9552, -0.8195, -0.3738,  0.5918, -1.0237,\n",
      "        -0.2215, -0.2401]) tensor([ 0.0513, -0.5074,  1.0951,  0.9644, -0.8324, -0.3520,  0.5506, -1.0487,\n",
      "         0.0575, -0.0457]) tensor([-0.2568, -0.5252,  1.1294,  0.9361, -0.8130, -0.3781,  0.5827, -1.0254,\n",
      "        -0.2140, -0.5821])\n",
      "R[0]\n",
      "tensor([-0.0001], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05360113993287086 0.00485722878407978 0.003229791264217056 0.006360047461465001 0.03435185860656202 0.4906564502120018 0.00850651432806626 42.96613729858399\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4613, -0.4012,  0.9047,  0.8792, -0.7250, -0.3321,  0.5862, -0.8787,\n",
      "        -0.2210, -0.4195]) tensor([ 0.0136, -0.4106,  0.9757,  0.9292, -0.7446, -0.2982,  0.5439, -0.9071,\n",
      "        -0.0176, -0.0913]) tensor([-0.1042, -0.4701,  1.0246,  0.8664, -0.7323, -0.3687,  0.6722, -0.9777,\n",
      "         0.6636,  0.7222])\n",
      "R[0]\n",
      "tensor([-0.0057], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05325463430583477 0.004401391148086986 0.0026645566718907503 0.005877018206985668 0.034063286336138844 0.48766515010595324 0.008262974518816918 43.033411628723144\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1413, -0.6234,  1.1087,  0.8313, -0.7285, -0.1514,  0.4854, -1.3003,\n",
      "         0.1518, -0.2134]) tensor([ 0.0209, -0.5855,  1.0789,  0.8150, -0.6904, -0.1344,  0.4560, -1.2436,\n",
      "         0.1276, -0.0141]) tensor([ 0.4848, -0.4766,  0.9858,  0.7732, -0.5787, -0.0817,  0.5094, -1.3326,\n",
      "        -0.5138,  0.2735])\n",
      "R[0]\n",
      "tensor([0.0050], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053168423615396025 0.004016895580542041 0.0032757173963545937 0.005992163941031322 0.033994800832122564 0.49470133727788923 0.00832682232838124 43.017600021362306\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1598, -0.4486,  0.9013,  0.8641, -0.7206, -0.2886,  0.5774, -0.9491,\n",
      "        -0.2947, -0.2302]) tensor([ 0.0202, -0.4814,  0.9624,  0.8981, -0.7650, -0.2725,  0.5372, -1.0090,\n",
      "         0.0081, -0.1083]) tensor([ 0.5057, -0.3160,  0.7531,  0.9269, -0.7305, -0.2624,  0.4537, -0.7503,\n",
      "        -0.0452, -0.1315])\n",
      "R[0]\n",
      "tensor([0.0047], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05272778552770615 0.00383320848596486 0.0026313976167548388 0.005579247727291658 0.03453634697198868 0.4856498664021492 0.00842969410866499 42.91402600097656\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0594, -0.5391,  1.3042,  1.2381, -0.6566, -0.0400, -0.1235, -0.6158,\n",
      "         0.3945, -0.2605]) tensor([-0.0619, -0.5592,  1.2301,  1.1978, -0.6508, -0.0493, -0.0786, -0.6586,\n",
      "         0.2213,  0.0414]) tensor([-1.0460, -0.5767,  1.3587,  1.2243, -0.6831, -0.0340, -0.1422, -0.6583,\n",
      "         0.1459,  0.3869])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05309236856549978 0.003995507468807773 0.00247241685714107 0.005960800958564505 0.03449688616767526 0.48868296593427657 0.008800120898056775 42.92780220031738\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2176, -0.4923,  1.1101,  0.9403, -0.7719, -0.3960,  0.6490, -0.9887,\n",
      "         0.1679,  0.0392]) tensor([ 0.0307, -0.4956,  1.1012,  0.9621, -0.8006, -0.3660,  0.5878, -1.0327,\n",
      "         0.0071, -0.1004]) tensor([ 0.3509, -0.5272,  1.0857,  0.9231, -0.7870, -0.3703,  0.6226, -1.0349,\n",
      "         0.1920, -0.3034])\n",
      "R[0]\n",
      "tensor([-0.0017], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053154936864972115 0.003433772073523869 0.0027556508982306696 0.005665990861132741 0.034127036033198235 0.4868248812556267 0.008674753434490413 42.850384941101076\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5452, -0.5465,  0.9668,  0.9458, -0.5304, -0.1819,  0.0708, -0.4704,\n",
      "        -0.9309,  0.1599]) tensor([ 0.0085, -0.6023,  1.0281,  0.9802, -0.5793, -0.1922,  0.1009, -0.5514,\n",
      "        -0.0438,  0.0085]) tensor([-0.2112, -0.5794,  0.9527,  0.8826, -0.4979, -0.1969,  0.1028, -0.4918,\n",
      "        -0.9529,  0.3580])\n",
      "R[0]\n",
      "tensor([-0.0025], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05336579032987356 0.004529644289308635 0.0024499340344518714 0.006027257992420346 0.034184656269848346 0.4868132948875427 0.008740723179653288 42.78257318878174\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1549, -0.6310,  1.1813,  1.1611, -0.6685, -0.0517, -0.0903, -0.7103,\n",
      "        -0.0117,  0.3604]) tensor([-0.0753, -0.6272,  1.1659,  1.1310, -0.6247, -0.0410, -0.0805, -0.6916,\n",
      "         0.1961, -0.0182]) tensor([-0.0441, -0.3964,  1.3197,  1.3869, -0.6179,  0.0459, -0.3344, -0.4375,\n",
      "         0.5119, -0.1308])\n",
      "R[0]\n",
      "tensor([0.0028], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053038330309092996 0.003704153910453897 0.0025302012889587785 0.0056153542017564175 0.033912407904863356 0.479556394636631 0.008659949813038111 42.811817764282225\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3678, -0.5763,  1.1740,  0.9633, -0.8187, -0.3364,  0.5547, -1.0785,\n",
      "        -0.4458,  0.0657]) tensor([ 0.0576, -0.5493,  1.1588,  0.9562, -0.7877, -0.3099,  0.5224, -1.0445,\n",
      "         0.0863, -0.0796]) tensor([-0.2917, -0.5307,  1.0700,  0.8874, -0.7372, -0.3175,  0.6444, -1.0538,\n",
      "         0.0060,  0.1391])\n",
      "R[0]\n",
      "tensor([0.0023], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05282029793411493 0.004184855693078134 0.0027934549513483945 0.005704262232873589 0.03395113540440798 0.4820591307282448 0.008794044769834726 42.7957396774292\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1884, -0.7566,  1.3680,  1.0069, -0.9108, -0.1778,  0.2058, -1.2029,\n",
      "        -0.1426, -0.3867]) tensor([ 0.0326, -0.7086,  1.3250,  0.9954, -0.8484, -0.1602,  0.2163, -1.1309,\n",
      "         0.2615,  0.0132]) tensor([ 0.7738, -0.7002,  1.2188,  0.9945, -0.8449, -0.2071,  0.3380, -1.1636,\n",
      "        -0.7104, -0.0132])\n",
      "R[0]\n",
      "tensor([0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05367564687132836 0.003860452430864825 0.002519010938180145 0.005636828386690468 0.033700011637061836 0.4805525460243225 0.008440263902768492 42.71280348205566\n",
      "Average (on the epoch) training loss: 0.0058418971970211715\n",
      "Episode average V value: 0\n",
      "epoch 9:\n",
      "Learning rate: 4.304672100000002e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 98.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 97.99020097990201 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6876, -0.5815,  1.1421,  0.9636, -0.8039, -0.3142,  0.5644, -1.1189,\n",
      "        -0.1134, -0.1040]) tensor([ 0.0582, -0.5575,  1.1537,  0.9685, -0.7836, -0.2859,  0.5251, -1.0888,\n",
      "         0.1034, -0.0257]) tensor([-0.3876, -0.5974,  1.1368,  0.9496, -0.8155, -0.3124,  0.5441, -1.1137,\n",
      "         0.0883,  0.5951])\n",
      "R[0]\n",
      "tensor([0.0040], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05317619341611862 0.0037479404478235664 0.0025616503708770326 0.005620019535999745 0.033678467635065316 0.4786956864595413 0.008528361968230456 42.67402359008789\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3452, -0.5030,  1.1317,  0.9496, -0.8179, -0.3729,  0.5869, -1.0255,\n",
      "         0.0819,  0.4454]) tensor([ 0.0688, -0.5058,  1.1208,  0.9589, -0.8380, -0.3565,  0.5484, -1.0606,\n",
      "         0.0517, -0.1120]) tensor([ 0.5226, -0.5264,  1.1758,  1.0018, -0.8287, -0.3736,  0.5652, -1.0310,\n",
      "        -0.3105, -0.2781])\n",
      "R[0]\n",
      "tensor([-0.0030], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05311441534757614 0.003609520625879668 0.002674035530289984 0.0056854207678698 0.034026123747229575 0.478443262398243 0.008441296910867094 42.71826998901367\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2597, -0.5715,  0.8334,  0.6806, -0.2672, -0.0848,  0.4483, -0.7647,\n",
      "         0.3673, -0.0448]) tensor([-0.1019, -0.5942,  0.9056,  0.7492, -0.3536, -0.0713,  0.3680, -0.8312,\n",
      "        -0.0260, -0.0621]) tensor([-0.5654, -0.5556,  0.8317,  0.6854, -0.5288, -0.0273,  0.2867, -1.2216,\n",
      "        -0.4291, -0.3153])\n",
      "R[0]\n",
      "tensor([0.0173], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05326849395036697 0.0043085801648339835 0.0025123920163023284 0.0058643380063585935 0.033823179367929695 0.4742573576569557 0.008313990422524512 42.647673736572266\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7158, -0.5958,  1.0244,  0.8642, -0.7376, -0.2710,  0.6111, -1.1469,\n",
      "        -0.3763,  0.2471]) tensor([-0.0029, -0.5758,  1.0445,  0.8534, -0.7142, -0.2602,  0.5584, -1.0985,\n",
      "         0.0161, -0.0978]) tensor([-0.5621, -0.5926,  0.9996,  0.8428, -0.7181, -0.2029,  0.5513, -1.2472,\n",
      "        -0.3774, -0.1927])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05371659018844366 0.0039606305112065456 0.002689053283102112 0.0056692658946849404 0.03374223145097494 0.46048929971456526 0.008386382841970772 42.459630241394045\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1543, -0.4248,  1.2666,  1.4014, -0.5557,  0.1233, -0.3166, -0.4627,\n",
      "         0.5878,  0.3791]) tensor([-0.0665, -0.4524,  1.2136,  1.3432, -0.5416,  0.1270, -0.2827, -0.5120,\n",
      "         0.2607,  0.0161]) tensor([ 0.5173, -0.5947,  1.1386,  1.0669, -0.6668, -0.1315,  0.0706, -0.7233,\n",
      "         0.1281,  1.0101])\n",
      "R[0]\n",
      "tensor([-0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05290195602178573 0.0035648046231763148 0.0024132829657428374 0.0055594734027981756 0.03424413492158055 0.47035073083639145 0.008375532737467438 42.46568898773193\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1909, -0.9812,  1.2410,  0.0890, -0.2188,  0.3247,  0.1341, -1.9017,\n",
      "         0.2950, -0.1479]) tensor([-0.0565, -0.8546,  1.2321,  0.2149, -0.2854,  0.1497,  0.3215, -1.6688,\n",
      "         0.3050,  0.1599]) tensor([-0.2798, -0.9571,  1.2591,  0.3174, -0.4120,  0.2846,  0.0153, -1.8032,\n",
      "         0.1842, -0.1736])\n",
      "R[0]\n",
      "tensor([0.0979], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05343670555204153 0.0038217775922566944 0.002509537119030938 0.005746984460391104 0.0333769590780139 0.46995200115442276 0.008334282386582344 42.36784474182129\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0454, -0.6154,  1.2683,  1.0531, -0.9644, -0.3163,  0.1686, -0.9491,\n",
      "        -0.3858, -0.3895]) tensor([ 0.0289, -0.5935,  1.2636,  1.0580, -0.9043, -0.2861,  0.1753, -0.9118,\n",
      "         0.1420, -0.0459]) tensor([-0.1296, -0.6464,  1.1870,  1.0081, -0.9159, -0.2899,  0.3259, -1.1002,\n",
      "        -0.6756,  0.2678])\n",
      "R[0]\n",
      "tensor([0.0083], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05348720799386501 0.004098552230101631 0.002825686446860345 0.006081729544559494 0.033299797885119914 0.4778977600932121 0.008212086987681687 42.35301740264892\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2528, -0.4085,  0.9586,  0.9393, -0.7270, -0.3035,  0.5553, -0.8813,\n",
      "        -0.0099, -0.3046]) tensor([ 0.0156, -0.4276,  0.9689,  0.9599, -0.7613, -0.2804,  0.5020, -0.9393,\n",
      "        -0.0201, -0.1053]) tensor([-0.6625, -0.4786,  1.1269,  0.9296, -0.7084, -0.3028,  0.5794, -0.9626,\n",
      "         0.4630, -0.0760])\n",
      "R[0]\n",
      "tensor([0.0019], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05314512828737497 0.004000557591831239 0.0022492125887583823 0.005875967390602454 0.03414093269780278 0.47963007718324663 0.008248878376558423 42.47726926422119\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5982, -0.5893,  1.0320,  0.9226, -0.5194, -0.1926,  0.0863, -0.5003,\n",
      "         0.0634,  0.6899]) tensor([-0.0897, -0.6051,  1.0776,  0.9360, -0.5006, -0.1666,  0.0517, -0.5156,\n",
      "         0.0683,  0.0165]) tensor([-0.1461, -0.6139,  1.0127,  0.8889, -0.5085, -0.1937,  0.0832, -0.4801,\n",
      "        -0.4016, -0.5313])\n",
      "R[0]\n",
      "tensor([0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05328864643722773 0.0038874116104489075 0.0022066173993771374 0.005712582915555686 0.034162872787564996 0.46560063236951826 0.007804859903175384 42.40278434753418\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1074, -0.7166,  1.2121,  1.1377, -0.7053, -0.0087, -0.1624, -0.7913,\n",
      "         0.1619, -0.0778]) tensor([-0.0765, -0.7239,  1.1785,  1.0919, -0.6702, -0.0457, -0.0671, -0.7697,\n",
      "         0.2151,  0.0253]) tensor([-0.1102, -0.6804,  1.0807,  1.0301, -0.6916, -0.1224,  0.0219, -0.7674,\n",
      "        -0.0618, -0.5169])\n",
      "R[0]\n",
      "tensor([-0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05284850987792015 0.003895791514823941 0.0024694863315708063 0.005731139843119308 0.034235130447894335 0.4680577089190483 0.00811603999696672 42.50581440734863\n",
      "Average (on the epoch) training loss: 0.005754692176193931\n",
      "Episode average V value: 0\n",
      "epoch 10:\n",
      "Learning rate: 3.874204890000002e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 100.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 99.9900009999 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3048, -0.4181,  1.0582,  1.1651, -0.6074, -0.2141,  0.1262, -0.5159,\n",
      "         0.1245,  0.2211]) tensor([-0.0346, -0.4570,  1.0466,  1.1399, -0.6244, -0.2120,  0.1208, -0.5804,\n",
      "         0.0237, -0.0727]) tensor([-0.0188, -0.4320,  1.1481,  1.2576, -0.5908, -0.0903, -0.0245, -0.5233,\n",
      "        -0.5285,  0.1376])\n",
      "R[0]\n",
      "tensor([0.0021], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05330820053070784 0.0039051887722598624 0.002637557925834699 0.006043092942563817 0.03415632300451398 0.47979560953378675 0.00783381005981937 42.544046989440915\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0296, -0.6058,  1.3013,  1.1722, -0.6640, -0.0461, -0.0922, -0.6804,\n",
      "        -0.0728, -0.3416]) tensor([-0.0530, -0.5992,  1.2598,  1.1513, -0.6297, -0.0243, -0.0763, -0.6868,\n",
      "         0.2662,  0.0272]) tensor([-0.1073, -0.8909,  1.5917,  1.1245, -0.7901,  0.0986, -0.1931, -1.1437,\n",
      "         0.8351,  0.0408])\n",
      "R[0]\n",
      "tensor([-0.0013], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05344652950018644 0.0035594669333368074 0.002680815072824771 0.005939326819963753 0.033363419845700265 0.47566675263643265 0.007704101628623903 42.54797378540039\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1693, -0.6870,  1.0559,  1.0535, -0.6531, -0.1160,  0.0576, -0.7427,\n",
      "         0.2840,  0.5422]) tensor([-0.0836, -0.6879,  1.0951,  1.0441, -0.6151, -0.0956,  0.0390, -0.7199,\n",
      "         0.1484, -0.0208]) tensor([-4.1351e-01, -6.8341e-01,  1.2685e+00,  1.1132e+00, -6.3178e-01,\n",
      "         1.2405e-04, -1.3625e-01, -7.4030e-01,  2.7129e-01,  6.3180e-02])\n",
      "R[0]\n",
      "tensor([0.0009], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052934180848300455 0.004149213107844844 0.002291437773677899 0.005967185903340578 0.034101141192018986 0.4795298233628273 0.007906310804653913 42.53589530181885\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2572, -0.7400,  1.0112,  0.7741, -0.4434, -0.1521,  0.3632, -0.7984,\n",
      "        -0.4131, -0.2353]) tensor([-0.1351, -0.7291,  1.0109,  0.7984, -0.4677, -0.1418,  0.3276, -0.8057,\n",
      "         0.1189, -0.0142]) tensor([ 0.3861, -0.6867,  1.0380,  0.8015, -0.4410, -0.1768,  0.3954, -0.7441,\n",
      "         0.0109,  0.2327])\n",
      "R[0]\n",
      "tensor([-0.0024], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052565624348819256 0.003775272400020185 0.002371439879992977 0.005883604716043919 0.03419561476632953 0.4789519295096397 0.007706515158060938 42.58179486846924\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1006, -0.5476,  1.3277,  1.2652, -0.6376,  0.0468, -0.2359, -0.6743,\n",
      "         0.4053,  0.0877]) tensor([-0.0463, -0.5638,  1.2423,  1.2078, -0.6269,  0.0196, -0.1636, -0.7044,\n",
      "         0.2507,  0.0461]) tensor([ 0.2209, -0.6889,  1.4608,  1.2509, -0.7068,  0.1226, -0.3552, -0.8799,\n",
      "         0.0031,  0.0413])\n",
      "R[0]\n",
      "tensor([0.0066], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0531775124296546 0.004020917929585266 0.0025901838312929614 0.0061237704453524205 0.03399676496908069 0.47507891708612443 0.007773347014095634 42.540650413513184\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1603, -0.7664,  1.4707,  1.0881, -0.8628, -0.0746, -0.0314, -1.0895,\n",
      "         0.0623, -0.1927]) tensor([ 0.0318, -0.7299,  1.3728,  1.0596, -0.8261, -0.0975,  0.0459, -1.0473,\n",
      "         0.3475,  0.0681]) tensor([-0.4427, -0.7655,  1.3937,  1.0279, -0.8948, -0.1459,  0.1631, -1.2016,\n",
      "         0.7608, -0.4056])\n",
      "R[0]\n",
      "tensor([-0.0019], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05297731056064367 0.003977212372712529 0.002216215863085381 0.00590334868687205 0.034297991704195736 0.47094638311862946 0.007949874158482998 42.51431373596191\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0536, -0.7932,  1.0442,  0.5463, -0.2451,  0.4812, -0.5372, -1.3405,\n",
      "         0.1990,  0.1447]) tensor([-0.0533, -0.7016,  1.0062,  0.6658, -0.3287,  0.2719, -0.2890, -1.1333,\n",
      "         0.2149,  0.0549]) tensor([ 0.0532, -0.6145,  1.1145,  1.1411, -0.7095, -0.0914, -0.0692, -0.7547,\n",
      "         0.3429, -0.3720])\n",
      "R[0]\n",
      "tensor([0.1368], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052918053537607194 0.0043236314234309245 0.002279186057705374 0.00588353520957753 0.03388188114017248 0.4779315060973167 0.007463227263418958 42.52409335327148\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0173, -0.2086,  0.8654,  1.2735, -0.1242,  0.6876, -0.5059, -0.6930,\n",
      "         0.4869,  0.4171]) tensor([-0.0615, -0.2889,  0.8839,  1.1559, -0.1625,  0.5324, -0.3598, -0.6803,\n",
      "         0.1686, -0.0115]) tensor([-0.4555, -0.7861,  1.0161,  0.6655, -0.4975, -0.2105,  0.2426, -0.7856,\n",
      "         0.2733, -0.1014])\n",
      "R[0]\n",
      "tensor([0.4165], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053045516982674595 0.004196530162895215 0.0024190431318129413 0.005795701650669798 0.03386266532540321 0.47511944806575773 0.007681316748261452 42.588414794921874\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2947, -1.1866,  1.1811,  0.0750,  0.0207, -0.0956,  0.2679, -0.8457,\n",
      "         0.3518, -0.1367]) tensor([-0.2111, -1.1728,  1.0104,  0.0823,  0.0062,  0.0098,  0.1365, -0.9792,\n",
      "         0.1968,  0.1063]) tensor([-0.3548, -1.1192,  1.1715,  0.1289, -0.0055, -0.1304,  0.3325, -0.7795,\n",
      "         0.6479,  0.8635])\n",
      "R[0]\n",
      "tensor([-0.0029], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053029359832406045 0.0039770093930164875 0.0025752306835020136 0.005714546593371779 0.034265812370926144 0.46992359572649 0.007763623898616061 42.60237294769287\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0305, -0.4701,  0.8049,  0.8375, -0.6949, -0.2368,  0.5528, -1.1004,\n",
      "        -0.3388, -0.1896]) tensor([ 0.0037, -0.4730,  0.8786,  0.8493, -0.6810, -0.2088,  0.4953, -1.0822,\n",
      "        -0.0486, -0.1470]) tensor([-0.2160, -0.4804,  0.8840,  0.9008, -0.7718, -0.3606,  0.6108, -0.9906,\n",
      "        -0.1514,  0.2379])\n",
      "R[0]\n",
      "tensor([9.4198e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052756700389087204 0.00419571043196629 0.002448475155310007 0.006007006475003436 0.03328264205530286 0.45866277796030047 0.0076666456926614045 42.581139389038086\n",
      "Average (on the epoch) training loss: 0.005926111944275908\n",
      "Episode average V value: 0\n",
      "epoch 11:\n",
      "Learning rate: 3.4867844010000016e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 106.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 105.989401059894 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6872, -0.7166,  1.2176,  0.9909, -0.8686, -0.2411,  0.4329, -1.2201,\n",
      "         0.3123, -0.5866]) tensor([ 0.0187, -0.6913,  1.2068,  0.9527, -0.8189, -0.2222,  0.4035, -1.1654,\n",
      "         0.1115, -0.0659]) tensor([-0.3719, -0.6521,  1.1594,  0.9494, -0.8356, -0.2856,  0.5118, -1.1713,\n",
      "        -0.3560, -0.5001])\n",
      "R[0]\n",
      "tensor([-0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0531440357118845 0.004003672052149341 0.0024178203909687 0.005884997563669458 0.03409904981032014 0.4593898646235466 0.007890491175930946 42.58304334259033\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2889, -0.5606,  0.9525,  1.0909, -0.5501,  0.0058, -0.0061, -0.7153,\n",
      "         0.5735,  0.2821]) tensor([-0.0816, -0.5725,  0.9658,  1.0447, -0.5096,  0.0166, -0.0192, -0.6991,\n",
      "         0.0664, -0.0503]) tensor([-0.0155, -0.3999,  0.9557,  1.2091, -0.5867, -0.0205, -0.0819, -0.5874,\n",
      "         0.1671, -0.1690])\n",
      "R[0]\n",
      "tensor([0.0020], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05279980982095003 0.0038367376398236955 0.00248245972056975 0.005714481417089701 0.033794532682746646 0.45740441435575485 0.007808331849984825 42.58618521881103\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.7076, -0.7787,  1.3777,  1.0661, -0.6491, -0.0087, -0.1655, -0.7878,\n",
      "         0.3563,  0.0286]) tensor([-0.0833, -0.7645,  1.3538,  1.0469, -0.6105,  0.0081, -0.1567, -0.7686,\n",
      "         0.3222,  0.0708]) tensor([-0.3604, -0.8105,  1.4776,  1.1448, -0.6835,  0.0591, -0.2929, -0.8171,\n",
      "         0.0504,  0.1920])\n",
      "R[0]\n",
      "tensor([0.0014], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05243341156840325 0.0036390143900534894 0.0028354062965518095 0.005705802410840988 0.03397554356232285 0.44611287307739256 0.008065404737368225 42.498475387573244\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5146, -0.4953,  1.2943,  1.1414, -0.6430, -0.1343,  0.0161, -0.6351,\n",
      "         0.3782, -0.4121]) tensor([-0.0713, -0.5244,  1.2544,  1.0914, -0.6463, -0.1565,  0.0822, -0.6760,\n",
      "         0.1880,  0.0205]) tensor([-0.4888, -0.5645,  1.2460,  1.1075, -0.6784, -0.1797,  0.0694, -0.6844,\n",
      "         0.2620, -0.0620])\n",
      "R[0]\n",
      "tensor([0.0025], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05281305024027824 0.004017065884458134 0.0029712609412599704 0.005930910282535479 0.034440726809203626 0.43031693482398986 0.007864373960532248 42.44018132019043\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5747, -0.4083,  0.9037,  0.8855, -0.7438, -0.3246,  0.5728, -0.8813,\n",
      "         0.6198, -0.2935]) tensor([-0.0350, -0.4098,  0.9190,  0.8811, -0.7297, -0.2891,  0.5203, -0.8914,\n",
      "        -0.0461, -0.1220]) tensor([-0.3738, -0.4151,  0.9821,  0.9094, -0.7384, -0.3135,  0.5463, -0.8995,\n",
      "         0.1325,  0.2824])\n",
      "R[0]\n",
      "tensor([0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05282673363387585 0.00332605593655353 0.002881272359016293 0.005191669673658908 0.03465341360494494 0.4270446599721909 0.008173136425670236 42.35340964508057\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1875, -0.4520,  1.0697,  1.1381, -0.5393, -0.0639, -0.1796, -0.3520,\n",
      "         0.4493, -0.1032]) tensor([-0.1370, -0.5152,  1.0856,  1.1208, -0.5601, -0.0911, -0.0942, -0.4293,\n",
      "         0.0855, -0.0173]) tensor([-0.6671, -0.5229,  0.9234,  0.9589, -0.4763, -0.1504, -0.0485, -0.3324,\n",
      "        -0.0439, -0.1814])\n",
      "R[0]\n",
      "tensor([-0.0019], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053355095714330676 0.004119434921121865 0.002577864373473858 0.005876669732155278 0.03360602998360991 0.43532383239269257 0.007997395214624703 42.41339045715332\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1552, -0.6948,  1.2395,  1.0324, -0.5962, -0.0965, -0.0364, -0.6808,\n",
      "         0.7117,  0.5220]) tensor([-0.1199, -0.6848,  1.2228,  1.0176, -0.5615, -0.0765, -0.0230, -0.6720,\n",
      "         0.2107,  0.0287]) tensor([-0.0956, -0.7246,  1.2177,  0.9242, -0.5118, -0.1227, -0.0216, -0.6168,\n",
      "        -0.4576, -0.1789])\n",
      "R[0]\n",
      "tensor([0.0022], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05305332857370377 0.003737196784652042 0.002313853434923658 0.005575436751358211 0.034424370847642424 0.4342498506307602 0.008325831822119652 42.39754030609131\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5710, -0.7084,  0.9668,  0.9834, -0.6220, -0.1157,  0.1118, -0.7580,\n",
      "        -0.3855,  0.2638]) tensor([-0.0691, -0.7402,  0.9908,  0.9720, -0.6220, -0.1340,  0.1450, -0.7793,\n",
      "         0.0450, -0.0083]) tensor([ 0.6279, -0.6654,  0.8996,  0.9666, -0.5852, -0.1616,  0.2093, -0.7210,\n",
      "         0.5340, -0.0726])\n",
      "R[0]\n",
      "tensor([-0.0110], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05287402826547623 0.0037510545279401415 0.0024073543951781177 0.0054023097094614055 0.03339553164690733 0.42691992497444153 0.008052193112205714 42.2476195602417\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1370, -0.5909,  1.1740,  1.0418, -0.6563, -0.2005,  0.1590, -0.7088,\n",
      "        -0.3881,  0.1551]) tensor([-0.0753, -0.5975,  1.1252,  1.0261, -0.6605, -0.1995,  0.1735, -0.7433,\n",
      "         0.1329, -0.0061]) tensor([-0.7591, -0.6029,  1.1247,  1.0288, -0.6668, -0.2122,  0.1863, -0.7267,\n",
      "        -0.1856,  0.3612])\n",
      "R[0]\n",
      "tensor([-0.0036], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05323309906572103 0.0038852661848504796 0.002664873021773019 0.005723329920321703 0.0339320462718606 0.4195860595703125 0.007889105581212788 42.12591229248047\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6191, -0.2494,  0.6296,  0.6304, -0.5300, -0.0246,  0.2200, -1.1527,\n",
      "         0.2581,  0.0505]) tensor([-0.0127, -0.2717,  0.7414,  0.7052, -0.5747, -0.0790,  0.2649, -1.1366,\n",
      "        -0.1703, -0.1407]) tensor([ 0.6094, -0.3223,  0.7652,  0.6678, -0.5994, -0.0414,  0.2022, -1.2269,\n",
      "         0.2191,  0.0667])\n",
      "R[0]\n",
      "tensor([0.0431], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05268432172387839 0.003768450846844644 0.0026262942573466717 0.005504967243643477 0.03430151767283678 0.417541537463665 0.008246004542801529 42.260204376220706\n",
      "Average (on the epoch) training loss: 0.005651057470473461\n",
      "Episode average V value: 0\n",
      "epoch 12:\n",
      "Learning rate: 3.138105960900002e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 99.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 98.99010098990101 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1096, -0.5228,  0.9910,  1.0960, -0.5555, -0.1084,  0.1164, -0.5947,\n",
      "        -0.0893,  0.1258]) tensor([-0.1114, -0.5397,  1.0241,  1.0973, -0.5516, -0.0876,  0.1034, -0.6172,\n",
      "         0.0921, -0.0449]) tensor([-0.0346, -0.5663,  1.1026,  1.0702, -0.5325, -0.1007,  0.1140, -0.5993,\n",
      "         0.1355,  0.2046])\n",
      "R[0]\n",
      "tensor([-0.0021], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05298052956163883 0.0035044425317828426 0.002718408272417946 0.0059213942750357094 0.034073834359645845 0.41216207218170164 0.007837328062858433 42.23785514068604\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0965, -0.5064,  0.7016,  0.9510, -0.3786, -0.0233,  0.2880, -0.5975,\n",
      "        -0.0318, -0.0953]) tensor([-1.4616e-01, -5.1897e-01,  7.4762e-01,  9.4717e-01, -3.7954e-01,\n",
      "         4.9329e-04,  2.3016e-01, -6.0540e-01, -2.3217e-02, -7.7241e-02]) tensor([ 0.0398, -0.5692,  0.7420,  0.8268, -0.2463,  0.0530,  0.3460, -0.6462,\n",
      "         0.1402, -0.2055])\n",
      "R[0]\n",
      "tensor([-0.0026], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05263062091171741 0.0038578789483635773 0.0024146647673223927 0.0057907032114453616 0.03406042855232954 0.40551878029108046 0.008026386813260615 42.20013900756836\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4400, -0.4640,  1.0981,  1.1492, -0.6132, -0.1658,  0.0617, -0.5416,\n",
      "         0.6827,  0.4742]) tensor([-0.1054, -0.4894,  1.1132,  1.1319, -0.6048, -0.1442,  0.0627, -0.5813,\n",
      "         0.1224,  0.0210]) tensor([ 0.4215, -0.5213,  1.2180,  1.2062, -0.6095, -0.0404, -0.0880, -0.6104,\n",
      "        -0.0921,  0.3216])\n",
      "R[0]\n",
      "tensor([-0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05265657998621464 0.003935372693114914 0.0022764552266344253 0.0058725371237378565 0.034428034119308 0.4097981797456741 0.007873346844222397 42.37446891784668\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2626, -0.4212,  0.8223,  0.8729, -0.7234, -0.2461,  0.4766, -1.0852,\n",
      "         0.2253,  0.1146]) tensor([-0.0021, -0.4119,  0.8583,  0.8610, -0.6835, -0.2230,  0.4353, -1.0442,\n",
      "        -0.1063, -0.1072]) tensor([ 0.1447, -0.4977,  0.8918,  0.9363, -0.7952, -0.2415,  0.4020, -1.0899,\n",
      "         0.0197,  0.3115])\n",
      "R[0]\n",
      "tensor([0.0014], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05240886817872524 0.004222664100685506 0.002824527476182993 0.0061183633930049835 0.03419347620755434 0.40810270166397095 0.007525146696716547 42.42212826538086\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4696, -0.5470,  1.2782,  1.1089, -0.6512, -0.1161,  0.0185, -0.7066,\n",
      "        -0.1606, -0.2265]) tensor([-0.0654, -0.5455,  1.2316,  1.0773, -0.6206, -0.1020,  0.0406, -0.7174,\n",
      "         0.1921,  0.0150]) tensor([-0.1360, -0.5174,  1.2749,  1.1567, -0.6427, -0.0984, -0.0325, -0.6606,\n",
      "         0.0696, -0.7528])\n",
      "R[0]\n",
      "tensor([0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052963782168924806 0.0036695705121928767 0.002775425953059312 0.005658678505569697 0.03361975151672959 0.4110072895884514 0.007583836778532714 42.31570048522949\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1499, -1.0496,  1.1607,  0.7494, -0.6508, -0.0183,  0.2113, -1.3281,\n",
      "         1.1041,  0.6221]) tensor([-0.0477, -1.0052,  1.1602,  0.7562, -0.6170, -0.0444,  0.2590, -1.2289,\n",
      "         0.2974,  0.1152]) tensor([-0.4285, -1.0266,  1.1621,  0.5556, -0.4232, -0.1122,  0.3585, -1.1184,\n",
      "         0.3968,  0.4895])\n",
      "R[0]\n",
      "tensor([-0.0110], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052843940749764444 0.003879208742280753 0.0026732971996661944 0.005872162764659151 0.03434531366080046 0.41894720113277434 0.007649684804026037 42.35376976776123\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3905, -0.4939,  1.0195,  0.9298, -0.8365, -0.3987,  0.5497, -0.9649,\n",
      "        -0.4596,  0.3376]) tensor([-0.0092, -0.4877,  1.0440,  0.9292, -0.8093, -0.3754,  0.5166, -0.9438,\n",
      "        -0.0259, -0.1044]) tensor([ 0.0409, -0.5026,  0.9691,  0.9257, -0.7712, -0.3153,  0.5218, -0.9599,\n",
      "        -0.2766,  0.1976])\n",
      "R[0]\n",
      "tensor([0.0022], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05295599733293056 0.004230158466274588 0.002488679688267439 0.00594102029595524 0.03409987403824925 0.4230705468058586 0.007573304214980453 42.33809230041504\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6183, -0.7555,  1.1063,  1.0215, -0.6809, -0.0565, -0.0472, -0.8058,\n",
      "         0.1181, -0.8679]) tensor([-0.1291, -0.7497,  1.1035,  0.9684, -0.6109, -0.0491, -0.0393, -0.7509,\n",
      "         0.1505, -0.0302]) tensor([ 0.0947, -0.7545,  1.0715,  1.0823, -0.6755, -0.0403, -0.0492, -0.7999,\n",
      "         0.3490, -0.1198])\n",
      "R[0]\n",
      "tensor([-0.0013], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05249900196492672 0.0036637568582809765 0.002442359782173298 0.005491554878884927 0.03368049014359713 0.4255600787997246 0.007767482398077846 42.419246055603026\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2883, -0.5496,  0.9262,  0.9230, -0.8132, -0.2700,  0.4619, -1.1066,\n",
      "         0.0276, -0.2034]) tensor([-0.0286, -0.5256,  0.9444,  0.9148, -0.7601, -0.2406,  0.4203, -1.0503,\n",
      "        -0.0162, -0.0749]) tensor([ 0.2580, -0.4491,  0.8667,  0.8746, -0.7378, -0.2054,  0.4234, -1.1283,\n",
      "        -0.4193, -0.1158])\n",
      "R[0]\n",
      "tensor([0.0010], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05276887619495392 0.003861610501109681 0.0026827636722318855 0.0056307788426056505 0.033442690268158916 0.42508753657341003 0.007760977530386299 42.39225408172607\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4047, -0.4915,  1.0687,  0.9219, -0.7534, -0.3853,  0.6682, -0.9835,\n",
      "         0.2102,  0.0691]) tensor([-0.0014, -0.4856,  1.0873,  0.9491, -0.7671, -0.3489,  0.6271, -1.0072,\n",
      "         0.0270, -0.0827]) tensor([ 0.2976, -0.5023,  1.0772,  0.9239, -0.7791, -0.3830,  0.6486, -1.0010,\n",
      "        -0.3682,  0.0806])\n",
      "R[0]\n",
      "tensor([-0.0040], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052693639889359475 0.0038633397350458835 0.0024197986949384357 0.005801995085086674 0.03399758111685514 0.4353201257586479 0.00799538533622399 42.572632766723636\n",
      "Average (on the epoch) training loss: 0.005809918837598525\n",
      "Episode average V value: 0\n",
      "epoch 13:\n",
      "Learning rate: 2.8242953648100018e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 117.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 116.98830116988302 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2903, -0.6950,  0.9543,  1.0203, -0.6343, -0.1161,  0.0942, -0.7525,\n",
      "        -0.2375,  0.1820]) tensor([-0.1292, -0.6818,  0.9763,  1.0014, -0.5784, -0.0969,  0.0755, -0.7008,\n",
      "         0.1087, -0.0297]) tensor([-0.0249, -0.6898,  1.0978,  1.1349, -0.6602, -0.0438, -0.0772, -0.7334,\n",
      "         0.0590,  0.1374])\n",
      "R[0]\n",
      "tensor([-0.0009], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05274410558491945 0.004193886797856976 0.002989927728642215 0.005952146195573732 0.033697807051241396 0.43663395911455155 0.007839851914905011 42.5223217086792\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1911, -0.4913,  0.8276,  1.0038, -0.4094, -0.1307,  0.3052, -0.5234,\n",
      "        -0.1661, -0.1683]) tensor([-0.1543, -0.5062,  0.8578,  1.0003, -0.4153, -0.1078,  0.2640, -0.5461,\n",
      "         0.0038, -0.0713]) tensor([-0.2869, -0.4549,  0.7833,  0.9877, -0.4502, -0.0189,  0.1208, -0.6940,\n",
      "        -0.3472,  0.0989])\n",
      "R[0]\n",
      "tensor([0.0021], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0523126030266285 0.004030770503668464 0.003124257282081089 0.006078593116952106 0.033793561954051254 0.4303114849328995 0.007804562097415328 42.58418675994873\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3508, -1.0130,  0.9640,  0.1824, -0.1265, -0.2125,  0.4306, -0.7814,\n",
      "        -0.1481,  0.1496]) tensor([-0.2581, -0.9773,  1.0302,  0.2983, -0.1449, -0.1520,  0.3629, -0.7804,\n",
      "         0.1474,  0.0249]) tensor([-0.0497, -1.1715,  1.2408,  0.5688, -0.4396,  0.0134,  0.2854, -1.3090,\n",
      "         0.5969,  0.2012])\n",
      "R[0]\n",
      "tensor([-0.0033], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05271871396154165 0.0033448813437917126 0.002402217690998441 0.005270924695534631 0.034102259401232 0.4316365740299225 0.007819488553795963 42.521144279479984\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0372, -0.7932,  0.9440,  0.7396, -0.7231, -0.2734,  0.3393, -1.0406,\n",
      "        -0.0604, -0.7358]) tensor([-0.0648, -0.7733,  0.9896,  0.8025, -0.7123, -0.2595,  0.3219, -1.0092,\n",
      "         0.0524, -0.0193]) tensor([-0.5525, -0.7854,  0.9052,  0.6796, -0.6768, -0.2852,  0.2552, -0.8879,\n",
      "        -0.2379, -0.3527])\n",
      "R[0]\n",
      "tensor([-0.0058], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052615461081266406 0.004086196193802607 0.002752035423180132 0.0058115656971931455 0.03420305750891566 0.42921483755111695 0.007948932205326855 42.54962405395508\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6848,  0.0034,  0.6897,  0.6378, -0.4604,  0.0202,  0.1287, -1.1417,\n",
      "        -0.6351, -0.3835]) tensor([ 2.5737e-04, -5.2069e-02,  7.7040e-01,  6.5260e-01, -5.1827e-01,\n",
      "        -8.3692e-02,  2.3698e-01, -1.1387e+00, -1.5352e-01, -9.3373e-02]) tensor([-0.4920, -0.0441,  0.7517,  0.6127, -0.4674,  0.0193,  0.1699, -1.2092,\n",
      "         0.3155, -0.1366])\n",
      "R[0]\n",
      "tensor([0.0731], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05353869818150997 0.004209273736145405 0.002366554709353295 0.005699610580690205 0.0333665301464498 0.4279562644958496 0.007812422236893326 42.353966354370115\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3393, -0.5000,  0.8993,  0.8424, -0.6979, -0.2882,  0.6476, -1.0001,\n",
      "         0.2667, -0.2615]) tensor([-0.0018, -0.5193,  0.9367,  0.8594, -0.7342, -0.2799,  0.6110, -1.0376,\n",
      "        -0.0226, -0.1319]) tensor([ 0.5485, -0.5434,  1.0454,  0.8663, -0.6922, -0.2159,  0.5292, -1.0376,\n",
      "         0.2736, -0.1595])\n",
      "R[0]\n",
      "tensor([0.0025], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05277135693281889 0.003493460777830478 0.002622055259962508 0.005456941993674263 0.03388894054666162 0.4193751683831215 0.008185793116688728 42.46123459625244\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3668, -0.6632,  0.9433,  0.7969, -0.7168, -0.1226,  0.5093, -1.3468,\n",
      "        -0.1976,  0.5056]) tensor([ 0.0088, -0.6325,  0.9385,  0.7684, -0.6607, -0.1044,  0.4588, -1.2753,\n",
      "         0.0504, -0.0746]) tensor([-0.0160, -0.5687,  0.8826,  0.6871, -0.5737, -0.0273,  0.5270, -1.4881,\n",
      "        -0.0335,  0.0379])\n",
      "R[0]\n",
      "tensor([0.0008], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05302362954616547 0.004032369994136389 0.0023857536248669932 0.005744134252192452 0.033407951422035696 0.430648572742939 0.008032671959605067 42.647690544128416\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1206, -0.6374,  0.8685,  1.0385, -0.6684, -0.1853,  0.1501, -0.6929,\n",
      "         0.2521,  0.2541]) tensor([-0.0809, -0.6506,  0.9063,  1.0539, -0.6658, -0.1792,  0.1388, -0.7018,\n",
      "        -0.0045, -0.1081]) tensor([-0.4518, -0.6399,  0.9057,  1.0314, -0.6536, -0.1769,  0.1501, -0.6957,\n",
      "         0.8444, -0.5438])\n",
      "R[0]\n",
      "tensor([-0.0045], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05304689096659422 0.0034759320795819805 0.002522382365721569 0.005851103766821325 0.03367894131317735 0.4273421552181244 0.00791468158038333 42.5204155960083\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1260, -0.6829,  1.2919,  0.9312, -0.8544, -0.2411,  0.4177, -1.2204,\n",
      "         0.3211, -0.3619]) tensor([ 0.0048, -0.6695,  1.2244,  0.8849, -0.8257, -0.2540,  0.4575, -1.2012,\n",
      "         0.1631, -0.0258]) tensor([ 0.2267, -0.6677,  1.3392,  0.9566, -0.8777, -0.2410,  0.3786, -1.1895,\n",
      "        -0.4481, -0.0798])\n",
      "R[0]\n",
      "tensor([0.0029], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05286809587478638 0.003900353253398862 0.0021828351653439314 0.005610207711113617 0.033784341782331466 0.4285895649790764 0.008281520503107459 42.53733364868164\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1349, -0.6840,  1.4333,  1.0317, -0.7920, -0.0649, -0.0485, -1.0434,\n",
      "        -0.0434, -0.0834]) tensor([-0.0046, -0.6633,  1.3784,  1.0051, -0.7445, -0.0520, -0.0098, -1.0251,\n",
      "         0.3122,  0.0591]) tensor([-0.1646, -0.7764,  1.4841,  1.1064, -0.7438,  0.0307, -0.1938, -0.9701,\n",
      "         0.4375,  0.0565])\n",
      "R[0]\n",
      "tensor([-0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05274559289216995 0.003808764529021573 0.0025433912715943736 0.0055002779441419986 0.03430450544506312 0.4227550809979439 0.008114441302139312 42.48139109802246\n",
      "Average (on the epoch) training loss: 0.005697550595388748\n",
      "Episode average V value: 0\n",
      "epoch 14:\n",
      "Learning rate: 2.5418658283290016e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 118.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 117.98820117988201 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0343, -0.0126,  0.8052,  0.6582, -0.4413,  0.0560,  0.1217, -1.1737,\n",
      "        -0.5784,  0.6910]) tensor([ 0.0177, -0.0627,  0.8514,  0.6608, -0.4930, -0.0424,  0.2351, -1.1827,\n",
      "        -0.1154, -0.0847]) tensor([-0.0285, -0.0895,  0.7484,  0.5644, -0.4687,  0.1680, -0.0196, -1.2444,\n",
      "         0.1280, -0.2383])\n",
      "R[0]\n",
      "tensor([0.0632], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05273013079166412 0.003973735508734535 0.002972322411093046 0.005777182741323486 0.033593815930187704 0.42357069182395934 0.008085406223777682 42.522126007080075\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2442, -0.7618,  0.6682,  0.4483, -0.2739,  0.2396, -0.0371, -1.1201,\n",
      "         0.2984, -0.0056]) tensor([-0.1375, -0.7327,  0.7558,  0.6253, -0.3880,  0.1553,  0.0587, -1.0668,\n",
      "         0.0619, -0.0197]) tensor([-0.5510, -0.4123,  0.8101,  1.1869, -0.5366,  0.0701, -0.0970, -0.6584,\n",
      "        -0.1974, -0.5954])\n",
      "R[0]\n",
      "tensor([0.1074], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05248139445483684 0.00392331777245272 0.0023640506109895796 0.005727450486505404 0.03387587820366025 0.4189253532886505 0.008225762102752924 42.48815447235108\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0567, -0.7635,  0.7532,  0.0709, -0.2989, -0.0888,  0.4518, -1.2988,\n",
      "        -0.0276,  0.0288]) tensor([-0.1352, -0.7290,  0.8572,  0.2539, -0.3793, -0.1086,  0.4533, -1.2699,\n",
      "        -0.0196, -0.0560]) tensor([-0.0384, -0.6641,  0.8633,  0.4139, -0.4109, -0.1890,  0.1644, -0.6839,\n",
      "         0.1673, -0.2499])\n",
      "R[0]\n",
      "tensor([0.0286], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05282424333691597 0.003925881988894616 0.0026435910633754245 0.005836168587440625 0.03404362251982093 0.4182371815443039 0.008157712521031498 42.33013272094727\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3701, -0.6973,  1.0372,  1.0700, -0.6260, -0.0491, -0.0388, -0.7176,\n",
      "         0.0154, -0.0525]) tensor([-0.1185, -0.6936,  1.0591,  1.0608, -0.5836, -0.0280, -0.0412, -0.6926,\n",
      "         0.1733,  0.0028]) tensor([ 0.1244, -0.7127,  1.1829,  1.1358, -0.6791, -0.0233, -0.1345, -0.7396,\n",
      "         0.1559,  0.4701])\n",
      "R[0]\n",
      "tensor([0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05273497318476438 0.003984799055571784 0.002683174678400974 0.005964563801186159 0.034219410069286825 0.42173240023851394 0.008219095344189555 42.40558755493164\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1477, -0.7000,  0.9390,  0.8072, -0.7428, -0.1119,  0.4721, -1.3965,\n",
      "        -0.1556, -0.1614]) tensor([-0.0152, -0.6550,  0.9340,  0.7718, -0.6688, -0.0967,  0.4342, -1.2890,\n",
      "         0.0526, -0.0687]) tensor([ 0.1868, -0.6218,  0.8385,  0.6930, -0.5901, -0.0431,  0.5651, -1.4754,\n",
      "         0.8397, -0.1372])\n",
      "R[0]\n",
      "tensor([0.0017], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05257917328178883 0.004172259949047657 0.0022372843629964337 0.005858838986605406 0.033914879696443676 0.4261550409793854 0.008176359986886383 42.320599891662596\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1127, -0.5732,  1.0806,  0.9396, -0.8156, -0.3306,  0.5774, -1.0582,\n",
      "        -0.5993, -0.2211]) tensor([ 0.0226, -0.5640,  1.0604,  0.9470, -0.8257, -0.3130,  0.5438, -1.0737,\n",
      "         0.0715, -0.0848]) tensor([-0.1094, -0.5633,  1.0948,  0.9537, -0.8157, -0.3391,  0.5857, -1.0692,\n",
      "        -0.6195, -0.1444])\n",
      "R[0]\n",
      "tensor([0.0043], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05327158493548632 0.00385861401216971 0.0023354408718587365 0.005783969307085499 0.03397662415355444 0.4231006931066513 0.008269490871578454 42.33926136779785\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8198, -0.7110,  1.0949,  0.8665, -0.7351, -0.1904,  0.5792, -1.3025,\n",
      "        -0.4695,  0.6917]) tensor([ 0.0978, -0.7275,  1.0774,  0.8429, -0.7295, -0.2037,  0.5611, -1.3129,\n",
      "         0.0262,  0.0326]) tensor([ 0.8271, -0.7453,  1.1074,  0.9158, -0.8088, -0.1889,  0.4752, -1.3231,\n",
      "         0.2852, -0.2259])\n",
      "R[0]\n",
      "tensor([-0.0116], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05249704597145319 0.003363064771227073 0.0024143447571477734 0.0054763337336480615 0.03286345823481679 0.4236624098420143 0.008233103956561535 42.323280784606936\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4721, -0.6326,  1.2623,  1.1378, -0.5937, -0.0368, -0.0752, -0.6601,\n",
      "        -0.0243,  0.6499]) tensor([-0.1104, -0.6489,  1.2154,  1.0772, -0.5721, -0.0690, -0.0068, -0.6606,\n",
      "         0.2010,  0.0222]) tensor([ 0.6137, -0.7602,  1.3651,  1.1144, -0.6436,  0.0134, -0.1973, -0.7718,\n",
      "         0.1873,  0.5021])\n",
      "R[0]\n",
      "tensor([-0.0033], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05325685665756464 0.00391473726334516 0.002557657208039018 0.005809498854214326 0.03367357021197677 0.41950465553998945 0.008132152770180255 42.26697374725342\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0135, -0.6541,  1.1214,  0.9476, -0.7798, -0.2447,  0.4024, -1.0527,\n",
      "         0.5700, -0.0879]) tensor([-0.0050, -0.6233,  1.1027,  0.9338, -0.7340, -0.2235,  0.3828, -1.0057,\n",
      "         0.1013, -0.0482]) tensor([ 0.1585, -0.6349,  1.0572,  0.9435, -0.7750, -0.2729,  0.4959, -1.0678,\n",
      "        -0.4943,  0.0624])\n",
      "R[0]\n",
      "tensor([0.0019], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05312716115266085 0.0037307236154847487 0.0028968280767694525 0.005756920892978087 0.03382757093757391 0.42327256554365156 0.008350985064171255 42.33236436462402\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1698, -0.3746,  1.1601,  1.3028, -0.6950, -0.1008, -0.1555, -0.4751,\n",
      "         0.3892, -0.0926]) tensor([-0.0167, -0.4100,  1.1077,  1.2570, -0.6946, -0.1145, -0.0973, -0.5431,\n",
      "         0.1109, -0.0167]) tensor([-0.6502, -0.5585,  1.1467,  1.1835, -0.6924, -0.1248, -0.0461, -0.6129,\n",
      "        -0.0585,  0.0434])\n",
      "R[0]\n",
      "tensor([0.0041], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05321479883790016 0.0037993155202366326 0.0025834047407079196 0.005908709543058649 0.0333828990906477 0.42353256410360335 0.008149286042433233 42.40982743835449\n",
      "Average (on the epoch) training loss: 0.00578996369340457\n",
      "Episode average V value: 0\n",
      "epoch 15:\n",
      "Learning rate: 2.2876792454961016e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 87.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 86.991300869913 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6344, -0.6843,  1.2302,  0.9551, -0.8792, -0.2490,  0.3894, -1.1994,\n",
      "        -0.0752,  0.4887]) tensor([ 0.0106, -0.6661,  1.2011,  0.9346, -0.8487, -0.2620,  0.4139, -1.1577,\n",
      "         0.1217, -0.0296]) tensor([-0.4426, -0.6863,  1.2780,  0.9891, -0.8852, -0.2507,  0.3841, -1.2010,\n",
      "         0.7343, -0.4926])\n",
      "R[0]\n",
      "tensor([0.0010], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053249672934412955 0.0037855795121540725 0.002327739889755321 0.005690590754151344 0.03411541969701648 0.4192601398229599 0.007967819712590427 42.3043949584961\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3887, -0.5679,  1.1116,  0.9736, -0.8195, -0.3539,  0.5831, -1.0475,\n",
      "        -0.3075, -0.5920]) tensor([ 0.0085, -0.5500,  1.1139,  0.9695, -0.7871, -0.3231,  0.5521, -1.0212,\n",
      "         0.0543, -0.1370]) tensor([ 0.9646, -0.5480,  1.0013,  0.9038, -0.7266, -0.3285,  0.6567, -1.0505,\n",
      "         0.1246, -0.4864])\n",
      "R[0]\n",
      "tensor([-0.0022], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052776338540017606 0.0036139305007181974 0.002507575259260193 0.005470191216096282 0.03335061199218035 0.4132063780426979 0.008193613584619015 42.26551360321045\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0313, -0.5811,  1.0404,  0.9087, -0.7564, -0.3235,  0.6414, -1.0776,\n",
      "        -0.4514,  0.1285]) tensor([ 0.0119, -0.5727,  1.0249,  0.9124, -0.7716, -0.3060,  0.5833, -1.0919,\n",
      "         0.0715, -0.1253]) tensor([-0.3406, -0.5592,  1.0625,  0.9348, -0.7828, -0.3347,  0.6061, -1.0844,\n",
      "         0.6076,  0.4571])\n",
      "R[0]\n",
      "tensor([0.0053], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052628624498844145 0.0041236091353421215 0.0027682946494915085 0.005962241404224187 0.03326817247644067 0.426357900083065 0.008003183967899532 42.392064712524416\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3657, -0.7014,  1.1566,  0.9775, -0.8670, -0.2453,  0.4454, -1.2097,\n",
      "         0.7203,  0.2825]) tensor([ 0.0156, -0.6669,  1.1370,  0.9553, -0.8137, -0.2162,  0.4202, -1.1575,\n",
      "         0.1611, -0.0155]) tensor([-0.2009, -0.6666,  1.1235,  0.9280, -0.7996, -0.2560,  0.5027, -1.1631,\n",
      "         0.3620,  0.4267])\n",
      "R[0]\n",
      "tensor([-0.0009], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052797879368066784 0.0038743646941002225 0.0023587235637660344 0.006098185048438609 0.03409695683419704 0.42209978181123736 0.008003705214709044 42.27530317687988\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2553,  0.1215,  1.0223,  1.0375, -0.5401, -0.0620, -0.0344, -0.6981,\n",
      "        -0.1128, -0.0461]) tensor([ 0.0208,  0.0661,  1.0037,  0.9884, -0.5444, -0.0715,  0.0181, -0.7806,\n",
      "        -0.0047, -0.0799]) tensor([ 0.1863,  0.0492,  1.1007,  1.0519, -0.6955, -0.3260,  0.1681, -0.6026,\n",
      "        -0.4620, -0.5614])\n",
      "R[0]\n",
      "tensor([-0.0085], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05276414170861244 0.0036934198787876085 0.002383348241033673 0.005680379249388352 0.033728524852544066 0.4264043655395508 0.007933078603353351 42.291529014587404\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6979, -1.1068,  0.9223,  0.0291,  0.0084,  0.0910,  0.1152, -0.9055,\n",
      "         0.0610,  0.1043]) tensor([-0.2614, -1.0580,  0.9396,  0.0981,  0.0272,  0.1201,  0.0835, -0.8528,\n",
      "         0.2368,  0.0995]) tensor([ 0.0625, -1.1096,  0.8185, -0.1962,  0.0203,  0.1215,  0.0279, -1.1166,\n",
      "         0.4698,  0.0578])\n",
      "R[0]\n",
      "tensor([0.0023], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05297976466268301 0.004068460805523501 0.0025594037439623206 0.005938854118110612 0.03331195122003555 0.43291855961084363 0.0077107181418687104 42.426681175231934\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.7187, -0.5837,  1.1294,  0.9692, -0.7574, -0.3087,  0.3651, -0.8612,\n",
      "        -0.3659,  0.1968]) tensor([-0.0070, -0.5685,  1.1220,  0.9662, -0.7258, -0.2854,  0.3486, -0.8427,\n",
      "         0.0752, -0.0404]) tensor([-0.1619, -0.6231,  1.1110,  0.9271, -0.7517, -0.3001,  0.4775, -1.0105,\n",
      "        -0.3612, -0.0965])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05304447865486145 0.003921270549300971 0.002275507950844258 0.006022438836283982 0.0339545233938843 0.4295822308659554 0.007798255173955113 42.41013137817383\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2051, -0.7114,  1.0423,  0.7102, -0.3688, -0.1988,  0.1690, -0.5507,\n",
      "        -0.2381, -0.7222]) tensor([-0.1664, -0.7410,  1.0506,  0.7153, -0.3867, -0.1767,  0.1560, -0.6193,\n",
      "         0.1359,  0.0292]) tensor([ 0.0744, -0.7714,  1.1962,  0.6967, -0.4206, -0.2069,  0.0448, -0.5641,\n",
      "         0.3891, -0.5890])\n",
      "R[0]\n",
      "tensor([0.0068], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052308083653450015 0.0036216633889380317 0.0024748285228215535 0.00568596270121634 0.03325496538728476 0.4269362788796425 0.00785106822149828 42.3761828994751\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5531, -0.7043,  1.0756,  0.8333, -0.7293, -0.0946,  0.4763, -1.4142,\n",
      "        -0.0386, -0.4676]) tensor([ 0.0432, -0.6690,  1.0487,  0.8239, -0.7198, -0.1142,  0.4734, -1.3479,\n",
      "         0.1183, -0.0516]) tensor([-0.2282, -0.6756,  0.9720,  0.8288, -0.7360, -0.1238,  0.4897, -1.3496,\n",
      "        -0.0434,  0.1132])\n",
      "R[0]\n",
      "tensor([0.0028], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05332962121069431 0.0038412521385744183 0.0023028947556431377 0.005969951517181471 0.033039866557344796 0.4289873008131981 0.007934400481637568 42.43672505187988\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 1.5404e-01, -9.7605e-01,  1.2183e+00, -1.6684e-03, -2.3426e-01,\n",
      "         3.1597e-01,  1.3940e-02, -1.9033e+00, -2.0679e-01, -2.3610e-01]) tensor([-0.1038, -0.8813,  1.1882,  0.1093, -0.2874,  0.1252,  0.2551, -1.6801,\n",
      "         0.2563,  0.1076]) tensor([-0.0541, -1.0751,  1.3105,  0.1298, -0.2607,  0.2259,  0.1552, -1.7737,\n",
      "         0.2761,  0.5676])\n",
      "R[0]\n",
      "tensor([0.1093], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052843901298940184 0.0036311416136140906 0.002334555253317376 0.005735425771679729 0.033393224708735944 0.42679462796449663 0.007844413988757879 42.45222891235352\n",
      "Average (on the epoch) training loss: 0.005825422061677091\n",
      "Episode average V value: 0\n",
      "epoch 16:\n",
      "Learning rate: 2.0589113209464913e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 115.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 114.98850114988501 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3708, -0.4810,  1.0971,  1.1804, -0.5633, -0.1146,  0.0344, -0.5041,\n",
      "        -0.0545, -0.6487]) tensor([-0.1090, -0.5264,  1.0987,  1.1275, -0.5679, -0.1447,  0.0868, -0.5391,\n",
      "         0.1463, -0.0180]) tensor([ 0.5050, -0.6115,  1.1649,  1.0546, -0.6676, -0.1706,  0.1039, -0.7083,\n",
      "         0.9197, -0.5106])\n",
      "R[0]\n",
      "tensor([-0.0050], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05296795478463173 0.0036850109001134116 0.002504532242734058 0.005705471157794818 0.03302979025617242 0.4250154520273209 0.007966527359560133 42.41981079101563\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1961, -0.6321,  0.8430,  0.8897, -0.5533, -0.2166,  0.3031, -0.6509,\n",
      "         0.2147,  0.4034]) tensor([-0.1238, -0.6325,  0.8995,  0.9021, -0.5295, -0.1811,  0.2494, -0.6374,\n",
      "         0.0436, -0.0839]) tensor([-0.7882, -0.6683,  0.9038,  0.9651, -0.6045, -0.1846,  0.1829, -0.6908,\n",
      "        -0.0659,  0.1970])\n",
      "R[0]\n",
      "tensor([0.0016], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05239138887822628 0.004081580463060164 0.002298111888589119 0.005843822522088885 0.03358226091042161 0.424754024207592 0.008252417877316474 42.41331509399414\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5036, -0.5664,  1.0624,  0.8795, -0.7132, -0.2662,  0.6370, -1.0844,\n",
      "         0.2122,  0.5196]) tensor([-8.9699e-04, -5.4559e-01,  1.0524e+00,  8.7089e-01, -7.0674e-01,\n",
      "        -2.4808e-01,  6.0017e-01, -1.0674e+00,  9.9058e-02, -6.3529e-02]) tensor([ 0.2119, -0.5572,  1.1441,  0.9314, -0.7073, -0.1929,  0.5034, -1.0440,\n",
      "        -0.0379, -0.2048])\n",
      "R[0]\n",
      "tensor([0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052737995229661466 0.003697969983015355 0.002667608346146153 0.005747302614850924 0.033611779306083917 0.410705129981041 0.008004429084714501 42.36722588348389\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0491, -0.6480,  1.1337,  1.0813, -0.6257, -0.1095,  0.0149, -0.6686,\n",
      "        -0.1692, -0.6936]) tensor([-0.0960, -0.6720,  1.1276,  1.0433, -0.6086, -0.1218,  0.0556, -0.6808,\n",
      "         0.1727,  0.0037]) tensor([-0.2845, -0.6330,  0.9821,  0.9861, -0.6170, -0.1972,  0.1653, -0.6565,\n",
      "         0.0790, -0.2588])\n",
      "R[0]\n",
      "tensor([-0.0023], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05269442440569401 0.004061217949356433 0.002399979454239656 0.005939962876960635 0.03330290536954999 0.4142150294780731 0.007949937343597412 42.284492362976074\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2480, -0.6679,  1.1875,  1.2217, -0.7001,  0.1081, -0.3116, -0.8254,\n",
      "         0.7583, -0.1535]) tensor([-0.0651, -0.6836,  1.1547,  1.1473, -0.6543,  0.0395, -0.1876, -0.7745,\n",
      "         0.2168,  0.0107]) tensor([-0.2366, -0.4736,  0.9257,  1.2878, -0.4501,  0.1344, -0.1677, -0.5102,\n",
      "         0.2239,  0.0279])\n",
      "R[0]\n",
      "tensor([0.0096], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0527138938754797 0.003178761478233355 0.00225320547544834 0.005699040251318365 0.034367436043918134 0.40779901105165484 0.008029606075026095 42.32465372467041\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1101, -0.6140,  1.1934,  1.0793, -0.6737, -0.1779,  0.0848, -0.7018,\n",
      "         0.2728, -0.1537]) tensor([-0.0866, -0.6263,  1.1585,  1.0386, -0.6564, -0.1963,  0.1482, -0.7121,\n",
      "         0.1831, -0.0165]) tensor([ 0.1271, -0.6513,  1.1224,  1.0181, -0.6792, -0.1925,  0.1666, -0.7384,\n",
      "        -0.1250,  0.1118])\n",
      "R[0]\n",
      "tensor([0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052888792484998705 0.004222821006958839 0.002517944338145753 0.006056889694416896 0.033613893691450354 0.4091538252234459 0.007859072342980652 42.393955055236816\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3146, -0.7976,  0.9119,  0.3708, -0.0475, -0.0560,  0.2856, -0.5415,\n",
      "         0.3273, -0.1560]) tensor([-0.2498, -0.7753,  0.9329,  0.4450, -0.0781, -0.0256,  0.2521, -0.5579,\n",
      "         0.1512,  0.0120]) tensor([-0.2268, -0.6411,  0.8588,  0.6541, -0.0808,  0.0528,  0.2448, -0.4989,\n",
      "         0.0556, -0.3943])\n",
      "R[0]\n",
      "tensor([0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05263623137027025 0.003904320827799893 0.0023235176010712164 0.005922761681722477 0.033556413315236566 0.4053238479495049 0.008189622698817402 42.33992529296875\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0052, -0.5775,  1.2293,  1.1021, -0.6932, -0.1711,  0.0726, -0.6781,\n",
      "         0.1152, -0.3794]) tensor([-0.0387, -0.5808,  1.1642,  1.0799, -0.6926, -0.1730,  0.1110, -0.7212,\n",
      "         0.1940,  0.0053]) tensor([ 0.0902, -0.5172,  1.1962,  1.1386, -0.6566, -0.1837,  0.0785, -0.6087,\n",
      "         0.7989, -0.1891])\n",
      "R[0]\n",
      "tensor([-0.0039], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052896332696080205 0.004050391455333738 0.0022796675342833623 0.0058757144415285435 0.03353193688392639 0.4182070224881172 0.007780363467056304 42.409696060180664\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4392, -0.8622,  1.0909,  0.5928, -0.4382, -0.2135,  0.0717, -0.6655,\n",
      "         0.0287,  0.0629]) tensor([-0.1620, -0.8323,  1.1052,  0.6305, -0.3897, -0.1766,  0.0675, -0.6269,\n",
      "         0.1977,  0.0141]) tensor([-0.3571, -0.6158,  1.0204,  0.9745, -0.5991, -0.1674,  0.0645, -0.6072,\n",
      "        -0.4912,  0.0751])\n",
      "R[0]\n",
      "tensor([0.0020], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05259990356117487 0.0038432994315407997 0.0024176777932771072 0.0059285079215187575 0.03381055189296603 0.42026048052310944 0.007687792697921395 42.42468933105469\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1078, -0.4373,  1.0116,  0.9193, -0.7422, -0.3777,  0.6570, -0.9202,\n",
      "        -0.0708,  0.1517]) tensor([ 0.0109, -0.4289,  1.0220,  0.9289, -0.7392, -0.3447,  0.6135, -0.9275,\n",
      "         0.0327, -0.1560]) tensor([-0.3127, -0.3756,  0.9228,  0.9069, -0.7352, -0.3016,  0.5542, -0.8423,\n",
      "         0.7724, -0.0271])\n",
      "R[0]\n",
      "tensor([-0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052385457821190355 0.0037425425233450368 0.00225286145850805 0.005928388982778415 0.03418157605454326 0.4154996060729027 0.007595383159816265 42.38995826721192\n",
      "Average (on the epoch) training loss: 0.005864786214497872\n",
      "Episode average V value: 0\n",
      "epoch 17:\n",
      "Learning rate: 1.8530201888518422e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 88.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 87.99120087991201 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9345, -0.8907,  1.0331,  0.5010, -0.0684,  0.1917,  0.0703, -0.7125,\n",
      "         0.4468,  0.6868]) tensor([-0.2295, -0.9008,  0.9679,  0.4772, -0.0992,  0.1890,  0.0602, -0.7765,\n",
      "         0.2226,  0.0582]) tensor([-0.3876, -1.1580,  1.1573,  0.1113,  0.0756,  0.1635,  0.0729, -0.8255,\n",
      "         0.7021,  0.4461])\n",
      "R[0]\n",
      "tensor([0.0120], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05266468677669764 0.0037693392027231313 0.002496048041186441 0.0060253155259415506 0.03388444599509239 0.4302035987377167 0.0074961930485442285 42.5674253616333\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0995, -0.4784,  1.1279,  1.2554, -0.5345, -0.0218, -0.0808, -0.4849,\n",
      "         0.6263,  0.2191]) tensor([-0.0606, -0.5076,  1.0799,  1.2035, -0.5447, -0.0353, -0.0496, -0.5444,\n",
      "         0.1362, -0.0304]) tensor([-0.3525, -0.6524,  1.2511,  1.1047, -0.6736, -0.1002, -0.0133, -0.7611,\n",
      "         0.5194,  0.4936])\n",
      "R[0]\n",
      "tensor([0.0019], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0523491268157959 0.0038333799436913976 0.0023875769035876146 0.006060249457135796 0.03391919049993158 0.4263447696566582 0.00762827351829037 42.458540992736815\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1362, -0.5018,  0.8021,  1.1411, -0.3663,  0.3071, -0.2515, -0.6269,\n",
      "        -0.0614,  0.2078]) tensor([-0.1070, -0.5442,  0.8395,  1.0882, -0.3493,  0.3007, -0.2541, -0.6388,\n",
      "         0.1927, -0.0359]) tensor([-0.3354, -0.4174,  0.6599,  1.2020, -0.1885,  0.4135, -0.2343, -0.4463,\n",
      "        -0.1261, -0.6838])\n",
      "R[0]\n",
      "tensor([0.0001], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052636659525334833 0.004061316481582253 0.0022969633166667336 0.006135695006232709 0.03403860317543149 0.4186817512512207 0.00729326202115044 42.46738748168945\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5285, -1.2245,  1.2862,  0.1691, -0.1743, -0.0618,  0.3678, -1.2063,\n",
      "         0.4313,  0.4079]) tensor([-0.1866, -1.1520,  1.2437,  0.2360, -0.2002, -0.0736,  0.3602, -1.1409,\n",
      "         0.3096,  0.1040]) tensor([ 0.4485, -1.1000,  1.2941,  0.2838, -0.1638, -0.1360,  0.4648, -1.0346,\n",
      "        -0.1189,  0.9249])\n",
      "R[0]\n",
      "tensor([0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05286302890628576 0.0040423111301588505 0.0021950747420996777 0.006082786709303036 0.03369533580541611 0.4178867311477661 0.007628072881139815 42.448027923583986\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0354, -0.5174,  1.0022,  0.8653, -0.7021, -0.3468,  0.7213, -1.0118,\n",
      "         0.2466, -0.2800]) tensor([-0.0051, -0.4969,  0.9983,  0.8669, -0.6924, -0.3147,  0.6681, -1.0020,\n",
      "         0.0173, -0.1188]) tensor([-0.0936, -0.5038,  1.0601,  0.9209, -0.7030, -0.2739,  0.5922, -0.9771,\n",
      "        -0.3711, -0.2040])\n",
      "R[0]\n",
      "tensor([-0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05246351702511311 0.004073669324656293 0.002615513358687167 0.006071855256799609 0.03357900414615869 0.423936778485775 0.0074909084415994585 42.46923815155029\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3709, -0.7893,  1.2829,  0.9146, -0.5715, -0.0999, -0.0833, -0.6914,\n",
      "        -0.0189,  0.0656]) tensor([-0.1208, -0.7733,  1.2714,  0.9231, -0.5362, -0.0733, -0.0689, -0.6819,\n",
      "         0.3097,  0.0539]) tensor([-0.4763, -1.0530,  1.4882,  0.6406, -0.4232, -0.0123, -0.1324, -0.8807,\n",
      "         0.6348,  0.7687])\n",
      "R[0]\n",
      "tensor([0.0022], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05244801214337349 0.0041072771267790815 0.0021594230572136437 0.005883861865615472 0.034350161802023646 0.4265120161175728 0.0074695593663491305 42.59139475250244\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2177, -0.6009,  0.9470,  0.8339, -0.6718, -0.2772,  0.7249, -1.1543,\n",
      "         0.6260,  0.3003]) tensor([-0.0072, -0.5928,  0.9816,  0.8346, -0.6700, -0.2464,  0.6656, -1.1412,\n",
      "         0.0771, -0.0658]) tensor([ 0.2053, -0.5608,  1.0962,  0.8334, -0.6657, -0.2695,  0.6828, -1.0947,\n",
      "         0.1887, -0.0324])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05270310915261507 0.004147478767044958 0.0019287552293826592 0.005860822702292353 0.03381071868166328 0.43384945517778395 0.007508265469223261 42.5436351776123\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3598, -0.6345,  0.9117,  0.1816, -0.1365, -0.2911,  0.4511, -0.6565,\n",
      "        -0.0439, -0.0502]) tensor([-0.1825, -0.6409,  0.9930,  0.2935, -0.1876, -0.2434,  0.4073, -0.7180,\n",
      "         0.0799, -0.0151]) tensor([ 0.2059, -0.4808,  0.9375,  0.4232, -0.4197, -0.2567,  0.4315, -0.9663,\n",
      "        -0.2587, -0.1399])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05216909051686525 0.0037485318577273573 0.0025500492894680064 0.005853807226754725 0.033740664411336184 0.42946071565151217 0.007429469137918204 42.61178009796143\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0075, -0.7064,  0.6885,  0.4531, -0.2878, -0.1411,  0.4619, -0.8199,\n",
      "        -0.3724, -0.3268]) tensor([-0.1438, -0.7334,  0.7647,  0.5352, -0.3672, -0.0981,  0.3680, -0.9125,\n",
      "         0.0447, -0.0547]) tensor([-0.3579, -0.8484,  0.7825,  0.4711, -0.4510, -0.1465,  0.3567, -0.9760,\n",
      "         0.1104,  0.5130])\n",
      "R[0]\n",
      "tensor([0.0155], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05286241374909878 0.004011202947764104 0.002333658746394576 0.0059441433537285775 0.03359782808460295 0.42388782507181166 0.00753275171853602 42.43960844421387\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6603, -0.9673,  0.9930,  0.3823, -0.2283, -0.2058,  0.2525, -0.6728,\n",
      "         0.5315,  0.1798]) tensor([-0.2139, -0.9529,  1.0351,  0.4630, -0.2628, -0.1813,  0.2016, -0.6822,\n",
      "         0.1642,  0.0222]) tensor([-0.4524, -0.8466,  0.9266,  0.4728, -0.3161, -0.2429,  0.1601, -0.5509,\n",
      "        -0.0682,  0.0132])\n",
      "R[0]\n",
      "tensor([9.3162e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0525595617890358 0.003955468787817154 0.0029118580827416736 0.00599079453991726 0.033502373076975345 0.43281216084957125 0.0073120341622270645 42.59747824859619\n",
      "Average (on the epoch) training loss: 0.005990933164372109\n",
      "Episode average V value: 0\n",
      "epoch 18:\n",
      "Learning rate: 1.667718169966658e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 113.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 112.98870112988702 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1088, -1.1098,  1.2063,  0.1213, -0.0341, -0.1148, -0.0280, -0.6137,\n",
      "         0.5521,  0.4824]) tensor([-0.2840, -1.0626,  1.1946,  0.1795, -0.0059, -0.0760, -0.0347, -0.5838,\n",
      "         0.3216,  0.1281]) tensor([-0.0145, -1.0176,  1.1237,  0.3721, -0.2360, -0.1280, -0.0199, -0.6734,\n",
      "         0.2947,  0.2304])\n",
      "R[0]\n",
      "tensor([0.0023], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05238526930660009 0.004003838790607915 0.0025625396906598327 0.005970996242482215 0.033522969208657744 0.42753854048252105 0.007531527810264379 42.6003258895874\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0011, -0.7054,  1.0743,  0.8623, -0.5331, -0.2170,  0.2237, -0.6641,\n",
      "         0.4260,  0.3512]) tensor([-0.0950, -0.7197,  1.0625,  0.8469, -0.5359, -0.2134,  0.2361, -0.6969,\n",
      "         0.1154, -0.0402]) tensor([-0.1594, -0.8165,  0.9459,  0.6904, -0.4272, -0.1595,  0.3189, -0.7778,\n",
      "        -0.2458,  0.3627])\n",
      "R[0]\n",
      "tensor([-0.0021], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052795863665640354 0.003748066903288418 0.0024103974331737845 0.005631839761510491 0.03350966133177281 0.42256657910346984 0.007519786260090768 42.4617038269043\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6441, -0.5219,  1.0567,  0.9357, -0.7869, -0.3801,  0.6169, -1.0154,\n",
      "         0.2333, -0.4598]) tensor([ 0.0493, -0.5142,  1.0871,  0.9635, -0.7842, -0.3412,  0.5660, -1.0230,\n",
      "         0.0802, -0.0843]) tensor([-0.4006, -0.4970,  1.0642,  0.9206, -0.7977, -0.3847,  0.6163, -1.0172,\n",
      "         0.4033, -0.2344])\n",
      "R[0]\n",
      "tensor([-0.0017], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05246694112569094 0.004113638669641659 0.002355007440513873 0.005880561769707128 0.0340822415985167 0.42367068910598754 0.007315305020660162 42.5235934753418\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3480, -0.9022,  1.0150,  0.5147, -0.2996, -0.2136,  0.1665, -0.6328,\n",
      "         0.5207,  0.2497]) tensor([-0.1726, -0.8810,  1.0381,  0.6022, -0.3260, -0.1937,  0.1600, -0.6456,\n",
      "         0.1068,  0.0123]) tensor([-0.5692, -0.8538,  0.9765,  0.4890, -0.2750, -0.2528,  0.1741, -0.5366,\n",
      "         0.5310,  0.5777])\n",
      "R[0]\n",
      "tensor([0.0062], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05233711142092943 0.0038815333332786394 0.0024735153911642554 0.005888827152550221 0.033555428843945266 0.4241518866419792 0.007401770310942084 42.569290733337404\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0680, -0.6689,  1.0748,  1.0069, -0.7868, -0.0428, -0.0830, -0.9765,\n",
      "         0.2363,  0.0394]) tensor([ 9.8625e-04, -6.6738e-01,  1.0510e+00,  9.8902e-01, -7.4677e-01,\n",
      "        -7.7044e-02,  1.9181e-02, -9.3962e-01,  1.4823e-01, -4.0029e-02]) tensor([-0.5656, -0.8821,  1.1885,  1.0242, -0.8969, -0.0518, -0.0533, -1.1701,\n",
      "         0.3084, -0.1472])\n",
      "R[0]\n",
      "tensor([0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05271337949484587 0.0040642624868414716 0.0022090883761320583 0.006120884041534737 0.03365526506304741 0.40826306051015854 0.00752976765204221 42.396008117675784\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6077, -0.6624,  0.8605,  0.8092, -0.7181, -0.1318,  0.4989, -1.3679,\n",
      "         0.0434,  0.1750]) tensor([-0.0062, -0.6479,  0.8804,  0.8108, -0.7111, -0.1511,  0.4767, -1.3073,\n",
      "         0.0163, -0.1158]) tensor([ 0.0700, -0.7382,  0.9579,  0.8617, -0.7974, -0.1555,  0.4527, -1.3382,\n",
      "         0.2914, -0.9166])\n",
      "R[0]\n",
      "tensor([-0.0039], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052826972253620624 0.004376007929660773 0.0025884497016122623 0.0062812452195212245 0.03363973868638277 0.40866105842590333 0.007660793655086309 42.35340705108643\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1239, -0.5267,  0.9150,  0.8824, -0.4818, -0.2502,  0.1519, -0.3904,\n",
      "         0.4249,  0.5632]) tensor([-0.1042, -0.5613,  0.9532,  0.9063, -0.5122, -0.2410,  0.1455, -0.4543,\n",
      "         0.0248, -0.0682]) tensor([-0.1838, -0.5273,  0.9051,  0.8743, -0.4776, -0.2567,  0.1461, -0.3838,\n",
      "        -0.5070,  0.3380])\n",
      "R[0]\n",
      "tensor([-0.0038], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05214957925677299 0.003498144471570413 0.0026321565688049303 0.005861541222548112 0.033863722875714306 0.41474968296289444 0.0077711825231090185 42.39413636779785\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4821, -0.7942,  1.0477,  0.8892, -0.6692, -0.1505,  0.1021, -0.8561,\n",
      "         0.0978, -0.3136]) tensor([-0.0751, -0.8056,  1.0405,  0.8649, -0.6385, -0.1588,  0.1450, -0.8495,\n",
      "         0.1308, -0.0113]) tensor([-0.3446, -0.7175,  0.8938,  0.8438, -0.5281, -0.1810,  0.2559, -0.7019,\n",
      "        -0.2388, -0.4728])\n",
      "R[0]\n",
      "tensor([0.0024], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052509933009743694 0.0038176525637591114 0.002134585863779648 0.0056372632985003295 0.03371303825452924 0.41070705565810206 0.007778459337074309 42.38499317932129\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2706, -0.8076,  0.7684,  0.5798, -0.3408, -0.1604,  0.3124, -0.6981,\n",
      "        -0.4062, -0.2330]) tensor([-0.1467, -0.8265,  0.8211,  0.6273, -0.3768, -0.1209,  0.2441, -0.7587,\n",
      "         0.0885, -0.0188]) tensor([-0.0201, -1.1196,  0.8106,  0.2329, -0.1830, -0.0772,  0.4082, -1.0218,\n",
      "         0.2369,  0.3889])\n",
      "R[0]\n",
      "tensor([0.0113], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052615716740489 0.00361540785447869 0.0023225855405271433 0.005717911085113883 0.033669188503175976 0.41796772134304044 0.007798157220706344 42.44095220184326\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3095, -0.4012,  1.6029,  1.2729, -0.5547,  0.2415, -0.4282, -0.8212,\n",
      "         0.4933,  0.4445]) tensor([ 0.0176, -0.4035,  1.4406,  1.1942, -0.5698,  0.1705, -0.2853, -0.8671,\n",
      "         0.3708,  0.0707]) tensor([ 0.0422, -0.6969,  1.6691,  1.2583, -0.6805,  0.3094, -0.5566, -1.0426,\n",
      "         0.4491,  0.3475])\n",
      "R[0]\n",
      "tensor([0.0160], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052860976293683054 0.003922250659108613 0.002628992279018348 0.006112365388777107 0.033188669223338366 0.42084326630830765 0.007471497099846601 42.4705963973999\n",
      "Average (on the epoch) training loss: 0.005910343518224545\n",
      "Episode average V value: 0\n",
      "epoch 19:\n",
      "Learning rate: 1.5009463529699922e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 85.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 84.99150084991501 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1818, -1.4656,  0.9672, -0.3937,  0.5020,  0.2026,  0.7346, -1.1934,\n",
      "         0.1068,  0.3233]) tensor([-0.3907, -1.3882,  0.9745, -0.2688,  0.3999,  0.2534,  0.5589, -1.1908,\n",
      "         0.3287,  0.1149]) tensor([-0.6279, -1.0561,  0.7817,  0.3227, -0.0793,  0.0818,  0.6205, -1.1234,\n",
      "        -0.1078,  0.1223])\n",
      "R[0]\n",
      "tensor([-0.0367], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052468593217432496 0.0037550591855560925 0.0024337966691000473 0.005829234872246161 0.033465767480432985 0.42938923358917236 0.007619267662521452 42.465772804260254\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2599, -0.7768,  0.8322,  0.7015, -0.4043, -0.1135,  0.1752, -0.6935,\n",
      "         0.2879,  0.2710]) tensor([-0.1720, -0.7657,  0.8795,  0.7123, -0.3598, -0.0789,  0.1293, -0.6505,\n",
      "         0.0732, -0.0372]) tensor([-0.1066, -0.7693,  0.8173,  0.7439, -0.4665, -0.1324,  0.1969, -0.7281,\n",
      "         0.2756, -0.3459])\n",
      "R[0]\n",
      "tensor([0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05241386391967535 0.004105100448123266 0.002626838649577621 0.006011769006261602 0.03389183846488595 0.4162689134478569 0.007800740407779813 42.430246719360355\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2023, -0.7018,  0.8905,  0.6374, -0.5731,  0.0326,  0.4807, -1.5814,\n",
      "         0.2609,  0.4009]) tensor([ 0.0050, -0.6816,  0.8761,  0.6182, -0.5791, -0.0201,  0.4945, -1.5048,\n",
      "         0.0564, -0.0930]) tensor([ 0.4707, -0.6890,  0.9413,  0.7308, -0.6383, -0.0334,  0.4905, -1.4887,\n",
      "        -0.2191, -0.4592])\n",
      "R[0]\n",
      "tensor([0.0062], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052672495014965535 0.0040979989042225495 0.0022056829759440006 0.0060488272844813765 0.033218946486711504 0.42156184202432634 0.007608443694654852 42.41586463165283\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1312, -0.5182,  1.0867,  1.0956, -0.6286, -0.2315,  0.1453, -0.5448,\n",
      "         0.7401,  0.5820]) tensor([-0.0577, -0.5368,  1.1290,  1.0897, -0.6154, -0.2052,  0.1320, -0.5634,\n",
      "         0.1536,  0.0030]) tensor([-0.5589, -0.5447,  1.1926,  1.1282, -0.6375, -0.1595,  0.0476, -0.6230,\n",
      "         0.0582,  0.0507])\n",
      "R[0]\n",
      "tensor([0.0022], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05295156643539667 0.004199261721496441 0.0022001175753994175 0.006066841631894931 0.03347534190490842 0.42040524452924727 0.0075177069120109085 42.38370368957519\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2471, -0.6633,  1.2119,  1.0941, -0.6613, -0.0436, -0.0331, -0.7990,\n",
      "        -0.2249,  0.0316]) tensor([-0.0560, -0.6493,  1.1752,  1.0550, -0.6103, -0.0300, -0.0220, -0.7751,\n",
      "         0.2404,  0.0071]) tensor([ 0.3843, -0.3742,  1.3159,  1.3853, -0.5912,  0.0732, -0.3352, -0.4379,\n",
      "        -0.2988,  0.2139])\n",
      "R[0]\n",
      "tensor([-0.0020], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05217369981855154 0.00386428806918957 0.002654900881645517 0.005998102926881984 0.033927939180284736 0.42625607228279117 0.0077620239858515565 42.420587699890135\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6043, -0.7053,  1.0259,  0.8203, -0.5102, -0.1490,  0.1674, -0.6953,\n",
      "         0.7016, -0.3327]) tensor([-0.1043, -0.7054,  1.0527,  0.8297, -0.4977, -0.1215,  0.1438, -0.7005,\n",
      "         0.1652, -0.0139]) tensor([ 1.0063e-03, -7.9720e-01,  1.2064e+00,  8.9766e-01, -5.8858e-01,\n",
      "        -9.9189e-02, -5.1965e-02, -7.3669e-01, -6.2449e-02,  1.9074e-01])\n",
      "R[0]\n",
      "tensor([0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05201624269783497 0.0038559094236061357 0.0021811398140343954 0.005871708330931142 0.033552318073809144 0.42869258093833923 0.007566300872713328 42.502067779541015\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2669, -0.4763,  0.9913,  1.1739, -0.4127, -0.0051,  0.0178, -0.4324,\n",
      "         0.1060,  0.0681]) tensor([-0.1001, -0.4944,  0.9781,  1.1375, -0.4091,  0.0082,  0.0103, -0.4710,\n",
      "         0.1217, -0.0199]) tensor([-0.2996, -0.6045,  1.3061,  1.2178, -0.6411,  0.0063, -0.1792, -0.6693,\n",
      "         0.6733,  0.1242])\n",
      "R[0]\n",
      "tensor([-0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05298280327022076 0.003812854666457497 0.0023040662108032846 0.005707576723536476 0.03353183968365193 0.4264841932058334 0.007623995250556618 42.35874946594238\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3290, -0.7317,  1.0652,  0.9603, -0.7984, -0.2039,  0.3836, -1.1571,\n",
      "        -0.1736, -0.3117]) tensor([ 0.0246, -0.7197,  1.0574,  0.9316, -0.7686, -0.2073,  0.3876, -1.1135,\n",
      "         0.1306, -0.0353]) tensor([ 0.4693, -0.7312,  1.0798,  0.9379, -0.7923, -0.1855,  0.4044, -1.2015,\n",
      "         0.3049,  0.2231])\n",
      "R[0]\n",
      "tensor([1.9640e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05287963405996561 0.004255795886116175 0.002321203285124284 0.005816367621067912 0.03353353203460574 0.4243325745463371 0.007551197716034949 42.29212966918945\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4565, -0.8699,  1.5733,  1.0265, -0.8436, -0.0106,  0.0982, -1.3390,\n",
      "         0.4127,  0.3536]) tensor([ 0.0358, -0.8066,  1.4389,  0.9987, -0.8264, -0.0530,  0.1804, -1.2765,\n",
      "         0.3902,  0.0540]) tensor([-0.1615, -0.8173,  1.4820,  1.0464, -0.9237, -0.1097,  0.1365, -1.2788,\n",
      "         0.0081,  0.2239])\n",
      "R[0]\n",
      "tensor([0.0043], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053038407944142815 0.004121566474083011 0.0018718735900110914 0.006037484545027837 0.03378729256242514 0.4160370483994484 0.007776698092930019 42.315148918151856\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8693, -0.4855,  1.1591,  1.2350, -0.6431, -0.0904, -0.0991, -0.5135,\n",
      "         0.4179,  0.0170]) tensor([-0.0731, -0.5024,  1.1304,  1.1828, -0.6130, -0.0751, -0.0937, -0.5448,\n",
      "         0.1654, -0.0112]) tensor([-0.5679, -0.3652,  1.1624,  1.3089, -0.5807, -0.0465, -0.1589, -0.3709,\n",
      "        -0.1096,  0.4743])\n",
      "R[0]\n",
      "tensor([-0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05343265640735626 0.004194898638874293 0.00208164038022187 0.006107513995841146 0.03322756865248084 0.41371863934397696 0.00756212491961196 42.26429804229736\n",
      "Average (on the epoch) training loss: 0.005949542693817057\n",
      "Episode average V value: 0\n",
      "epoch 20:\n",
      "Learning rate: 1.350851717672993e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 111.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 110.98890110988901 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0045, -0.5186,  1.1328,  1.1792, -0.6193, -0.0988, -0.0398, -0.5705,\n",
      "         0.6420,  0.2344]) tensor([-0.0457, -0.5361,  1.0948,  1.1468, -0.6211, -0.1067, -0.0075, -0.6120,\n",
      "         0.0936, -0.0205]) tensor([ 0.1793, -0.5585,  1.0519,  1.1291, -0.6262, -0.1619,  0.0676, -0.5838,\n",
      "        -0.4446,  0.3503])\n",
      "R[0]\n",
      "tensor([-0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05260105015337467 0.004076021988248612 0.0022193772265181907 0.005983002248452976 0.03376371479034424 0.4270752133727074 0.007574804403819144 42.473583679199216\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1314, -0.1683,  0.5247,  0.6879, -0.6532, -0.1067,  0.2387, -0.9601,\n",
      "        -0.0283, -0.3178]) tensor([ 0.0317, -0.2267,  0.6499,  0.7759, -0.7102, -0.1353,  0.2738, -1.0064,\n",
      "        -0.1784, -0.1784]) tensor([ 0.2432, -0.2080,  0.5948,  0.7076, -0.6632, -0.1061,  0.2326, -0.9963,\n",
      "        -0.2180, -0.4364])\n",
      "R[0]\n",
      "tensor([0.0051], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053155454188585284 0.004021253944296405 0.002565917706513574 0.006198635069886223 0.03423835649713874 0.4222056727409363 0.0076791453049518165 42.434931533813476\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0783, -0.9487,  1.2411,  0.4922, -0.2150, -0.0781, -0.0501, -0.6117,\n",
      "        -0.3564,  0.2201]) tensor([-0.1928, -0.9407,  1.1111,  0.4424, -0.1983, -0.0438, -0.0405, -0.6946,\n",
      "         0.2322,  0.0977]) tensor([-0.1724, -0.8223,  1.0628,  0.6039, -0.3031, -0.1378,  0.1606, -0.6404,\n",
      "         0.0801,  0.4427])\n",
      "R[0]\n",
      "tensor([0.0152], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052736879497766495 0.0042881708879758665 0.0021530843241725963 0.0060371291760820895 0.03310151687823236 0.4228380144834518 0.0077027960643172265 42.32480337524414\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4279, -0.7876,  0.9144,  0.3913, -0.1984, -0.2172,  0.3981, -0.6541,\n",
      "         0.0581, -0.2259]) tensor([-0.1653, -0.7754,  0.9648,  0.5135, -0.2778, -0.1912,  0.3455, -0.7051,\n",
      "         0.0785,  0.0091]) tensor([-0.2686, -0.7617,  0.7095,  0.6542, -0.4201, -0.1567,  0.3098, -0.7431,\n",
      "         0.3398,  0.1499])\n",
      "R[0]\n",
      "tensor([0.0179], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05256140308827162 0.00446839263790207 0.0020548103737564817 0.005943846686044708 0.033775021173059944 0.4276788376569748 0.007488002982921898 42.42672054290772\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5028, -0.4046,  0.5126,  0.7804,  0.1032,  0.2611,  0.2517, -0.3765,\n",
      "        -0.4467,  0.1758]) tensor([-0.2103, -0.4871,  0.6267,  0.7890,  0.0017,  0.2525,  0.1770, -0.4788,\n",
      "         0.0304, -0.1103]) tensor([-0.2520, -0.6253,  0.5157,  0.1837, -0.0849, -0.0710,  0.4696, -0.8065,\n",
      "         0.1174, -0.3400])\n",
      "R[0]\n",
      "tensor([-0.0033], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05314295949041843 0.004418475616887008 0.0021293037836439908 0.006131964112864807 0.03354060898348689 0.43080406993627546 0.007582089625298977 42.382189430236814\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6040, -0.5477,  1.0262,  0.8988, -0.7302, -0.2603,  0.5760, -1.0441,\n",
      "        -0.2246,  0.4538]) tensor([-0.0030, -0.5542,  1.0547,  0.8982, -0.7357, -0.2460,  0.5401, -1.0503,\n",
      "         0.0899, -0.0709]) tensor([ 1.1720, -0.5605,  1.0072,  0.8812, -0.7361, -0.3022,  0.6372, -1.0644,\n",
      "         0.6826,  0.8120])\n",
      "R[0]\n",
      "tensor([0.0008], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05275634047389031 0.003953651619191078 0.0019474302026337683 0.005797170601785183 0.03368295615538955 0.4226164438724518 0.007599699549376965 42.35365690612793\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0561, -0.6760,  1.1365,  1.4705, -0.3415,  0.6464, -0.6862, -0.7018,\n",
      "         0.7697, -0.0560]) tensor([-0.1036, -0.6865,  1.0614,  1.3327, -0.2716,  0.6057, -0.6422, -0.6516,\n",
      "         0.3743,  0.1157]) tensor([-0.3068, -0.7026,  1.2483,  1.5466, -0.3471,  0.7187, -0.8111, -0.7131,\n",
      "         0.7090, -0.3660])\n",
      "R[0]\n",
      "tensor([0.0045], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0529308470338583 0.004182363233583601 0.001975113415484884 0.005893147717928514 0.03350423637032509 0.4283890774846077 0.007468603836372495 42.40822466278076\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5878, -0.5084,  0.7015,  0.5687, -0.5517, -0.0526,  0.5118, -1.3889,\n",
      "         0.0345, -0.2503]) tensor([ 0.0255, -0.5174,  0.7866,  0.5808, -0.5382, -0.0369,  0.4515, -1.3505,\n",
      "        -0.0269, -0.1025]) tensor([ 0.3925, -0.6400,  0.9684,  0.7037, -0.6542, -0.1294,  0.4925, -1.3329,\n",
      "         0.3264, -0.5252])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05345665965229273 0.004162838508396817 0.0022744791422028357 0.005938654647557997 0.03430366198718548 0.4203740472793579 0.007423540437594056 42.28404237365723\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0902, -0.7989,  1.3183,  1.0777, -0.8155, -0.0354, -0.1208, -0.9848,\n",
      "         0.8014, -0.1469]) tensor([-0.0286, -0.7702,  1.2750,  1.0437, -0.7377, -0.0267, -0.1005, -0.9224,\n",
      "         0.2850,  0.0317]) tensor([-0.0686, -0.7831,  1.1333,  0.9875, -0.8449, -0.1382,  0.1129, -1.0676,\n",
      "         0.4880, -0.1726])\n",
      "R[0]\n",
      "tensor([0.0021], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05314032018184662 0.003981269857093139 0.0019654161644702983 0.005738334642723203 0.03422914101183414 0.4212490607500076 0.007603572289925069 42.327652320861816\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2087, -0.8135,  1.5136,  1.2306, -0.6925,  0.2145, -0.5460, -0.8589,\n",
      "         0.1936, -0.0918]) tensor([-0.0638, -0.7949,  1.4451,  1.1799, -0.6243,  0.2185, -0.4919, -0.8290,\n",
      "         0.4418,  0.1342]) tensor([ 0.1949, -1.2639,  1.5655,  0.1136,  0.0467,  0.1040, -0.1684, -0.8648,\n",
      "         0.6675,  0.2517])\n",
      "R[0]\n",
      "tensor([0.0014], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053250106111168864 0.004153410704706402 0.0019592780470193247 0.006047932712826878 0.03341912418231368 0.42335583639144897 0.00735626007663086 42.31576777648926\n",
      "Average (on the epoch) training loss: 0.005970981761615258\n",
      "Episode average V value: 0\n",
      "epoch 21:\n",
      "Learning rate: 1.2157665459056937e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 99.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 98.99010098990101 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5028, -0.5208,  1.0408,  0.9500, -0.7864, -0.3795,  0.6299, -0.9941,\n",
      "         0.0359, -1.0937]) tensor([-0.0038, -0.5219,  1.0498,  0.9223, -0.7676, -0.3627,  0.6049, -0.9845,\n",
      "         0.0068, -0.1870]) tensor([-0.5562, -0.5572,  1.0601,  0.9213, -0.7484, -0.3318,  0.6535, -1.0799,\n",
      "         0.5796, -0.3187])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05291664337366819 0.004051132584550942 0.002293280171873448 0.006039519598009065 0.03339914213865995 0.4240256954431534 0.007395779558923095 42.29952210235596\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1447, -0.8183,  1.0042,  0.6850, -0.2532,  0.1028,  0.0207, -0.6806,\n",
      "         0.0232,  0.1346]) tensor([-0.1920, -0.8076,  1.0176,  0.7077, -0.2520,  0.1235,  0.0062, -0.6802,\n",
      "         0.2635,  0.0416]) tensor([-0.5379, -0.8859,  0.8465,  0.3499, -0.1649, -0.0587,  0.2840, -0.7037,\n",
      "        -0.2224,  0.3205])\n",
      "R[0]\n",
      "tensor([0.0020], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05255480306595564 0.00438772082608375 0.0018702972733499338 0.005952376339584589 0.033659215580672024 0.42693562591075895 0.007774522261694073 42.36203407287598\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3741, -0.6708,  1.2496,  0.9777, -0.8252, -0.2159,  0.3900, -1.2131,\n",
      "        -0.0984, -0.2363]) tensor([ 0.0218, -0.6370,  1.1700,  0.9555, -0.8169, -0.2250,  0.4120, -1.1944,\n",
      "         0.1788, -0.0161]) tensor([ 0.2886, -0.6607,  1.2787,  0.9998, -0.8783, -0.2425,  0.3170, -1.1411,\n",
      "         0.4461, -0.4218])\n",
      "R[0]\n",
      "tensor([-0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05269980224967003 0.0037151716018397566 0.002027495834421643 0.005743462163489312 0.03336372504010796 0.42736346715688706 0.007596102978102863 42.43250768280029\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1421, -0.6443,  0.9863,  0.8684, -0.7477, -0.2471,  0.5748, -1.1863,\n",
      "         0.2420, -0.5780]) tensor([ 0.0024, -0.6337,  1.0221,  0.8779, -0.7255, -0.2196,  0.5203, -1.1550,\n",
      "         0.0809, -0.0579]) tensor([-0.4143, -0.5717,  1.0063,  0.8219, -0.6396, -0.2630,  0.7232, -1.1103,\n",
      "         0.5314, -0.3348])\n",
      "R[0]\n",
      "tensor([-0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05270237785577774 0.004227574513713989 0.0017948374069219426 0.005753237530821935 0.03370404165610671 0.41839502477645873 0.007571423925459385 42.332384880065916\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5154, -1.1012,  1.1035, -0.2370,  0.3947, -0.0461,  0.2809, -0.5973,\n",
      "         0.4066, -0.2175]) tensor([-0.3595, -1.0679,  1.1305, -0.1084,  0.3201, -0.0084,  0.2265, -0.6400,\n",
      "         0.2548,  0.1735]) tensor([-0.0186, -1.0413,  1.1856,  0.0475,  0.2613, -0.0323,  0.0951, -0.5010,\n",
      "        -0.1320,  0.3007])\n",
      "R[0]\n",
      "tensor([-0.0087], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052748779572546485 0.004508407867506321 0.0021186684892963966 0.0059450555322691796 0.034315947830677034 0.4225278193354607 0.007579273222479969 42.39510877227783\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1496, -0.7475,  1.0424,  0.8446, -0.5424, -0.1819,  0.1596, -0.7039,\n",
      "        -0.7487,  0.1742]) tensor([-0.0845, -0.7506,  1.0319,  0.8443, -0.5403, -0.1773,  0.1541, -0.7192,\n",
      "         0.1465,  0.0032]) tensor([-0.0272, -0.7234,  0.9584,  0.8832, -0.5666, -0.1902,  0.2127, -0.7018,\n",
      "         0.1361, -0.2478])\n",
      "R[0]\n",
      "tensor([-0.0063], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052652631603181364 0.003770662293358328 0.0021577441667741367 0.0057886168125551194 0.03329471838101745 0.42654226875305173 0.0073623555628582835 42.372134048461916\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2466, -0.9968,  1.0247,  0.1176, -0.1758, -0.1739,  0.3481, -0.9275,\n",
      "        -0.0268,  0.0901]) tensor([-0.2228, -0.9435,  1.0302,  0.1754, -0.1503, -0.1346,  0.3111, -0.8753,\n",
      "         0.1814,  0.0598]) tensor([ 0.8395, -0.9056,  0.7773,  0.1716, -0.0963, -0.1699,  0.4391, -0.7276,\n",
      "        -0.7090, -0.1592])\n",
      "R[0]\n",
      "tensor([0.0024], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05294201397895813 0.004194012022790048 0.002057671124697663 0.006054201699094847 0.033514561504125594 0.41980733305215834 0.007331861986778676 42.340135215759275\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0744, -0.6374,  1.7889,  1.2534, -0.5877,  0.4428, -0.6479, -1.1049,\n",
      "         1.1767,  0.3750]) tensor([ 0.0270, -0.6241,  1.6706,  1.1850, -0.5602,  0.4163, -0.5612, -1.1112,\n",
      "         0.6045,  0.1606]) tensor([-0.0699, -0.4040,  1.5342,  1.6387, -0.2903,  0.6811, -0.8651, -0.5834,\n",
      "         0.7863,  0.5508])\n",
      "R[0]\n",
      "tensor([0.0033], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053154709048569206 0.004877840994060534 0.0019579297051132015 0.006159860107116401 0.03339175843819976 0.4266299324631691 0.0071113408855162565 42.348478660583496\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3312, -0.6405,  1.0160,  1.0812, -0.6435, -0.1372,  0.0179, -0.6401,\n",
      "         0.6681,  0.1566]) tensor([-0.0732, -0.6689,  1.0286,  1.0502, -0.6201, -0.1444,  0.0541, -0.6515,\n",
      "         0.0909, -0.0332]) tensor([-0.4341, -0.6646,  0.9179,  0.9867, -0.6170, -0.1710,  0.1518, -0.6716,\n",
      "         0.1548, -0.3582])\n",
      "R[0]\n",
      "tensor([0.0013], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05290489233285189 0.0045190566822820985 0.001812942317164925 0.006123806422110647 0.033440683025866745 0.428481707572937 0.0071905619199387726 42.406984939575196\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1657, -0.5820,  1.3373,  1.2763, -0.6477,  0.0213, -0.2387, -0.6132,\n",
      "        -0.0192,  0.6273]) tensor([-0.0870, -0.5833,  1.2867,  1.2289, -0.6127,  0.0214, -0.2024, -0.6218,\n",
      "         0.2807,  0.0391]) tensor([-0.3933, -0.5908,  1.1490,  1.0827, -0.6384, -0.1186,  0.0067, -0.6190,\n",
      "         0.9086, -0.0135])\n",
      "R[0]\n",
      "tensor([0.0024], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05261761975288391 0.00476460895208129 0.0016320825923630763 0.006116026020376012 0.03343249326571822 0.4296597222685814 0.007174396320711821 42.407868309021\n",
      "Average (on the epoch) training loss: 0.00596761622254271\n",
      "Episode average V value: 0\n",
      "epoch 22:\n",
      "Learning rate: 1.0941898913151244e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 91.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 90.99090090990902 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4618, -1.0203,  1.1338,  0.1507,  0.0599, -0.1443,  0.1912, -0.5320,\n",
      "         0.2163, -0.1645]) tensor([-0.2819, -0.9884,  1.1647,  0.2365,  0.0440, -0.1070,  0.1620, -0.5280,\n",
      "         0.2596,  0.1456]) tensor([-0.4571, -1.0266,  1.1262,  0.1577,  0.0641, -0.1616,  0.2306, -0.5515,\n",
      "        -0.2068, -0.0288])\n",
      "R[0]\n",
      "tensor([-0.0028], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052457638770341875 0.00443154367000534 0.0021569085937917405 0.006549619593424722 0.03423248647153378 0.43766048389673234 0.007342720545828342 42.519056617736815\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0044, -0.8161,  0.7774,  0.7224, -0.4905, -0.1433,  0.1889, -0.7667,\n",
      "        -0.2779,  0.2669]) tensor([-0.1453, -0.8092,  0.8432,  0.7272, -0.4253, -0.1041,  0.1357, -0.7068,\n",
      "         0.0826, -0.0240]) tensor([-0.0511, -0.9483,  1.3456,  0.6797, -0.4572, -0.0831, -0.1973, -0.6983,\n",
      "         0.8626,  0.1750])\n",
      "R[0]\n",
      "tensor([0.0013], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052609513625502584 0.004286214173245753 0.0018651750732369692 0.006059867969946936 0.03380275335907936 0.43510134488344193 0.007325870576780289 42.482384857177735\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1988, -0.7032,  1.1373,  0.9601, -0.7523, -0.1922,  0.2773, -0.9933,\n",
      "         0.1237,  0.0376]) tensor([-0.0355, -0.6804,  1.0864,  0.9568, -0.7469, -0.1909,  0.2890, -0.9914,\n",
      "         0.1438, -0.0303]) tensor([-0.3895, -0.6640,  1.1528,  1.0943, -0.7051, -0.1345,  0.0367, -0.7386,\n",
      "        -0.3209,  0.5661])\n",
      "R[0]\n",
      "tensor([-0.0054], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0522395546361804 0.004161138895645309 0.0021143615904384207 0.00609863443323411 0.03381588944047689 0.4328892120718956 0.007117233965080232 42.42654800415039\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2583, -0.5492,  1.0306,  0.8577, -0.7207,  0.0379,  0.0451, -1.3478,\n",
      "         0.3438,  0.5412]) tensor([ 0.0319, -0.5423,  1.0254,  0.8485, -0.7001, -0.0446,  0.1588, -1.2530,\n",
      "         0.0982, -0.0367]) tensor([ 0.1982, -0.6874,  1.2040,  0.7254, -0.5918,  0.3128,  0.0856, -1.8252,\n",
      "         0.3576,  0.0197])\n",
      "R[0]\n",
      "tensor([0.0219], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052791272319853304 0.0048689106776455444 0.0018592836847328726 0.0062315158441197125 0.03375449043512344 0.432867744743824 0.007371731033548713 42.551927742004395\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0285, -0.5416,  1.0432,  0.9115, -0.7045, -0.2808,  0.6129, -1.0276,\n",
      "         0.0180,  0.5841]) tensor([-1.0649e-04, -5.2568e-01,  1.0279e+00,  8.9592e-01, -6.9250e-01,\n",
      "        -2.5774e-01,  5.7722e-01, -1.0211e+00,  7.1671e-02, -7.4103e-02]) tensor([ 0.6631, -0.5399,  0.9376,  0.8295, -0.6824, -0.2388,  0.6500, -1.1116,\n",
      "        -0.0489, -0.1912])\n",
      "R[0]\n",
      "tensor([0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05271370028704405 0.00428397270014284 0.001871259571689734 0.006180097357719206 0.03402583982795477 0.4336927812099457 0.007103285167366267 42.6094645614624\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4217, -0.5267,  1.0135,  0.9153, -0.7715, -0.3631,  0.6453, -1.0334,\n",
      "        -0.6351,  0.0012]) tensor([ 0.0540, -0.5252,  1.0505,  0.9343, -0.7729, -0.3301,  0.6004, -1.0404,\n",
      "         0.0311, -0.0788]) tensor([ 0.3299, -0.5367,  1.0085,  0.9263, -0.7773, -0.3720,  0.6425, -1.0211,\n",
      "         0.7185,  0.1806])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05230731645226479 0.004155083183461102 0.0020534543002686404 0.00608433515462093 0.03409277818724513 0.43615577441453934 0.007358932028524578 42.56825912475586\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.7031, -0.6719,  0.8290,  0.6778, -0.5858,  0.0217,  0.5018, -1.5746,\n",
      "         0.4093,  0.7352]) tensor([ 0.0416, -0.6722,  0.8940,  0.6421, -0.5367,  0.0283,  0.4298, -1.4886,\n",
      "         0.0835,  0.0082]) tensor([-0.4132, -0.6985,  0.9237,  0.7115, -0.6278, -0.0068,  0.4756, -1.5161,\n",
      "        -0.5828, -0.0159])\n",
      "R[0]\n",
      "tensor([0.0028], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052571598082780835 0.00440618757073571 0.0022655406165886234 0.006226927425945178 0.03385324121266604 0.4390257353782654 0.007039361920207739 42.52838851165772\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0554, -1.2241,  1.2469,  0.2382, -0.1652, -0.0453,  0.4303, -1.2273,\n",
      "        -0.3010,  0.1747]) tensor([-1.6200e-01, -1.1572e+00,  1.0665e+00,  1.7444e-01, -1.5274e-01,\n",
      "        -6.8959e-05,  3.5477e-01, -1.2551e+00,  2.6140e-01,  1.2803e-01]) tensor([-0.0908, -0.9751,  1.2825,  0.2496, -0.3022,  0.1147,  0.2694, -1.5984,\n",
      "        -0.2377,  0.5131])\n",
      "R[0]\n",
      "tensor([0.0217], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052222130924463275 0.004662064286489112 0.002299204645041755 0.006125749900471419 0.03347887777537108 0.42696000188589095 0.007241417939774692 42.5469432144165\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1137, -0.4947,  0.7832,  0.7749, -0.6297, -0.1814,  0.5985, -1.2022,\n",
      "        -0.0457, -0.7047]) tensor([ 0.0023, -0.4945,  0.8194,  0.7594, -0.6022, -0.1638,  0.5426, -1.1667,\n",
      "        -0.0402, -0.0775]) tensor([-0.2307, -0.3520,  0.5293,  0.8620, -0.2387,  0.0229,  0.4233, -0.5222,\n",
      "        -0.0384,  0.1704])\n",
      "R[0]\n",
      "tensor([-0.0021], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05251905138790607 0.0041857452686545 0.0023190514419075044 0.006137692603748292 0.03388047111406922 0.4316557896733284 0.007218243364710361 42.542918319702146\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2128, -0.4852,  0.7954,  0.8895, -0.7063, -0.2068,  0.3559, -0.9707,\n",
      "         0.4049,  0.0634]) tensor([-0.0140, -0.4923,  0.8448,  0.8767, -0.6597, -0.1772,  0.3150, -0.9423,\n",
      "        -0.0437, -0.1027]) tensor([-0.2204, -0.4859,  0.7093,  0.7600, -0.7422, -0.1589,  0.3507, -1.1781,\n",
      "        -0.6006, -0.4800])\n",
      "R[0]\n",
      "tensor([0.0010], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052071131981909276 0.004151136877910176 0.0015698902617305066 0.005548356073908508 0.03414126642048359 0.42358518546819685 0.007343820865266025 42.53783472442627\n",
      "Average (on the epoch) training loss: 0.0061242796357139015\n",
      "Episode average V value: 0\n",
      "epoch 23:\n",
      "Learning rate: 9.84770902183612e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 117.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 116.98830116988302 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1036, -0.2125,  0.7297,  0.7093, -0.2260,  0.4632, -0.0295, -1.4263,\n",
      "        -0.0169,  0.2397]) tensor([-0.0287, -0.2571,  0.7898,  0.7085, -0.3041,  0.2511,  0.1578, -1.3020,\n",
      "        -0.0160, -0.0255]) tensor([ 0.3031, -0.6126,  0.9471,  0.9188, -0.7818, -0.3002,  0.6019, -1.1377,\n",
      "         0.4892,  0.0771])\n",
      "R[0]\n",
      "tensor([0.3797], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05258479810506105 0.004643085019113641 0.0023468521308750495 0.0063810566685860975 0.033204464487731455 0.42326321750879287 0.007450483383610844 42.436827224731445\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1047, -0.5221,  1.0165,  0.9192, -0.7438, -0.3614,  0.6809, -1.0109,\n",
      "         0.2709, -0.3328]) tensor([ 2.0535e-02, -5.1310e-01,  9.9243e-01,  9.2887e-01, -7.7499e-01,\n",
      "        -3.4216e-01,  6.3306e-01, -1.0513e+00, -3.4654e-04, -7.9805e-02]) tensor([-0.3342, -0.4969,  1.0035,  0.9341, -0.7585, -0.3705,  0.6618, -0.9955,\n",
      "        -0.7726,  0.4020])\n",
      "R[0]\n",
      "tensor([0.0052], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05231713999807835 0.004301914737974585 0.0024600228433537268 0.006102131475927308 0.033835841275751594 0.42551832616329194 0.007201184022706002 42.46626889038086\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4705, -0.4971,  0.9926,  0.9195, -0.7478, -0.3795,  0.6807, -0.9824,\n",
      "        -0.0890, -0.2679]) tensor([ 0.0196, -0.4913,  1.0277,  0.9514, -0.7581, -0.3426,  0.6338, -0.9966,\n",
      "         0.0287, -0.0698]) tensor([-0.1218, -0.4944,  1.0084,  0.9083, -0.7629, -0.3876,  0.6707, -0.9835,\n",
      "         0.3721, -0.0908])\n",
      "R[0]\n",
      "tensor([-0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052406373761594294 0.004111870222357538 0.0022428161650004767 0.0058945061967242505 0.03413121298328042 0.4211095053553581 0.0071793703334406015 42.30183303833008\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1139, -0.4888,  1.0375,  1.1310, -0.5974, -0.1954,  0.1139, -0.5007,\n",
      "        -0.2239,  0.0105]) tensor([-0.0690, -0.5111,  1.0783,  1.1479, -0.6021, -0.1664,  0.1033, -0.5451,\n",
      "         0.1244, -0.0147]) tensor([ 0.2019, -0.5303,  1.1682,  1.1325, -0.6155, -0.1457,  0.0427, -0.5925,\n",
      "        -0.0251,  0.5999])\n",
      "R[0]\n",
      "tensor([0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05213223771005869 0.003669930466943697 0.0019923066947139887 0.0055999677890213205 0.03434729975089431 0.41472437864542006 0.007297386391554027 42.30139623260498\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0445, -0.8578,  0.7768,  0.0351,  0.0247, -0.0562,  0.2871, -0.6748,\n",
      "         0.1580, -0.4171]) tensor([-0.2723, -0.8546,  0.8771,  0.2345, -0.1053, -0.0434,  0.2399, -0.7459,\n",
      "         0.0830,  0.0482]) tensor([-0.4845, -0.9107,  0.8343,  0.1010, -0.0207, -0.0526,  0.2887, -0.6957,\n",
      "        -0.0300, -0.1639])\n",
      "R[0]\n",
      "tensor([0.0028], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05257667496055365 0.004162405958228191 0.0022089376099193032 0.005709079605527222 0.03389362257346511 0.4129550985097885 0.0073494279640726745 42.358907981872555\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1093, -0.7042,  0.9832,  1.0220, -0.6641, -0.1477,  0.0780, -0.7191,\n",
      "         0.1524,  0.7779]) tensor([-0.0576, -0.7106,  0.9908,  1.0224, -0.6516, -0.1525,  0.0943, -0.7156,\n",
      "         0.0986, -0.0442]) tensor([-0.0573, -0.6914,  0.9621,  1.0035, -0.6515, -0.1627,  0.0967, -0.7088,\n",
      "         0.7417,  0.9990])\n",
      "R[0]\n",
      "tensor([-0.0077], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05224081507325173 0.004039181444219139 0.002261077349166044 0.005714595669647679 0.03376161513477564 0.41556676059961317 0.007324181044008583 42.40285101318359\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3580, -0.6148,  1.1202,  1.0830, -0.7395, -0.1970,  0.0540, -0.7191,\n",
      "         0.0461,  1.0411]) tensor([-0.0570, -0.6288,  1.1669,  1.0925, -0.7193, -0.1820,  0.0536, -0.7173,\n",
      "         0.1619,  0.0854]) tensor([ 0.0806, -0.5026,  0.9659,  1.0978, -0.6518, -0.2007,  0.0931, -0.5805,\n",
      "         0.2984, -0.7738])\n",
      "R[0]\n",
      "tensor([0.0017], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05250584445893765 0.003960012572497363 0.0020733501003942366 0.0058458000107202675 0.0338222706541419 0.413927090883255 0.0072654003608040515 42.31789665222168\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2888, -0.4657,  1.0127,  0.9148, -0.7560, -0.4102,  0.6860, -0.9485,\n",
      "        -0.0726,  0.7148]) tensor([ 0.0536, -0.4930,  1.0242,  0.8973, -0.7800, -0.4138,  0.6684, -0.9898,\n",
      "         0.0096, -0.0827]) tensor([-0.4794, -0.4766,  1.0015,  0.9251, -0.7681, -0.4149,  0.6641, -0.9538,\n",
      "         0.1565, -0.7845])\n",
      "R[0]\n",
      "tensor([-0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052637801721692086 0.004096785798936253 0.001939080679023391 0.005544985346263275 0.03364911015331745 0.4178662426173687 0.007530092388391495 42.3108924407959\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1048, -0.5271,  0.8814,  0.8247, -0.4470, -0.2855,  0.1934, -0.3551,\n",
      "         0.1575,  0.4742]) tensor([-0.1126, -0.5569,  0.9151,  0.8694, -0.4919, -0.2663,  0.1801, -0.4416,\n",
      "        -0.0058, -0.0815]) tensor([ 0.7268, -0.5272,  0.9029,  0.8538, -0.4537, -0.2847,  0.1883, -0.3637,\n",
      "         0.1309, -0.0493])\n",
      "R[0]\n",
      "tensor([0.0057], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05268621502071619 0.004185981419825111 0.0020313367456965352 0.005482694330858066 0.03368790087848902 0.4157715839743614 0.00752113702846691 42.369292289733885\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0528, -0.7782,  0.7009,  0.7409, -0.5342, -0.1828,  0.2292, -0.7536,\n",
      "        -0.5850,  0.3281]) tensor([-0.0885, -0.8043,  0.7801,  0.7876, -0.5466, -0.1651,  0.2062, -0.7759,\n",
      "         0.0161, -0.0284]) tensor([-0.0950, -0.7676,  0.6876,  0.7548, -0.5373, -0.1846,  0.2383, -0.7559,\n",
      "         0.1087, -0.2918])\n",
      "R[0]\n",
      "tensor([0.0100], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05272185645997524 0.004330749655848194 0.002110072846920957 0.005903267384972423 0.03374049321189523 0.4138665001392364 0.007403370359912515 42.30314138031006\n",
      "Average (on the epoch) training loss: 0.005817808447824791\n",
      "Episode average V value: 0\n",
      "epoch 24:\n",
      "Learning rate: 8.862938119652508e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 109.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 108.98910108989101 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0901, -0.8010,  0.8741,  0.3850, -0.1469, -0.2379,  0.1907, -0.3694,\n",
      "        -0.2001,  0.0432]) tensor([-0.2057, -0.8275,  0.8674,  0.4156, -0.1891, -0.1769,  0.1351, -0.5111,\n",
      "         0.0673,  0.0315]) tensor([-0.5714, -1.2379,  1.2318,  0.4286, -0.2356,  0.0026,  0.2712, -1.1260,\n",
      "         0.4514,  0.4364])\n",
      "R[0]\n",
      "tensor([0.0162], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05243603336066008 0.0038857715215854112 0.0021498797364965867 0.005889462770661339 0.033757249083369974 0.4138888111114502 0.007582979323808104 42.39364839172363\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1523, -0.5930,  1.1982,  1.1022, -0.6906, -0.1546,  0.0260, -0.6888,\n",
      "         0.0373,  0.3838]) tensor([-0.0491, -0.5980,  1.2094,  1.1050, -0.6695, -0.1276,  0.0287, -0.7071,\n",
      "         0.2075,  0.0135]) tensor([ 0.6186, -0.6895,  1.2833,  1.0879, -0.7121, -0.1198,  0.0050, -0.8006,\n",
      "         0.5688, -0.3399])\n",
      "R[0]\n",
      "tensor([0.0009], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05249194714426994 0.0037825148935171455 0.0021143307980883035 0.005876331013161689 0.03436948610469699 0.4253668607473373 0.007429429074283689 42.50254267883301\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0283, -0.6992,  0.7456,  0.4903, -0.1184, -0.0323,  0.3454, -0.5742,\n",
      "        -0.1833, -0.2308]) tensor([-0.1893, -0.7396,  0.7802,  0.5177, -0.2025, -0.0083,  0.2653, -0.6922,\n",
      "         0.0750, -0.0067]) tensor([-0.1745, -0.7931,  0.8667,  0.3504, -0.1417, -0.1064,  0.3273, -0.5961,\n",
      "         0.0963, -0.0412])\n",
      "R[0]\n",
      "tensor([0.0036], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052428234107792376 0.004517053650675735 0.002033547394028574 0.005999332797480747 0.03374501302838326 0.41439305239915847 0.007613187236245721 42.32492852020264\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2803, -0.5401,  1.1930,  1.1472, -0.2589,  0.1600, -0.1789, -0.3865,\n",
      "         0.4181,  0.0045]) tensor([-0.1029, -0.5563,  1.0951,  1.0923, -0.3003,  0.1311, -0.1292, -0.4697,\n",
      "         0.2235,  0.0800]) tensor([-3.1430e-01, -4.7825e-01,  1.0244e+00,  1.1417e+00, -2.9757e-01,\n",
      "         9.5823e-02,  5.9808e-04, -4.2977e-01,  1.4006e-01,  3.4259e-01])\n",
      "R[0]\n",
      "tensor([0.0067], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052796984232962134 0.004171484501611303 0.002146525118673708 0.006101951720193028 0.03416247038543224 0.40897808015346526 0.007402204136829823 42.297797737121584\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2241, -0.6056,  0.9141,  0.7429, -0.3962, -0.2930,  0.2116, -0.3948,\n",
      "         0.0242, -0.2080]) tensor([-0.1599, -0.6098,  0.9599,  0.7858, -0.3883, -0.2526,  0.1910, -0.4181,\n",
      "         0.0592, -0.0059]) tensor([-0.2149, -0.5939,  0.8873,  0.7692, -0.4049, -0.2951,  0.2096, -0.3772,\n",
      "        -0.5105,  0.0956])\n",
      "R[0]\n",
      "tensor([-0.0014], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05252670682966709 0.004581448911774714 0.0021357714678251795 0.0063391606349032376 0.03412500662729144 0.4150627196729183 0.00737501123920083 42.40919421386719\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.7613, -0.6590,  1.1228,  0.9135, -0.8367, -0.2417,  0.3873, -1.1286,\n",
      "         0.4481,  0.4609]) tensor([ 0.0443, -0.6494,  1.1572,  0.9142, -0.7982, -0.2058,  0.3405, -1.0978,\n",
      "         0.1564, -0.0094]) tensor([-0.0374, -0.6248,  0.8772,  0.8399, -0.7054, -0.2349,  0.6476, -1.1904,\n",
      "        -0.0302, -0.0514])\n",
      "R[0]\n",
      "tensor([0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052556157253682616 0.004401490346539504 0.0022350828890294 0.006113538935780525 0.03462484868615866 0.4225299156010151 0.00741141370497644 42.47132513427734\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1000, -0.4424,  0.9338,  0.8816, -0.7400, -0.3842,  0.6450, -0.9096,\n",
      "        -0.1680, -0.5999]) tensor([ 0.0114, -0.4545,  0.9912,  0.9200, -0.7542, -0.3485,  0.6061, -0.9407,\n",
      "        -0.0098, -0.1083]) tensor([ 0.0649, -0.4582,  0.9799,  0.9091, -0.7420, -0.4046,  0.6724, -0.9339,\n",
      "        -0.2242, -0.8875])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05279469934850931 0.004193756525566641 0.002217300975444232 0.005879432945512235 0.03396980142220855 0.42395606166124344 0.007373261551838368 42.43318788146973\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2293, -0.8046,  1.1380,  1.1090, -0.4009,  0.3677, -0.3079, -0.8369,\n",
      "         0.0417,  0.2672]) tensor([-0.1172, -0.8002,  1.0510,  1.0434, -0.3942,  0.2981, -0.2172, -0.8046,\n",
      "         0.3411,  0.0869]) tensor([ 0.1978, -0.8041,  1.2641,  1.2440, -0.3885,  0.4857, -0.4814, -0.8432,\n",
      "         0.7923, -0.5397])\n",
      "R[0]\n",
      "tensor([0.0398], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05302137386798859 0.0041688727568398466 0.0023732939480214555 0.005822244527284056 0.033546254877001046 0.4223397518992424 0.007268182597123087 42.38362424468994\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1101, -1.1432,  1.2009,  0.2033, -0.0382, -0.1230,  0.2667, -0.7719,\n",
      "         0.3384,  0.0806]) tensor([-0.2617, -1.0883,  1.2047,  0.2820, -0.0425, -0.0876,  0.2355, -0.7389,\n",
      "         0.3061,  0.1594]) tensor([-0.1395, -1.1325,  1.2546,  0.2072,  0.0178, -0.1118,  0.2043, -0.6940,\n",
      "         0.6076,  0.2711])\n",
      "R[0]\n",
      "tensor([0.0008], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05252315264195204 0.00419490136332206 0.0021013795592698444 0.006177519674412906 0.03452676228806376 0.4261356745362282 0.00743590624909848 42.50276843261719\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5357, -0.4961,  1.0082,  1.0584, -0.6155, -0.2831,  0.2221, -0.5099,\n",
      "         0.0455, -0.3640]) tensor([-0.0553, -0.5310,  1.0318,  1.0402, -0.6261, -0.2855,  0.2429, -0.5511,\n",
      "         0.0704, -0.0102]) tensor([ 0.5648, -0.4984,  1.0118,  1.0608, -0.6155, -0.2817,  0.2339, -0.5170,\n",
      "         0.0977,  0.1036])\n",
      "R[0]\n",
      "tensor([-0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0528075689598918 0.003920817704374713 0.0023558173004612397 0.006107264881487936 0.034244829442352055 0.42497706300020216 0.00753808107227087 42.50034512329101\n",
      "Average (on the epoch) training loss: 0.00603062399008777\n",
      "Episode average V value: 0\n",
      "epoch 25:\n",
      "Learning rate: 7.976644307687257e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 102.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 101.98980101989801 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1302, -0.6265,  1.0555,  1.0037, -0.7606, -0.2377,  0.1999, -0.8277,\n",
      "        -0.0683,  0.4786]) tensor([-0.0303, -0.6324,  1.1026,  1.0156, -0.7274, -0.2048,  0.1803, -0.8203,\n",
      "         0.1281, -0.0193]) tensor([-0.2642, -0.7730,  1.3017,  1.0554, -0.8006, -0.0596, -0.0089, -1.0362,\n",
      "         0.5510, -0.6746])\n",
      "R[0]\n",
      "tensor([0.0019], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052929519139230254 0.004282393519193647 0.0020569291982901632 0.005974638394545764 0.03331246193870902 0.42293008568882945 0.007165010320488364 42.45098928070068\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5578, -0.6249,  1.0849,  0.9445, -0.8010, -0.2993,  0.5263, -1.1127,\n",
      "        -0.0786,  0.0078]) tensor([ 0.0097, -0.6070,  1.1013,  0.9503, -0.7763, -0.2669,  0.4896, -1.0880,\n",
      "         0.1047, -0.0220]) tensor([-0.0521, -0.6874,  0.9857,  0.8603, -0.7201, -0.2511,  0.4846, -1.0398,\n",
      "        -0.1621,  0.6910])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05258043452352285 0.004018640937119926 0.0018562142506125382 0.006000900009879843 0.033807384543120864 0.4206529771089554 0.0070367433018982415 42.417789070129395\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4373, -0.4851,  1.0242,  1.0617, -0.6125, -0.2728,  0.2108, -0.5144,\n",
      "         0.0494, -0.0108]) tensor([-0.0146, -0.5025,  1.0049,  1.0581, -0.6327, -0.2565,  0.2058, -0.5876,\n",
      "         0.0347, -0.0380]) tensor([-0.1632, -0.4952,  1.0070,  1.0570, -0.6208, -0.2810,  0.2181, -0.5171,\n",
      "        -0.3654, -0.4329])\n",
      "R[0]\n",
      "tensor([-0.0020], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05256506957113743 0.003709961550994194 0.001695062992836938 0.005660620273789391 0.03352832073718309 0.4205812147259712 0.007201536512933672 42.42208190917969\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3478, -0.1419,  0.8366,  1.3581, -0.2700,  0.2036, -0.2458, -0.2074,\n",
      "         0.8260,  0.4915]) tensor([-0.1191, -0.2133,  0.8363,  1.2583, -0.2649,  0.1987, -0.2347, -0.2915,\n",
      "         0.0638,  0.0316]) tensor([-0.0514, -0.5680,  1.1845,  1.2149, -0.6807,  0.0276, -0.2051, -0.7219,\n",
      "         0.1021, -0.4545])\n",
      "R[0]\n",
      "tensor([0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05228414522856474 0.003819282380685763 0.0018318957019218941 0.00573475534026511 0.03386882591620088 0.4174936430454254 0.007028553079813719 42.457250816345216\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4310, -0.5455,  1.1731,  1.1197, -0.6499, -0.1161,  0.0388, -0.6496,\n",
      "        -0.1341, -0.0295]) tensor([-0.0508, -0.5501,  1.1488,  1.0895, -0.6202, -0.1000,  0.0519, -0.6664,\n",
      "         0.1772,  0.0132]) tensor([-0.0730, -0.6055,  1.1114,  0.9878, -0.6954, -0.2332,  0.3016, -0.8144,\n",
      "         0.0245, -0.0909])\n",
      "R[0]\n",
      "tensor([0.0009], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05231020267307758 0.004247417628585026 0.0018885424777881782 0.005775108700850978 0.03388566663861275 0.42294479471445084 0.007149061392061412 42.379730308532714\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0080, -0.7798,  0.7104, -0.5422,  0.1842,  0.2037,  0.0212, -1.3256,\n",
      "         0.4502,  0.0276]) tensor([-0.2332, -0.7773,  0.7703, -0.4504,  0.1735,  0.1951,  0.0156, -1.3025,\n",
      "        -0.0202,  0.1074]) tensor([-0.1031, -0.9197,  0.8632, -0.5515,  0.3183,  0.1009,  0.0910, -1.1997,\n",
      "         0.1849,  0.1393])\n",
      "R[0]\n",
      "tensor([-0.0013], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05236142262071371 0.0037299828619034086 0.00175914699090481 0.005487419343320653 0.03438002637773752 0.41919221299886705 0.007383480411022902 42.5031455001831\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1120, -0.7807,  1.1343,  0.7237, -0.3966, -0.1646,  0.1139, -0.6326,\n",
      "        -0.0249, -0.6499]) tensor([-0.1316, -0.7713,  1.1135,  0.7614, -0.4204, -0.1572,  0.1266, -0.6665,\n",
      "         0.1737,  0.0838]) tensor([ 0.0100, -0.6530,  0.9617,  0.7237, -0.3935, -0.2510,  0.1938, -0.4818,\n",
      "         0.1331, -0.1120])\n",
      "R[0]\n",
      "tensor([0.0025], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05257386910915375 0.004567918060387455 0.002058953924973139 0.005922474214807153 0.03395972774550319 0.4202707876563072 0.007203622899018228 42.418473663330076\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2956, -0.5138,  0.7344,  0.9295, -0.6173, -0.1330,  0.1220, -0.6689,\n",
      "        -0.3598, -0.2425]) tensor([-7.9083e-02, -5.3730e-01,  7.9546e-01,  9.1795e-01, -5.6932e-01,\n",
      "        -1.0551e-01,  9.9441e-02, -6.5564e-01,  2.2149e-04, -4.6687e-02]) tensor([ 0.4522, -0.5970,  0.7460,  0.9315, -0.7028, -0.0485,  0.0220, -0.9249,\n",
      "        -0.4554, -0.3220])\n",
      "R[0]\n",
      "tensor([0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05253348758071661 0.003903458401258831 0.0018743481976944167 0.005632624569116161 0.03427732192352414 0.4109930767416954 0.00755654745362699 42.429067428588866\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3654, -0.7277,  0.7876,  0.6004, -0.5663, -0.1662,  0.6840, -1.3075,\n",
      "        -0.2667, -0.5668]) tensor([-0.0305, -0.7180,  0.8624,  0.6363, -0.5586, -0.1370,  0.6166, -1.2651,\n",
      "         0.0124, -0.0748]) tensor([-0.4187, -0.7164,  0.7668,  0.5707, -0.5379, -0.2035,  0.6982, -1.2418,\n",
      "         0.2000, -0.0765])\n",
      "R[0]\n",
      "tensor([-0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052643523447215554 0.004245076454439186 0.0017031907681748634 0.005705155646195635 0.03389263651892543 0.41662274396419524 0.0072681692424230275 42.39020106506348\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4111, -0.4013,  0.7105,  1.0958, -0.3471,  0.0854,  0.0116, -0.5160,\n",
      "        -0.4100, -0.0309]) tensor([-0.1129, -0.4774,  0.7800,  1.0624, -0.3934,  0.0326,  0.0381, -0.5547,\n",
      "         0.0175, -0.0171]) tensor([-0.5618, -0.4102,  0.7171,  1.1052, -0.2958,  0.0054,  0.1724, -0.3898,\n",
      "        -0.5498,  0.7268])\n",
      "R[0]\n",
      "tensor([-0.0143], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05220819242298603 0.004302209011297236 0.0018066855862798547 0.005827609668718651 0.033784532964229584 0.4156653136610985 0.007416579341050237 42.4800559387207\n",
      "Average (on the epoch) training loss: 0.005772130616148933\n",
      "Episode average V value: 0\n",
      "epoch 26:\n",
      "Learning rate: 7.1789798769185315e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 129.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 128.98710128987102 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2003, -0.8862,  1.3182,  1.1076, -0.9056, -0.0085, -0.2435, -1.0705,\n",
      "         0.5845, -0.2436]) tensor([-0.0241, -0.8692,  1.3171,  1.0881, -0.8125,  0.0124, -0.2306, -1.0039,\n",
      "         0.3105,  0.1044]) tensor([ 0.1780, -0.8285,  1.4465,  1.1672, -0.8712,  0.0685, -0.3547, -1.0361,\n",
      "         0.7120, -0.3729])\n",
      "R[0]\n",
      "tensor([0.0031], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05229800739139318 0.0038481271659074993 0.0022093022774961357 0.005604055622359738 0.034237861104309555 0.41125810754299164 0.007368549291975796 42.484813262939454\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2102, -0.7385,  1.1270,  0.9863, -0.7980, -0.1377,  0.1299, -1.0293,\n",
      "         0.2319, -0.5423]) tensor([-0.0297, -0.7238,  1.1171,  0.9564, -0.7247, -0.1206,  0.1281, -0.9762,\n",
      "         0.1709,  0.0404]) tensor([-0.4359, -0.7136,  1.0262,  0.9833, -0.8142, -0.2200,  0.2633, -1.0303,\n",
      "         0.1432,  0.9134])\n",
      "R[0]\n",
      "tensor([0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05217769031226635 0.0040919737114854795 0.0021323124799055224 0.005932582921814173 0.034258243957534434 0.41868864101171493 0.0072569390973076225 42.542916801452634\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5971, -1.1492,  1.3693,  0.3337, -0.0281,  0.2533, -0.1347, -0.8586,\n",
      "         0.8581,  0.4990]) tensor([-0.2112, -1.0966,  1.2750,  0.3458, -0.0258,  0.2543, -0.0990, -0.8495,\n",
      "         0.4935,  0.2093]) tensor([-0.1068, -1.1541,  1.2416,  0.2363,  0.1081,  0.3399,  0.0945, -0.9250,\n",
      "         0.5379,  0.4549])\n",
      "R[0]\n",
      "tensor([0.0032], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0520747172087431 0.004096916484955727 0.002109911693668437 0.006184346198569984 0.034061866983771324 0.41977297377586364 0.007321172452531755 42.469830993652344\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1636, -0.4403,  0.7288,  0.9793, -0.1088,  0.1702,  0.2103, -0.4110,\n",
      "        -0.2244, -0.1393]) tensor([-0.1804, -0.5106,  0.7869,  0.9547, -0.2103,  0.1236,  0.1830, -0.4875,\n",
      "         0.0992, -0.0242]) tensor([-0.3733, -0.6061,  0.8076,  0.8365, -0.2301,  0.0963,  0.1718, -0.5603,\n",
      "        -0.4604,  0.0229])\n",
      "R[0]\n",
      "tensor([-0.0212], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05268276460468769 0.0042437991671959024 0.00205498428975352 0.006055224432377145 0.03430744720250368 0.4197097081542015 0.007303370073437691 42.55425146484375\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5950, -0.4131,  0.7361,  1.0985, -0.2790,  0.0258,  0.1354, -0.3686,\n",
      "        -0.0756, -0.4189]) tensor([-0.1236, -0.4810,  0.8127,  1.0735, -0.3368, -0.0070,  0.1260, -0.4166,\n",
      "         0.0539, -0.0088]) tensor([-0.0501, -0.4542,  0.8294,  1.0795, -0.3456, -0.0661,  0.2062, -0.4136,\n",
      "         0.4043,  0.4126])\n",
      "R[0]\n",
      "tensor([-0.0138], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052349504053592684 0.004140175435239144 0.0020981739283679416 0.0061961401225999 0.03385277624055743 0.41346748572587966 0.007317031499929726 42.437629943847654\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4842, -0.6421,  1.2741,  1.4353, -0.4364,  0.4640, -0.5615, -0.6792,\n",
      "         0.6410,  0.0361]) tensor([-0.0749, -0.6493,  1.1884,  1.3217, -0.3851,  0.4403, -0.5197, -0.6696,\n",
      "         0.3707,  0.1292]) tensor([-0.4543, -0.4247,  1.3737,  1.6296, -0.4351,  0.4733, -0.7343, -0.4512,\n",
      "        -0.0071,  0.0019])\n",
      "R[0]\n",
      "tensor([-9.5882e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052706609532237055 0.004358751960877271 0.002343103910166974 0.006421991001814604 0.03404301307722926 0.41959488433599473 0.007355220492463559 42.45398388671875\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2752, -0.8064,  1.1974,  0.8697, -0.7848, -0.0989,  0.3366, -1.3547,\n",
      "         0.1040,  0.2362]) tensor([ 0.0226, -0.7674,  1.1178,  0.8273, -0.7476, -0.1197,  0.3755, -1.2947,\n",
      "         0.1848,  0.0014]) tensor([-0.1752, -0.7975,  1.1884,  0.8591, -0.8030, -0.1097,  0.3587, -1.3781,\n",
      "         0.7964, -0.3764])\n",
      "R[0]\n",
      "tensor([0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05249611809849739 0.00406579963448894 0.0020797202210478647 0.0058839161570649594 0.03376325612515211 0.4158286421895027 0.007364229967352003 42.45404901885986\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4856, -0.7785,  1.0789,  0.9594, -0.9035, -0.1836,  0.3217, -1.2847,\n",
      "        -0.1262, -0.4471]) tensor([ 0.0462, -0.7588,  1.0662,  0.9332, -0.8533, -0.1900,  0.3495, -1.2177,\n",
      "         0.1382,  0.0145]) tensor([-0.0474, -0.7641,  1.1070,  0.9307, -0.9151, -0.1850,  0.3022, -1.2740,\n",
      "         0.1272,  0.3348])\n",
      "R[0]\n",
      "tensor([0.0026], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05238354724645615 0.004302751724029804 0.0019544345747372063 0.006178637005621567 0.033946423497051 0.41858505648374555 0.0076354925129562615 42.533407409667966\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0512, -0.5882,  0.9649,  0.8048, -0.4330, -0.2767,  0.2155, -0.4475,\n",
      "         0.6107, -0.1340]) tensor([-1.3191e-01, -5.9317e-01,  9.9529e-01,  8.2922e-01, -4.2191e-01,\n",
      "        -2.4424e-01,  1.9833e-01, -4.6856e-01,  4.7162e-02, -6.5456e-04]) tensor([-0.1955, -0.5864,  0.9129,  0.7311, -0.3989, -0.3021,  0.2736, -0.4086,\n",
      "         0.3946,  0.4308])\n",
      "R[0]\n",
      "tensor([-0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05250876115262509 0.0038660903756590416 0.0023602269900775356 0.006022031367057934 0.03384596777148545 0.4119683467745781 0.007526647137012333 42.48964986419678\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2307, -0.7086,  0.8033,  0.5039, -0.1943, -0.1484,  0.4028, -0.5799,\n",
      "        -0.0259,  0.3062]) tensor([-0.1732, -0.7132,  0.8478,  0.5889, -0.2748, -0.1325,  0.3480, -0.6433,\n",
      "         0.0396, -0.0518]) tensor([ 0.0702, -0.7577,  0.8202,  0.7632, -0.5468, -0.1256,  0.3034, -0.8800,\n",
      "         0.2540,  0.0397])\n",
      "R[0]\n",
      "tensor([0.0047], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05248936424404383 0.004036256176472307 0.0018831221644704783 0.00594238396268338 0.03402656449750066 0.4088545146584511 0.007607532108202576 42.47810598754883\n",
      "Average (on the epoch) training loss: 0.006042130879196339\n",
      "Episode average V value: 0\n",
      "epoch 27:\n",
      "Learning rate: 6.461081889226678e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 96.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 95.99040095990401 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7828, -0.8298,  0.9706,  0.3588, -0.0598, -0.1760,  0.2166, -0.4725,\n",
      "         0.6056, -0.3107]) tensor([-0.2364, -0.8162,  0.9962,  0.4505, -0.1299, -0.1673,  0.1934, -0.5105,\n",
      "         0.0969,  0.0685]) tensor([-0.2793, -0.8564,  0.9881,  0.3374, -0.0490, -0.1978,  0.2835, -0.4766,\n",
      "         0.9477, -0.6087])\n",
      "R[0]\n",
      "tensor([0.0041], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052394131377339365 0.003983947041469946 0.0021471598008320145 0.005962467807810754 0.03385777585580945 0.4096962563991547 0.007584244304802269 42.44449405670166\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3492, -0.4047,  0.8671,  0.8891, -0.7001, -0.3388,  0.6520, -0.9001,\n",
      "        -0.5739, -0.1698]) tensor([ 0.0048, -0.4423,  0.9175,  0.8874, -0.7361, -0.3413,  0.6234, -0.9404,\n",
      "        -0.0022, -0.0937]) tensor([-0.6974, -0.4829,  0.9677,  0.9035, -0.7338, -0.3821,  0.6797, -0.9576,\n",
      "         0.2490, -0.4958])\n",
      "R[0]\n",
      "tensor([-0.0018], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052862046852707865 0.004400247067431337 0.0023100326087605936 0.006083969522500411 0.03371596458926797 0.4170344686508179 0.007474688712507486 42.45503397369385\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6277, -0.6421,  0.8731,  1.0334,  0.0671,  0.8105, -0.6096, -0.6768,\n",
      "         0.0579,  0.1628]) tensor([-0.1614, -0.6800,  0.8410,  0.9620,  0.0218,  0.6599, -0.4786, -0.6208,\n",
      "         0.2957,  0.1169]) tensor([-0.3009, -1.0310,  0.9164,  0.2234, -0.1274, -0.1392,  0.3635, -0.7812,\n",
      "         0.7528, -0.4597])\n",
      "R[0]\n",
      "tensor([0.4027], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05242807500809431 0.00407361097949979 0.002003182719596225 0.0057566076749935744 0.03397018689289689 0.41673714250326155 0.0075752732520923015 42.53753653717041\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0804, -0.6328,  1.1868,  1.1230, -0.6650, -0.1055, -0.0263, -0.6448,\n",
      "        -0.0722, -0.2827]) tensor([-0.0785, -0.6292,  1.1655,  1.0995, -0.6221, -0.0835, -0.0132, -0.6459,\n",
      "         0.1998,  0.0560]) tensor([ 0.1026, -0.5945,  1.1226,  1.0878, -0.6335, -0.1392,  0.0357, -0.6177,\n",
      "         0.4552,  0.5120])\n",
      "R[0]\n",
      "tensor([-2.5734e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052527816146612165 0.004464287414366481 0.00200170526110378 0.0062592723162379115 0.03435375608690083 0.41899404722452166 0.007500890916213393 42.62187519836426\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2867, -0.6532,  1.0306,  0.9133, -0.8265, -0.2049,  0.3790, -1.1719,\n",
      "        -0.2304, -0.0376]) tensor([ 0.0289, -0.6467,  1.0607,  0.9125, -0.7864, -0.1787,  0.3572, -1.1396,\n",
      "         0.1182, -0.0224]) tensor([-0.1624, -0.6079,  0.7927,  0.7779, -0.6563, -0.2262,  0.7215, -1.1882,\n",
      "         0.1327, -0.0226])\n",
      "R[0]\n",
      "tensor([-0.0001], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052444179654121396 0.004063119854936304 0.0019088339291874945 0.006050774842035025 0.03398678526654839 0.4097162787616253 0.007605192547198385 42.5290085067749\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3560, -0.8227,  1.4779,  1.1373, -0.8405,  0.0405, -0.2211, -1.0671,\n",
      "         0.4451,  0.1879]) tensor([-0.0338, -0.7952,  1.4340,  1.1131, -0.7775,  0.0566, -0.1950, -1.0281,\n",
      "         0.3829,  0.0991]) tensor([ 0.0863, -0.9472,  1.4614,  1.0886, -0.9306,  0.0201, -0.1226, -1.3051,\n",
      "        -0.1436,  0.2667])\n",
      "R[0]\n",
      "tensor([0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05209320618212223 0.004099479545267968 0.002135138520721739 0.0058457459777127956 0.03385157653689384 0.42034960436820984 0.007464563565794379 42.61868041229248\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1874, -0.6406,  1.0547,  1.0775, -0.5937, -0.0786, -0.0307, -0.6512,\n",
      "        -0.0326,  0.0595]) tensor([-0.0778, -0.6537,  1.0865,  1.0719, -0.5622, -0.0556, -0.0320, -0.6528,\n",
      "         0.1739,  0.0427]) tensor([-0.2122, -0.6280,  1.2292,  1.1694, -0.6563, -0.0509, -0.1491, -0.6394,\n",
      "         0.0753,  0.1733])\n",
      "R[0]\n",
      "tensor([0.0001], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052788347609341146 0.0035748255511070964 0.0016115383087235387 0.005446696892613545 0.03422612104192376 0.4179952267408371 0.0076603717168327425 42.555779602050784\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1537, -0.6042,  0.8796,  0.9557, -0.5778, -0.2384,  0.2619, -0.6160,\n",
      "        -0.1715, -0.5270]) tensor([-0.0934, -0.6122,  0.9212,  0.9565, -0.5430, -0.2066,  0.2326, -0.6068,\n",
      "         0.0325, -0.0049]) tensor([-0.3462, -0.6077,  1.0309,  1.0574, -0.6114, -0.1814,  0.1125, -0.6092,\n",
      "         0.9360,  0.3186])\n",
      "R[0]\n",
      "tensor([-0.0001], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05274806065112352 0.00437909516909167 0.002566174624547784 0.006383553179446608 0.033929282065480945 0.4168545877933502 0.007547595373820513 42.56317671203613\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0242, -0.5621,  1.1756,  1.1013, -0.6423, -0.1320,  0.0361, -0.6383,\n",
      "        -0.1465, -0.2805]) tensor([-0.0693, -0.5625,  1.1523,  1.0788, -0.6098, -0.1105,  0.0501, -0.6539,\n",
      "         0.1703,  0.0439]) tensor([ 0.9820, -0.5292,  1.1203,  1.1274, -0.6142, -0.1643,  0.0740, -0.5726,\n",
      "         0.2751, -0.1791])\n",
      "R[0]\n",
      "tensor([-0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05280707611143589 0.004158897857498232 0.0025162811504542333 0.006175421911524609 0.03342152335867286 0.41293432712554934 0.007634524882771075 42.5862551651001\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2780, -0.7685,  1.1826,  0.9779, -0.8804, -0.1955,  0.3702, -1.2719,\n",
      "        -0.2420, -0.4213]) tensor([ 0.0019, -0.7345,  1.1636,  0.9488, -0.8115, -0.1717,  0.3547, -1.2005,\n",
      "         0.1668,  0.0329]) tensor([ 0.6121, -0.7859,  1.1247,  0.9631, -0.8912, -0.1738,  0.3445, -1.3024,\n",
      "         0.7393,  0.1359])\n",
      "R[0]\n",
      "tensor([-0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05254343611001969 0.004147614268755206 0.0024774734298734983 0.006097633157158271 0.034126981414854526 0.41189941346645353 0.007639453360345215 42.55307343292236\n",
      "Average (on the epoch) training loss: 0.00600621432820335\n",
      "Episode average V value: 0\n",
      "epoch 28:\n",
      "Learning rate: 5.81497370030401e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 107.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 106.98930106989302 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3356, -0.7838,  1.1545,  0.9605, -0.8675, -0.1391,  0.1145, -1.1212,\n",
      "        -0.4876,  0.5444]) tensor([-0.0051, -0.7665,  1.1308,  0.9641, -0.8417, -0.1628,  0.1577, -1.0751,\n",
      "         0.1672,  0.0201]) tensor([ 0.2953, -0.7218,  1.1389,  0.9618, -0.8377, -0.2126,  0.2738, -1.1124,\n",
      "         0.3459, -0.6393])\n",
      "R[0]\n",
      "tensor([-0.0036], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052655362166464326 0.0042216123369635174 0.0025144584079625928 0.00604132378147915 0.033625356800854204 0.41744732770323756 0.007673738304525614 42.54315280151367\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1392, -0.5161,  0.9374,  0.8822, -0.4885, -0.3128,  0.2732, -0.4359,\n",
      "         0.4269, -0.0845]) tensor([-0.1200, -0.5264,  0.9703,  0.9013, -0.4802, -0.2761,  0.2486, -0.4670,\n",
      "         0.0118, -0.0176]) tensor([ 0.5236, -0.5504,  0.9413,  0.8492, -0.4841, -0.3082,  0.2585, -0.4222,\n",
      "        -0.2928,  0.6647])\n",
      "R[0]\n",
      "tensor([5.7578e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05295730236172676 0.004001785665616808 0.002111119297285768 0.0057448959518224 0.033823640730232 0.4082240317761898 0.007517798471730203 42.46137303924561\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 1.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0730, -0.7433,  0.9699,  0.8409, -0.5852, -0.2156,  0.1180, -0.6850,\n",
      "         0.5369,  0.1904]) tensor([-0.0971, -0.7413,  0.9877,  0.8770, -0.5829, -0.2021,  0.1235, -0.6946,\n",
      "         0.0470, -0.0122]) tensor([ 0.0936, -0.8187,  0.7506,  0.8846, -0.6637, -0.1259,  0.1884, -0.8855,\n",
      "         0.7113,  0.3054])\n",
      "R[0]\n",
      "tensor([-0.0040], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052303107000887396 0.003845431742029177 0.0023102465392512385 0.005849955649347976 0.03371586013585329 0.4089189563989639 0.007716482123825699 42.47332761383057\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1158, -0.5868,  1.0173,  1.0917, -0.0946,  0.4355, -0.2692, -0.4738,\n",
      "         0.0586,  0.5686]) tensor([-0.2045, -0.6306,  0.9774,  1.0101, -0.1371,  0.3580, -0.2053, -0.5017,\n",
      "         0.2366,  0.0496]) tensor([-0.2638, -0.4321,  0.8759,  0.9818,  0.0735,  0.3982, -0.0917, -0.2863,\n",
      "         0.1878, -0.1024])\n",
      "R[0]\n",
      "tensor([0.0045], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05297745376825333 0.004457022589549524 0.0022111659875372423 0.006213315826840699 0.03352678756415844 0.41080934250354767 0.007320618131197989 42.44586544036865\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0625, -0.7388,  0.9411,  0.7667, -0.5845, -0.1499,  0.3891, -0.9698,\n",
      "         0.1829,  0.5020]) tensor([-0.0674, -0.7245,  0.9394,  0.7933, -0.6013, -0.1471,  0.3752, -0.9696,\n",
      "         0.0847, -0.0598]) tensor([ 0.0633, -0.5992,  0.6206,  0.2531, -0.0704, -0.2088,  0.5809, -0.4357,\n",
      "        -0.1366, -0.4322])\n",
      "R[0]\n",
      "tensor([-0.0047], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05303524018079042 0.0042329943055501645 0.0021423503061278096 0.0060733196809887886 0.03386641592904925 0.41203654915094373 0.007209222045261413 42.54133950805664\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1777, -0.7068,  1.1140,  0.9724, -0.8682, -0.2316,  0.3556, -1.1694,\n",
      "        -0.0901, -0.1599]) tensor([ 0.0229, -0.6902,  1.1358,  0.9750, -0.8208, -0.2005,  0.3350, -1.1280,\n",
      "         0.1545,  0.0059]) tensor([-0.0592, -0.7487,  1.1406,  0.9684, -0.8396, -0.1545,  0.3561, -1.3023,\n",
      "        -0.0866, -0.0144])\n",
      "R[0]\n",
      "tensor([0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05294845631718636 0.0040530277697998825 0.002038312921275974 0.006065185496583581 0.03356146091967821 0.41401434034109114 0.0074924307763576505 42.603665725708005\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1117, -0.2011,  0.6731,  0.9624, -0.2244,  0.3453, -0.1848, -0.8210,\n",
      "         0.3939,  0.3374]) tensor([-0.0938, -0.2864,  0.7475,  0.9400, -0.2902,  0.2337, -0.0917, -0.8294,\n",
      "        -0.0378, -0.0444]) tensor([ 0.1751, -0.3025,  0.6336,  1.1409, -0.1995,  0.2348, -0.0622, -0.4739,\n",
      "         0.0558,  0.2969])\n",
      "R[0]\n",
      "tensor([0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053286753870546814 0.004395066021728781 0.002298503004474696 0.0063889002152718605 0.03389002895355225 0.4113373433947563 0.007246705282479525 42.48170516967773\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0470, -0.7843,  1.2619,  1.0595, -0.8219, -0.0693, -0.0474, -0.9990,\n",
      "         0.4849, -0.4486]) tensor([-0.0042, -0.7631,  1.1961,  1.0452, -0.7929, -0.0939,  0.0222, -0.9722,\n",
      "         0.2265,  0.0583]) tensor([ 0.1742, -0.7449,  0.9824,  0.7876, -0.7605,  0.0169,  0.2485, -1.4999,\n",
      "        -0.9384, -0.3646])\n",
      "R[0]\n",
      "tensor([0.0023], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05322258085012436 0.004705003029157524 0.002205648207668673 0.006400083428248763 0.03398608878999949 0.40917814946174624 0.007242416799068451 42.5771686630249\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3265, -0.5316,  0.6811,  0.7654, -0.5345, -0.3105,  0.4333, -0.6037,\n",
      "        -0.1039, -0.3809]) tensor([-0.0637, -0.5534,  0.7693,  0.8478, -0.5806, -0.2757,  0.3690, -0.6589,\n",
      "        -0.0677, -0.0738]) tensor([ 0.3622, -0.5602,  0.7613,  0.8550, -0.5576, -0.2934,  0.3630, -0.5931,\n",
      "        -0.4770, -0.4011])\n",
      "R[0]\n",
      "tensor([0.0083], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05302723330259323 0.004831162157204744 0.0025513557387066613 0.006482502316590398 0.03345605984702706 0.41491233217716217 0.007164058836642653 42.54031866455078\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1089, -0.4284,  0.9897,  1.2707, -0.2856,  0.1026, -0.0446, -0.3266,\n",
      "         0.1857,  0.2041]) tensor([-0.1619, -0.4851,  0.9835,  1.1978, -0.3277,  0.0504, -0.0015, -0.3782,\n",
      "         0.1313,  0.0256]) tensor([-0.0135, -0.4275,  0.9262,  1.1363, -0.2797,  0.0222,  0.0847, -0.3407,\n",
      "         0.7005,  0.0397])\n",
      "R[0]\n",
      "tensor([-0.0143], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05267381160706282 0.004561273713907212 0.0017350493020139766 0.006067742123035714 0.034018834054470065 0.4086200096607208 0.007380922393407673 42.38300608062744\n",
      "Average (on the epoch) training loss: 0.0061327224470209335\n",
      "Episode average V value: 0\n",
      "epoch 29:\n",
      "Learning rate: 5.23347633027361e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 129.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 128.98710128987102 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4090, -0.5140,  0.9851,  0.8879, -0.7180, -0.3388,  0.6589, -0.9887,\n",
      "         0.3344, -0.7890]) tensor([-0.0016, -0.5101,  0.9751,  0.8919, -0.7512, -0.3351,  0.6240, -1.0121,\n",
      "         0.0296, -0.0849]) tensor([-0.2755, -0.5451,  1.0315,  0.8529, -0.6451, -0.2989,  0.7207, -1.0394,\n",
      "         0.6311, -0.3585])\n",
      "R[0]\n",
      "tensor([0.0025], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0530200654566288 0.003982096736866879 0.0018956092577145681 0.00585015779430978 0.033652182295918466 0.40886970442533493 0.007405484125483781 42.382374855041505\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4966, -0.6629,  1.3377,  0.9947, -0.5220, -0.0356, -0.0686, -0.7014,\n",
      "         0.2427,  0.1645]) tensor([-0.0815, -0.6455,  1.2741,  0.9657, -0.4924, -0.0278, -0.0365, -0.7066,\n",
      "         0.2701,  0.0826]) tensor([ 0.4041, -0.5377,  1.2390,  1.1555, -0.6088, -0.0978, -0.0611, -0.5643,\n",
      "         0.2365,  0.5750])\n",
      "R[0]\n",
      "tensor([-0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05267943377047777 0.004025219874722098 0.00170380881242545 0.00621857491391711 0.033786985982209444 0.4144692425131798 0.0074515952193178235 42.49230907440185\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4270, -0.5687,  1.1939,  1.0880, -0.6484, -0.1326,  0.0412, -0.6703,\n",
      "         0.4306, -0.1683]) tensor([-0.0461, -0.5817,  1.1499,  1.0452, -0.6374, -0.1498,  0.1033, -0.6936,\n",
      "         0.1410,  0.0343]) tensor([ 0.6671, -0.6680,  1.1001,  1.0213, -0.6866, -0.1521,  0.1131, -0.8074,\n",
      "         0.0641,  0.0169])\n",
      "R[0]\n",
      "tensor([-0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0523370158970356 0.0042325135072369445 0.0021537619593491398 0.0061252454407513144 0.03342271228134632 0.4154597995877266 0.00721782199665904 42.58897843170166\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2318, -0.6543,  0.9701,  1.0297, -0.6494, -0.2007,  0.1257, -0.6443,\n",
      "         0.6575,  0.4555]) tensor([-0.0707, -0.6689,  1.0372,  1.0335, -0.6122, -0.1653,  0.0966, -0.6322,\n",
      "         0.1052,  0.0178]) tensor([-0.3926, -0.6668,  1.1635,  1.0588, -0.6693, -0.1030, -0.0556, -0.6843,\n",
      "         0.5127, -0.2751])\n",
      "R[0]\n",
      "tensor([0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052167215958237645 0.0042455551529255895 0.0022581482561217854 0.00599229467404075 0.03362177334725857 0.41560151809453966 0.007221477855928242 42.60581328582764\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4361, -0.3369,  0.7096,  0.9552, -0.3649,  0.1943, -0.0957, -0.8315,\n",
      "         0.1200, -0.2242]) tensor([-0.0364, -0.3865,  0.7505,  0.9414, -0.3952,  0.1342, -0.0465, -0.8380,\n",
      "        -0.0186,  0.0096]) tensor([ 0.1191, -0.1895,  0.6677,  0.8172, -0.2844,  0.2791, -0.1047, -1.0089,\n",
      "         0.0342, -0.4384])\n",
      "R[0]\n",
      "tensor([0.0376], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05301075750589371 0.004504635796409275 0.0021306989767299455 0.0061097269426099955 0.034210355125367645 0.4101197965145111 0.007275250667706132 42.51727709197998\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2904, -0.7399,  1.1170,  1.0728, -0.7985, -0.1398, -0.0441, -0.8435,\n",
      "         0.3026,  0.2857]) tensor([-0.0587, -0.7385,  1.1564,  1.0702, -0.7304, -0.1034, -0.0563, -0.8076,\n",
      "         0.1802,  0.0379]) tensor([ 0.0635, -0.8289,  1.2916,  1.0630, -0.8300, -0.0205, -0.1604, -1.0062,\n",
      "         0.4929,  0.6484])\n",
      "R[0]\n",
      "tensor([0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052457917675375935 0.0047429258533793475 0.0020105226157793366 0.006125376750947907 0.033975819230079654 0.4126579403281212 0.007258010600693524 42.478205253601075\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5523, -0.5775,  0.7802,  0.8090, -0.6976, -0.1502,  0.4830, -1.2605,\n",
      "        -0.3488,  0.1193]) tensor([-0.0119, -0.6020,  0.8242,  0.8050, -0.7086, -0.1742,  0.4832, -1.2470,\n",
      "        -0.0045, -0.0495]) tensor([ 0.6072, -0.7291,  0.8857,  0.8206, -0.7398, -0.1475,  0.4921, -1.3352,\n",
      "        -0.0666, -0.1147])\n",
      "R[0]\n",
      "tensor([-0.0060], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052667842403054235 0.004383195651362257 0.0021178360276717283 0.006238879437325522 0.03394004712626338 0.4177575699687004 0.007267041394952684 42.529446090698244\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0279, -0.7247,  1.0933,  0.9396, -0.8994, -0.2140,  0.3327, -1.2123,\n",
      "         0.4399,  0.1774]) tensor([-0.0219, -0.7002,  1.0665,  0.9420, -0.8754, -0.2050,  0.3189, -1.1893,\n",
      "         0.1323, -0.0061]) tensor([ 0.1581, -0.7352,  1.1263,  0.9710, -0.9040, -0.2129,  0.3270, -1.2153,\n",
      "         0.0617,  0.4669])\n",
      "R[0]\n",
      "tensor([0.0008], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052879746168851854 0.004230709552271946 0.0021783070443361792 0.006050166971050203 0.03406034641712904 0.4174387471079826 0.007286578081082552 42.575864654541014\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1162, -0.6217,  0.8989,  0.7887, -0.6263, -0.2836,  0.5996, -0.9546,\n",
      "         0.0551, -0.1138]) tensor([-0.0444, -0.6030,  0.9097,  0.7955, -0.6058, -0.2517,  0.5594, -0.9357,\n",
      "         0.0239, -0.0489]) tensor([-0.0211, -0.7777,  1.2449,  0.9759, -0.9037, -0.1787,  0.2984, -1.2820,\n",
      "        -0.1461, -0.2213])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052632381364703176 0.004532242159892121 0.0020160062297027255 0.006211476899217814 0.034205494921654464 0.4174395272731781 0.007193797280080617 42.57207873535156\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3471, -0.3793,  0.6176,  0.6850, -0.5690, -0.0637,  0.3226, -1.0795,\n",
      "         0.3997, -0.8704]) tensor([-0.0220, -0.4477,  0.7252,  0.7212, -0.6131, -0.0900,  0.3262, -1.1214,\n",
      "        -0.0843, -0.1125]) tensor([-0.1547, -0.6112,  0.8410,  0.7023, -0.6198, -0.1365,  0.4238, -1.1313,\n",
      "         0.3078, -0.0261])\n",
      "R[0]\n",
      "tensor([-0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05249847200512886 0.004177250725455451 0.0020276994843616194 0.006079367807600647 0.03392593337595463 0.416669156730175 0.0071580956024117764 42.512098114013675\n",
      "Average (on the epoch) training loss: 0.006100126763177104\n",
      "Episode average V value: 0\n",
      "epoch 30:\n",
      "Learning rate: 4.710128697246249e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 98.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 97.99020097990201 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5861, -0.8929,  1.0283,  0.4105, -0.2144, -0.2549,  0.2987, -0.5966,\n",
      "         0.1963,  0.4634]) tensor([-0.1689, -0.8862,  0.9692,  0.3896, -0.2105, -0.2033,  0.2478, -0.6757,\n",
      "         0.0781,  0.0451]) tensor([-0.2808, -0.7846,  1.0248,  0.6173, -0.3459, -0.2539,  0.3194, -0.6123,\n",
      "         0.1860,  0.1156])\n",
      "R[0]\n",
      "tensor([-0.0045], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05238779255747795 0.004397968792147367 0.001980773262805087 0.006213240211363882 0.03364926026389003 0.4251742123961449 0.007155030610971153 42.59016069793701\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1656, -0.8060,  0.8177,  0.4602, -0.2242, -0.1455,  0.4112, -0.6912,\n",
      "         0.3827,  0.0826]) tensor([-0.1890, -0.7977,  0.8900,  0.5296, -0.2420, -0.1086,  0.3538, -0.6890,\n",
      "         0.0889,  0.0200]) tensor([-0.2564, -0.7458,  0.8289,  0.5768, -0.2872, -0.1151,  0.3303, -0.6639,\n",
      "         0.0898, -0.3110])\n",
      "R[0]\n",
      "tensor([0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05241441033780575 0.0045004573996156975 0.0026174292326504654 0.006456497187027708 0.034028056986629966 0.4238302415013313 0.007096948946360498 42.63319138336182\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7343, -0.5562,  1.0419,  0.9512, -0.5496, -0.2504,  0.1810, -0.5157,\n",
      "         0.7769, -0.0186]) tensor([-0.1057, -0.5824,  1.0413,  0.9341, -0.5546, -0.2377,  0.1938, -0.5758,\n",
      "         0.0802, -0.0135]) tensor([ 0.0690, -0.5702,  0.9957,  0.8518, -0.4677, -0.2660,  0.2301, -0.4686,\n",
      "         0.4182, -0.0728])\n",
      "R[0]\n",
      "tensor([0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05245138369500637 0.00416146203882272 0.0022546650736403537 0.006203153908252716 0.03407838485389948 0.4286066744923592 0.007108804851770401 42.640160202026365\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2314, -0.4868,  1.0339,  1.0736, -0.6118, -0.2485,  0.1761, -0.5231,\n",
      "        -0.4523, -0.5686]) tensor([-0.0618, -0.5065,  1.0794,  1.0919, -0.6060, -0.2188,  0.1674, -0.5537,\n",
      "         0.0577, -0.0163]) tensor([-0.0852, -0.5030,  1.1349,  1.1277, -0.6143, -0.1562,  0.0660, -0.5751,\n",
      "        -0.6083, -0.1415])\n",
      "R[0]\n",
      "tensor([-0.0017], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05257943863421678 0.004567908753231677 0.0024767981305458308 0.006316270416602493 0.03414742769300937 0.4297089867591858 0.007141760929021984 42.676966583251954\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2886, -0.6735,  1.1203,  1.0621, -0.6815, -0.1341, -0.0282, -0.6840,\n",
      "        -0.1125,  0.3476]) tensor([-0.0788, -0.6708,  1.1246,  1.0447, -0.6276, -0.1120, -0.0242, -0.6633,\n",
      "         0.1779,  0.0253]) tensor([ 0.0039, -0.6896,  1.1375,  1.1061, -0.6592, -0.0893, -0.0569, -0.6735,\n",
      "         0.6983,  0.1167])\n",
      "R[0]\n",
      "tensor([0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05235480836033821 0.004092638967649691 0.0023220580608876843 0.005901216450845822 0.034220522597432135 0.4346093195080757 0.007158540341071784 42.69693852233887\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2910, -0.8846,  1.2756,  0.6747, -0.3931, -0.0981, -0.0102, -0.7045,\n",
      "        -0.0138,  0.4734]) tensor([-0.1655, -0.8506,  1.2380,  0.6839, -0.3566, -0.0773,  0.0058, -0.6819,\n",
      "         0.2960,  0.1084]) tensor([-0.1326, -0.6987,  1.2479,  1.0454, -0.5763, -0.0772, -0.0484, -0.6595,\n",
      "         0.4791, -0.1666])\n",
      "R[0]\n",
      "tensor([0.0019], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05250606754422188 0.004342656601665112 0.0025856780743033596 0.00618453601654619 0.03431391291692853 0.42927364802360535 0.007231266600545495 42.62433578491211\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4079,  0.0650,  0.6861,  1.2033, -0.4015,  0.2846, -0.4371, -0.5719,\n",
      "         0.2254,  0.1587]) tensor([-0.0253, -0.0508,  0.7879,  1.2023, -0.4604,  0.1839, -0.2955, -0.6288,\n",
      "        -0.0629, -0.0900]) tensor([-0.1542, -0.3522,  0.8517,  1.1798, -0.4625,  0.0232, -0.0513, -0.4850,\n",
      "        -0.3167,  0.0812])\n",
      "R[0]\n",
      "tensor([-0.0105], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052551424697041514 0.0041844472052398485 0.002425802047850084 0.006043481823522597 0.03424886241555214 0.4222419850230217 0.007011843126732856 42.514371887207034\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0192, -0.8313,  0.8754, -0.6153,  0.3149,  0.2092,  0.0716, -1.4367,\n",
      "         0.3658,  0.1347]) tensor([-0.2351, -0.8299,  0.8625, -0.6044,  0.3190,  0.2442, -0.0153, -1.4750,\n",
      "         0.0361,  0.1855]) tensor([-0.1143, -0.9684,  0.8769, -0.4770,  0.2769,  0.1244, -0.0266, -1.1330,\n",
      "        -0.2957,  0.2688])\n",
      "R[0]\n",
      "tensor([0.0028], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052516546502709385 0.003993152487306361 0.0021825059580178278 0.005785562598612159 0.033535758417099715 0.4260101884007454 0.00730965894414112 42.64006848144531\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2031, -0.4905,  0.9106,  0.9139, -0.5000, -0.3115,  0.2439, -0.4041,\n",
      "        -0.2628,  0.3479]) tensor([-0.0947, -0.5432,  0.9531,  0.9156, -0.5305, -0.3094,  0.2526, -0.4835,\n",
      "         0.0192, -0.0241]) tensor([ 0.1076, -0.4988,  0.9079,  0.9172, -0.5007, -0.3049,  0.2594, -0.4029,\n",
      "        -0.2541,  0.8056])\n",
      "R[0]\n",
      "tensor([-0.0016], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052368696004152296 0.0039961582101823295 0.0025236391484522755 0.00603379956795834 0.03406931719183922 0.4284261552095413 0.0071660142792388795 42.618522605896\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0537, -0.0495,  0.6337,  0.7786, -0.3415,  0.1996, -0.0389, -1.0579,\n",
      "        -0.5084, -0.4151]) tensor([-0.0058, -0.1250,  0.7327,  0.7535, -0.3441,  0.1829, -0.0429, -1.0838,\n",
      "        -0.0733, -0.0203]) tensor([-0.5192, -0.0350,  0.6620,  0.7487, -0.3661,  0.2306, -0.0655, -1.1781,\n",
      "        -0.8452, -0.1321])\n",
      "R[0]\n",
      "tensor([-0.0115], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05234930033236742 0.004046852587460307 0.00221502968637742 0.0060203244141303 0.03358931225910783 0.4337360159158707 0.007285808936692774 42.685913749694826\n",
      "Average (on the epoch) training loss: 0.006115808259486221\n",
      "Episode average V value: 0\n",
      "epoch 31:\n",
      "Learning rate: 4.239115827521624e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 97.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 96.99030096990302 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6096, -0.3589,  0.9109,  1.3421, -0.3893,  0.0592, -0.1058, -0.3052,\n",
      "         0.2567, -0.0271]) tensor([-0.0810, -0.4033,  0.9419,  1.3085, -0.3970,  0.0738, -0.1208, -0.3654,\n",
      "         0.0982,  0.0348]) tensor([ 0.2447, -0.3257,  0.8690,  1.4026, -0.3499,  0.0963, -0.1312, -0.2671,\n",
      "         0.0112, -0.0731])\n",
      "R[0]\n",
      "tensor([-0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052661598727107045 0.004231201931523174 0.001961664189815565 0.00579851605091244 0.034257917379960416 0.4376180119514465 0.007314007812179625 42.69823840332031\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-2.7061e-05, -5.8059e-01,  1.2114e+00,  1.2046e+00, -5.0401e-01,\n",
      "         1.5978e-01, -3.8959e-01, -6.1052e-01,  1.8121e-02, -1.8709e-01]) tensor([-0.1000, -0.6069,  1.1555,  1.1372, -0.4881,  0.1109, -0.2796, -0.6236,\n",
      "         0.2337,  0.1068]) tensor([-0.0596, -0.4600,  0.9732,  1.1494, -0.5364, -0.0995, -0.0898, -0.3760,\n",
      "        -0.0637, -0.3644])\n",
      "R[0]\n",
      "tensor([0.0028], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05232016558945179 0.004262523339324616 0.0017788759134891735 0.005920030833804049 0.033577170792967084 0.430105514228344 0.007273500183597207 42.65553719329834\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3349, -0.6918,  0.7018,  0.5087, -0.1424, -0.0366,  0.3131, -0.5249,\n",
      "         0.3536, -0.1136]) tensor([-0.2158, -0.6952,  0.7532,  0.5481, -0.1572, -0.0072,  0.2605, -0.5390,\n",
      "         0.0549, -0.0160]) tensor([ 0.0714, -0.8393,  0.8072,  0.4293, -0.1620, -0.0575,  0.2777, -0.6549,\n",
      "         0.2019, -0.6994])\n",
      "R[0]\n",
      "tensor([-0.0018], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05295109413564205 0.004652160294701389 0.002084080373009783 0.006117140698479489 0.03379073755256832 0.43694775861501695 0.007303311299532652 42.66775881958008\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5569, -0.5979,  0.9501,  0.8401, -0.7057, -0.2206,  0.5889, -1.1940,\n",
      "         0.0509, -0.0840]) tensor([-0.0220, -0.5744,  0.9393,  0.8165, -0.6709, -0.1982,  0.5482, -1.1542,\n",
      "         0.0444, -0.0328]) tensor([ 0.1584, -0.4437,  0.6738,  0.7087, -0.4979, -0.0761,  0.6564, -1.2814,\n",
      "         0.3358,  0.0497])\n",
      "R[0]\n",
      "tensor([-0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052782710775732995 0.004334148356459991 0.0019315164212939636 0.0060393444746732715 0.03353272583335638 0.4392677087187767 0.007126003431621939 42.68858159637451\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0795, -0.5158,  0.9232,  0.9301, -0.5243, -0.2965,  0.2332, -0.4297,\n",
      "         0.7934, -0.2713]) tensor([-0.0935, -0.5414,  0.9833,  0.9565, -0.5287, -0.2651,  0.2101, -0.4701,\n",
      "         0.0527, -0.0173]) tensor([-0.0451, -0.5030,  1.0019,  0.9764, -0.5459, -0.2639,  0.1724, -0.4406,\n",
      "         0.1875, -0.1560])\n",
      "R[0]\n",
      "tensor([-0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052996640011668206 0.004779385428711975 0.0019841492501627726 0.006264792748959735 0.033339249305427074 0.43686382031440735 0.007108308922499419 42.723709159851076\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4346, -0.5804,  0.9807,  1.1358, -0.6268, -0.1298,  0.0312, -0.5814,\n",
      "         0.5919, -0.3764]) tensor([-0.0722, -0.6277,  1.0070,  1.0967, -0.6153, -0.1508,  0.0696, -0.6020,\n",
      "         0.0770,  0.0193]) tensor([ 0.2924, -0.5998,  0.9649,  1.0801, -0.6207, -0.1357,  0.0519, -0.6006,\n",
      "        -0.1099, -0.0096])\n",
      "R[0]\n",
      "tensor([-0.0018], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05278524719923735 0.004446953619570195 0.0019298720721490099 0.005933736221166328 0.033784279409795996 0.4446694971323013 0.007097516507841647 42.79586238098145\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0269, -0.6593,  0.9285,  0.8538, -0.7830, -0.1536,  0.3958, -1.2406,\n",
      "         0.9369,  0.4827]) tensor([ 0.0238, -0.6607,  0.9510,  0.8552, -0.7768, -0.1679,  0.4186, -1.2105,\n",
      "         0.0837,  0.0036]) tensor([ 0.0850, -0.6617,  0.8335,  0.7913, -0.7189, -0.1330,  0.4668, -1.3077,\n",
      "         0.1352, -0.2510])\n",
      "R[0]\n",
      "tensor([-0.0025], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05241930106282234 0.004810841369413538 0.0018757555883576061 0.006154150128364563 0.03421550370939076 0.4421287490129471 0.007341136179398746 42.77071901702881\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0360, -0.7314,  1.0037,  0.8732, -0.7817, -0.1891,  0.5281, -1.3001,\n",
      "         0.6328,  0.2438]) tensor([ 0.0075, -0.7022,  0.9954,  0.8415, -0.7278, -0.1676,  0.4984, -1.2369,\n",
      "         0.0906, -0.0061]) tensor([ 0.3826, -0.7898,  1.0534,  0.8492, -0.7716, -0.1205,  0.4588, -1.3982,\n",
      "         0.4199,  0.2803])\n",
      "R[0]\n",
      "tensor([0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05278222390264273 0.0043041776381087405 0.0022155858594032907 0.005897946559358388 0.033932944383472205 0.4460253409743309 0.007183933097403497 42.88274737548828\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0546, -0.5378,  0.9131,  0.8389, -0.4524, -0.3277,  0.2986, -0.4095,\n",
      "        -0.2397, -0.3517]) tensor([-0.1154, -0.5583,  0.9860,  0.8975, -0.4711, -0.2908,  0.2809, -0.4545,\n",
      "         0.0448, -0.0035]) tensor([-0.8867, -0.5754,  0.9083,  0.7532, -0.4273, -0.3065,  0.2820, -0.4364,\n",
      "         0.6775,  0.0701])\n",
      "R[0]\n",
      "tensor([-0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052987102702260015 0.004639774231975934 0.0022046755817427765 0.00617521858541295 0.033806819647550584 0.4447913781404495 0.007030881624203175 42.760038452148436\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5817, -0.8378,  0.6180, -0.0092,  0.0925, -0.2321,  0.7230, -0.6533,\n",
      "         0.2810,  0.3128]) tensor([-0.2646, -0.8426,  0.7787,  0.2000, -0.0625, -0.1955,  0.5813, -0.7242,\n",
      "        -0.0207, -0.0302]) tensor([-0.0596, -0.6106,  0.8385,  0.4385, -0.3483, -0.3674,  0.6588, -0.7457,\n",
      "        -0.0871, -0.1490])\n",
      "R[0]\n",
      "tensor([0.0132], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052788088254630564 0.004841833068729102 0.001959872420213287 0.006266167495166883 0.03335968102142215 0.44242570191621783 0.007138258455321193 42.819452980041504\n",
      "Average (on the epoch) training loss: 0.00605670437962981\n",
      "Episode average V value: 0\n",
      "epoch 32:\n",
      "Learning rate: 3.815204244769462e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 119.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 118.98810118988101 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2345, -0.6884,  1.0687,  1.0236, -0.6377, -0.1412,  0.0441, -0.6842,\n",
      "        -0.3606,  1.0845]) tensor([-0.0527, -0.7072,  1.0621,  1.0246, -0.6337, -0.1445,  0.0552, -0.7191,\n",
      "         0.0794,  0.0795]) tensor([-0.2966, -0.6599,  0.9241,  0.9718, -0.6211, -0.1738,  0.1514, -0.6599,\n",
      "        -0.1497,  0.0028])\n",
      "R[0]\n",
      "tensor([-0.0052], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05269985917210579 0.004439254051345415 0.00269641890818275 0.006124531554058194 0.03383085222542286 0.44498284697532653 0.007318381372839212 42.80504772949219\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3787, -0.7272,  0.7569,  0.7359, -0.4034, -0.1501,  0.2498, -0.6509,\n",
      "         0.1149, -0.1323]) tensor([-0.1434, -0.7374,  0.8460,  0.7766, -0.3892, -0.1115,  0.1974, -0.6397,\n",
      "         0.0566,  0.0288]) tensor([-0.4444, -0.6911,  0.8265,  0.6908, -0.2370, -0.1125,  0.1986, -0.4898,\n",
      "         0.3433, -0.3683])\n",
      "R[0]\n",
      "tensor([-0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05262658676505089 0.004014599975678721 0.0023369399047896877 0.0056999936874490235 0.034224364593625066 0.4465196741223335 0.007235736651811749 42.90603150939941\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4547, -0.6485,  0.8001,  0.8794, -0.7599, -0.2646,  0.6235, -1.1880,\n",
      "        -0.3029,  0.1095]) tensor([-0.0100, -0.6662,  0.8468,  0.8725, -0.7649, -0.2691,  0.5910, -1.1738,\n",
      "         0.0056, -0.0515]) tensor([ 0.5710, -0.6019,  0.8353,  0.9030, -0.7518, -0.3193,  0.6686, -1.1038,\n",
      "         0.0417, -0.4329])\n",
      "R[0]\n",
      "tensor([-0.0060], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05265258328616619 0.004251894534785606 0.002255300329835336 0.0061003423638176174 0.03417782114073634 0.4486175425648689 0.007129570422694087 42.81594777679443\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6723, -0.6356,  1.0014,  0.8326, -0.7285, -0.2309,  0.5592, -1.1993,\n",
      "        -0.0910, -0.3084]) tensor([ 0.0191, -0.6314,  0.9966,  0.8116, -0.7273, -0.2368,  0.5495, -1.1817,\n",
      "         0.0751, -0.0120]) tensor([-0.5549, -0.5647,  0.9766,  0.8552, -0.7120, -0.2616,  0.6148, -1.1062,\n",
      "        -0.5293, -0.5070])\n",
      "R[0]\n",
      "tensor([-0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05275323895365 0.004796068449392806 0.0023185535157872438 0.006291252956027165 0.03390292927250266 0.4486531599164009 0.007163651657290757 42.8544289932251\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2860, -0.6933,  1.0821,  0.9990, -0.8839, -0.2668,  0.2858, -1.0476,\n",
      "        -0.8084, -0.9015]) tensor([ 0.0575, -0.6855,  1.0977,  1.0188, -0.8665, -0.2427,  0.2646, -1.0394,\n",
      "         0.0159, -0.0938]) tensor([ 0.4844, -0.6729,  1.0851,  0.9869, -0.8760, -0.2753,  0.2913, -1.0298,\n",
      "        -0.0277,  0.1616])\n",
      "R[0]\n",
      "tensor([0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05269507750123739 0.004411229280547559 0.0018944137833068453 0.006061164844315499 0.033348374340683225 0.4495251650810242 0.007314112186664715 42.82684658050537\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6710, -0.7144,  1.1999,  1.0141, -0.9073, -0.2057,  0.2577, -1.1796,\n",
      "         0.2131,  0.6582]) tensor([ 0.0403, -0.7043,  1.2178,  1.0032, -0.8541, -0.1760,  0.2283, -1.1440,\n",
      "         0.1779,  0.0461]) tensor([-0.3830, -0.6730,  0.8858,  0.8253, -0.7433, -0.1783,  0.5457, -1.2564,\n",
      "        -0.4724,  0.4898])\n",
      "R[0]\n",
      "tensor([0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0524942995980382 0.004499221613288682 0.0014971657418100222 0.005687453452963382 0.03348682731389999 0.4425349823832512 0.007223560662940144 42.77838564300537\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4442, -0.4642,  1.0616,  1.0898, -0.6113, -0.2210,  0.1393, -0.5208,\n",
      "         0.8473, -0.4523]) tensor([-0.0307, -0.5174,  1.0772,  1.0517, -0.6209, -0.2405,  0.1743, -0.5755,\n",
      "         0.0739, -0.0188]) tensor([-0.5304, -0.5532,  1.1777,  1.0990, -0.6438, -0.1493,  0.0567, -0.6438,\n",
      "         0.2466,  0.2703])\n",
      "R[0]\n",
      "tensor([-0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05259837990254164 0.004426377254381805 0.0026397333902286844 0.006285258908057585 0.034109632939100264 0.4502627320885658 0.007141781365033239 42.84114547729492\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7052, -0.7941,  0.9647,  0.5731, -0.3397, -0.2833,  0.2758, -0.5543,\n",
      "         0.0365,  0.0602]) tensor([-0.1283, -0.7828,  0.9865,  0.6459, -0.3734, -0.2588,  0.2487, -0.5879,\n",
      "         0.0689,  0.0323]) tensor([ 0.1816, -0.7387,  0.9057,  0.6176, -0.3742, -0.2954,  0.2333, -0.4872,\n",
      "        -0.3731, -0.2445])\n",
      "R[0]\n",
      "tensor([0.0232], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05253853537887335 0.004293461394658152 0.001967372527039515 0.005897404133109376 0.034104651492089036 0.4491669691801071 0.007113022732548415 42.8282386932373\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4054, -0.8398,  0.6811,  0.7742, -0.5900, -0.1378,  0.1755, -0.8346,\n",
      "         0.3129,  0.2551]) tensor([-0.0700, -0.8402,  0.7715,  0.8506, -0.5823, -0.1185,  0.1470, -0.8044,\n",
      "        -0.0069, -0.0458]) tensor([-0.0222, -0.8308,  0.6543,  0.8029, -0.5962, -0.1387,  0.1854, -0.8327,\n",
      "         0.1933,  0.0480])\n",
      "R[0]\n",
      "tensor([-0.0054], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05242157672345638 0.004269989222435469 0.002565970535057204 0.005972270249389112 0.034438362456858156 0.44284565126895903 0.007270384272560477 42.787461975097656\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1063, -0.9035,  1.2391,  0.6052, -0.3299, -0.0857, -0.0639, -0.6507,\n",
      "         0.2063, -0.2262]) tensor([-0.1591, -0.8951,  1.1330,  0.5494, -0.3002, -0.0682, -0.0330, -0.7060,\n",
      "         0.1990,  0.1311]) tensor([ 0.5735, -0.6811,  1.0664,  0.9001, -0.5256, -0.1267,  0.0703, -0.6520,\n",
      "         0.0160, -0.5729])\n",
      "R[0]\n",
      "tensor([0.0110], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053134713910520076 0.00407753702447917 0.0019359273015588769 0.006092790673254057 0.034228827752172945 0.444258570253849 0.007405092410743237 42.725012603759765\n",
      "Average (on the epoch) training loss: 0.006021246282244101\n",
      "Episode average V value: 0\n",
      "epoch 33:\n",
      "Learning rate: 3.4336838202925156e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 132.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 131.98680131986802 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0308, -0.8422,  1.5999,  1.2415, -0.6511,  0.2910, -0.6903, -0.8513,\n",
      "         0.5419,  0.2892]) tensor([-0.0402, -0.8151,  1.4477,  1.1707, -0.6067,  0.2275, -0.5253, -0.8207,\n",
      "         0.4224,  0.1672]) tensor([-0.2082, -0.9245,  1.4608,  1.0577, -0.5798,  0.2391, -0.6083, -0.8573,\n",
      "         0.4466,  0.1951])\n",
      "R[0]\n",
      "tensor([0.0153], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052592651888728144 0.004800075347236998 0.0021669550417918798 0.006108349109417759 0.034139351760968564 0.4455396302640438 0.007137235651724041 42.773993080139164\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0194, -0.5801,  1.1753,  1.0851, -0.6705, -0.1500,  0.0415, -0.6820,\n",
      "        -0.6333,  0.3060]) tensor([-0.0370, -0.5955,  1.1888,  1.0759, -0.6510, -0.1291,  0.0451, -0.7067,\n",
      "         0.1672,  0.0420]) tensor([-0.3132, -0.6192,  1.3860,  1.1620, -0.6658,  0.0485, -0.1966, -0.8361,\n",
      "         0.3000, -0.0821])\n",
      "R[0]\n",
      "tensor([0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052752393327653406 0.00429099803273948 0.0020776144801875488 0.005777057152241468 0.03381197903677821 0.4405581343173981 0.007345946764573455 42.71302897644043\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1384, -0.0736,  0.9058,  1.4966, -0.5676,  0.0585, -0.4086, -0.1663,\n",
      "         0.1724, -0.0599]) tensor([-0.0405, -0.1515,  0.9293,  1.4336, -0.5504,  0.0674, -0.3771, -0.2645,\n",
      "         0.0245, -0.0211]) tensor([-0.0855, -0.2064,  1.0862,  1.4425, -0.6842, -0.0326, -0.3378, -0.3033,\n",
      "        -0.0329,  0.0126])\n",
      "R[0]\n",
      "tensor([-0.0039], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052997286453843113 0.004173365784867201 0.002038536936080163 0.005921599003486335 0.033523171588778496 0.4393386244773865 0.0072743855114094915 42.76195134735107\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0934, -0.5516,  0.8213,  0.7538, -0.7653, -0.1111,  0.3136, -1.1992,\n",
      "         0.1262,  0.4184]) tensor([ 0.0150, -0.5570,  0.8485,  0.7957, -0.7794, -0.1282,  0.3412, -1.1942,\n",
      "         0.0060, -0.1130]) tensor([-0.1343, -0.6870,  1.0049,  0.8489, -0.8192, -0.1521,  0.3203, -1.2129,\n",
      "         0.3277, -0.1702])\n",
      "R[0]\n",
      "tensor([-0.0075], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052925118252635 0.004211250424601531 0.0021300242913093823 0.005871278394712135 0.03383196737244725 0.4433006747364998 0.007348630933556706 42.82070004272461\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0088, -0.5335,  0.7413,  1.1151, -0.3218,  0.2720, -0.1031, -0.5935,\n",
      "         0.0962,  0.0766]) tensor([-0.1456, -0.5940,  0.7941,  1.0819, -0.3599,  0.2135, -0.0687, -0.6057,\n",
      "         0.1054, -0.0026]) tensor([ 0.0805, -0.5914,  0.8612,  0.6980, -0.2050,  0.0157,  0.2465, -0.5516,\n",
      "         0.1822,  0.3453])\n",
      "R[0]\n",
      "tensor([-0.0013], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052480471923947336 0.004593249969589124 0.0018439787703246112 0.005928801027592271 0.033464055277407166 0.43646622949838637 0.007300821816548705 42.79139273071289\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5938, -0.7586,  0.9016,  0.7907, -0.6930, -0.1475,  0.5417, -1.3588,\n",
      "        -0.7825,  0.2966]) tensor([ 0.0476, -0.7512,  0.9320,  0.7678, -0.6517, -0.1304,  0.4875, -1.3033,\n",
      "         0.0110,  0.0384]) tensor([-0.4930, -0.7193,  0.8928,  0.7348, -0.6838, -0.1514,  0.5233, -1.3117,\n",
      "         0.3112,  0.4912])\n",
      "R[0]\n",
      "tensor([0.0013], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052343627355992794 0.004659561281283459 0.0020388628901291668 0.0061442013862542805 0.034715147417038676 0.4352304645776749 0.007377101130317897 42.746565505981444\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1394, -0.5905,  0.9154,  0.7777, -0.1814,  0.0618,  0.1866, -0.5066,\n",
      "         0.0805,  0.1906]) tensor([-1.7140e-01, -6.0631e-01,  8.9504e-01,  7.9505e-01, -2.6174e-01,\n",
      "         5.1315e-02,  1.7312e-01, -5.9230e-01,  1.1472e-01, -5.4547e-04]) tensor([-0.3458, -0.6485,  0.9824,  0.7800, -0.1890,  0.0910,  0.0986, -0.5335,\n",
      "         0.6454,  0.4758])\n",
      "R[0]\n",
      "tensor([-0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052549138903617856 0.004924811182239864 0.002074115600888035 0.005945926183834672 0.034016751676797866 0.43443266934156416 0.007308016661088913 42.725532379150394\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2449, -0.9694,  1.0198,  0.2437, -0.0099,  0.0628,  0.0171, -0.6082,\n",
      "         0.3674, -0.0353]) tensor([-0.2127, -0.9545,  0.8971,  0.2186, -0.0309,  0.1089, -0.0248, -0.7315,\n",
      "         0.1602,  0.0933]) tensor([-0.3352, -0.8020,  1.1179,  0.0910, -0.0979, -0.0433,  0.1591, -0.8126,\n",
      "         0.6808, -0.0877])\n",
      "R[0]\n",
      "tensor([0.0636], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05255428809672594 0.004829347706418048 0.0022651207143599096 0.006063566513592377 0.03401410166919232 0.4307436263561249 0.007293721860740334 42.77171156311035\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0128, -0.7197,  0.7839,  0.5764, -0.2548, -0.0441,  0.3180, -0.6666,\n",
      "        -0.5643, -0.2143]) tensor([-0.1916, -0.7422,  0.8282,  0.5714, -0.2479, -0.0367,  0.2920, -0.6710,\n",
      "         0.0307, -0.0653]) tensor([-0.3229, -0.5671,  0.8519,  0.6296, -0.1351, -0.0386,  0.3302, -0.4566,\n",
      "         0.1739, -0.5578])\n",
      "R[0]\n",
      "tensor([0.0001], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05262562243640423 0.004735433413306964 0.0019600539609582485 0.005766480903374031 0.03423844219744206 0.43424264079332353 0.007289579100906849 42.77727816772461\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7431, -0.6205,  0.7756,  0.6835, -0.5592, -0.1049,  0.6733, -1.3455,\n",
      "        -0.0664,  0.1043]) tensor([-5.2106e-04, -6.0968e-01,  7.8710e-01,  6.4943e-01, -5.3567e-01,\n",
      "        -9.9919e-02,  6.1878e-01, -1.2956e+00, -3.0351e-03, -4.9582e-02]) tensor([-0.3729, -0.7162,  0.7070,  0.4204, -0.1106, -0.1073,  0.5307, -0.6400,\n",
      "         0.3481, -0.3851])\n",
      "R[0]\n",
      "tensor([-0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05264984515309334 0.004531554046219753 0.0020580994692199965 0.006191321136662736 0.03354511757194996 0.43171382272243497 0.007287362372968346 42.711713340759275\n",
      "Average (on the epoch) training loss: 0.005971858081116807\n",
      "Episode average V value: 0\n",
      "epoch 34:\n",
      "Learning rate: 3.090315438263264e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 132.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 131.98680131986802 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2145, -0.5560,  0.8891,  0.8021, -0.6776, -0.2074,  0.5989, -1.1553,\n",
      "        -0.4340, -0.1116]) tensor([-0.0029, -0.5506,  0.8810,  0.8161, -0.7136, -0.2054,  0.5655, -1.1782,\n",
      "         0.0381, -0.0560]) tensor([-0.1571, -0.6933,  1.0691,  0.8674, -0.7620, -0.1566,  0.4740, -1.3013,\n",
      "         0.6588,  0.4329])\n",
      "R[0]\n",
      "tensor([-0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05244971693307161 0.004544041225264664 0.0020068374371630853 0.0060474482463905585 0.03389741912856698 0.426663200199604 0.00724793943297118 42.61693579864502\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4147, -0.8070,  1.3925,  1.1999, -0.6201,  0.1860, -0.4814, -0.7713,\n",
      "         0.2234, -0.1407]) tensor([-0.0868, -0.7931,  1.3403,  1.1460, -0.5489,  0.1869, -0.4396, -0.7344,\n",
      "         0.3658,  0.1589]) tensor([-0.4736, -0.7557,  1.4083,  1.2699, -0.6959,  0.1008, -0.4065, -0.7428,\n",
      "         0.4574,  0.2956])\n",
      "R[0]\n",
      "tensor([-0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05288997722417116 0.00416151975604771 0.002010744594775133 0.00570967992558144 0.03423642159625888 0.4254466406702995 0.007171571729239076 42.56037679290772\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3162, -0.8581,  1.4758,  1.1329, -0.7013,  0.1118, -0.3796, -0.8750,\n",
      "         0.0360, -0.0498]) tensor([-0.0675, -0.8308,  1.3566,  1.0987, -0.6820,  0.0699, -0.2626, -0.8644,\n",
      "         0.3797,  0.1396]) tensor([-0.6123, -0.8121,  1.5031,  1.0361, -0.6643,  0.0518, -0.2025, -0.9581,\n",
      "         0.3124, -0.2347])\n",
      "R[0]\n",
      "tensor([0.0061], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05337879841029644 0.004665553053097028 0.0022935213868013307 0.006154678542166949 0.03294983961805701 0.42943234139680864 0.007213807910680771 42.698850860595705\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2172, -0.6472,  0.7642,  0.7137, -0.4562, -0.1410,  0.5376, -0.9592,\n",
      "        -0.2369,  0.2575]) tensor([-0.0754, -0.6411,  0.7907,  0.7040, -0.4406, -0.1221,  0.4862, -0.9326,\n",
      "         0.0234, -0.0562]) tensor([-0.6204, -0.7226,  0.7874,  0.3932, -0.0841, -0.1470,  0.4534, -0.5250,\n",
      "         0.2868,  0.1881])\n",
      "R[0]\n",
      "tensor([0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05256829855591059 0.004489866088424606 0.0017134814082046433 0.006031509103486314 0.03342934898659587 0.42627660793066025 0.007295792666263878 42.697578689575195\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2086, -0.6766,  1.0451,  0.9707, -0.7827, -0.1947,  0.1555, -0.9254,\n",
      "         0.3140, -0.0695]) tensor([-0.0263, -0.6660,  1.0549,  0.9561, -0.7171, -0.1657,  0.1451, -0.8871,\n",
      "         0.0942,  0.0135]) tensor([-0.5668, -0.6821,  1.1173,  1.0045, -0.7349, -0.1386,  0.0646, -0.8604,\n",
      "        -0.0420, -0.4568])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05286218266934156 0.004965623093685281 0.002014157263881316 0.005874535254202783 0.03383715034276247 0.42872375017404557 0.007354166313540191 42.69130294799805\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3114, -0.4835,  1.0295,  1.0941, -0.6143, -0.2385,  0.1460, -0.5151,\n",
      "         0.4401,  0.3380]) tensor([-0.0411, -0.5037,  1.0144,  1.0877, -0.6336, -0.2271,  0.1536, -0.5866,\n",
      "         0.0158, -0.0218]) tensor([-0.2811, -0.4835,  1.0043,  1.0303, -0.6098, -0.2556,  0.1862, -0.5144,\n",
      "         0.2223, -0.0587])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052771721333265305 0.004857722213458146 0.0021784115995114916 0.006265630241949111 0.03365978179499507 0.4230587760806084 0.007289767197798938 42.684324905395506\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0822, -0.7253,  1.0060,  0.8342, -0.7386, -0.1532,  0.5011, -1.3283,\n",
      "         0.3494, -0.0706]) tensor([ 3.3261e-03, -6.9238e-01,  9.8808e-01,  8.0321e-01, -6.8503e-01,\n",
      "        -1.3827e-01,  4.7098e-01, -1.2585e+00,  8.6600e-02,  1.6671e-04]) tensor([-0.3721, -0.7510,  0.9793,  0.8778, -0.7728, -0.1599,  0.4871, -1.3219,\n",
      "         0.2046, -0.2510])\n",
      "R[0]\n",
      "tensor([-0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05286701365560293 0.004823152505548932 0.0019804049860158556 0.006120321005117148 0.03336384659260511 0.4309505271911621 0.007000326898414642 42.726179763793944\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.7187, -0.6704,  0.7414,  0.6003, -0.5119, -0.1030,  0.7365, -1.3979,\n",
      "         0.6838, -0.2007]) tensor([-5.5891e-04, -6.7184e-01,  8.0134e-01,  6.4115e-01, -5.6178e-01,\n",
      "        -1.0295e-01,  6.4547e-01, -1.3877e+00,  2.4950e-02, -9.7126e-02]) tensor([ 0.1547, -0.7549,  0.8994,  0.8061, -0.7170, -0.1436,  0.5495, -1.3561,\n",
      "        -0.0924, -0.6123])\n",
      "R[0]\n",
      "tensor([-0.0155], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05262004863470793 0.004674174360607139 0.0019235304757048652 0.006071345927659422 0.03388079704716802 0.42831813180446626 0.007334903010632843 42.72849540710449\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 1.1107, -0.7299,  1.1537,  0.9407, -0.8543, -0.2180,  0.3873, -1.2310,\n",
      "         0.2587,  0.1511]) tensor([ 0.0611, -0.7012,  1.1398,  0.9114, -0.7993, -0.1960,  0.3529, -1.1715,\n",
      "         0.1551,  0.0240]) tensor([ 0.1847, -0.7576,  1.0726,  0.9282, -0.8373, -0.1981,  0.4135, -1.2745,\n",
      "        -0.3994, -0.8770])\n",
      "R[0]\n",
      "tensor([0.0008], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05254416290670633 0.00453480814858085 0.0017779080357495332 0.005931438392726704 0.03416831897199154 0.42092145681381227 0.007230994970537722 42.625895500183105\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0038, -0.6311,  1.0909,  0.9273, -0.5471, -0.2275,  0.2885, -0.6806,\n",
      "        -0.1864,  0.3386]) tensor([-0.0797, -0.6298,  1.1073,  0.9453, -0.5494, -0.2021,  0.2769, -0.7005,\n",
      "         0.1534,  0.0156]) tensor([ 0.3381, -0.6166,  1.1109,  0.9817, -0.5820, -0.2160,  0.2173, -0.6230,\n",
      "         0.5026, -0.3125])\n",
      "R[0]\n",
      "tensor([0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05297225905954838 0.0049314900555764325 0.002035102225270748 0.006145506987348199 0.03387585448846221 0.4226351224780083 0.007491535406094044 42.6101711807251\n",
      "Average (on the epoch) training loss: 0.006035209362662863\n",
      "Episode average V value: 0\n",
      "epoch 35:\n",
      "Learning rate: 2.7812838944369375e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 132.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 131.98680131986802 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2090, -0.6284,  1.0136,  0.8358, -0.7003, -0.1653,  0.5175, -1.2678,\n",
      "        -0.1348,  0.0955]) tensor([ 0.0053, -0.6025,  0.9923,  0.8044, -0.6622, -0.1529,  0.4940, -1.2203,\n",
      "         0.0937, -0.0171]) tensor([ 0.1801, -0.7124,  0.9805,  0.8805, -0.7370, -0.1241,  0.4533, -1.3299,\n",
      "         0.3709,  0.1904])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052856932081282136 0.004689643746032744 0.001740953503505807 0.006118977289414033 0.033902277156710625 0.42260562247037886 0.007394261364359409 42.695368034362794\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2842, -0.7162,  0.6953,  0.6342, -0.5082, -0.1865,  0.3176, -0.8184,\n",
      "        -0.1337, -0.2380]) tensor([-0.0974, -0.7183,  0.7768,  0.6601, -0.4613, -0.1478,  0.2684, -0.7757,\n",
      "         0.0102, -0.0138]) tensor([ 0.0285, -0.5614,  0.5580,  0.4909, -0.1590, -0.1304,  0.5494, -0.5655,\n",
      "         0.1942, -0.9086])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052651338696479796 0.004076341071933711 0.0013893259165488417 0.005624389276606962 0.03361885003373027 0.4222409714460373 0.007262763660866767 42.70410843658447\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3288, -1.0237,  0.8365, -0.3068,  0.0647, -0.1427,  0.3575, -1.0213,\n",
      "         0.5274,  0.3486]) tensor([-0.1159, -0.8533,  0.9438,  0.2947, -0.3081, -0.1667,  0.3293, -1.0114,\n",
      "         0.1333,  0.0314]) tensor([-0.0481, -0.4877,  0.9743,  0.8076, -0.5806, -0.3895,  0.8284, -0.9383,\n",
      "         0.3427, -0.0736])\n",
      "R[0]\n",
      "tensor([0.2037], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05202136715501547 0.004506527850902785 0.002009065436651326 0.005839848485309631 0.033739491187036036 0.42360631680488586 0.0072452901746146384 42.644036270141605\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0301, -0.6536,  1.1805,  1.1722, -0.0239,  0.7501, -0.4821, -0.7860,\n",
      "         0.7721,  0.2212]) tensor([-0.1821, -0.6767,  1.0912,  1.0647, -0.0757,  0.6117, -0.3641, -0.7497,\n",
      "         0.3567,  0.1539]) tensor([-0.4167, -0.7855,  1.1519,  1.0659, -0.1809,  0.5872, -0.4914, -0.7640,\n",
      "         0.4077,  0.3381])\n",
      "R[0]\n",
      "tensor([0.0189], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053183059401810166 0.004763381606187977 0.0020614514480930667 0.006267942746868357 0.034175378020852805 0.430001522898674 0.007157657092437148 42.671578086853025\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4023, -0.7104,  1.1921,  1.0986, -0.7317, -0.0976, -0.0678, -0.7763,\n",
      "        -0.1216, -0.4413]) tensor([-0.0418, -0.7179,  1.1632,  1.0576, -0.6963, -0.1061, -0.0100, -0.7727,\n",
      "         0.1948,  0.0849]) tensor([ 0.0954, -0.7102,  1.1304,  1.0197, -0.8051, -0.1906,  0.0590, -0.8518,\n",
      "         0.3285, -0.1579])\n",
      "R[0]\n",
      "tensor([0.0027], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053153563529253 0.004850165179863325 0.0018190398584742979 0.006090103925904259 0.03351341005600989 0.428403399348259 0.007283848957624286 42.66998825836182\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6345, -0.5162,  0.9899,  0.9169, -0.7491, -0.3714,  0.6608, -1.0048,\n",
      "         0.5598, -0.4586]) tensor([-0.0320, -0.5187,  1.0048,  0.9045, -0.7512, -0.3522,  0.6299, -1.0140,\n",
      "         0.0441, -0.0649]) tensor([ 0.1797, -0.5074,  0.9952,  0.9081, -0.7653, -0.3833,  0.6537, -1.0063,\n",
      "         0.5481, -0.2574])\n",
      "R[0]\n",
      "tensor([-0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05276908055692911 0.004571574904013687 0.0021189987650559487 0.006069118213374167 0.03356946917064488 0.42485762149095535 0.007103446520864963 42.65406929779053\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1153, -0.6315,  1.3280,  1.0827, -0.5508, -0.0158, -0.1009, -0.6702,\n",
      "         0.6248,  0.5900]) tensor([-0.0769, -0.6397,  1.2532,  1.0174, -0.5419, -0.0456, -0.0250, -0.6930,\n",
      "         0.2432,  0.0657]) tensor([-0.0358, -0.6055,  1.1884,  0.8784, -0.5029, -0.1844,  0.0935, -0.5829,\n",
      "        -0.3377,  0.1694])\n",
      "R[0]\n",
      "tensor([-0.0010], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052425745837390424 0.0045025356138503414 0.0016759008219805764 0.005769857302075252 0.033813028044998646 0.427995908677578 0.007268343772273511 42.678576248168945\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5073, -1.0452,  1.2602,  0.0692,  0.2144, -0.0024,  0.0472, -0.5327,\n",
      "        -0.1358,  0.7768]) tensor([-0.3004, -1.0166,  1.0497, -0.0365,  0.2253,  0.0614, -0.0269, -0.6776,\n",
      "         0.1826,  0.2060]) tensor([-0.9442, -1.2844,  1.1119, -0.3501,  0.3918, -0.1561,  0.5763, -0.7934,\n",
      "         0.1968,  0.6243])\n",
      "R[0]\n",
      "tensor([0.0446], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052635459311306476 0.004754605923550116 0.0020278828316268116 0.006070085290819406 0.03400521486252546 0.42577267146110537 0.007457859782036394 42.68901582336426\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0424, -0.7619,  1.2684,  1.1168, -0.7230, -0.0241, -0.1328, -0.8328,\n",
      "         0.5185,  0.2235]) tensor([-6.1512e-02, -7.5054e-01,  1.2645e+00,  1.1067e+00, -6.7258e-01,\n",
      "         6.2148e-04, -1.2446e-01, -8.1190e-01,  2.6540e-01,  7.9668e-02]) tensor([-0.0346, -0.5284,  1.2691,  1.3733, -0.5644,  0.1674, -0.3707, -0.5588,\n",
      "         0.8951, -0.1084])\n",
      "R[0]\n",
      "tensor([0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05303230857104063 0.004664108347236834 0.0018268912546036517 0.006226025029551238 0.033914039973169566 0.4258343220949173 0.007379058835562319 42.67499967956543\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0531, -0.5993,  0.9323,  0.8113, -0.3165,  0.0082,  0.1842, -0.5649,\n",
      "        -0.1014,  0.0618]) tensor([-0.1514, -0.6331,  0.9287,  0.7961, -0.3681, -0.0105,  0.1945, -0.6324,\n",
      "         0.1432,  0.0028]) tensor([-0.3008, -0.8117,  0.8902,  0.5261, -0.2625, -0.0605,  0.2638, -0.7009,\n",
      "         0.2444, -0.0922])\n",
      "R[0]\n",
      "tensor([-0.0074], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05240549094229936 0.004769067961371548 0.001700198744327281 0.005945972181856632 0.034430922988802196 0.4239809579849243 0.007205027217976749 42.68810121917725\n",
      "Average (on the epoch) training loss: 0.006002231974177994\n",
      "Episode average V value: 0\n",
      "epoch 36:\n",
      "Learning rate: 2.503155504993244e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 132.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 131.98680131986802 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1623, -0.6259,  1.1736,  1.1168, -0.5964, -0.0752, -0.0585, -0.6143,\n",
      "        -0.3361, -0.0724]) tensor([-0.0822, -0.6274,  1.1569,  1.0859, -0.5565, -0.0568, -0.0477, -0.6182,\n",
      "         0.2054,  0.0517]) tensor([-0.4671, -0.6309,  0.9855,  0.9712, -0.6024, -0.1940,  0.1445, -0.6349,\n",
      "         0.1512,  0.4265])\n",
      "R[0]\n",
      "tensor([-0.0001], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052825918555259706 0.004116744812246907 0.0019128811362988927 0.005819176183547824 0.033868471700698136 0.4197612495422363 0.0071894048852846025 42.663539726257326\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3059, -0.6045,  1.1100,  1.0911, -0.7020, -0.1826,  0.0460, -0.7037,\n",
      "        -0.2719, -1.2316]) tensor([ 0.0093, -0.6237,  1.1129,  1.0799, -0.6910, -0.1731,  0.0406, -0.7333,\n",
      "         0.0791, -0.0940]) tensor([ 0.3395, -0.4957,  1.0169,  1.1205, -0.5905, -0.1419,  0.0571, -0.5533,\n",
      "        -0.1491, -0.7170])\n",
      "R[0]\n",
      "tensor([-0.0010], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05254143542796373 0.004475517883765861 0.0019652904744925765 0.0059668767852708695 0.03432602323591709 0.4210086540579796 0.007199496593791992 42.672330665588376\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0915, -0.7793,  1.0465,  0.9324, -0.8169, -0.1431,  0.4113, -1.3506,\n",
      "        -0.3242,  0.0425]) tensor([ 0.0013, -0.7624,  1.0161,  0.8910, -0.7867, -0.1609,  0.4295, -1.2956,\n",
      "         0.1402,  0.0182]) tensor([ 0.0274, -0.8167,  1.0759,  0.9450, -0.8784, -0.1361,  0.3287, -1.3632,\n",
      "        -0.0945, -0.8274])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053101323917508124 0.004256146329880721 0.0019138567590580352 0.005879571951460093 0.033668205697089434 0.4181832612156868 0.007412013521417975 42.64779224395752\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1855, -0.5687,  0.9763,  0.8894, -0.7873, -0.3527,  0.6134, -1.0437,\n",
      "        -0.6506, -0.2429]) tensor([ 0.0293, -0.5659,  0.9770,  0.9010, -0.8036, -0.3338,  0.5718, -1.0697,\n",
      "         0.0337, -0.0530]) tensor([-0.0026, -0.5477,  0.9694,  0.9232, -0.7818, -0.3634,  0.6138, -1.0474,\n",
      "        -0.0963, -0.5236])\n",
      "R[0]\n",
      "tensor([0.0016], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05254366023093462 0.004906847494676185 0.0018579564056103663 0.00608007329585962 0.03428527505323291 0.41871188732981685 0.007266019971109926 42.627681938171385\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4248, -0.2699,  1.2176,  1.6092, -0.4615,  0.2844, -0.6027, -0.2176,\n",
      "         0.0643, -0.3683]) tensor([-0.0849, -0.3370,  1.1781,  1.5123, -0.4754,  0.2187, -0.4856, -0.2786,\n",
      "         0.2441,  0.0994]) tensor([ 0.0858, -0.3497,  1.2265,  1.5008, -0.5383,  0.1565, -0.4695, -0.3117,\n",
      "        -0.3483,  0.4280])\n",
      "R[0]\n",
      "tensor([-0.0029], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05280704148858786 0.005022019572135833 0.0020078886884475652 0.0065656694313511255 0.03365788520313799 0.41795808508992194 0.0072166956150904295 42.64826054382324\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5708, -1.1426,  1.0158, -0.0378, -0.1468, -0.1400,  0.3934, -1.1815,\n",
      "        -0.2198,  0.3204]) tensor([-0.2039, -1.0859,  1.0182,  0.0052, -0.1086, -0.1165,  0.3594, -1.0973,\n",
      "         0.1848,  0.1235]) tensor([-0.6210, -1.2087,  1.2315,  0.2060, -0.1584, -0.0832,  0.3966, -1.1758,\n",
      "         0.4270, -0.1189])\n",
      "R[0]\n",
      "tensor([0.0046], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05290482301265001 0.004539828677838159 0.002281611973463441 0.005998132259119302 0.034377896402031184 0.41586154013872145 0.0072086154664866625 42.59054772186279\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3487, -0.5234,  1.1649,  1.2719, -0.4399,  0.0754, -0.1607, -0.4400,\n",
      "         0.1980,  0.2101]) tensor([-0.1335, -0.5619,  1.1290,  1.1999, -0.4550,  0.0301, -0.0945, -0.4766,\n",
      "         0.1991,  0.0708]) tensor([-0.9326, -0.4937,  1.1242,  1.2381, -0.3765,  0.0798, -0.1171, -0.4091,\n",
      "         0.6718,  0.8440])\n",
      "R[0]\n",
      "tensor([-0.0081], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0527906411215663 0.0044677667445321275 0.0020467592486247666 0.005680953263305128 0.03411501177400351 0.41616412556171417 0.007383829447440803 42.61714527130127\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1621, -1.0287,  0.9799,  0.2225, -0.1284, -0.2220,  0.2625, -0.6473,\n",
      "         0.4945,  0.3845]) tensor([-0.2587, -0.9926,  1.0138,  0.2731, -0.0975, -0.1835,  0.2265, -0.5961,\n",
      "         0.1530,  0.0894]) tensor([-0.2417, -0.9427,  0.9989,  0.2570, -0.1370, -0.2678,  0.3132, -0.5773,\n",
      "         0.2945,  0.0756])\n",
      "R[0]\n",
      "tensor([-0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05280351599305868 0.004453368523407335 0.0019766579505303525 0.005652911152108572 0.03351105136051774 0.40968683552742 0.007392658189637587 42.51904582214355\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3098, -1.3711,  1.5041,  0.0605, -0.0102, -0.0503,  0.2879, -1.1140,\n",
      "         0.6713, -0.2571]) tensor([-0.1831, -1.3045,  1.2227, -0.1006,  0.0412, -0.0053,  0.2096, -1.1863,\n",
      "         0.3269,  0.1704]) tensor([ 0.2280, -1.3431,  1.4588,  0.1373, -0.0666, -0.0248,  0.3114, -1.1589,\n",
      "         0.5868, -0.0246])\n",
      "R[0]\n",
      "tensor([-0.0127], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05301194433867931 0.00452173645792027 0.0017632173618776505 0.0057841214796062555 0.03381240912526846 0.4178305421769619 0.007286066798493266 42.57743009185791\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4330, -0.6853,  0.9516,  0.9002, -0.7926, -0.2569,  0.5494, -1.2027,\n",
      "         0.2095,  0.2131]) tensor([ 0.0172, -0.6781,  0.9598,  0.8872, -0.7784, -0.2570,  0.5341, -1.1705,\n",
      "         0.0387, -0.0526]) tensor([ 0.7624, -0.6727,  0.9644,  0.9252, -0.8181, -0.2789,  0.5328, -1.1877,\n",
      "        -0.3096,  0.7882])\n",
      "R[0]\n",
      "tensor([0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05273499695211649 0.004557491927565934 0.002383433923568191 0.00621013728203252 0.034158493109047415 0.40919358813762663 0.007217624536715448 42.458531959533694\n",
      "Average (on the epoch) training loss: 0.005963762308366131\n",
      "Episode average V value: 0\n",
      "epoch 37:\n",
      "Learning rate: 2.2528399544939195e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 124.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 123.98760123987601 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3697, -0.6100,  0.9598,  1.0888, -0.6471, -0.1351, -0.0435, -0.5803,\n",
      "         0.1782, -0.0154]) tensor([-0.0620, -0.6327,  1.0245,  1.0959, -0.6094, -0.1037, -0.0538, -0.5817,\n",
      "         0.1059,  0.0331]) tensor([-0.4847, -0.5727,  1.0786,  1.1430, -0.5589, -0.0379, -0.1511, -0.5269,\n",
      "        -0.0602,  0.3043])\n",
      "R[0]\n",
      "tensor([0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05276254904270172 0.004523670692657106 0.0019633494716554197 0.005676254858379253 0.034732470978051426 0.4097990151643753 0.007495580712333322 42.56948078155518\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4086, -1.1392,  1.1065,  0.1576, -0.0521, -0.1448,  0.2543, -0.7698,\n",
      "         0.3180,  1.0511]) tensor([-0.2494, -1.0990,  1.1011,  0.2411, -0.0932, -0.1495,  0.2624, -0.7540,\n",
      "         0.2177,  0.1658]) tensor([-0.3334, -1.0631,  1.1193,  0.1871, -0.0876, -0.2103,  0.2337, -0.6549,\n",
      "        -0.0546,  0.0514])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052582495629787444 0.004489507248368682 0.0016581641787934132 0.0057501590978354215 0.033596082821488384 0.414846889257431 0.007135720854625106 42.62055595397949\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3453, -0.5898,  1.1381,  1.1359, -0.6375, -0.0945, -0.0461, -0.6157,\n",
      "         0.1759, -0.2038]) tensor([-0.0896, -0.6195,  1.1182,  1.0906, -0.6279, -0.1186,  0.0193, -0.6407,\n",
      "         0.1465,  0.0631]) tensor([-0.5889, -0.5975,  1.0111,  0.9890, -0.6578, -0.2149,  0.1984, -0.6835,\n",
      "        -0.6629,  0.2345])\n",
      "R[0]\n",
      "tensor([-0.0016], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05304118645191193 0.00451964479146227 0.0015460919010279212 0.005760407587280497 0.03418286299332976 0.42097314435243605 0.007385724888183177 42.662572898864745\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1557, -0.9279,  1.2455,  0.9684, -0.5860,  0.1517, -0.4150, -0.8787,\n",
      "        -0.0748, -0.2067]) tensor([-0.1104, -0.9090,  1.1851,  0.9571, -0.5538,  0.1102, -0.3102, -0.8338,\n",
      "         0.3217,  0.1544]) tensor([ 0.2105, -0.9199,  1.1032,  0.8775, -0.6128,  0.0404, -0.2569, -0.8721,\n",
      "         0.6696,  0.1198])\n",
      "R[0]\n",
      "tensor([0.0138], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05242003145813942 0.004149811577977744 0.0016826839028972246 0.0055339637149591 0.03390314415097237 0.4156460229754448 0.007582250120583922 42.67057814025879\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0382, -0.9691,  1.1423,  0.3828, -0.1308, -0.0604,  0.0053, -0.6232,\n",
      "         0.7381, -0.1267]) tensor([-0.1939, -0.9698,  1.0395,  0.3174, -0.1112, -0.0331, -0.0159, -0.7029,\n",
      "         0.1462,  0.1191]) tensor([-0.3122, -0.9808,  1.0508,  0.4623, -0.2940, -0.0775, -0.0088, -0.7228,\n",
      "        -0.0938,  0.3129])\n",
      "R[0]\n",
      "tensor([0.0238], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0527539306357503 0.004461029702750238 0.0022047547532265525 0.005842721576802433 0.03412882633879781 0.41058982038497926 0.007278641219483689 42.59939771270752\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3232, -0.9210,  1.3715,  1.0872, -0.8627,  0.0461, -0.2334, -1.1331,\n",
      "         0.4104, -0.1726]) tensor([-0.0234, -0.8901,  1.2869,  1.0652, -0.8227,  0.0025, -0.1276, -1.0770,\n",
      "         0.3261,  0.1142]) tensor([ 0.1526, -0.9222,  1.2951,  1.0365, -0.9199, -0.0350, -0.1100, -1.2032,\n",
      "         0.0734, -0.0372])\n",
      "R[0]\n",
      "tensor([0.0056], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05262698595970869 0.004434917629845586 0.002034087805832314 0.00586195370927453 0.03386094296723604 0.418326122879982 0.007541505459230393 42.558421867370605\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0080, -0.2822,  0.9572,  1.4829, -0.2513,  0.2229, -0.2460, -0.2178,\n",
      "         0.5011,  0.0664]) tensor([-0.1114, -0.3379,  0.9622,  1.4227, -0.2759,  0.2212, -0.2435, -0.3039,\n",
      "         0.1218,  0.0737]) tensor([-0.2658, -0.3065,  0.9659,  1.4910, -0.2702,  0.2380, -0.2756, -0.2340,\n",
      "         0.1961,  0.3465])\n",
      "R[0]\n",
      "tensor([-0.0022], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05279699660092592 0.00433246438387323 0.0018038214614230128 0.005838771204464138 0.03374738452583551 0.4200460087656975 0.007302034452091903 42.55574337005615\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1707, -1.2079,  0.9750, -0.0100, -0.0266, -0.0162,  0.1322, -0.8127,\n",
      "         0.4220,  0.3409]) tensor([-0.1938, -1.1275,  0.8784,  0.1139, -0.1002,  0.0486,  0.0767, -0.8998,\n",
      "         0.2114,  0.0823]) tensor([-0.6191, -1.1327,  1.0133, -0.0189, -0.0222,  0.0432, -0.0024, -0.8820,\n",
      "        -0.3824,  0.5016])\n",
      "R[0]\n",
      "tensor([0.0727], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05301124607026577 0.004607732359232614 0.0013966698363551586 0.005875264378963039 0.03331590780615806 0.4198367547392845 0.0075232372037135065 42.63231562042236\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5854, -0.7452,  1.2746,  0.9949, -0.8496, -0.1822,  0.2783, -1.1706,\n",
      "         0.5498,  0.2920]) tensor([-0.0087, -0.7122,  1.2415,  0.9654, -0.7965, -0.1624,  0.2665, -1.1208,\n",
      "         0.2118,  0.0331]) tensor([-0.1113, -0.6972,  1.5946,  1.1557, -0.8020,  0.0353, -0.2521, -1.0210,\n",
      "         0.7115,  0.4643])\n",
      "R[0]\n",
      "tensor([0.0014], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052515923589468 0.004279988115275046 0.0018969298085826267 0.005444936924381182 0.03400161964446306 0.41639482364058494 0.00723931806976907 42.67512948608398\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0155, -0.7246,  1.3090,  1.1984, -0.6707,  0.0600, -0.2898, -0.7207,\n",
      "         0.9426,  0.3065]) tensor([-0.0672, -0.7268,  1.3039,  1.1740, -0.6242,  0.0794, -0.2718, -0.7172,\n",
      "         0.3011,  0.1024]) tensor([-0.3118, -0.7433,  1.2647,  1.1471, -0.6741,  0.0103, -0.2162, -0.7459,\n",
      "         0.8110, -0.8505])\n",
      "R[0]\n",
      "tensor([0.0015], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05256439337879419 0.004442630971747349 0.0016017679115416287 0.005817387713817879 0.034258702989667655 0.41961145132780076 0.007268433636985719 42.61831436157227\n",
      "Average (on the epoch) training loss: 0.005740182076615747\n",
      "Episode average V value: 0\n",
      "epoch 38:\n",
      "Learning rate: 2.0275559590445276e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 124.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 123.98760123987601 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2101, -0.5930,  0.8494,  0.7786, -0.7322, -0.0717,  0.3085, -1.3263,\n",
      "        -0.1159, -0.0872]) tensor([-0.0032, -0.5935,  0.9006,  0.7720, -0.6815, -0.0498,  0.2785, -1.2754,\n",
      "         0.0644, -0.0042]) tensor([ 0.5060, -0.5795,  0.8018,  0.7145, -0.6622, -0.0770,  0.4183, -1.3147,\n",
      "        -0.1387, -0.6178])\n",
      "R[0]\n",
      "tensor([-0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052653663851320746 0.004942065833360175 0.001747807772066153 0.005900198440998793 0.03386859978735447 0.4181776105761528 0.0072314839260652665 42.61050804901123\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0563, -1.2158,  0.9323, -0.1606,  0.1086, -0.0981,  0.3198, -0.7721,\n",
      "         0.2798, -0.3977]) tensor([-0.3140, -1.1854,  0.9756, -0.0883,  0.1023, -0.0610,  0.2651, -0.7488,\n",
      "         0.1706,  0.0992]) tensor([-0.5069, -1.1278,  0.8921, -0.1243,  0.0654, -0.1170,  0.2376, -0.6491,\n",
      "         0.8473,  0.0082])\n",
      "R[0]\n",
      "tensor([-0.0029], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052920058846473696 0.004399282614580443 0.0018067258175001372 0.005706416601315141 0.033719801988452675 0.42025735914707185 0.007348905021324754 42.62962079620361\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2387, -0.7381,  1.1244,  1.0435, -0.6516, -0.0783, -0.0544, -0.7281,\n",
      "         0.7671,  0.0446]) tensor([-0.0563, -0.7336,  1.0903,  1.0373, -0.6396, -0.0808, -0.0211, -0.7398,\n",
      "         0.1371,  0.0501]) tensor([ 0.2373, -0.7134,  1.1449,  1.0503, -0.6636, -0.0956, -0.0561, -0.7265,\n",
      "         0.7365,  0.2040])\n",
      "R[0]\n",
      "tensor([0.0042], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052873519912362096 0.00445303919428352 0.00185721204111087 0.005576353301526979 0.03347124225646257 0.4147763818502426 0.007247708604671061 42.6235771408081\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1579, -0.6582,  1.0287,  1.0540, -0.6554, -0.1620,  0.0579, -0.6609,\n",
      "         0.1595, -0.7174]) tensor([-0.0797, -0.6685,  1.0464,  1.0267, -0.6034, -0.1426,  0.0513, -0.6450,\n",
      "         0.1187,  0.0430]) tensor([ 0.3319, -0.6818,  1.1186,  1.0779, -0.6520, -0.1017, -0.0237, -0.6895,\n",
      "        -0.0308,  0.0388])\n",
      "R[0]\n",
      "tensor([-0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05245232063531875 0.00480595119264035 0.001942987389784321 0.005911335453623906 0.034909714728593826 0.41363464945554734 0.007553246938157827 42.58072032928467\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1478, -0.7964,  1.1155,  0.1079, -0.2703,  0.1559,  0.2072, -1.6205,\n",
      "         0.1722,  0.0457]) tensor([-0.1032, -0.7522,  1.0890,  0.2127, -0.3496,  0.0454,  0.3307, -1.5321,\n",
      "         0.1967,  0.1137]) tensor([-0.1711, -0.9519,  1.2811,  0.2106, -0.2908,  0.1185,  0.2364, -1.6173,\n",
      "        -0.1224,  0.3006])\n",
      "R[0]\n",
      "tensor([0.0316], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052670785933732985 0.004368879307294265 0.001727359112297563 0.005616795974317938 0.033647971168160436 0.41341302466392515 0.007436224385164678 42.6051263961792\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0128, -0.7845,  1.0230,  0.8753, -0.7760, -0.1060,  0.4276, -1.4052,\n",
      "        -0.7513,  0.1619]) tensor([ 0.0014, -0.7712,  0.9999,  0.8384, -0.7540, -0.1250,  0.4349, -1.3551,\n",
      "         0.1098,  0.0455]) tensor([ 0.4482, -0.8080,  1.0533,  0.8807, -0.8311, -0.1203,  0.3627, -1.3743,\n",
      "         0.0907,  0.4767])\n",
      "R[0]\n",
      "tensor([0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052832807920873165 0.004311179137010185 0.001994580066603703 0.005652711754897609 0.03448753529787064 0.41523601773381236 0.007369941972661763 42.67960360717773\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4457, -0.6529,  0.9191,  0.6214, -0.3672, -0.3300,  0.2872, -0.4520,\n",
      "        -0.3008, -0.1491]) tensor([-0.1401, -0.6819,  0.9389,  0.6290, -0.3869, -0.2976,  0.2606, -0.5341,\n",
      "         0.0316,  0.0346]) tensor([-0.5432, -0.7296,  0.9108,  0.5455, -0.3277, -0.3191,  0.2759, -0.4659,\n",
      "        -0.0235,  0.2180])\n",
      "R[0]\n",
      "tensor([0.0073], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052501307509839536 0.004723935159128814 0.0015253822996423878 0.005699394996394404 0.03381381103396416 0.4138039808869362 0.00746729849698022 42.65883306121826\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2339, -0.6322,  0.9663,  0.8558, -0.2254,  0.1063,  0.0548, -0.5321,\n",
      "        -0.2457,  0.1681]) tensor([-0.1575, -0.6424,  0.9756,  0.8623, -0.2479,  0.1137,  0.0518, -0.5658,\n",
      "         0.1889,  0.0515]) tensor([ 0.1081, -0.5742,  0.8587,  0.8778, -0.2915,  0.0529,  0.1743, -0.5577,\n",
      "        -0.4627, -0.4195])\n",
      "R[0]\n",
      "tensor([0.0010], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05295006945729255 0.00523207016575725 0.0019305417405471416 0.0060999920431058854 0.03396671812608838 0.4092718721628189 0.007305273001547903 42.57858600616455\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1838, -0.9342,  1.2993,  0.9625, -0.8563, -0.0120,  0.1853, -1.4369,\n",
      "         0.1187, -0.1267]) tensor([ 0.0121, -0.8894,  1.2653,  0.9367, -0.7904,  0.0019,  0.1843, -1.3553,\n",
      "         0.3064,  0.1020]) tensor([-0.0062, -0.5449,  1.3252,  1.3368, -0.6826,  0.1854, -0.3935, -0.7933,\n",
      "        -0.1090,  0.0782])\n",
      "R[0]\n",
      "tensor([0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05248442924022675 0.004877122518942997 0.0014000697029828188 0.006012511477572843 0.03446633541956544 0.41132034033536913 0.007515717609785497 42.65266569519043\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2233, -0.6812,  0.9821,  0.7320, -0.4112, -0.2776,  0.3073, -0.5428,\n",
      "        -0.0502,  0.1119]) tensor([-0.1601, -0.6780,  0.9791,  0.7715, -0.4498, -0.2591,  0.2853, -0.5950,\n",
      "         0.0533,  0.0107]) tensor([-0.0544, -0.7055,  0.9663,  0.6835, -0.4040, -0.2942,  0.2537, -0.5075,\n",
      "         0.1102,  0.0091])\n",
      "R[0]\n",
      "tensor([0.0091], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052749590560793876 0.004706004419136662 0.0020410018767861404 0.006063474432565272 0.03405153403803706 0.40886829048395157 0.007335569923743606 42.53598548126221\n",
      "Average (on the epoch) training loss: 0.005823918447631877\n",
      "Episode average V value: 0\n",
      "epoch 39:\n",
      "Learning rate: 1.824800363140075e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 132.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 131.98680131986802 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3673, -0.5096,  0.6562,  0.8445, -0.6373, -0.3373,  0.3740, -0.6292,\n",
      "        -0.5344,  0.0531]) tensor([-0.0508, -0.5636,  0.7791,  0.8930, -0.6630, -0.3199,  0.3398, -0.6703,\n",
      "        -0.0583, -0.0757]) tensor([-0.6162, -0.5420,  0.7506,  0.8951, -0.6379, -0.3165,  0.3192, -0.6129,\n",
      "        -0.3939,  0.1067])\n",
      "R[0]\n",
      "tensor([0.0049], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05275624990463257 0.004329152084386806 0.0015255139800483448 0.005626686625182628 0.03402067817933858 0.4160116692781448 0.007865904303267598 42.6309701461792\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2975, -0.9261,  1.1231,  0.3945, -0.2525, -0.1066,  0.1096, -0.6826,\n",
      "         0.3821, -0.4897]) tensor([-0.1643, -0.9225,  1.0240,  0.3442, -0.2405, -0.0748,  0.0968, -0.7676,\n",
      "         0.1524,  0.0950]) tensor([-0.5622, -0.5779,  0.6775,  0.4498,  0.1110,  0.0727,  0.2806, -0.4024,\n",
      "        -0.1063, -0.0221])\n",
      "R[0]\n",
      "tensor([0.0164], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05263663324713707 0.004542086303163159 0.00202922974993362 0.006002877312479541 0.03423780632764101 0.4123847380578518 0.007561552425380797 42.56124700164795\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2001, -0.8941,  1.1691,  0.3982, -0.1759, -0.2406,  0.4462, -0.7353,\n",
      "        -0.0823,  0.8668]) tensor([-0.1892, -0.8820,  1.0712,  0.3347, -0.1766, -0.2134,  0.3971, -0.8023,\n",
      "         0.1198,  0.1046]) tensor([-0.5957, -1.0868,  1.4009,  0.2531, -0.1648, -0.2127,  0.3751, -0.9001,\n",
      "         0.5233,  0.3438])\n",
      "R[0]\n",
      "tensor([-0.0058], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05275953768193722 0.004651852962744669 0.0019496317996681683 0.00609660196583718 0.03403150299936533 0.4080553054213524 0.0076141312783584 42.58843156433105\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3603, -0.6555,  1.1820,  1.0239, -0.8984, -0.2101,  0.2006, -1.1188,\n",
      "         0.4557,  0.2304]) tensor([ 0.0326, -0.6453,  1.1391,  0.9976, -0.8619, -0.2167,  0.2533, -1.1033,\n",
      "         0.1119, -0.0022]) tensor([ 0.5615, -0.6248,  1.1321,  1.0317, -0.8949, -0.2631,  0.2876, -1.0721,\n",
      "        -0.1334,  0.5148])\n",
      "R[0]\n",
      "tensor([0.0026], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053034383967518806 0.0045829482312437905 0.001673534422722696 0.006065940887900069 0.0338941118940711 0.40924929195642473 0.007327809076290577 42.49199019622803\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7239, -0.7301,  1.0502,  0.8159, -0.7414, -0.1348,  0.4927, -1.3397,\n",
      "         0.5018, -0.0819]) tensor([-3.1412e-04, -7.0157e-01,  1.0140e+00,  7.6873e-01, -6.9254e-01,\n",
      "        -1.2083e-01,  4.6240e-01, -1.2898e+00,  1.2940e-01,  1.9722e-02]) tensor([ 0.7814, -0.7548,  1.0518,  0.8329, -0.7657, -0.1259,  0.4472, -1.3725,\n",
      "         1.1169,  0.2471])\n",
      "R[0]\n",
      "tensor([0.0001], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05282642043381929 0.004660833662224832 0.0013090197893552613 0.005842252522474155 0.0344792004711926 0.4175890356898308 0.00752112542418763 42.5883132019043\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0317, -0.7156,  1.2346,  1.0817, -0.6145, -0.0073, -0.1723, -0.6916,\n",
      "         0.0348,  0.6239]) tensor([-0.0845, -0.7230,  1.1796,  1.0381, -0.5909, -0.0281, -0.0996, -0.7043,\n",
      "         0.2090,  0.0644]) tensor([ 0.2743, -0.7578,  1.2115,  1.0291, -0.5915, -0.0026, -0.1800, -0.7009,\n",
      "         0.8457, -0.1677])\n",
      "R[0]\n",
      "tensor([0.0008], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053084946937859055 0.00463479333453688 0.0020749836316799703 0.0061064739096909765 0.03397218787297607 0.41023533582687377 0.007410662423353642 42.543118911743164\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8580, -0.5972,  0.9281,  0.7567, -0.4320, -0.3040,  0.2584, -0.4213,\n",
      "        -0.2968, -0.3041]) tensor([-0.0528, -0.6062,  0.9925,  0.8023, -0.4370, -0.2791,  0.2517, -0.4284,\n",
      "         0.0193,  0.0258]) tensor([-0.1077, -0.6040,  1.0468,  0.9134, -0.5128, -0.2412,  0.1719, -0.5218,\n",
      "         0.1466,  0.1095])\n",
      "R[0]\n",
      "tensor([-0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05312949379533529 0.004745659197474197 0.001282892812494083 0.0061122321176808325 0.03363515400886535 0.4112906814813614 0.007575173798948526 42.544269691467285\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.7048, -0.6192,  0.9290,  0.9002, -0.7790, -0.2970,  0.6022, -1.1327,\n",
      "        -0.3144, -0.1965]) tensor([ 0.0136, -0.6089,  0.9645,  0.9038, -0.7566, -0.2719,  0.5639, -1.0984,\n",
      "         0.0179, -0.0033]) tensor([-0.0656, -0.5883,  0.9856,  0.9366, -0.7852, -0.3377,  0.6005, -1.0680,\n",
      "         0.5055, -0.3951])\n",
      "R[0]\n",
      "tensor([5.1796e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05252860647439957 0.004291675510101413 0.0018882745442774648 0.0059944428079761565 0.03395017495006323 0.4096702170372009 0.007272587853716686 42.519177085876464\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2104, -0.7038,  0.9719,  1.0186, -0.7821, -0.1610,  0.0766, -0.8645,\n",
      "         0.4684, -0.3333]) tensor([-0.0454, -0.7113,  1.0268,  1.0242, -0.7249, -0.1308,  0.0563, -0.8322,\n",
      "         0.1072,  0.0368]) tensor([-0.6068, -0.5190,  1.0502,  1.1920, -0.6409, -0.0592, -0.0950, -0.5882,\n",
      "        -0.0408,  0.1665])\n",
      "R[0]\n",
      "tensor([0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052914920657873156 0.004502594032892375 0.0015050466602451707 0.005793787848670035 0.03368981074914336 0.41040671199560164 0.007587498625740409 42.56027370452881\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3730, -0.6682,  1.7977,  1.2363, -0.7375,  0.1879, -0.3675, -1.0722,\n",
      "         0.0161,  0.4245]) tensor([-0.0209, -0.6456,  1.6861,  1.1962, -0.7218,  0.1756, -0.3005, -1.0950,\n",
      "         0.4849,  0.1874]) tensor([-0.1054, -0.6606,  1.5289,  1.1171, -0.8144, -0.0639, -0.0545, -1.0127,\n",
      "         0.6253,  0.0228])\n",
      "R[0]\n",
      "tensor([-0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05247525379806757 0.005093140498551293 0.0018753693086518979 0.006219716386171058 0.03392204963043332 0.41755787098407743 0.00748950403323397 42.62719927978516\n",
      "Average (on the epoch) training loss: 0.005986101238406263\n",
      "Episode average V value: 0\n",
      "epoch 40:\n",
      "Learning rate: 1.6423203268260674e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 132.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 131.98680131986802 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3198, -0.7562,  1.1978,  1.1153, -0.6327,  0.0553, -0.2752, -0.7283,\n",
      "         0.8475,  0.1252]) tensor([-0.0836, -0.7548,  1.1818,  1.0750, -0.5637,  0.0727, -0.2610, -0.7057,\n",
      "         0.2262,  0.0913]) tensor([-0.3190, -0.6454,  1.1113,  1.1684, -0.5980,  0.0163, -0.1647, -0.6291,\n",
      "        -0.2424,  0.0899])\n",
      "R[0]\n",
      "tensor([0.0016], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05282614380121231 0.004642024677445079 0.0019011136401823024 0.005991770030464977 0.034322577103972435 0.4120712466239929 0.00762473339214921 42.591102584838865\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7811, -1.1145,  1.2190,  0.0310,  0.0982, -0.0524,  0.0047, -0.6254,\n",
      "         0.2207, -0.1683]) tensor([-0.2955, -1.0705,  1.1898,  0.0728,  0.1166, -0.0331,  0.0138, -0.5983,\n",
      "         0.2692,  0.1992]) tensor([-0.3741, -1.0698,  1.0948,  0.2220, -0.1424, -0.0882, -0.0043, -0.6967,\n",
      "         0.4841,  0.3665])\n",
      "R[0]\n",
      "tensor([0.0019], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05270831599831581 0.004559248978081087 0.0015459755058523114 0.005565652388846502 0.03422922456264496 0.41531573963165286 0.007454785292036832 42.66121755218506\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1041, -0.7368,  1.3959,  1.1317, -0.7685,  0.0673, -0.2824, -0.9687,\n",
      "         0.3463,  0.4032]) tensor([-0.0253, -0.7238,  1.2975,  1.0770, -0.7288,  0.0309, -0.1693, -0.9533,\n",
      "         0.2874,  0.0841]) tensor([-0.3564, -0.9601,  1.3911,  1.0977, -0.8834,  0.1058, -0.3426, -1.1932,\n",
      "         0.1345,  0.8848])\n",
      "R[0]\n",
      "tensor([0.0036], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053140789940953254 0.004224848801597545 0.001581658259692631 0.005736785338725895 0.03378517775610089 0.4080628825426102 0.007625585022382439 42.52276030731201\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3766, -0.4419,  0.8605,  0.8622, -0.6951, -0.3268,  0.6216, -0.9583,\n",
      "         0.3528,  0.0153]) tensor([-0.0247, -0.4545,  0.8787,  0.8788, -0.7334, -0.3087,  0.5701, -1.0101,\n",
      "        -0.0757, -0.0933]) tensor([ 0.2338, -0.5408,  0.9715,  0.8699, -0.7256, -0.2803,  0.5998, -1.0871,\n",
      "        -0.1122,  0.2188])\n",
      "R[0]\n",
      "tensor([-0.0079], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052816711388528344 0.0048820453945609184 0.0018531691914281509 0.005958746440708637 0.03414940635487437 0.41553284657001494 0.007548667225986719 42.593923202514645\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6529, -0.4442,  0.7683,  1.2739, -0.1913,  0.3240, -0.1536, -0.4389,\n",
      "         0.3477, -0.1471]) tensor([-0.1132, -0.4836,  0.7700,  1.1842, -0.1746,  0.3212, -0.1817, -0.4609,\n",
      "         0.1032,  0.0560]) tensor([-0.3003, -0.5071,  0.7701,  1.0650, -0.2491,  0.1857,  0.0323, -0.5348,\n",
      "        -0.4702, -0.3268])\n",
      "R[0]\n",
      "tensor([-0.0026], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05279605586081743 0.004743722825935038 0.0013831538594427002 0.0059865249947179105 0.034295474540442225 0.41153988111019135 0.007302785736275837 42.53943459320068\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1072, -0.5904,  1.0860,  0.9575, -0.8792, -0.2503,  0.1741, -1.0661,\n",
      "        -0.2630, -0.4948]) tensor([-4.5497e-04, -5.8803e-01,  1.1062e+00,  9.3926e-01, -8.0526e-01,\n",
      "        -2.1986e-01,  1.6973e-01, -1.0289e+00,  8.9945e-02,  3.0928e-02]) tensor([-0.1562, -0.6887,  0.7968,  0.8630, -0.5775, -0.1687,  0.2609, -0.7535,\n",
      "         0.1062, -0.1413])\n",
      "R[0]\n",
      "tensor([-0.0014], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05296761205047369 0.004840398550210011 0.0019633470558201227 0.005730618147645146 0.033888219065964224 0.4120024374127388 0.007384301685262471 42.51347761535644\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4430, -0.6856,  1.0903,  0.9328, -0.8403, -0.2541,  0.4849, -1.2057,\n",
      "        -0.4248, -0.3398]) tensor([ 3.1307e-03, -6.8381e-01,  1.0711e+00,  8.9862e-01, -8.2862e-01,\n",
      "        -2.6682e-01,  5.0529e-01, -1.1868e+00,  1.0326e-01,  1.0145e-03]) tensor([-0.2536, -0.6708,  1.0837,  0.9294, -0.8392, -0.2713,  0.5022, -1.1748,\n",
      "        -0.3524, -0.1407])\n",
      "R[0]\n",
      "tensor([0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05310558892786503 0.004629209029078083 0.0015425142699468778 0.005856407438172027 0.0348211184963584 0.4110362955033779 0.007344300974160433 42.5251259765625\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2267,  0.0719,  0.6582,  1.0815, -0.3710,  0.4880, -0.6412, -0.8496,\n",
      "        -0.1807,  0.3189]) tensor([ 0.0108, -0.0406,  0.7340,  1.0698, -0.4219,  0.3344, -0.4400, -0.8525,\n",
      "        -0.0467, -0.0498]) tensor([-0.1323,  0.1943,  0.5423,  1.1867, -0.4557,  0.4069, -0.7327, -0.5905,\n",
      "        -0.0660,  0.0521])\n",
      "R[0]\n",
      "tensor([0.0593], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052654919512569905 0.004663935203225265 0.001949276948285842 0.005881405444466509 0.034101633846759793 0.4134311662018299 0.007420620435848832 42.54304947662354\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6896, -0.5015,  0.9596,  0.9064, -0.7352, -0.3670,  0.6517, -0.9975,\n",
      "        -0.1128,  0.1025]) tensor([-0.0176, -0.5022,  0.9488,  0.9049, -0.7632, -0.3533,  0.6055, -1.0358,\n",
      "        -0.0345, -0.0587]) tensor([-0.3986, -0.5344,  0.9841,  0.9335, -0.7494, -0.3709,  0.6620, -1.0050,\n",
      "         0.2306,  0.8789])\n",
      "R[0]\n",
      "tensor([-0.0047], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05311081669479609 0.00478341063764492 0.0017415488052115507 0.0060522570118773725 0.034073419108986855 0.4051171256005764 0.0076148151117376986 42.441401634216305\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0709, -0.7003,  0.7271,  0.8138, -0.4744, -0.0126,  0.2069, -0.8109,\n",
      "         0.0038,  0.1285]) tensor([-0.1027, -0.7139,  0.8065,  0.8308, -0.4523,  0.0151,  0.1622, -0.7897,\n",
      "         0.0748, -0.0079]) tensor([-0.2677, -0.6996,  0.6732,  0.7853, -0.4412,  0.0168,  0.1773, -0.7840,\n",
      "        -0.4063,  0.0340])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05266359270364046 0.004494977202652081 0.0016084286140880977 0.005665443925652653 0.034634998232126235 0.40779507261514664 0.007427339660935104 42.57781178283692\n",
      "Average (on the epoch) training loss: 0.005842561116127763\n",
      "Episode average V value: 0\n",
      "epoch 41:\n",
      "Learning rate: 1.4780882941434607e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 134.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 133.986601339866 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0016, -0.7964,  1.4901,  1.1633, -0.8284,  0.0454, -0.2429, -1.0337,\n",
      "         0.1913,  0.1899]) tensor([-0.0387, -0.7638,  1.4169,  1.1270, -0.7647,  0.0517, -0.1980, -0.9989,\n",
      "         0.3667,  0.1145]) tensor([-0.3851, -0.6199,  1.4047,  1.1627, -0.6801,  0.0414, -0.2106, -0.8045,\n",
      "         0.8514,  0.4861])\n",
      "R[0]\n",
      "tensor([0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052954287827014924 0.004721677374562205 0.0019430650932208665 0.006269546497613192 0.03383141314983368 0.41284500309824945 0.007323110060300678 42.58208409118652\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1830, -0.6549,  1.1130,  1.0801, -0.5585, -0.0213, -0.1091, -0.6174,\n",
      "        -0.0397, -0.0841]) tensor([-0.0777, -0.6598,  1.0649,  1.0564, -0.5559, -0.0301, -0.0700, -0.6498,\n",
      "         0.1792,  0.0825]) tensor([-0.4678, -0.6348,  1.0386,  1.0790, -0.5848, -0.0698, -0.0243, -0.6323,\n",
      "         0.1918, -0.4162])\n",
      "R[0]\n",
      "tensor([0.0030], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05322877658158541 0.004474179642400486 0.0017534782684942912 0.005921572477556765 0.03403594629466534 0.4128974259495735 0.007369662816636265 42.57125540161133\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1113, -0.9869,  1.4549,  1.0365, -0.9716,  0.0339, -0.1762, -1.3324,\n",
      "         0.1607, -0.3139]) tensor([-0.0123, -0.9447,  1.4030,  1.0010, -0.8733,  0.0437, -0.1399, -1.2454,\n",
      "         0.3706,  0.1393]) tensor([ 0.2940, -0.9079,  1.3162,  0.9993, -0.9003, -0.0353, -0.0102, -1.2650,\n",
      "         0.6680,  0.4156])\n",
      "R[0]\n",
      "tensor([0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05278974612057209 0.004263680145397302 0.0014011017262305359 0.005892059278208762 0.03425292650982738 0.4114600602686405 0.007581784988287836 42.5786600189209\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3753, -0.7189,  1.0633,  0.9759, -0.8835, -0.2324,  0.3573, -1.2048,\n",
      "        -0.6711,  0.0738]) tensor([ 0.0219, -0.7188,  1.0431,  0.9422, -0.8589, -0.2441,  0.3875, -1.1848,\n",
      "         0.0856,  0.0302]) tensor([ 0.7826, -0.7141,  1.1046,  0.9376, -0.8972, -0.2382,  0.3444, -1.1748,\n",
      "        -0.1061, -0.6847])\n",
      "R[0]\n",
      "tensor([0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05269682696461678 0.004561026337560179 0.0016164481905179854 0.005844878978095948 0.03399289108812809 0.41097992730140687 0.007359707686118782 42.516554588317874\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0019, -0.7216,  1.4580,  1.1724, -0.7160,  0.1091, -0.2926, -0.9344,\n",
      "         0.4406,  0.3055]) tensor([-0.0491, -0.6989,  1.3852,  1.1321, -0.6647,  0.1116, -0.2462, -0.9186,\n",
      "         0.3530,  0.1121]) tensor([ 0.0758, -0.5595,  1.3422,  1.1612, -0.6081,  0.0360, -0.1622, -0.7324,\n",
      "         0.1652,  0.0065])\n",
      "R[0]\n",
      "tensor([0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05261244311928749 0.0046595000476663696 0.001477217035079775 0.005841659678379073 0.03497997686639428 0.4180421881079674 0.007580556409433484 42.58027406311035\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9907, -0.4187,  1.0494,  1.3225, -0.5334,  0.0186, -0.1892, -0.4155,\n",
      "         0.2099,  0.7596]) tensor([-0.1139, -0.4658,  1.0352,  1.2696, -0.5453, -0.0014, -0.1742, -0.4798,\n",
      "         0.0886,  0.0838]) tensor([ 0.5189, -0.5129,  1.0294,  1.2258, -0.5838, -0.0392, -0.1106, -0.5054,\n",
      "         0.4559,  0.0078])\n",
      "R[0]\n",
      "tensor([0.0059], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05289900705963373 0.005180777527739338 0.0018157490042199243 0.006170997459674254 0.03407288059592247 0.4129600960612297 0.007172339249867946 42.59745296478272\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1286, -0.6481,  0.9423,  0.6804, -0.3791, -0.3052,  0.2681, -0.4570,\n",
      "         0.2739, -0.3720]) tensor([-0.1513, -0.6536,  0.9667,  0.7452, -0.4235, -0.2847,  0.2478, -0.5152,\n",
      "         0.0225,  0.0341]) tensor([ 0.5034, -0.6287,  0.9252,  0.6969, -0.3880, -0.3111,  0.2921, -0.4478,\n",
      "        -0.0049,  0.3421])\n",
      "R[0]\n",
      "tensor([0.0170], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05301856838166714 0.004711399413212348 0.0014391588015109846 0.005957912759389728 0.034368296567350624 0.4179715077877045 0.007257572881877422 42.587739700317385\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1925, -0.5398,  0.6487,  0.5694, -0.2606, -0.1562,  0.5263, -0.6597,\n",
      "        -0.3751,  0.0945]) tensor([-0.1385, -0.5699,  0.7377,  0.6506, -0.3536, -0.1420,  0.4356, -0.7302,\n",
      "        -0.0164, -0.0786]) tensor([ 0.2240, -0.6011,  0.8323,  0.9839, -0.4840,  0.1037,  0.0615, -0.8587,\n",
      "         0.0191, -0.1079])\n",
      "R[0]\n",
      "tensor([0.0108], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05260455776751041 0.004794121081558842 0.0015593333721853923 0.006202912973123602 0.03399528119340539 0.4112965224981308 0.00745540920086205 42.517683319091795\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1659, -0.7356,  1.0548,  0.9261, -0.8020, -0.1340,  0.3703, -1.3149,\n",
      "         0.0597, -0.6451]) tensor([ 0.0106, -0.7333,  1.0512,  0.8904, -0.7739, -0.1538,  0.3887, -1.2636,\n",
      "         0.1291,  0.0437]) tensor([-0.2590, -0.7345,  1.0648,  0.8684, -0.7720, -0.0992,  0.3571, -1.3502,\n",
      "        -0.2018,  0.6793])\n",
      "R[0]\n",
      "tensor([0.0018], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05275128837674856 0.00445880954425229 0.0014379746339950542 0.005878670947160572 0.03408634587749839 0.4122918338179588 0.007329432226717472 42.47680072021485\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2498, -0.6143,  1.0390,  0.9422, -0.5414, -0.2067,  0.1281, -0.5527,\n",
      "         0.0810, -0.2467]) tensor([-0.1043, -0.6245,  1.0797,  0.9687, -0.5321, -0.1780,  0.1254, -0.5720,\n",
      "         0.1213,  0.0494]) tensor([ 0.1347, -0.6120,  0.9618,  0.9626, -0.5773, -0.2130,  0.1867, -0.6114,\n",
      "         0.1130, -0.1063])\n",
      "R[0]\n",
      "tensor([-0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05258197785168886 0.004558469207737289 0.0014849967105374162 0.005736185300396756 0.034140295781195165 0.41676500445604325 0.007337576325517148 42.56438005065918\n",
      "Average (on the epoch) training loss: 0.005971639634959865\n",
      "Episode average V value: 0\n",
      "epoch 42:\n",
      "Learning rate: 1.3302794647291146e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 132.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 131.98680131986802 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5474, -0.7715,  1.3367,  1.1043, -0.6340,  0.0504, -0.2367, -0.7697,\n",
      "         0.2643, -0.8406]) tensor([-0.1035, -0.7726,  1.3022,  1.0403, -0.5774,  0.0508, -0.2067, -0.7477,\n",
      "         0.2868,  0.0792]) tensor([-0.1993, -0.7061,  1.1618,  1.0850, -0.6351, -0.0606, -0.0750, -0.6981,\n",
      "        -0.1087, -0.0158])\n",
      "R[0]\n",
      "tensor([-0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053125540636479854 0.004190984825068881 0.0013398867484602306 0.0055831608483567835 0.03414855994842946 0.41381361919641496 0.007429423925932497 42.56330660247803\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2481, -0.6813,  1.0553,  0.9011, -0.8056, -0.2377,  0.4724, -1.1876,\n",
      "         0.0703, -0.3176]) tensor([-0.0145, -0.6631,  1.0709,  0.9064, -0.7730, -0.2127,  0.4486, -1.1519,\n",
      "         0.1121,  0.0287]) tensor([ 0.3432, -0.7034,  0.9979,  0.8641, -0.7756, -0.2230,  0.5285, -1.2347,\n",
      "        -1.3533, -0.5446])\n",
      "R[0]\n",
      "tensor([-0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052568435899913314 0.004487643342059528 0.001821643515885171 0.0061841140082106 0.034296180119737986 0.41268235665559766 0.007537026517093181 42.48892578887939\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0024, -0.5439,  0.9101,  0.8444, -0.6867, -0.2421,  0.6444, -1.0992,\n",
      "        -0.0443,  0.5362]) tensor([-0.0014, -0.5432,  0.9038,  0.8482, -0.7207, -0.2385,  0.6036, -1.1272,\n",
      "         0.0080, -0.0875]) tensor([-0.5774, -0.6767,  1.0871,  0.8620, -0.7565, -0.1878,  0.5075, -1.2590,\n",
      "        -0.0830,  0.3326])\n",
      "R[0]\n",
      "tensor([-0.0029], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05272934067249298 0.004460827798387981 0.001683229054268395 0.005984592834720388 0.034373805912211536 0.41132944464683535 0.007198474071454256 42.43611747741699\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6212, -0.5526,  1.0025,  0.8969, -0.7545, -0.3618,  0.6388, -1.0140,\n",
      "        -0.0549,  0.6467]) tensor([ 0.0051, -0.5586,  0.9982,  0.8963, -0.7776, -0.3496,  0.5890, -1.0526,\n",
      "        -0.0110, -0.0345]) tensor([-0.4747, -0.5314,  1.0046,  0.9156, -0.7668, -0.3671,  0.6218, -1.0020,\n",
      "        -0.6172,  0.3448])\n",
      "R[0]\n",
      "tensor([-0.0077], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05307756020128727 0.004870163184077683 0.0016851582908520867 0.006001807139022276 0.034076203607022765 0.40917441973090174 0.007227479931898415 42.56344549560547\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5516, -0.6820,  1.1002,  0.8839, -0.7590, -0.1824,  0.5034, -1.2628,\n",
      "        -0.0239, -0.5560]) tensor([ 0.0342, -0.6588,  1.0658,  0.8757, -0.7672, -0.1890,  0.4966, -1.2453,\n",
      "         0.1147,  0.0173]) tensor([ 0.1079, -0.7686,  1.1566,  0.9280, -0.8258, -0.1443,  0.3782, -1.3379,\n",
      "         0.5910,  0.4440])\n",
      "R[0]\n",
      "tensor([0.0046], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05264546194672585 0.004583273472484507 0.0015512982558798286 0.005975791378878057 0.03399155358970165 0.4108699262738228 0.007647645458113402 42.491577796936035\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2081, -1.4190,  1.3362, -0.1773,  0.1000, -0.0910,  0.3468, -1.1100,\n",
      "         0.4007,  0.7050]) tensor([-0.2265, -1.3207,  1.0456, -0.2842,  0.1263, -0.0075,  0.2393, -1.2111,\n",
      "         0.2966,  0.2262]) tensor([-0.2306, -1.4770,  1.4045, -0.0776,  0.0450, -0.0034,  0.2582, -1.1854,\n",
      "         0.8138,  0.3428])\n",
      "R[0]\n",
      "tensor([-0.0085], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052914068847894666 0.004452702991720799 0.0012413576227800148 0.005914060972398147 0.03421046153455973 0.4131101567745209 0.007480382854118943 42.551369087219236\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1996, -0.8887,  1.0539,  0.4211, -0.2169, -0.2555,  0.2934, -0.5996,\n",
      "        -0.0617,  0.4045]) tensor([-0.1876, -0.8825,  0.9865,  0.3841, -0.2097, -0.2102,  0.2479, -0.6758,\n",
      "         0.0978,  0.0682]) tensor([-0.1361, -0.9631,  1.0011,  0.2134, -0.0587, -0.2385,  0.3715, -0.6222,\n",
      "         0.3711,  0.1096])\n",
      "R[0]\n",
      "tensor([0.0025], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052951139099895954 0.004559220976551842 0.0017494609430495985 0.006072789724334143 0.03446624537184834 0.40901153221726416 0.007412370896432549 42.46539698791504\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2448, -0.5431,  0.9292,  0.7977, -0.4510, -0.3020,  0.2575, -0.4383,\n",
      "         0.4738, -0.3730]) tensor([-0.1239, -0.5924,  0.9764,  0.8045, -0.4740, -0.2943,  0.2551, -0.5082,\n",
      "        -0.0059,  0.0120]) tensor([-0.2429, -0.5508,  0.9412,  0.8297, -0.4681, -0.2982,  0.2519, -0.4355,\n",
      "         0.2865,  0.3375])\n",
      "R[0]\n",
      "tensor([0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053006372705101966 0.0046321424726138505 0.0012402244188092482 0.005833759244880639 0.03418761256709695 0.4141253371834755 0.007583205605391413 42.5113341217041\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3789, -0.7177,  1.1307,  1.1535, -0.6021,  0.0817, -0.2565, -0.7207,\n",
      "        -0.0934, -0.0501]) tensor([-0.0849, -0.7199,  1.1254,  1.1067, -0.5343,  0.0930, -0.2447, -0.6878,\n",
      "         0.2326,  0.0979]) tensor([ 0.4331, -0.5944,  1.3755,  1.1729, -0.5938,  0.1886, -0.4569, -0.7942,\n",
      "         0.7690, -0.0935])\n",
      "R[0]\n",
      "tensor([-0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05277928037196398 0.00432266607735437 0.0016050583073488269 0.005668906843755394 0.03464068729802966 0.4139388945400715 0.007541416537947953 42.49765190887451\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1066, -0.6018,  1.1197,  1.0220, -0.7577, -0.2069,  0.1236, -0.8061,\n",
      "        -0.0634,  0.0133]) tensor([-0.0432, -0.5964,  1.1183,  1.0101, -0.7103, -0.1804,  0.1267, -0.7965,\n",
      "         0.1361,  0.0171]) tensor([ 0.1398, -0.5714,  1.1938,  1.0636, -0.7002, -0.1792,  0.0703, -0.7082,\n",
      "         0.0343,  0.4222])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05269582250714302 0.004530888456411048 0.0018027046712559241 0.006090058088069781 0.033720877289772036 0.41174408438801763 0.0075745969554409385 42.4858384399414\n",
      "Average (on the epoch) training loss: 0.005930904108262621\n",
      "Episode average V value: 0\n",
      "epoch 43:\n",
      "Learning rate: 1.1972515182562032e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 135.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 134.98650134986502 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2058, -0.4600,  1.0707,  1.2337, -0.4607, -0.0076, -0.0490, -0.4502,\n",
      "        -0.1251, -0.7685]) tensor([-9.0623e-02, -4.8363e-01,  1.0569e+00,  1.1847e+00, -4.4161e-01,\n",
      "         9.0895e-04, -4.4079e-02, -4.8487e-01,  1.0658e-01,  3.5771e-02]) tensor([-0.9437, -0.4449,  1.0445,  1.2210, -0.4753, -0.0456, -0.0061, -0.4425,\n",
      "         0.5619, -0.4102])\n",
      "R[0]\n",
      "tensor([-0.0018], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05323827987164259 0.004489199343512155 0.001642631443467053 0.0059961037589237095 0.034006964832544326 0.4129493629336357 0.0073108244179748 42.51241926574707\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4561, -0.7560,  1.1876,  0.9939, -0.9061, -0.2113,  0.3141, -1.2411,\n",
      "        -0.4243,  0.6702]) tensor([-0.0243, -0.7359,  1.1845,  0.9677, -0.8519, -0.2085,  0.3028, -1.1726,\n",
      "         0.1352,  0.0718]) tensor([-0.6652, -0.8183,  1.1659,  0.9859, -0.8980, -0.1499,  0.3007, -1.3295,\n",
      "         1.1889,  0.0526])\n",
      "R[0]\n",
      "tensor([0.0016], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05268808636814356 0.004141468827972858 0.0015513494638994417 0.005565913539147004 0.034188036609441044 0.40931607863307 0.007387380509171635 42.50976333618164\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6534, -0.4359,  0.8189,  1.2046, -0.3289,  0.0944, -0.0100, -0.4302,\n",
      "         0.4094, -0.3815]) tensor([-0.1137, -0.4735,  0.8225,  1.1264, -0.3134,  0.0957, -0.0257, -0.4577,\n",
      "         0.0538,  0.0201]) tensor([ 0.2748, -0.4134,  0.8287,  1.2268, -0.3302,  0.0779, -0.0144, -0.3933,\n",
      "        -0.6560,  0.2000])\n",
      "R[0]\n",
      "tensor([-0.0029], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05265335962921381 0.004010655268753908 0.002222161725112528 0.006093199049588293 0.033823348999023437 0.4165681780576706 0.0074131476276088504 42.49749642944336\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2733, -0.7952,  1.1963,  0.9341, -0.8634, -0.1563,  0.1697, -1.1836,\n",
      "         0.7083, -0.0642]) tensor([-0.0175, -0.7682,  1.1795,  0.9119, -0.7912, -0.1391,  0.1671, -1.1200,\n",
      "         0.1812,  0.0423]) tensor([-0.3858, -0.9147,  1.3925,  1.0394, -0.9631, -0.0612,  0.0250, -1.3470,\n",
      "        -0.2313,  0.6372])\n",
      "R[0]\n",
      "tensor([0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05275247683376074 0.004090255914705267 0.0016253193023731002 0.005791928478982299 0.03409304622933269 0.4143894677758217 0.007481199011672288 42.5552314453125\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0599, -0.6821,  0.8031,  0.4677, -0.1052, -0.1297,  0.3772, -0.4879,\n",
      "        -0.1397,  0.1262]) tensor([-0.2366, -0.6929,  0.8524,  0.5539, -0.1984, -0.1185,  0.3179, -0.5580,\n",
      "         0.0484, -0.0039]) tensor([-0.2938, -0.5379,  0.7752,  0.9137, -0.2315,  0.1436,  0.0989, -0.5284,\n",
      "         0.0074, -0.2134])\n",
      "R[0]\n",
      "tensor([0.0115], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0527829821407795 0.0041205126298191315 0.0016490764986929207 0.005617520890198648 0.0341925331428647 0.4134950203299522 0.007288776533212513 42.4762875289917\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4291, -0.7165,  0.9569,  1.2095, -0.5066,  0.2570, -0.2964, -0.7181,\n",
      "         0.0482,  0.5496]) tensor([-0.1084, -0.7333,  0.9650,  1.1421, -0.4374,  0.2626, -0.3072, -0.6843,\n",
      "         0.1857,  0.0635]) tensor([-0.4713, -0.6503,  0.8969,  1.2174, -0.4331,  0.2833, -0.2899, -0.6344,\n",
      "         0.2921,  0.7922])\n",
      "R[0]\n",
      "tensor([0.0023], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052876997128129 0.0041834575579432565 0.0013525436856593842 0.005565121293184348 0.0340912907384336 0.4157142984867096 0.0075636275280267 42.513087989807126\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.7707, -0.5498,  1.0213,  0.8996, -0.7525, -0.3597,  0.6360, -1.0237,\n",
      "         0.1759,  0.6443]) tensor([ 0.0212, -0.5576,  1.0236,  0.8914, -0.7725, -0.3481,  0.5814, -1.0544,\n",
      "         0.0101, -0.0060]) tensor([ 0.0084, -0.5609,  1.0174,  0.8968, -0.7120, -0.3136,  0.6347, -1.0323,\n",
      "        -0.4887, -0.0865])\n",
      "R[0]\n",
      "tensor([-0.0119], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05282485876232386 0.004362743132509422 0.0011250122759488476 0.005691501048160717 0.03398709403537214 0.4178532607555389 0.0073422376196831465 42.507481475830076\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2030, -0.5873,  0.9555,  0.7284, -0.4195, -0.3043,  0.2648, -0.4388,\n",
      "        -0.5833,  0.0749]) tensor([-0.1359, -0.6255,  0.9768,  0.7255, -0.4435, -0.2892,  0.2570, -0.5177,\n",
      "         0.0513,  0.0226]) tensor([-0.9124, -0.5696,  0.9500,  0.7872, -0.4299, -0.3043,  0.2485, -0.4297,\n",
      "         0.2052,  0.8254])\n",
      "R[0]\n",
      "tensor([0.0044], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0529279628098011 0.004782245636750304 0.0016766812588198264 0.005899558586301282 0.03469707025587559 0.4162376794219017 0.007308440902736038 42.53000699615478\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0803, -0.5369,  1.0059,  0.9412, -0.7871, -0.3858,  0.6145, -0.9920,\n",
      "         0.0963, -0.1961]) tensor([-0.0127, -0.5488,  1.0197,  0.9291, -0.7961, -0.3885,  0.6092, -0.9992,\n",
      "         0.0166, -0.0246]) tensor([-0.5400, -0.5240,  1.0048,  0.9215, -0.7867, -0.3855,  0.6266, -0.9789,\n",
      "         0.1114, -0.5762])\n",
      "R[0]\n",
      "tensor([0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0531408990174532 0.0048109829811983215 0.0018744985353118864 0.005738321621669457 0.03463108459860086 0.4165349752306938 0.007318108691368252 42.505539916992184\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0727, -0.8443,  1.0340,  0.4476, -0.1076,  0.0489,  0.1401, -0.6565,\n",
      "         0.0640,  0.1788]) tensor([-0.2253, -0.8263,  1.0057,  0.5055, -0.1753,  0.0343,  0.1495, -0.6927,\n",
      "         0.2053,  0.0786]) tensor([ 0.1762, -0.7631,  1.1447,  0.9988, -0.3072,  0.3238, -0.0870, -0.8255,\n",
      "         0.2379,  0.4944])\n",
      "R[0]\n",
      "tensor([-0.0033], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05313867676258087 0.004602108745339137 0.0016463001501929285 0.005978458016179502 0.03413350024446845 0.4137031511068344 0.007567323733586818 42.42761253356934\n",
      "Average (on the epoch) training loss: 0.005793762628233526\n",
      "Episode average V value: 0\n",
      "epoch 44:\n",
      "Learning rate: 1.0775263664305828e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 135.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 134.98650134986502 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0604,  0.0899,  0.7700,  1.1369, -0.2872,  0.5623, -0.6406, -0.8865,\n",
      "         0.0935,  0.4265]) tensor([ 0.0108, -0.0225,  0.8153,  1.0911, -0.3415,  0.3996, -0.4457, -0.8932,\n",
      "        -0.0150, -0.0112]) tensor([ 0.4560, -0.2760,  0.9309,  1.0561, -0.2376,  1.0297, -0.8842, -1.4423,\n",
      "         0.6849, -0.3974])\n",
      "R[0]\n",
      "tensor([0.1208], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05278044382482767 0.004466256522424374 0.0015483521135774936 0.00606248141406104 0.03401126246154308 0.41625371962785723 0.007211745561566204 42.5304190826416\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2131, -0.7507,  1.0600,  0.9411, -0.8479, -0.1666,  0.3612, -1.2803,\n",
      "         0.7187,  0.2583]) tensor([ 0.0110, -0.7362,  1.0804,  0.9270, -0.7958, -0.1390,  0.3362, -1.2325,\n",
      "         0.1348,  0.0389]) tensor([-0.1950, -0.7115,  0.8581,  0.8128, -0.7111, -0.1638,  0.5621, -1.3112,\n",
      "         0.8266, -0.2082])\n",
      "R[0]\n",
      "tensor([0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052985758297145365 0.004421930868882555 0.0014859945111684284 0.006242121542571113 0.03366089860536158 0.4139373333156109 0.0072492584823630754 42.38143796539307\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1092, -0.6254,  1.1712,  0.9806, -0.8576, -0.2968,  0.3722, -1.0490,\n",
      "         0.4831,  0.1069]) tensor([ 0.0059, -0.6115,  1.1788,  0.9899, -0.8303, -0.2672,  0.3632, -1.0383,\n",
      "         0.1216,  0.0176]) tensor([-0.2671, -0.6463,  1.0300,  0.9668, -0.8396, -0.2699,  0.4237, -1.0899,\n",
      "        -0.0355,  0.0811])\n",
      "R[0]\n",
      "tensor([-0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05287329732626676 0.004780866096496538 0.0016916355785501764 0.00597781903273426 0.03410738336667418 0.4168913857936859 0.007367091838736087 42.47297434234619\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0976, -1.0077,  0.8496, -0.1074,  0.1369,  0.0492,  0.1362, -0.7742,\n",
      "        -0.1859,  0.5155]) tensor([-0.3032, -0.9859,  0.8791, -0.0549,  0.1469,  0.0703,  0.1046, -0.7454,\n",
      "         0.1621,  0.0991]) tensor([-0.3271, -0.8972,  0.7930,  0.0055,  0.0470,  0.0663,  0.0952, -0.8586,\n",
      "         0.3919, -0.0577])\n",
      "R[0]\n",
      "tensor([0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05277367345243692 0.004312774494530458 0.0018164917305871313 0.005925252770190128 0.03462820272520185 0.4195381143689156 0.007254863855894655 42.51507801055908\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7360, -0.5960,  0.9571,  0.7469, -0.4131, -0.2996,  0.2690, -0.4475,\n",
      "        -0.2666,  0.5541]) tensor([-0.1227, -0.6176,  0.9861,  0.7782, -0.4474, -0.2911,  0.2437, -0.5010,\n",
      "         0.0200, -0.0014]) tensor([-1.0346, -0.5791,  0.9480,  0.7827, -0.4264, -0.2967,  0.2665, -0.4226,\n",
      "        -0.7114, -0.4272])\n",
      "R[0]\n",
      "tensor([0.0143], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052610576160252095 0.004408753189984964 0.0014474117346453567 0.005879241549642757 0.03396691419184208 0.4144743999838829 0.007588201688136905 42.445958717346194\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0299, -0.7002,  1.0361,  0.8962, -0.8072, -0.1707,  0.4455, -1.3134,\n",
      "         0.6812, -0.3751]) tensor([ 0.0272, -0.6841,  1.0136,  0.8923, -0.8046, -0.1870,  0.4418, -1.2825,\n",
      "         0.0807, -0.0026]) tensor([-0.0334, -0.6703,  0.9926,  0.9647, -0.8203, -0.2712,  0.5219, -1.1875,\n",
      "        -0.1299, -0.1621])\n",
      "R[0]\n",
      "tensor([-0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05254269839823246 0.00432108430036169 0.0016273999723216547 0.005776854123920202 0.03425332988426089 0.4198784686923027 0.0070461673475801945 42.46815153503418\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3485, -1.0682,  1.1928,  0.0453,  0.1839, -0.0503,  0.0493, -0.5296,\n",
      "         0.5503,  0.1128]) tensor([-0.2595, -1.0378,  0.9912, -0.0480,  0.1948,  0.0235, -0.0293, -0.6817,\n",
      "         0.1687,  0.1654]) tensor([-4.6239e-01, -1.0620e+00,  1.0836e+00,  1.3909e-01, -1.9121e-04,\n",
      "        -8.2585e-02,  3.0793e-02, -6.2570e-01, -5.9991e-02,  4.2889e-01])\n",
      "R[0]\n",
      "tensor([0.0297], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05318164195120335 0.004562963973614388 0.0015478880851669602 0.006025961873820052 0.03385945850610733 0.41242884504795074 0.007308519089594483 42.398552711486815\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1347, -0.7465,  1.1205,  0.9829, -0.8068, -0.1354,  0.1012, -1.0235,\n",
      "        -0.7632,  0.1865]) tensor([-0.0145, -0.7482,  1.0895,  0.9538, -0.7793, -0.1441,  0.1483, -1.0204,\n",
      "         0.1182,  0.0610]) tensor([-0.6631, -0.7504,  1.0604,  0.9846, -0.8402, -0.1912,  0.1755, -1.0279,\n",
      "         0.2540, -0.3294])\n",
      "R[0]\n",
      "tensor([0.0031], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05321903756260872 0.004591878750684373 0.0013414660595308305 0.005784976781345904 0.03419983525946736 0.41674184444546697 0.007497083032038063 42.43504881286621\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7699, -0.6400,  1.1921,  1.0459, -0.6931, -0.1432,  0.0415, -0.7560,\n",
      "         0.4541,  0.4745]) tensor([-0.0698, -0.6500,  1.1657,  1.0243, -0.6760, -0.1451,  0.0818, -0.7794,\n",
      "         0.1481,  0.0405]) tensor([ 0.4139, -0.6710,  1.0957,  1.0207, -0.7248, -0.1751,  0.1019, -0.8280,\n",
      "        -0.4939,  0.3426])\n",
      "R[0]\n",
      "tensor([0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05316021558642387 0.004890955880018737 0.0016125630485348665 0.0060060630943626165 0.034131224803626535 0.4202138686776161 0.007311289524659514 42.48560076141357\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4054, -0.4695,  1.0324,  1.0716, -0.5826, -0.2328,  0.1765, -0.5057,\n",
      "         0.0392,  0.2661]) tensor([-0.0690, -0.5080,  1.0516,  1.0528, -0.5978, -0.2436,  0.2036, -0.5499,\n",
      "         0.0585, -0.0172]) tensor([-0.2072, -0.4917,  1.0169,  1.0517, -0.5850, -0.2435,  0.1809, -0.5095,\n",
      "         0.1120,  0.0487])\n",
      "R[0]\n",
      "tensor([-0.0028], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0530119718760252 0.004250088300987045 0.001496046484405724 0.005836382699781098 0.03423028296977282 0.41642667442560194 0.007398222817108035 42.45088576507568\n",
      "Average (on the epoch) training loss: 0.005951715488242916\n",
      "Episode average V value: 0\n",
      "epoch 45:\n",
      "Learning rate: 9.697737297875246e-07\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 133.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 132.986701329867 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1918, -0.5682,  0.7998,  0.8387, -0.7002, -0.1556,  0.4772, -1.2153,\n",
      "         0.1411,  0.1953]) tensor([ 0.0093, -0.5734,  0.8609,  0.8380, -0.6714, -0.1320,  0.4306, -1.1801,\n",
      "         0.0032, -0.0332]) tensor([ 0.5638, -0.6748,  1.0391,  0.9677, -0.8260, -0.1699,  0.3271, -1.2234,\n",
      "        -0.0773,  0.7164])\n",
      "R[0]\n",
      "tensor([-0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053347492776811126 0.00472445832457197 0.0017119886771433813 0.006163692146190442 0.03420457236096263 0.4212376393675804 0.007421267750207335 42.43948818206787\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4648, -0.8179,  1.3986,  1.0651, -0.7479,  0.0755, -0.2215, -1.0297,\n",
      "         0.0055, -0.1972]) tensor([-0.0274, -0.7956,  1.3029,  1.0117, -0.7022,  0.0489, -0.1248, -1.0019,\n",
      "         0.2989,  0.1371]) tensor([-0.0895, -0.9119,  1.2306,  0.9871, -0.7970,  0.0256, -0.1222, -1.1193,\n",
      "         0.6780,  0.5261])\n",
      "R[0]\n",
      "tensor([0.0083], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05291751451790333 0.004503536897008416 0.0022090247883807023 0.006023017666302621 0.03401222654804587 0.42114734756946565 0.007386186464224011 42.510047149658206\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5400, -0.5318,  0.9895,  0.8983, -0.7433, -0.3715,  0.6561, -1.0001,\n",
      "        -0.5016, -0.1484]) tensor([ 0.0130, -0.5271,  1.0212,  0.9150, -0.7449, -0.3480,  0.6283, -0.9963,\n",
      "         0.0128, -0.0250]) tensor([-0.4386, -0.5240,  0.9827,  0.9167, -0.7670, -0.3766,  0.6506, -1.0068,\n",
      "         0.3529, -0.2209])\n",
      "R[0]\n",
      "tensor([-5.7638e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05302914391458034 0.00494453806610909 0.0014210633304610383 0.005862104401108808 0.034036690793931484 0.4262105734348297 0.007237153761088848 42.54228493499756\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5094, -0.9714,  1.3819,  0.3214,  0.3692,  0.7100, -0.9040, -0.8039,\n",
      "         0.2993,  0.4269]) tensor([-0.2754, -0.9508,  1.2929,  0.2979,  0.3813,  0.6617, -0.8177, -0.7792,\n",
      "         0.4700,  0.3177]) tensor([-0.1741, -0.9617,  1.3855,  0.3561,  0.3977,  0.7630, -0.9517, -0.8172,\n",
      "         0.9187,  0.3206])\n",
      "R[0]\n",
      "tensor([0.0247], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05263067851960659 0.0043594941427345475 0.001642173969423311 0.00588307479931973 0.03416411398723722 0.42387616050243376 0.0072720007072202865 42.47092640686035\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1043, -0.5405,  0.9520,  0.8624, -0.4697, -0.2897,  0.2141, -0.4293,\n",
      "        -0.1825, -0.0746]) tensor([-0.1213, -0.5806,  0.9847,  0.8636, -0.4914, -0.2827,  0.2221, -0.4934,\n",
      "         0.0437,  0.0266]) tensor([-0.7592, -0.5394,  0.9596,  0.8774, -0.4793, -0.2825,  0.2212, -0.4226,\n",
      "         0.0740, -0.4250])\n",
      "R[0]\n",
      "tensor([0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052619716234505176 0.004531824363248234 0.0019278202523282744 0.00579577341733966 0.034236954517662524 0.4186224039196968 0.007639925399329514 42.41798928070068\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6452, -0.9180,  0.8989,  0.1751, -0.0454, -0.1378,  0.2818, -0.5952,\n",
      "         0.0962,  0.4312]) tensor([-0.2235, -0.9029,  0.9464,  0.2967, -0.1154, -0.1262,  0.2477, -0.6224,\n",
      "         0.0996,  0.0458]) tensor([ 0.1746, -0.7862,  0.9387,  0.4846, -0.1589, -0.0260,  0.1950, -0.5817,\n",
      "         0.4887,  1.0114])\n",
      "R[0]\n",
      "tensor([0.0046], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052769100554287435 0.004201993002758172 0.0015286659307394074 0.005804616196081042 0.03428821764886379 0.42502054923772814 0.007342504682485014 42.52490696716308\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6303, -0.8706,  1.0561,  0.5206, -0.3223, -0.2373,  0.1978, -0.6395,\n",
      "         0.3888,  0.2607]) tensor([-0.1732, -0.8474,  1.0677,  0.5486, -0.2911, -0.2053,  0.1848, -0.6162,\n",
      "         0.1349,  0.0900]) tensor([ 0.1162, -1.0143,  1.1328,  0.3077, -0.1891, -0.2304,  0.1882, -0.6520,\n",
      "         0.3994,  0.3355])\n",
      "R[0]\n",
      "tensor([-0.0004], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052961437925696374 0.004351240265053093 0.0016544562372500877 0.00610609514429234 0.0341832080334425 0.4187849286198616 0.00747940459381789 42.39932638549805\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5030, -0.6965,  1.2154,  1.0498, -0.6014, -0.0569, -0.0772, -0.6806,\n",
      "         0.2920,  0.3286]) tensor([-0.0524, -0.6903,  1.1583,  1.0362, -0.6008, -0.0657, -0.0369, -0.7063,\n",
      "         0.1854,  0.0586]) tensor([-0.1770, -0.7614,  1.2856,  1.1152, -0.6345,  0.0247, -0.1900, -0.7462,\n",
      "         0.8125,  0.4285])\n",
      "R[0]\n",
      "tensor([0.0061], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05299394427984953 0.004867526146481396 0.0016748128691506281 0.005881463072029873 0.033871407713741065 0.42375624579191207 0.007210405343677849 42.409404258728024\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4784, -0.6674,  0.9304,  0.7814, -0.1342,  0.1634,  0.0137, -0.5155,\n",
      "         0.0664, -0.3392]) tensor([-0.1778, -0.6752,  0.9181,  0.7590, -0.1370,  0.1649,  0.0150, -0.5354,\n",
      "         0.1689,  0.0741]) tensor([-0.2691, -0.6243,  0.9154,  0.9297, -0.1511,  0.2866, -0.1185, -0.5072,\n",
      "        -0.2800,  0.3235])\n",
      "R[0]\n",
      "tensor([-0.0009], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053002201445400715 0.00474823491879215 0.001507419705987104 0.00594352493819315 0.03404623506218195 0.4189257172942162 0.00726664203312248 42.422629112243655\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0897, -1.1453,  1.0525,  0.0626, -0.0530, -0.0685,  0.1405, -0.7721,\n",
      "        -0.2293,  0.8371]) tensor([-0.3096, -1.1186,  1.0791,  0.1566, -0.0818, -0.0819,  0.1273, -0.7375,\n",
      "         0.1531,  0.1925]) tensor([-0.0486, -0.9996,  0.9765,  0.2246, -0.1669, -0.1303,  0.2702, -0.7710,\n",
      "        -0.1314, -0.2652])\n",
      "R[0]\n",
      "tensor([-0.0070], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052838379979133605 0.004927964616314057 0.0017592601458554782 0.006071966709336266 0.03402110183238983 0.42072403320670126 0.007503594667417929 42.390574569702146\n",
      "Average (on the epoch) training loss: 0.005953532849019393\n",
      "Episode average V value: 0\n",
      "epoch 46:\n",
      "Learning rate: 8.727963568087721e-07\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 125.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 124.98750124987501 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4723, -0.5035,  0.9398,  0.8901, -0.7240, -0.3360,  0.6487, -0.9730,\n",
      "        -0.0924, -0.2300]) tensor([-0.0356, -0.5269,  0.9663,  0.8832, -0.7525, -0.3441,  0.6370, -0.9961,\n",
      "         0.0223, -0.0351]) tensor([-0.3312, -0.5282,  0.9636,  0.8885, -0.7314, -0.3528,  0.6677, -1.0030,\n",
      "        -0.1547, -0.0635])\n",
      "R[0]\n",
      "tensor([-0.0026], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05285697884857655 0.004124284572124452 0.0018193283318769318 0.005732052551116794 0.03368167556449771 0.4271892120242119 0.007377067970111966 42.45393675994873\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0159, -0.4872,  0.9205,  0.8467, -0.6918, -0.3246,  0.6837, -0.9819,\n",
      "        -0.5758, -0.2511]) tensor([-0.0210, -0.5110,  0.9537,  0.8443, -0.7299, -0.3294,  0.6566, -1.0100,\n",
      "         0.0475, -0.0456]) tensor([-0.6067, -0.4824,  0.9315,  0.8906, -0.7309, -0.3505,  0.6392, -0.9519,\n",
      "         0.6172,  0.0079])\n",
      "R[0]\n",
      "tensor([-0.0019], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05287097208201885 0.0046658641506455755 0.001891550469964386 0.005768167251953855 0.03419753707945347 0.4197344174385071 0.007385577528737485 42.403121543884275\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 1.0742, -0.6501,  0.9709,  0.8588, -0.6996, -0.2758,  0.6056, -1.0979,\n",
      "         0.1883, -0.4206]) tensor([ 0.0396, -0.6727,  0.9981,  0.8321, -0.7024, -0.2852,  0.5886, -1.0947,\n",
      "         0.0752, -0.0402]) tensor([-0.6497, -0.6474,  0.9904,  0.8629, -0.7050, -0.2844,  0.6110, -1.1049,\n",
      "        -0.1086, -0.1276])\n",
      "R[0]\n",
      "tensor([-0.0044], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053178554259240625 0.004251996451916057 0.0015782663979966856 0.005765196501743048 0.03418046580255032 0.42138824582099915 0.007545671429019421 42.37339150238037\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2762, -0.6008,  1.3279,  1.3854, -0.5251,  0.2938, -0.4903, -0.6320,\n",
      "         0.4008,  0.2440]) tensor([-0.1005, -0.6246,  1.2558,  1.2967, -0.5141,  0.2295, -0.3792, -0.6334,\n",
      "         0.3039,  0.1181]) tensor([ 0.0291, -0.7289,  1.0855,  1.0497, -0.6982, -0.0262, -0.0557, -0.8523,\n",
      "        -0.2786,  0.1027])\n",
      "R[0]\n",
      "tensor([0.0026], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052423748783767224 0.004060306456287435 0.0015139484972751234 0.005612213591579348 0.03383260214701295 0.42348269909620284 0.007629891175543889 42.44264640808105\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2419, -0.6006,  0.9686,  0.7895, -0.4371, -0.2662,  0.1799, -0.4469,\n",
      "         0.1469,  0.0902]) tensor([-0.1422, -0.6388,  0.9929,  0.7876, -0.4533, -0.2573,  0.1870, -0.5125,\n",
      "         0.0382,  0.0312]) tensor([ 0.3557, -0.5983,  0.9505,  0.7545, -0.4270, -0.2887,  0.2243, -0.4218,\n",
      "        -0.4816,  0.1883])\n",
      "R[0]\n",
      "tensor([-0.0010], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05257780864834785 0.004731456983010503 0.0016028226693479155 0.005824644390726462 0.03384848218411207 0.4173086766600609 0.007698914322536439 42.381763786315915\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2381, -0.5665,  0.9023,  0.8301, -0.1999,  0.0562,  0.1567, -0.4883,\n",
      "         0.4628,  0.1314]) tensor([-0.1571, -0.5742,  0.8942,  0.8169, -0.2145,  0.0655,  0.1472, -0.5230,\n",
      "         0.0986,  0.0313]) tensor([-0.0581, -0.5810,  0.8654,  0.7660, -0.1847,  0.0199,  0.2315, -0.4936,\n",
      "        -0.2988, -0.5575])\n",
      "R[0]\n",
      "tensor([-3.5301e-05], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05313152018934488 0.00426946070257327 0.0016457443639014855 0.00562471006414853 0.03347153231501579 0.42623381727933884 0.007281841300893575 42.401186889648436\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3770, -1.0010,  0.9483,  0.2386, -0.1572, -0.0140,  0.1588, -0.8546,\n",
      "         0.4664,  0.4061]) tensor([-0.2065, -0.9695,  0.9632,  0.2761, -0.1291,  0.0082,  0.1459, -0.8082,\n",
      "         0.1783,  0.0911]) tensor([-0.2585, -0.9632,  0.9337,  0.1421, -0.0307,  0.1084, -0.0019, -0.8478,\n",
      "         0.2247,  0.2449])\n",
      "R[0]\n",
      "tensor([0.0007], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05267060685157776 0.004545670759483983 0.0014181928057810183 0.005595124646555633 0.034263482414186 0.4208644853234291 0.007400678753387183 42.34958055114746\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5810, -0.8358,  1.2536,  0.9841, -0.8808, -0.1341,  0.3069, -1.3528,\n",
      "         0.4308, -0.0335]) tensor([-0.0094, -0.7920,  1.2093,  0.9447, -0.8133, -0.1232,  0.2964, -1.2725,\n",
      "         0.2255,  0.0619]) tensor([ 2.9892e-01, -7.7195e-01,  1.5707e+00,  1.1134e+00, -8.2994e-01,\n",
      "         1.0542e-03, -1.8126e-01, -1.0572e+00,  2.1280e-02,  1.9917e-01])\n",
      "R[0]\n",
      "tensor([0.0005], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05304662176221609 0.004218355731820339 0.00151424540745802 0.005649862993275747 0.0338950157687068 0.42189386731386186 0.007200654675252736 42.26839836120605\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5752, -0.5428,  1.1588,  1.1821, -0.4027,  0.0585, -0.1061, -0.4544,\n",
      "        -0.0488,  0.7654]) tensor([-0.1385, -0.5582,  1.1307,  1.1365, -0.3989,  0.0512, -0.0900, -0.4822,\n",
      "         0.1963,  0.1124]) tensor([ 0.2260, -0.6380,  1.3681,  1.2929, -0.4605,  0.2353, -0.3438, -0.6292,\n",
      "         0.1954, -0.1748])\n",
      "R[0]\n",
      "tensor([0.0024], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05296820024400949 0.004264837058668491 0.0015385425381959977 0.005754324023146182 0.03418801990523934 0.4221626242995262 0.007580933784134686 42.38171020507812\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3296, -0.5124,  1.0054,  0.4578, -0.3445,  0.4819,  0.0719, -1.9154,\n",
      "         0.7291,  0.2539]) tensor([ 0.0131, -0.5080,  1.0205,  0.5339, -0.4402,  0.2750,  0.2547, -1.7542,\n",
      "         0.1707,  0.0742]) tensor([ 0.0203, -0.3796,  0.9140,  0.6286, -0.3531,  0.5102, -0.1152, -1.6941,\n",
      "        -0.0172,  0.0131])\n",
      "R[0]\n",
      "tensor([0.3340], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05278942884504795 0.004601490830893454 0.0011714324111221685 0.005620201495243236 0.03428356554731727 0.4186123885512352 0.007416932767257094 42.39556706237793\n",
      "Average (on the epoch) training loss: 0.005694649750948883\n",
      "Episode average V value: 0\n",
      "epoch 47:\n",
      "Learning rate: 7.855167211278949e-07\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 129.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 128.98710128987102 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2898, -0.9217,  1.0437,  0.4152, -0.2290, -0.1192,  0.2811, -0.7423,\n",
      "         0.0973, -0.4996]) tensor([-0.1729, -0.9191,  0.9817,  0.3792, -0.2331, -0.0843,  0.2349, -0.8145,\n",
      "         0.1460,  0.0980]) tensor([-0.4213, -0.9293,  0.9217,  0.3168, -0.0962, -0.0876,  0.4454, -0.7710,\n",
      "         0.0115,  0.0321])\n",
      "R[0]\n",
      "tensor([0.0064], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0528000638410449 0.004080717799999548 0.0017217382321141486 0.00565961909876205 0.03404497668519616 0.42007965648174284 0.0074181656530126925 42.30434118652344\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0879, -0.5568,  0.9766,  0.8730, -0.6798, -0.3090,  0.7145, -1.0558,\n",
      "         0.1993, -0.0937]) tensor([-0.0109, -0.5457,  0.9940,  0.8929, -0.6955, -0.2858,  0.6784, -1.0618,\n",
      "         0.0378, -0.0278]) tensor([ 0.2387, -0.5311,  0.9727,  0.9050, -0.7320, -0.3331,  0.6347, -0.9968,\n",
      "         0.4407, -0.3456])\n",
      "R[0]\n",
      "tensor([-0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05268581439554691 0.004685372897221896 0.0018641931110914812 0.005961418281309307 0.03387937492132187 0.4190570906400681 0.007749070298392326 42.407603828430176\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5420, -0.9139,  0.9281,  0.1723,  0.0573, -0.0293,  0.4447, -0.6924,\n",
      "         0.0503, -0.0698]) tensor([-0.2429, -0.8939,  0.9613,  0.2567, -0.0020, -0.0139,  0.4122, -0.7082,\n",
      "         0.1723,  0.0606]) tensor([-0.1880, -1.0290,  1.0804,  0.2026,  0.0265,  0.0384,  0.3583, -0.8209,\n",
      "        -0.0078, -0.0303])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05302002384513617 0.004462554259411263 0.0017631313261981631 0.005804546693572775 0.03401432196795941 0.4206916410923004 0.007612884133122861 42.338010154724124\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3720, -0.8436,  1.3242,  1.0287, -0.9532, -0.1383,  0.1240, -1.2912,\n",
      "        -0.2799, -0.2983]) tensor([ 0.0227, -0.8136,  1.2644,  0.9919, -0.8982, -0.1444,  0.1811, -1.2407,\n",
      "         0.2249,  0.0908]) tensor([ 0.0924, -0.7794,  1.2679,  0.9817, -0.9033, -0.1898,  0.2496, -1.2489,\n",
      "        -0.4736, -0.0706])\n",
      "R[0]\n",
      "tensor([0.0044], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05258450471609831 0.004296733185365156 0.0013475058390140476 0.005514545891317539 0.034458790253847835 0.4161183891892433 0.007448865358252078 42.282522552490235\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3218, -0.6189,  1.0692,  0.9343, -0.5005, -0.2101,  0.1301, -0.5215,\n",
      "        -0.0783,  0.5940]) tensor([-0.1009, -0.6306,  1.1104,  0.9582, -0.4947, -0.1797,  0.1109, -0.5456,\n",
      "         0.1306,  0.0595]) tensor([-0.0071, -0.6218,  1.0472,  0.9831, -0.5716, -0.1844,  0.1070, -0.5896,\n",
      "        -0.0056, -0.0755])\n",
      "R[0]\n",
      "tensor([0.0009], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052828553840517996 0.00441251850039589 0.0014903217979203873 0.005663500800263136 0.034001976732164624 0.4232713857293129 0.007557168832514435 42.35579860687256\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3501, -0.5659,  1.0158,  0.8608, -0.6791, -0.2867,  0.6615, -1.0758,\n",
      "        -0.6677, -0.2060]) tensor([ 0.0056, -0.5636,  1.0052,  0.8568, -0.7059, -0.2797,  0.6150, -1.1001,\n",
      "         0.0547, -0.0327]) tensor([-0.0784, -0.5997,  0.9721,  0.8396, -0.6816, -0.2787,  0.6911, -1.1229,\n",
      "        -0.0548, -0.0168])\n",
      "R[0]\n",
      "tensor([0.0051], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05263456048071385 0.004229456237518207 0.0013541207230023246 0.0054010434767697004 0.03328275204077363 0.4226255171895027 0.007637893768493086 42.2817551651001\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3759, -1.0916,  1.3039,  0.0883,  0.1776,  0.0201, -0.0839, -0.5568,\n",
      "         0.5042,  0.3358]) tensor([-0.2531, -1.0500,  1.0667, -0.0219,  0.1992,  0.0815, -0.1299, -0.6961,\n",
      "         0.2332,  0.1938]) tensor([-0.5172, -1.4525,  1.2647, -0.2114,  0.2071, -0.0381,  0.2759, -0.9645,\n",
      "         0.2767,  0.2935])\n",
      "R[0]\n",
      "tensor([0.0560], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05267735093086958 0.004983928053572527 0.0017586627976515956 0.005891140076564625 0.03383102498948574 0.42422778898477553 0.0074409510223194955 42.362933029174805\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4549, -0.8679,  0.9874,  0.5351, -0.2601, -0.0564,  0.2785, -0.7611,\n",
      "        -0.1043,  0.3293]) tensor([-0.1507, -0.8478,  0.9797,  0.5818, -0.3020, -0.0603,  0.2570, -0.7676,\n",
      "         0.1675,  0.0435]) tensor([-0.0351, -0.7540,  0.9706,  0.7400, -0.3367,  0.0035,  0.1362, -0.6829,\n",
      "        -0.2841,  0.1472])\n",
      "R[0]\n",
      "tensor([0.0011], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05283796228468418 0.004566083797979445 0.0018724822706608392 0.005734342789277434 0.03351173561811447 0.42304947671294213 0.007279082640074193 42.312685546875\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0049, -0.4400,  0.8825,  0.9827, -0.3133,  0.1912, -0.0013, -0.8192,\n",
      "         0.4525,  0.3972]) tensor([-0.0906, -0.4697,  0.9137,  0.9494, -0.3114,  0.1903, -0.0149, -0.8314,\n",
      "         0.0963,  0.0516]) tensor([ 0.0023, -0.5653,  1.0211,  0.2717, -0.3256,  0.3197,  0.0731, -1.6874,\n",
      "         0.4340, -0.1334])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05285182471573353 0.0046716321926924135 0.0019324882632672598 0.005681931782048196 0.03376095437258482 0.4186051079630852 0.007327059330884367 42.21578040313721\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3386, -0.8320,  1.1220,  0.4576, -0.1183, -0.1208,  0.1290, -0.5165,\n",
      "         0.1403, -0.0702]) tensor([-0.2098, -0.8102,  1.0966,  0.5242, -0.1748, -0.1206,  0.1380, -0.5559,\n",
      "         0.1691,  0.1306]) tensor([-0.2473, -0.8590,  1.2458,  0.5192, -0.0893, -0.0316, -0.0375, -0.4929,\n",
      "         0.6659,  0.5725])\n",
      "R[0]\n",
      "tensor([0.0149], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0528362238034606 0.004544478775313109 0.001623975786693336 0.005931485510780476 0.034330526724457744 0.42234031641483305 0.0075985111696645615 42.33799261474609\n",
      "Average (on the epoch) training loss: 0.005724357440066524\n",
      "Episode average V value: 0\n",
      "epoch 48:\n",
      "Learning rate: 7.069650490151055e-07\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 127.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 126.98730126987302 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4413, -1.1693,  1.0453,  0.1261, -0.0941, -0.0071,  0.1890, -0.9104,\n",
      "         0.3848,  0.6814]) tensor([-0.1814, -1.1125,  0.9109,  0.1236, -0.1012,  0.0465,  0.1419, -0.9818,\n",
      "         0.2054,  0.1112]) tensor([-0.2615, -1.1050,  1.0002, -0.0201,  0.0514, -0.0129,  0.1658, -0.8083,\n",
      "         0.7352,  0.5348])\n",
      "R[0]\n",
      "tensor([0.0416], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052596515700221065 0.004301929554749222 0.0014796795093880064 0.005417072794400155 0.03447517057880759 0.4188016831278801 0.007495489842724055 42.28589402770996\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2418, -0.0124,  0.9388,  1.0904, -0.2885,  0.5586, -0.5616, -1.0237,\n",
      "        -0.1100,  0.2834]) tensor([ 0.0218, -0.0776,  0.9236,  0.9886, -0.2667,  0.5052, -0.4967, -1.0488,\n",
      "         0.0845,  0.0298]) tensor([-0.1393, -0.1974,  0.8821,  0.8984, -0.3159,  0.5867, -0.4265, -1.3639,\n",
      "         0.4226, -0.1200])\n",
      "R[0]\n",
      "tensor([-0.0038], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.0528102557733655 0.004397885116472025 0.0014233497188811271 0.005731934915762395 0.03401155311986804 0.42033015021681785 0.00741795267118141 42.29683792877197\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2286, -0.7092,  1.2134,  0.9820, -0.8872, -0.2269,  0.3254, -1.1944,\n",
      "         0.0608, -0.0889]) tensor([ 0.0446, -0.6776,  1.1558,  0.9775, -0.8753, -0.2304,  0.3455, -1.1767,\n",
      "         0.1578,  0.0398]) tensor([-0.5889, -0.7015,  1.2506,  0.9847, -0.8963, -0.2292,  0.3270, -1.1940,\n",
      "         0.0142, -0.2017])\n",
      "R[0]\n",
      "tensor([0.0024], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052847805730998516 0.004603278763195703 0.001379016072394279 0.005603658553212881 0.03372459629178047 0.4256623656749725 0.007435894275549799 42.36934854888916\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2096, -1.2072,  0.9660, -0.2317, -0.0330, -0.1382,  0.4109, -1.1955,\n",
      "         0.4633, -0.1485]) tensor([-0.1583, -1.0880,  0.9468,  0.0619, -0.2107, -0.1064,  0.3285, -1.2250,\n",
      "         0.1652,  0.0606]) tensor([-2.7063e-01, -6.9697e-01,  8.1062e-01, -2.3175e-01,  1.0554e-02,\n",
      "         2.7820e-01, -1.6677e-01, -1.4147e+00, -3.8014e-04, -2.3343e-02])\n",
      "R[0]\n",
      "tensor([0.1156], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05281610594689846 0.004300011870054732 0.0012688220021154848 0.005682823114329949 0.0342618281468749 0.42021392688155174 0.0075885892799124124 42.35989259338379\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0512, -0.6738,  1.2281,  1.1311, -0.6777, -0.0832, -0.1033, -0.6989,\n",
      "        -0.2004, -0.2362]) tensor([-0.0782, -0.6686,  1.2137,  1.1045, -0.6247, -0.0614, -0.0919, -0.6874,\n",
      "         0.2191,  0.0917]) tensor([ 0.3075, -0.6680,  1.1355,  1.0529, -0.6502, -0.1318,  0.0274, -0.6952,\n",
      "        -0.0487, -0.3257])\n",
      "R[0]\n",
      "tensor([0.0001], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05280455952882767 0.004293394438658652 0.0013478874012307642 0.00540719734155573 0.03405917336046696 0.4238343923687935 0.007373051734175533 42.30413248443603\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1161, -0.7805,  1.0938,  0.9422, -0.8200, -0.1630,  0.4263, -1.2653,\n",
      "         0.5016, -0.5622]) tensor([ 0.0014, -0.7753,  1.0778,  0.9016, -0.7944, -0.1879,  0.4391, -1.2132,\n",
      "         0.1299,  0.0220]) tensor([-0.3325, -0.7904,  1.1029,  0.9421, -0.8661, -0.1710,  0.3850, -1.3040,\n",
      "         0.3021,  0.5392])\n",
      "R[0]\n",
      "tensor([0.0019], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05298629965633154 0.004370574323925212 0.0017368249162309439 0.005516179061727598 0.03366817701235413 0.42799936842918396 0.0075550521844998005 42.37881692504883\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0801, -0.6426,  0.8109,  0.9801, -0.4922,  0.0754,  0.0729, -0.8352,\n",
      "        -0.0417, -0.2801]) tensor([-0.0771, -0.6594,  0.8311,  0.9745, -0.5028,  0.0596,  0.0647, -0.8334,\n",
      "         0.0903,  0.0571]) tensor([ 0.8530, -0.7111,  0.9459,  0.9056, -0.7931, -0.0710,  0.1945, -1.2451,\n",
      "         0.2154, -0.0166])\n",
      "R[0]\n",
      "tensor([0.0070], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052825243957340715 0.004522747414452169 0.0013559614025361953 0.005705712612019851 0.034008836830034854 0.4262601748108864 0.007510390312410891 42.33915175628662\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1039, -0.1644,  0.9426,  0.8640, -0.3413,  0.5032, -0.3158, -1.3766,\n",
      "         0.2513, -0.4574]) tensor([ 0.0120, -0.2166,  0.9520,  0.7941, -0.3296,  0.4565, -0.2742, -1.3792,\n",
      "         0.1016,  0.1144]) tensor([ 0.1931, -0.0329,  0.8845,  0.9420, -0.3098,  0.5029, -0.4068, -1.1793,\n",
      "        -0.2259, -0.0431])\n",
      "R[0]\n",
      "tensor([-0.0088], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05267357727885246 0.004314652072116587 0.0019496823855888578 0.005573702516267076 0.03425288005545735 0.4251580465435982 0.007719715411309153 42.32859857940674\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2103, -0.9603,  0.9403,  0.5863, -0.4179, -0.0787,  0.0436, -0.7989,\n",
      "         0.1578,  0.6953]) tensor([-0.1598, -0.9545,  1.0076,  0.6119, -0.3627, -0.0410,  0.0042, -0.7491,\n",
      "         0.1666,  0.0810]) tensor([ 0.3660, -0.9376,  0.9092,  0.5234, -0.3216, -0.0609,  0.0623, -0.7507,\n",
      "        -0.8083, -0.1079])\n",
      "R[0]\n",
      "tensor([0.0017], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053130492106080056 0.004575539662033406 0.0014698701717975383 0.005615693381754681 0.03429592821002007 0.42474978160858157 0.007640995616093278 42.268034530639646\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1976, -0.7684,  1.1865,  1.0459, -0.6762, -0.0570, -0.1075, -0.7667,\n",
      "        -0.4320,  0.0392]) tensor([-0.0829, -0.7611,  1.1827,  1.0174, -0.6126, -0.0361, -0.1038, -0.7348,\n",
      "         0.2286,  0.0757]) tensor([ 0.9710, -0.7347,  1.1950,  1.0812, -0.6539, -0.0471, -0.1015, -0.7324,\n",
      "         0.1684,  0.2299])\n",
      "R[0]\n",
      "tensor([0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05300559292733669 0.004741747837366347 0.0013940069757759374 0.005537721899803728 0.03414194315299392 0.4234939826130867 0.007663425303064287 42.25689126586914\n",
      "Average (on the epoch) training loss: 0.0055791696190834045\n",
      "Episode average V value: 0\n",
      "epoch 49:\n",
      "Learning rate: 6.362685441135949e-07\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 126.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 125.98740125987402 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4266, -0.6201,  1.1499,  1.0926, -0.5943, -0.1082, -0.0070, -0.5875,\n",
      "         0.2006,  0.3858]) tensor([-0.0515, -0.6246,  1.1077,  1.0779, -0.6023, -0.1113,  0.0173, -0.6295,\n",
      "         0.1376,  0.0276]) tensor([ 0.8512, -0.5768,  1.2807,  1.1408, -0.6125, -0.0793, -0.1022, -0.5931,\n",
      "        -0.3059,  0.2428])\n",
      "R[0]\n",
      "tensor([0.0043], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053029097661376 0.0046811138080702225 0.0018029542921526626 0.005690684226690792 0.033766132716089484 0.42409024673700335 0.0075583585347048935 42.321840385437014\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1671, -0.6929,  1.1444,  1.0216, -0.6949, -0.1439,  0.0747, -0.7933,\n",
      "         0.0566, -0.3715]) tensor([-0.0777, -0.7066,  1.1220,  0.9848, -0.6732, -0.1561,  0.1235, -0.7999,\n",
      "         0.1551,  0.0721]) tensor([ 0.1113, -0.7031,  1.1163,  1.0331, -0.7327, -0.1733,  0.1110, -0.8292,\n",
      "         0.4255, -0.0294])\n",
      "R[0]\n",
      "tensor([0.0012], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.052946740433573725 0.00453012356641193 0.0014479785602420634 0.005550068801268935 0.03400066476687789 0.4288500652909279 0.007395865084603429 42.38672054290772\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2179, -0.6692,  1.1457,  0.9609, -0.8331, -0.2535,  0.4284, -1.1745,\n",
      "         0.6768, -0.6879]) tensor([ 0.0031, -0.6758,  1.1278,  0.9098, -0.8125, -0.2825,  0.4487, -1.1397,\n",
      "         0.1120, -0.0054]) tensor([ 0.4472, -0.7091,  1.0916,  0.9523, -0.8440, -0.2244,  0.4393, -1.2322,\n",
      "         0.3316,  0.2856])\n",
      "R[0]\n",
      "tensor([0.0031], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05274983490258455 0.004582891967482283 0.0013940336975128958 0.0058196085998788475 0.03420796186104417 0.42629538995027544 0.007596848643850535 42.31213496398926\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2643, -0.6590,  1.0669,  1.0303, -0.6528, -0.1426,  0.0310, -0.6635,\n",
      "         0.5574, -0.9399]) tensor([-8.8198e-02, -6.7682e-01,  1.0729e+00,  9.7940e-01, -6.0647e-01,\n",
      "        -1.4600e-01,  3.4332e-02, -6.4123e-01,  1.7036e-01, -1.8692e-04]) tensor([ 0.3550, -0.6958,  1.1110,  1.0338, -0.6481, -0.1025, -0.0256, -0.7027,\n",
      "        -0.0913, -0.1074])\n",
      "R[0]\n",
      "tensor([-0.0002], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05255688040703535 0.004206821789419337 0.0017747310483232468 0.005540284188347869 0.03397911087796092 0.4234030202627182 0.007626887869555503 42.359834434509274\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0349, -0.5439,  0.8719,  0.9159, -0.5624, -0.2982,  0.3417, -0.5548,\n",
      "         0.0372, -0.6149]) tensor([-0.0996, -0.5568,  0.9153,  0.9268, -0.5459, -0.2692,  0.3125, -0.5652,\n",
      "         0.0105, -0.0071]) tensor([ 0.2487, -0.6061,  0.8692,  0.8881, -0.5381, -0.2422,  0.2854, -0.5947,\n",
      "        -0.0352,  0.5983])\n",
      "R[0]\n",
      "tensor([-0.0013], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05288947494328022 0.0041270640437141995 0.001748181055404075 0.005525257770903408 0.03408418165147305 0.42196199411153795 0.007666169036645442 42.36992972564697\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3872, -0.5835,  1.0429,  0.8748, -0.6971, -0.2930,  0.6376, -1.0502,\n",
      "        -0.2019, -0.2390]) tensor([-0.0360, -0.5593,  1.0226,  0.8645, -0.6840, -0.2738,  0.6140, -1.0336,\n",
      "         0.0668, -0.0083]) tensor([-0.3694, -0.5750,  0.9847,  0.8286, -0.7026, -0.2468,  0.6329, -1.1499,\n",
      "        -0.8072, -0.0947])\n",
      "R[0]\n",
      "tensor([-0.0003], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05259955946356058 0.004220426542402492 0.0017493407885972375 0.0055833328801672905 0.03379316818341613 0.42359618347883227 0.007675003795418888 42.29210159301758\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2047, -0.5538,  0.9822,  0.8980, -0.7305, -0.3439,  0.6482, -1.0282,\n",
      "        -0.1837, -0.5012]) tensor([-0.0165, -0.5492,  1.0189,  0.9224, -0.7319, -0.3170,  0.6133, -1.0259,\n",
      "         0.0313, -0.0178]) tensor([ 0.1605, -0.5556,  0.9913,  0.9135, -0.7488, -0.3558,  0.6433, -1.0335,\n",
      "        -0.1439,  0.2185])\n",
      "R[0]\n",
      "tensor([-0.0010], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05319124883413315 0.005002395083196462 0.0013958813009085135 0.005833254521246999 0.033987427178770305 0.4244711946249008 0.007591470041777938 42.34634085083008\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9130, -0.9129,  1.3414,  1.0384, -0.8533,  0.0154, -0.1669, -1.1365,\n",
      "         0.1283, -0.1791]) tensor([-0.0318, -0.8788,  1.2871,  1.0234, -0.8150, -0.0178, -0.1010, -1.0622,\n",
      "         0.2898,  0.1161]) tensor([ 0.1126, -0.9019,  1.2818,  1.0233, -0.9041, -0.0550, -0.0651, -1.1851,\n",
      "        -0.6071,  0.2194])\n",
      "R[0]\n",
      "tensor([0.0089], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05287195320427418 0.004330572199267408 0.001468905326456479 0.005786207605851814 0.03359865852817893 0.417546046257019 0.00750304545648396 42.316688293457034\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5866, -0.5869,  0.8632,  0.9160, -0.6067, -0.2779,  0.2743, -0.5972,\n",
      "        -0.6531, -0.9244]) tensor([-0.1158, -0.6122,  0.9349,  0.9244, -0.5738, -0.2343,  0.2340, -0.6106,\n",
      "        -0.0530, -0.1269]) tensor([-0.4015, -0.6244,  0.9676,  0.9698, -0.6205, -0.2230,  0.1830, -0.6121,\n",
      "        -0.2876,  0.3648])\n",
      "R[0]\n",
      "tensor([-0.0006], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.05290600624680519 0.004369997497193253 0.0015679535759850296 0.005604157157591544 0.03397361498326063 0.42187358993291857 0.007658114291727543 42.31772883605957\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0524, -0.7497,  1.1364,  0.9512, -0.8679, -0.2233,  0.4005, -1.2382,\n",
      "         0.1109,  0.4946]) tensor([ 1.1460e-03, -7.1708e-01,  1.1195e+00,  9.2985e-01, -8.1306e-01,\n",
      "        -2.0451e-01,  3.8462e-01, -1.1773e+00,  1.4694e-01,  1.1098e-02]) tensor([ 0.5763, -0.7909,  1.1427,  0.9876, -0.8738, -0.1774,  0.3731, -1.3006,\n",
      "        -0.2500, -0.1993])\n",
      "R[0]\n",
      "tensor([0.0008], grad_fn=<SelectBackward0>)\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q,                 self.loss_disentangle_t, self.loss_disambiguate1,                self.loss_disambiguate2, self.loss_VAE\n",
      "0.053402199216187 0.004863528715335633 0.001688211060174126 0.0057785471942042935 0.03361247704178095 0.42201047071814535 0.0076003515534102915 42.2486053314209\n",
      "Average (on the epoch) training loss: 0.005671140294615179\n",
      "Episode average V value: 0\n",
      "epoch 50:\n",
      "Learning rate: 5.726416897022355e-07\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 127.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 126.98730126987302 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:326: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:362: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best neural net obtained after 43 epochs, with validation score 135.0\n",
      "{'vs': [2.0, 2.0, 14.0, 7.0, 50.0, 26.0, 64.0, 99.0, 98.0, 100.0, 106.0, 99.0, 117.0, 118.0, 87.0, 115.0, 88.0, 113.0, 85.0, 111.0, 99.0, 91.0, 117.0, 109.0, 102.0, 129.0, 96.0, 107.0, 129.0, 98.0, 97.0, 119.0, 132.0, 132.0, 132.0, 132.0, 124.0, 124.0, 132.0, 132.0, 134.0, 132.0, 135.0, 135.0, 133.0, 125.0, 129.0, 127.0, 126.0, 127.0], 'ts': []}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"params\")\n",
    "except Exception:\n",
    "    pass\n",
    "dump(vars(parameters), \"params/\" + fname + \".jldump\")\n",
    "#agent.gathering_data=False\n",
    "agent.setNetwork('saved')\n",
    "agent.run(parameters.epochs, parameters.steps_per_epoch)\n",
    "\n",
    "# --- Show results ---\n",
    "basename = \"scores/\" + fname\n",
    "scores = load(basename + \"_scores.jldump\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.setNetwork(fname, nEpoch=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent._in_episode = True\n",
    "agent._mode = 0 # Testing mode with plan_depth=0\n",
    "initState = env.reset(agent._mode)\n",
    "inputDims = env.inputDimensions()\n",
    "\n",
    "for i in range(len(inputDims)):\n",
    "    if inputDims[i][0] > 1:\n",
    "        agent._state[i][1:] = initState[i][1:]\n",
    "agent._Vs_on_last_episode = []\n",
    "is_terminal = False\n",
    "reward = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for i in range(100):\n",
    "    obs = env.observe()\n",
    "    _obs = obs[0].reshape((env.WIDTH, env.HEIGHT))\n",
    "    plt.figure()\n",
    "    plt.imshow(np.flip(_obs.squeeze()))\n",
    "    plt.show()\n",
    "    for i in range(len(obs)):\n",
    "        agent._state[i][0:-1] = agent._state[i][1:]\n",
    "        agent._state[i][-1] = obs[i]\n",
    "    V, action, reward, _ = agent._step()\n",
    "    print(action)\n",
    "    agent._Vs_on_last_episode.append(V)\n",
    "    is_terminal = env.inTerminalState()\n",
    "    if is_terminal: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "obs = env.observe()\n",
    "_obs = obs[0].reshape((env.WIDTH, env.HEIGHT))\n",
    "_obs = np.flip(_obs.squeeze())\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "im = ax.imshow(np.zeros(_obs.shape))\n",
    "\n",
    "def init():\n",
    "    plt.cla()\n",
    "    im = ax.imshow(_obs)\n",
    "    return [im]\n",
    "\n",
    "def animate(i, *args, **kwargs):\n",
    "    plt.cla()\n",
    "    obs = env.observe()\n",
    "    _obs = obs[0].reshape((env.WIDTH, env.HEIGHT))\n",
    "    _obs = np.flip(_obs.squeeze())\n",
    "    im = ax.imshow(_obs)\n",
    "    for i in range(len(obs)):\n",
    "        agent._state[i][0:-1] = agent._state[i][1:]\n",
    "        agent._state[i][-1] = obs[i]\n",
    "        V, action, reward, _ = agent._step()\n",
    "        agent._Vs_on_last_episode.append(V)\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, init_func=init, \n",
    "     frames=100, blit=False, repeat=True)\n",
    "ani.save('behavior.gif', writer=\"ffmpeg\", fps = 15)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
