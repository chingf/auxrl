{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import hash, dump, load\n",
    "import os\n",
    "\n",
    "from deer.default_parser import process_args\n",
    "from deer.agent import NeuralAgent\n",
    "from deer.learning_algos.CRAR_torch import CRAR\n",
    "from figure8_env import MyEnv as figure8_env\n",
    "import deer.experiment.base_controllers as bc\n",
    "\n",
    "from deer.policies import EpsilonGreedyPolicy, FixedFigure8Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure8_give_rewards = True\n",
    "nn_yaml = 'network_noconv.yaml'\n",
    "high_dim_obs = False\n",
    "internal_dim = 10\n",
    "fname = '2d_obs'\n",
    "set_network = None #['expanded_tcm', 15, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Defaults:\n",
    "    # ----------------------\n",
    "    # Setup Parameters (copied for convenience)\n",
    "    # ----------------------\n",
    "    figure8_give_rewards = figure8_give_rewards\n",
    "    nn_yaml = nn_yaml\n",
    "    high_dim_obs = high_dim_obs\n",
    "    internal_dim = internal_dim\n",
    "    fname = fname\n",
    "    \n",
    "    # ----------------------\n",
    "    # Experiment Parameters\n",
    "    # ----------------------\n",
    "    steps_per_epoch = 2500\n",
    "    epochs = 50\n",
    "    steps_per_test = 1000\n",
    "    period_btw_summary_perfs = 1\n",
    "\n",
    "    # ----------------------\n",
    "    # Temporal Processing Parameters\n",
    "    # ----------------------\n",
    "    nstep = 15\n",
    "    nstep_decay = 0.8\n",
    "    expand_tcm = True\n",
    "    encoder_type = 'regular'\n",
    "    \n",
    "    # ----------------------\n",
    "    # Environment Parameters\n",
    "    # ----------------------\n",
    "    frame_skip = 2\n",
    "    show_rewards = False\n",
    "\n",
    "    # ----------------------\n",
    "    # DQN Agent parameters:\n",
    "    # ----------------------\n",
    "    learning_rate = 1*1E-4\n",
    "    learning_rate_decay = 1.0\n",
    "    discount = 0.9\n",
    "    epsilon_start = 1.0\n",
    "    epsilon_min = 1.0\n",
    "    epsilon_decay = 1000\n",
    "    update_frequency = 1\n",
    "    replay_memory_size = 100000 #50000\n",
    "    batch_size = 64\n",
    "    freeze_interval = 1000\n",
    "    deterministic = False\n",
    "    \n",
    "    # ----------------------\n",
    "    # Learning algo parameters\n",
    "    # ----------------------\n",
    "    # T, entropy_neighbor, entropy_random, volume, gamma, R, Q, variational\n",
    "    #loss_weights = [5E-3, 1E-3, 5E-3, 5E-3, 5E-3, 5E-3, 1.]\n",
    "    loss_weights = [0, 0, 0, 0, 0, 0, 1., 0.]\n",
    "    #loss_weights = [0., 0., 0., 0., 0., 0., 1., 2E-4]\n",
    "    #loss_weights = [5E-3, 1E-3, 5E-3, 5E-3, 5E-3, 5E-3, 0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = Defaults()\n",
    "with open(f'params/{fname}.p', 'wb') as f:\n",
    "    pickle.dump(parameters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end gathering data\n"
     ]
    }
   ],
   "source": [
    "if parameters.deterministic:\n",
    "    rng = np.random.RandomState(123456)\n",
    "else:\n",
    "    rng = np.random.RandomState()\n",
    "\n",
    "# --- Instantiate environment ---\n",
    "env = figure8_env(\n",
    "    give_rewards=figure8_give_rewards,\n",
    "    intern_dim=internal_dim,\n",
    "    high_dim_obs=high_dim_obs,\n",
    "    show_rewards=parameters.show_rewards\n",
    "    )\n",
    "\n",
    "# --- Instantiate learning_algo ---\n",
    "learning_algo = CRAR(\n",
    "    env,\n",
    "    parameters.freeze_interval,\n",
    "    parameters.batch_size,\n",
    "    rng,\n",
    "    high_int_dim=False,\n",
    "    internal_dim=internal_dim, lr=parameters.learning_rate,\n",
    "    nn_yaml=nn_yaml, double_Q=True,\n",
    "    loss_weights=parameters.loss_weights,\n",
    "    nstep=parameters.nstep, nstep_decay=parameters.nstep_decay,\n",
    "    encoder_type=parameters.encoder_type,\n",
    "    expand_tcm=parameters.expand_tcm\n",
    "    )\n",
    "\n",
    "if figure8_give_rewards:\n",
    "    train_policy = EpsilonGreedyPolicy(\n",
    "        learning_algo, env.nActions(), rng, 0.2,\n",
    "        consider_valid_transitions=False\n",
    "        )\n",
    "    test_policy = EpsilonGreedyPolicy(\n",
    "        learning_algo, env.nActions(), rng, 0.\n",
    "        )\n",
    "else:\n",
    "    train_policy = FixedFigure8Policy.FixedFigure8Policy(\n",
    "        learning_algo, env.nActions(), rng, epsilon=0.2,\n",
    "        height=env.HEIGHT, width=env.WIDTH\n",
    "        )\n",
    "    test_policy = FixedFigure8Policy.FixedFigure8Policy(\n",
    "        learning_algo, env.nActions(), rng,\n",
    "        height=env.HEIGHT, width=env.WIDTH\n",
    "        )\n",
    "\n",
    "# --- Instantiate agent ---\n",
    "agent = NeuralAgent(\n",
    "    env, learning_algo,\n",
    "    parameters.replay_memory_size,\n",
    "    1, parameters.batch_size, rng,\n",
    "    train_policy=train_policy, test_policy=test_policy)\n",
    "if set_network is not None:\n",
    "    agent.setNetwork(\n",
    "        f'{set_network[0]}/fname', nEpoch=set_network[1],\n",
    "        encoder_only=set_network[2]\n",
    "        )\n",
    "\n",
    "agent.run(10, 500)\n",
    "print(\"end gathering data\")\n",
    "\n",
    "# --- Bind controllers to the agent ---\n",
    "# Before every training epoch (periodicity=1), we want to print a summary of the agent's epsilon, discount and \n",
    "# learning rate as well as the training epoch number.\n",
    "agent.attach(bc.VerboseController(\n",
    "    evaluate_on='epoch', \n",
    "    periodicity=1))\n",
    "\n",
    "# Learning rate may follow a scheduler\n",
    "agent.attach(bc.LearningRateController(\n",
    "    initial_learning_rate=parameters.learning_rate, \n",
    "    learning_rate_decay=parameters.learning_rate_decay,\n",
    "    periodicity=1))\n",
    "\n",
    "# During training epochs, we want to train the agent after every [parameters.update_frequency] action it takes.\n",
    "# Plus, we also want to display after each training episode (!= than after every training) the average bellman\n",
    "# residual and the average of the V values obtained during the last episode, hence the two last arguments.\n",
    "agent.attach(bc.TrainerController(\n",
    "    evaluate_on='action', \n",
    "    periodicity=parameters.update_frequency, \n",
    "    show_episode_avg_V_value=True, \n",
    "    show_avg_Bellman_residual=True))\n",
    "\n",
    "# We wish to discover, among all versions of our neural network (i.e., after every training epoch), which one \n",
    "# has the highest validation score.\n",
    "# To achieve this goal, one can use the FindBestController along with an InterleavedTestEpochControllers. It is \n",
    "# important that the validationID is the same than the id argument of the InterleavedTestEpochController.\n",
    "# The FindBestController will dump on disk the validation scores for each and every network, as well as the \n",
    "# structure of the neural network having the best validation score. These dumps can then used to plot the evolution \n",
    "# of the validation and test scores (see below) or simply recover the resulting neural network for your \n",
    "# application.\n",
    "agent.attach(bc.FindBestController(\n",
    "    validationID=figure8_env.VALIDATION_MODE,\n",
    "    testID=None,\n",
    "    unique_fname=fname, savefrequency=5))\n",
    "\n",
    "# All previous controllers control the agent during the epochs it goes through. However, we want to interleave a \n",
    "# \"validation epoch\" between each training epoch. For each validation epoch, we want also to display the sum of all \n",
    "# rewards obtained, hence the showScore=True. Finally, we want to call the summarizePerformance method of ALE_env \n",
    "# every [parameters.period_btw_summary_perfs] *validation* epochs.\n",
    "agent.attach(bc.InterleavedTestEpochController(\n",
    "    id=figure8_env.VALIDATION_MODE, \n",
    "    epoch_length=parameters.steps_per_test,\n",
    "    periodicity=1,\n",
    "    show_score=True,\n",
    "    summarize_every=1,\n",
    "    unique_fname=fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0359, -0.2225,  0.3165,  0.1578,  0.2568,  0.0076, -0.0083,  0.3265,\n",
      "        -0.0484,  0.0728]) tensor([ 0.1811, -0.0303,  0.0336,  0.3680, -0.1580, -0.2024,  0.1085,  0.1297,\n",
      "        -0.1646, -0.2863]) tensor([ 0.0994, -0.2553,  0.2563,  0.0890,  0.3583, -0.0465, -0.0044,  0.3508,\n",
      "        -0.1148,  0.0970])\n",
      "R[0]\n",
      "tensor([0.1647], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.058171156398952005; R = 0.015935857269912958;                 Gamma = 0.689298388838768; Q = 0.002145316639856901;\n",
      "Entropy Neighbor = 0.7433496443033218;                 Entropy Random = 0.6659789493083954;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1715, -0.1128,  0.3757,  0.1519, -0.0440, -0.1954, -0.1946,  0.6030,\n",
      "         0.4154,  0.0104]) tensor([ 0.3045,  0.0731,  0.0881,  0.3361, -0.4558, -0.3934, -0.0625,  0.4208,\n",
      "         0.3041, -0.3634]) tensor([ 0.1715, -0.1128,  0.3757,  0.1519, -0.0440, -0.1954, -0.1946,  0.6030,\n",
      "         0.4154,  0.0104])\n",
      "R[0]\n",
      "tensor([0.1193], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.05771194225549698; R = 0.013313213542103767;                 Gamma = 0.6951341005563736; Q = 0.0014112538118351949;\n",
      "Entropy Neighbor = 0.7939622777700425;                 Entropy Random = 0.6050440025925636;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3802, -0.0869, -0.1234,  0.0679,  0.2693, -0.1763,  0.0159,  0.1628,\n",
      "        -0.1999, -0.1487]) tensor([-0.2301,  0.1588, -0.4001,  0.2982, -0.1588, -0.3816,  0.1091, -0.0042,\n",
      "        -0.2776, -0.5060]) tensor([-0.3545, -0.1849, -0.1566, -0.0164,  0.3039, -0.1763, -0.0244,  0.1852,\n",
      "        -0.2336, -0.1625])\n",
      "R[0]\n",
      "tensor([0.1241], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.05998998296260834; R = 0.01573616545088589;                 Gamma = 0.6853315136432647; Q = 0.0006835319963647635;\n",
      "Entropy Neighbor = 0.7757538833618164;                 Entropy Random = 0.5345097148418426;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1833, -0.4061, -0.0744,  0.0192,  0.3876, -0.1066,  0.0949,  0.1787,\n",
      "        -0.3021, -0.0564]) tensor([-0.0225, -0.1383, -0.3520,  0.2822, -0.0506, -0.3203,  0.1526,  0.0232,\n",
      "        -0.3887, -0.4051]) tensor([-0.1484, -0.4200, -0.0668,  0.0242,  0.4232, -0.0825,  0.1116,  0.1536,\n",
      "        -0.3041, -0.0391])\n",
      "R[0]\n",
      "tensor([0.1078], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.059721098586916925; R = 0.015025346724316479;                 Gamma = 0.6897243121862412; Q = 0.0008599821453062759;\n",
      "Entropy Neighbor = 0.7609400899410248;                 Entropy Random = 0.5354128592610359;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2048, -0.0087,  0.0172,  0.1156,  0.0762, -0.1626, -0.0272,  0.1406,\n",
      "        -0.0138,  0.0222]) tensor([-0.0583,  0.2199, -0.2635,  0.3337, -0.3466, -0.3664,  0.0771, -0.0297,\n",
      "        -0.1017, -0.3399]) tensor([-0.2003,  0.0249,  0.1160,  0.1747,  0.0793, -0.1064, -0.0171,  0.1395,\n",
      "        -0.0363,  0.0186])\n",
      "R[0]\n",
      "tensor([0.1228], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.05998932325094938; R = 0.014032553466036915;                 Gamma = 0.6969873297214508; Q = 0.0006453985253356223;\n",
      "Entropy Neighbor = 0.76143021941185;                 Entropy Random = 0.5386777679324151;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0011490966237397515\n",
      "Episode average V value: 0.05572398750557929\n",
      "epoch 1:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/miniforge3/envs/auxrl/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:366: RuntimeWarning: invalid value encountered in divide\n",
      "  dist_matrix = dist_matrix/np.nanpercentile(dist_matrix.flatten(), 99)\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:403: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1182,  0.0510,  0.0382,  0.0831, -0.0323, -0.1822, -0.1320,  0.1309,\n",
      "         0.0105,  0.0749]) tensor([ 0.0282,  0.2775, -0.2436,  0.2987, -0.4537, -0.3863, -0.0272, -0.0367,\n",
      "        -0.0836, -0.2879]) tensor([-0.1343,  0.0389,  0.0633,  0.1093, -0.0266, -0.1729, -0.1053,  0.1553,\n",
      "         0.0451,  0.0736])\n",
      "R[0]\n",
      "tensor([0.1159], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06037188592553139; R = 0.01337101586908102;                 Gamma = 0.7014917446374893; Q = 0.000675403090499458;\n",
      "Entropy Neighbor = 0.7835826264619827;                 Entropy Random = 0.584825124502182;                 Volume = 0.00019380903616547583; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0269,  0.0794,  0.1409,  0.1096, -0.0972, -0.0938, -0.1799,  0.0978,\n",
      "         0.0031, -0.0156]) tensor([ 0.1714,  0.3115, -0.1414,  0.3254, -0.5122, -0.3097, -0.0958, -0.0424,\n",
      "        -0.1304, -0.3736]) tensor([ 0.0269,  0.0794,  0.1409,  0.1096, -0.0972, -0.0938, -0.1799,  0.0978,\n",
      "         0.0031, -0.0156])\n",
      "R[0]\n",
      "tensor([0.0721], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.060625634491443633; R = 0.012532190164551139;                 Gamma = 0.7058608980178833; Q = 0.0006704415234416956;\n",
      "Entropy Neighbor = 0.803365112543106;                 Entropy Random = 0.60392110735178;                 Volume = 0.0006094884648919106; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0594,  0.1769,  0.1035,  0.1201, -0.2399, -0.1926, -0.2913,  0.1117,\n",
      "         0.0296,  0.1142]) tensor([ 0.0884,  0.4036, -0.1797,  0.3346, -0.6601, -0.3979, -0.1882, -0.0508,\n",
      "        -0.0741, -0.2483]) tensor([-0.0594,  0.1769,  0.1035,  0.1201, -0.2399, -0.1926, -0.2913,  0.1117,\n",
      "         0.0296,  0.1142])\n",
      "R[0]\n",
      "tensor([0.1085], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06139890015870333; R = 0.012591007240116596;                 Gamma = 0.7090310277938843; Q = 0.0006093443966601626;\n",
      "Entropy Neighbor = 0.826756180882454;                 Entropy Random = 0.6430737657546997;                 Volume = 0.000868453748524189; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0237,  0.2052,  0.1009,  0.1323, -0.2866, -0.2096, -0.3370,  0.1165,\n",
      "         0.0564,  0.1030]) tensor([ 0.1242,  0.4314, -0.1830,  0.3450, -0.7057, -0.4158, -0.2340, -0.0443,\n",
      "        -0.0511, -0.2594]) tensor([-0.0295,  0.2229,  0.1051,  0.1396, -0.2889, -0.2059, -0.3389,  0.1039,\n",
      "         0.0375,  0.0985])\n",
      "R[0]\n",
      "tensor([0.1055], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06254180816560984; R = 0.013410953789949416;                 Gamma = 0.710987364411354; Q = 0.0009455761970530148;\n",
      "Entropy Neighbor = 0.827070988535881;                 Entropy Random = 0.6461650071144104;                 Volume = 0.0018275681994855404; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0155,  0.2532,  0.1084,  0.1481, -0.3417, -0.2291, -0.3892,  0.0961,\n",
      "         0.0599,  0.1022]) tensor([ 0.1702,  0.4702, -0.1749,  0.3640, -0.7562, -0.4470, -0.2921, -0.0727,\n",
      "        -0.0816, -0.2498]) tensor([ 0.0142,  0.2420,  0.1008,  0.1498, -0.3377, -0.2310, -0.3840,  0.0938,\n",
      "         0.0662,  0.1117])\n",
      "R[0]\n",
      "tensor([0.1349], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06206597392261028; R = 0.012615914594382048;                 Gamma = 0.7134905897378921; Q = 0.0005940100627631182;\n",
      "Entropy Neighbor = 0.8500234903097152;                 Entropy Random = 0.6921459951400757;                 Volume = 0.0013856239877641202; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0006989550540834898\n",
      "Episode average V value: 0.06238524524867534\n",
      "epoch 2:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:366: RuntimeWarning: invalid value encountered in divide\n",
      "  dist_matrix = dist_matrix/np.nanpercentile(dist_matrix.flatten(), 99)\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:403: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0117,  0.2413,  0.1072,  0.1659, -0.3579, -0.2274, -0.3962,  0.0732,\n",
      "         0.0428,  0.1135]) tensor([ 0.1539,  0.5022, -0.1778,  0.4175, -0.7880, -0.4482, -0.3418, -0.0649,\n",
      "        -0.0865, -0.2335]) tensor([-0.0080,  0.2447,  0.1053,  0.1745, -0.3523, -0.2258, -0.3826,  0.0673,\n",
      "         0.0434,  0.1064])\n",
      "R[0]\n",
      "tensor([0.0761], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06239106052368879; R = 0.01294782404974103;                 Gamma = 0.7138180400133133; Q = 0.0009408590035600355;\n",
      "Entropy Neighbor = 0.8428135544061661;                 Entropy Random = 0.6704539647102356;                 Volume = 0.0020481328144669533; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0131,  0.2170,  0.1392,  0.1697, -0.3892, -0.2042, -0.4021,  0.0640,\n",
      "         0.0562,  0.0800]) tensor([ 0.1592,  0.4525, -0.1439,  0.3844, -0.8029, -0.4208, -0.3202, -0.0669,\n",
      "        -0.0871, -0.2779]) tensor([ 0.0151,  0.2164,  0.1482,  0.1771, -0.3839, -0.1908, -0.3975,  0.0577,\n",
      "         0.0596,  0.0742])\n",
      "R[0]\n",
      "tensor([0.0606], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.062274441331624984; R = 0.012132527781650424;                 Gamma = 0.7163708474636078; Q = 0.00034865958686714296;\n",
      "Entropy Neighbor = 0.8534254710674286;                 Entropy Random = 0.6837083867788315;                 Volume = 0.0016698802672326565; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0387,  0.2379,  0.1401,  0.1914, -0.3697, -0.1964, -0.3645,  0.0452,\n",
      "         0.0843,  0.0805]) tensor([ 0.1873,  0.4628, -0.1449,  0.4023, -0.7868, -0.4042, -0.2611, -0.1144,\n",
      "        -0.0270, -0.2820]) tensor([ 0.0444,  0.2454,  0.1544,  0.1887, -0.3744, -0.1847, -0.3690,  0.0418,\n",
      "         0.0856,  0.0769])\n",
      "R[0]\n",
      "tensor([0.1040], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06210407935082912; R = 0.011432089485228062;                 Gamma = 0.716804956316948; Q = 0.0007490778719075024;\n",
      "Entropy Neighbor = 0.8500660955905914;                 Entropy Random = 0.6680999368429184;                 Volume = 0.0015737083628773688; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0544,  0.2887,  0.1283,  0.2026, -0.3346, -0.2039, -0.3614,  0.0123,\n",
      "         0.0669,  0.0958]) tensor([ 0.2009,  0.5216, -0.1565,  0.4146, -0.7457, -0.4232, -0.2790, -0.1193,\n",
      "        -0.0791, -0.2621]) tensor([ 0.0654,  0.2913,  0.1166,  0.1994, -0.3237, -0.2167, -0.3525,  0.0197,\n",
      "         0.0775,  0.0892])\n",
      "R[0]\n",
      "tensor([0.0590], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.062288472183048726; R = 0.011821330837905406;                 Gamma = 0.7181296633481979; Q = 0.0005635072279401356;\n",
      "Entropy Neighbor = 0.8516165372133255;                 Entropy Random = 0.6721057376861572;                 Volume = 0.0015158521160483361; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0903,  0.2923,  0.1988,  0.1726, -0.4077, -0.2004, -0.4156,  0.0748,\n",
      "         0.0932,  0.1082]) tensor([ 0.2353,  0.5222, -0.0857,  0.3825, -0.8193, -0.4175, -0.3306, -0.0574,\n",
      "        -0.0551, -0.2507]) tensor([ 0.0832,  0.3021,  0.1763,  0.1880, -0.4019, -0.2043, -0.4071,  0.0461,\n",
      "         0.0973,  0.1119])\n",
      "R[0]\n",
      "tensor([0.0586], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06245667539536953; R = 0.011678361872211098;                 Gamma = 0.7194487062692643; Q = 0.0009564142324379645;\n",
      "Entropy Neighbor = 0.8396204043626785;                 Entropy Random = 0.6398822373747826;                 Volume = 0.0017051761634647845; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0007117035845425562\n",
      "Episode average V value: 0.05780923259097805\n",
      "epoch 3:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:366: RuntimeWarning: invalid value encountered in divide\n",
      "  dist_matrix = dist_matrix/np.nanpercentile(dist_matrix.flatten(), 99)\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:403: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0943,  0.2804,  0.1511,  0.2016, -0.3967, -0.2029, -0.3867,  0.0124,\n",
      "         0.1090,  0.0925]) tensor([ 0.2594,  0.5367, -0.1355,  0.4488, -0.8239, -0.4251, -0.3298, -0.1265,\n",
      "        -0.0247, -0.2554]) tensor([ 0.1018,  0.2898,  0.1600,  0.2079, -0.3763, -0.1905, -0.3653,  0.0061,\n",
      "         0.1096,  0.0917])\n",
      "R[0]\n",
      "tensor([0.0751], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06273420323431492; R = 0.011617353445850312;                 Gamma = 0.7194670553207397; Q = 0.0006751020355441142;\n",
      "Entropy Neighbor = 0.8411960542201996;                 Entropy Random = 0.6372062109708786;                 Volume = 0.0015386807769536973; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0712,  0.3117,  0.1513,  0.2001, -0.4011, -0.2293, -0.4490,  0.0395,\n",
      "         0.0754,  0.1229]) tensor([ 0.2174,  0.5439, -0.1337,  0.4110, -0.8119, -0.4479, -0.3661, -0.0901,\n",
      "        -0.0735, -0.2355]) tensor([ 0.0712,  0.3117,  0.1513,  0.2001, -0.4011, -0.2293, -0.4490,  0.0395,\n",
      "         0.0754,  0.1229])\n",
      "R[0]\n",
      "tensor([0.0551], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06315904416143894; R = 0.012286156255751848;                 Gamma = 0.7191957434415818; Q = 0.0012367709724057931;\n",
      "Entropy Neighbor = 0.815774529337883;                 Entropy Random = 0.568278746008873;                 Volume = 0.0018726802691817284; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0788,  0.3197,  0.1555,  0.2078, -0.4034, -0.2253, -0.4520,  0.0323,\n",
      "         0.0826,  0.1206]) tensor([ 0.2279,  0.5435, -0.1311,  0.4167, -0.8186, -0.4346, -0.3491, -0.1246,\n",
      "        -0.0340, -0.2423]) tensor([ 0.0788,  0.3197,  0.1555,  0.2078, -0.4034, -0.2253, -0.4520,  0.0323,\n",
      "         0.0826,  0.1206])\n",
      "R[0]\n",
      "tensor([0.0968], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06383470031619072; R = 0.013226305276155472;                 Gamma = 0.7201047599315643; Q = 0.0010431629244703798;\n",
      "Entropy Neighbor = 0.7984931576251983;                 Entropy Random = 0.5501511514186859;                 Volume = 0.001685225360095501; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1421,  0.3296,  0.1780,  0.2154, -0.3858, -0.1937, -0.3790,  0.0152,\n",
      "         0.1298,  0.0830]) tensor([ 0.2878,  0.5576, -0.1080,  0.4227, -0.7947, -0.4135, -0.2937, -0.1172,\n",
      "        -0.0215, -0.2757]) tensor([ 0.1421,  0.3296,  0.1780,  0.2154, -0.3858, -0.1937, -0.3790,  0.0152,\n",
      "         0.1298,  0.0830])\n",
      "R[0]\n",
      "tensor([0.0581], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06451004081964493; R = 0.01369510619342327;                 Gamma = 0.7208526486158371; Q = 0.0018233716185786762;\n",
      "Entropy Neighbor = 0.7596052720546722;                 Entropy Random = 0.4713879849910736;                 Volume = 0.002379245761781931; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0675,  0.3168,  0.1612,  0.2275, -0.4089, -0.2182, -0.4428,  0.0266,\n",
      "         0.0792,  0.1229]) tensor([ 0.2166,  0.5407, -0.1253,  0.4368, -0.8242, -0.4275, -0.3399, -0.1305,\n",
      "        -0.0367, -0.2399]) tensor([ 0.0675,  0.3168,  0.1612,  0.2275, -0.4089, -0.2182, -0.4428,  0.0266,\n",
      "         0.0792,  0.1229])\n",
      "R[0]\n",
      "tensor([0.0981], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06567113163322211; R = 0.015044605896808207;                 Gamma = 0.7208943392038345; Q = 0.0015805816042702644;\n",
      "Entropy Neighbor = 0.7343568307161331;                 Entropy Random = 0.4582410082221031;                 Volume = 0.0021303205378353594; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0012717978310538456\n",
      "Episode average V value: 0.15195090278014542\n",
      "epoch 4:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 57.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 56.99430056994301 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:268: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  torch.as_tensor([action_encoding]).to(device)\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0862,  0.3218,  0.1659,  0.2188, -0.4261, -0.2309, -0.4521,  0.0453,\n",
      "         0.0886,  0.1107]) tensor([ 0.2514,  0.5783, -0.1210,  0.4653, -0.8531, -0.4533, -0.3953, -0.0922,\n",
      "        -0.0472, -0.2373]) tensor([ 0.0781,  0.3371,  0.1835,  0.2206, -0.4203, -0.2194, -0.4624,  0.0465,\n",
      "         0.0793,  0.1172])\n",
      "R[0]\n",
      "tensor([0.0714], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06627194117754698; R = 0.015919183759950103;                 Gamma = 0.7198234907388688; Q = 0.002464969843160361;\n",
      "Entropy Neighbor = 0.678620010137558;                 Entropy Random = 0.3696032619476318;                 Volume = 0.0034313320443034173; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2023,  0.3779,  0.2256,  0.2845, -0.4296, -0.1868, -0.3937,  0.0097,\n",
      "         0.1845,  0.0944]) tensor([ 0.3501,  0.5926, -0.0632,  0.4852, -0.8405, -0.3977, -0.2853, -0.1508,\n",
      "         0.0618, -0.2696]) tensor([ 0.1549,  0.3636,  0.2018,  0.2791, -0.4305, -0.1989, -0.4146,  0.0058,\n",
      "         0.1505,  0.0947])\n",
      "R[0]\n",
      "tensor([0.0996], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0674729751944542; R = 0.016386698331683873;                 Gamma = 0.7204279081821442; Q = 0.0018724355077138172;\n",
      "Entropy Neighbor = 0.6581725513935089;                 Entropy Random = 0.34992400220036507;                 Volume = 0.0032481761388480665; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2420,  0.2808,  0.1695,  0.1915, -0.1860, -0.1818, -0.2164,  0.0951,\n",
      "         0.2000,  0.0398]) tensor([ 0.3868,  0.4898, -0.1187,  0.3873, -0.5960, -0.3920, -0.1026, -0.0733,\n",
      "         0.0821, -0.3252]) tensor([ 0.4002,  0.3253,  0.2314,  0.2311,  0.0394, -0.1460, -0.0531,  0.1687,\n",
      "         0.2514, -0.0340])\n",
      "R[0]\n",
      "tensor([0.1046], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.06946663912385702; R = 0.01887556687463075;                 Gamma = 0.7194239051342011; Q = 0.002751533392351121;\n",
      "Entropy Neighbor = 0.6124458144903183;                 Entropy Random = 0.2497117347717285;                 Volume = 0.004492450293153524; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0778, -0.0337, -0.0330,  0.0463, -0.1521, -0.2282, -0.2364,  0.1612,\n",
      "        -0.0027, -0.0010]) tensor([ 0.0666,  0.2076, -0.3123,  0.2657, -0.5698, -0.4421, -0.1551,  0.0258,\n",
      "        -0.1315, -0.3586]) tensor([-0.0098, -0.1249, -0.0464,  0.0149, -0.1218, -0.2713, -0.1756,  0.2748,\n",
      "         0.0560, -0.0188])\n",
      "R[0]\n",
      "tensor([0.0687], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07080580691993237; R = 0.020039539713412522;                 Gamma = 0.7191383628845215; Q = 0.0024647166886134072;\n",
      "Entropy Neighbor = 0.5922691630125045;                 Entropy Random = 0.2331041777431965;                 Volume = 0.004739748898893594; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0517,  0.3369,  0.2411,  0.1671, -0.4033, -0.1927, -0.5199,  0.1234,\n",
      "         0.0414,  0.1124]) tensor([ 0.2005,  0.5604, -0.0449,  0.3781, -0.8209, -0.3999, -0.4177, -0.0337,\n",
      "        -0.0755, -0.2503]) tensor([ 0.0545,  0.3405,  0.2491,  0.1658, -0.4026, -0.1884, -0.5235,  0.1271,\n",
      "         0.0421,  0.1179])\n",
      "R[0]\n",
      "tensor([0.0961], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07150785692036152; R = 0.021797600915655493;                 Gamma = 0.7194663052558898; Q = 0.0029789236872456966;\n",
      "Entropy Neighbor = 0.5657901415228843;                 Entropy Random = 0.18002859359979628;                 Volume = 0.005530203234404326; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0025065158238168806\n",
      "Episode average V value: 0.30618712684586646\n",
      "epoch 5:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 99.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 98.99010098990101 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 1.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0220,  0.2699,  0.2421,  0.0979, -0.3401, -0.1660, -0.5170,  0.1697,\n",
      "        -0.0412,  0.1313]) tensor([ 0.1267,  0.4967, -0.0421,  0.3143, -0.7614, -0.3706, -0.4166,  0.0117,\n",
      "        -0.1517, -0.2310]) tensor([-0.0066,  0.2835,  0.2525,  0.0945, -0.3115, -0.1585, -0.5059,  0.1804,\n",
      "        -0.0369,  0.1270])\n",
      "R[0]\n",
      "tensor([0.0986], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07285787776857615; R = 0.023396272771060468;                 Gamma = 0.7183314474821091; Q = 0.002355642563547008;\n",
      "Entropy Neighbor = 0.5471491819024086;                 Entropy Random = 0.169674096763134;                 Volume = 0.005264438662678003; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0249,  0.3139,  0.2976,  0.0991, -0.3465, -0.1520, -0.5289,  0.2027,\n",
      "        -0.0172,  0.1292]) tensor([ 0.1728,  0.5366,  0.0125,  0.3123, -0.7667, -0.3567, -0.4264,  0.0434,\n",
      "        -0.1312, -0.2338]) tensor([-0.0077,  0.2912,  0.2700,  0.0952, -0.3321, -0.1561, -0.5227,  0.1895,\n",
      "        -0.0333,  0.1324])\n",
      "R[0]\n",
      "tensor([0.0979], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0735213513225317; R = 0.025429420415312053;                 Gamma = 0.7170317375659943; Q = 0.0031149311632616447;\n",
      "Entropy Neighbor = 0.5259338375329972;                 Entropy Random = 0.14594818802177906;                 Volume = 0.006222383450716734; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0031,  0.2375,  0.2155,  0.1415, -0.2790, -0.1584, -0.4288,  0.1453,\n",
      "        -0.0107,  0.1213]) tensor([ 0.1423,  0.4697, -0.0683,  0.3572, -0.6938, -0.3737, -0.3464,  0.0124,\n",
      "        -0.1530, -0.2372]) tensor([-0.0138,  0.2459,  0.2243,  0.1425, -0.2937, -0.1536, -0.4323,  0.1410,\n",
      "        -0.0243,  0.1329])\n",
      "R[0]\n",
      "tensor([0.0605], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07448679056763649; R = 0.026471016105264426;                 Gamma = 0.7175839558839798; Q = 0.002406788403983228;\n",
      "Entropy Neighbor = 0.515378491461277;                 Entropy Random = 0.13843359218537807;                 Volume = 0.005669904679059983; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0664, -0.4078, -0.0110,  0.0767,  0.7414, -0.0168,  0.3582,  0.3269,\n",
      "        -0.1563, -0.0822]) tensor([ 0.0797, -0.2067, -0.2905,  0.2902,  0.3259, -0.2306,  0.4722,  0.1215,\n",
      "        -0.2563, -0.4380]) tensor([-0.0530, -0.3628,  0.1776,  0.2327,  0.7820,  0.1670,  0.4543,  0.1494,\n",
      "        -0.2640,  0.0079])\n",
      "R[0]\n",
      "tensor([0.1747], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07560389226675034; R = 0.03003649508394301;                 Gamma = 0.7165245411396026; Q = 0.003174868579371832;\n",
      "Entropy Neighbor = 0.49834116637706755;                 Entropy Random = 0.13120189216732978;                 Volume = 0.007490382269024849; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2112,  0.2325,  0.2021,  0.1785, -0.0112, -0.1391, -0.1555,  0.2075,\n",
      "         0.1591,  0.0344]) tensor([ 0.3514,  0.4454, -0.0859,  0.3760, -0.4171, -0.3580, -0.0608,  0.0626,\n",
      "         0.0116, -0.3277]) tensor([ 0.2609,  0.3208,  0.2495,  0.2040, -0.0054, -0.1118, -0.1525,  0.1810,\n",
      "         0.1746,  0.0353])\n",
      "R[0]\n",
      "tensor([0.0674], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07556262089312077; R = 0.030170392107218506;                 Gamma = 0.7160530340671539; Q = 0.002403647822793573;\n",
      "Entropy Neighbor = 0.4901885590553284;                 Entropy Random = 0.12605096645653247;                 Volume = 0.0068474473692476745; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0026911757065914573\n",
      "Episode average V value: 0.44682624388635156\n",
      "epoch 6:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 119.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 118.98810118988101 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0474,  0.1160,  0.1199,  0.0952, -0.0529, -0.1407, -0.2965,  0.1672,\n",
      "        -0.0609,  0.1051]) tensor([ 0.1168,  0.3746, -0.1649,  0.3504, -0.4856, -0.3592, -0.2417,  0.0235,\n",
      "        -0.1806, -0.2429]) tensor([-0.2384,  0.0349,  0.1422,  0.0345, -0.1720, -0.1292, -0.4082,  0.1874,\n",
      "        -0.1829,  0.1675])\n",
      "R[0]\n",
      "tensor([0.0827], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07526154637336731; R = 0.03142352532222867;                 Gamma = 0.7138921304941177; Q = 0.003425708547816612;\n",
      "Entropy Neighbor = 0.472198095202446;                 Entropy Random = 0.12081430124491453;                 Volume = 0.007926449485123157; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0887,  0.1770,  0.1250,  0.1372, -0.0490, -0.1494, -0.1896,  0.1501,\n",
      "         0.0831,  0.0669]) tensor([ 0.2314,  0.4004, -0.1605,  0.3445, -0.4593, -0.3670, -0.1013,  0.0093,\n",
      "        -0.0578, -0.2932]) tensor([ 0.1035,  0.1885,  0.1451,  0.1115, -0.0902, -0.1662, -0.2414,  0.1886,\n",
      "         0.0923,  0.0549])\n",
      "R[0]\n",
      "tensor([0.0672], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07639654910564422; R = 0.03329636987671256;                 Gamma = 0.7148314335346222; Q = 0.0026483140202471986;\n",
      "Entropy Neighbor = 0.46261081349849703;                 Entropy Random = 0.11901883099228144;                 Volume = 0.007847413141280412; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3059,  0.3572,  0.3063,  0.2395,  0.0052, -0.1384, -0.1534,  0.2374,\n",
      "         0.2309,  0.0163]) tensor([ 0.4641,  0.5888,  0.0147,  0.4674, -0.4147, -0.3612, -0.0813,  0.0832,\n",
      "         0.0921, -0.3368]) tensor([ 0.3059,  0.3572,  0.3063,  0.2395,  0.0052, -0.1384, -0.1534,  0.2374,\n",
      "         0.2309,  0.0163])\n",
      "R[0]\n",
      "tensor([0.0790], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07693962314724923; R = 0.034703401107341054;                 Gamma = 0.7142869943380356; Q = 0.0029182815966196356;\n",
      "Entropy Neighbor = 0.4592242478132248;                 Entropy Random = 0.12021211241185666;                 Volume = 0.008590134844183922; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0662,  0.1766,  0.1352,  0.0939, -0.2022, -0.1770, -0.3994,  0.1588,\n",
      "        -0.0235,  0.1321]) tensor([ 0.0989,  0.4369, -0.1495,  0.3494, -0.6352, -0.3955, -0.3459,  0.0188,\n",
      "        -0.1477, -0.2152]) tensor([-0.2099,  0.0569,  0.1453,  0.0272, -0.0339, -0.0888, -0.3465,  0.1885,\n",
      "        -0.1955,  0.1422])\n",
      "R[0]\n",
      "tensor([0.0779], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07686118364334106; R = 0.034974785750731825;                 Gamma = 0.7140688003301621; Q = 0.00217869248741772;\n",
      "Entropy Neighbor = 0.4641657362580299;                 Entropy Random = 0.12412761622667312;                 Volume = 0.008020312964916228; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0323,  0.1733,  0.1568,  0.0685, -0.0449, -0.1294, -0.3123,  0.2003,\n",
      "        -0.0137,  0.1227]) tensor([ 0.1145,  0.3940, -0.1281,  0.2823, -0.4650, -0.3341, -0.2078,  0.0350,\n",
      "        -0.1173, -0.2407]) tensor([-0.0585,  0.1707,  0.1517,  0.0485, -0.0892, -0.1477, -0.3606,  0.2091,\n",
      "        -0.0274,  0.1250])\n",
      "R[0]\n",
      "tensor([0.1067], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07734994947910309; R = 0.03679630722105503;                 Gamma = 0.7141845905780793; Q = 0.002567794056609273;\n",
      "Entropy Neighbor = 0.45801838165521624;                 Entropy Random = 0.12212428195774555;                 Volume = 0.010682663232088089; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.002747758141742088\n",
      "Episode average V value: 0.5637912408351898\n",
      "epoch 7:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 123.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 122.98770122987702 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0547,  0.2873,  0.2274,  0.1551, -0.3249, -0.1563, -0.4074,  0.1054,\n",
      "         0.0913,  0.1071]) tensor([ 0.1997,  0.5155, -0.0578,  0.3668, -0.7374, -0.3729, -0.3232, -0.0275,\n",
      "        -0.0558, -0.2518]) tensor([ 0.1044,  0.3185,  0.2424,  0.1908, -0.3346, -0.1529, -0.3921,  0.0859,\n",
      "         0.1189,  0.1005])\n",
      "R[0]\n",
      "tensor([0.0604], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07788006852567196; R = 0.038441196633502844;                 Gamma = 0.7126074876785279; Q = 0.0022373276885482483;\n",
      "Entropy Neighbor = 0.45618480747938156;                 Entropy Random = 0.12405283932387828;                 Volume = 0.011944755986332893; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0778,  0.2109,  0.1304,  0.1690,  0.1548, -0.1083, -0.0743,  0.1856,\n",
      "         0.0796,  0.0091]) tensor([ 0.2398,  0.4577, -0.1579,  0.4127, -0.2719, -0.3304, -0.0127,  0.0341,\n",
      "        -0.0448, -0.3403]) tensor([ 0.1182,  0.1900,  0.1485,  0.2298,  0.2089, -0.1006,  0.0269,  0.1842,\n",
      "         0.1309,  0.0088])\n",
      "R[0]\n",
      "tensor([0.0869], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07937437149882316; R = 0.03977397799491882;                 Gamma = 0.7144169261455536; Q = 0.002607689482276328;\n",
      "Entropy Neighbor = 0.450995898604393;                 Entropy Random = 0.12777819437533616;                 Volume = 0.015568020522594452; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1989,  0.1453,  0.1529,  0.0395, -0.1726, -0.1349, -0.4080,  0.1815,\n",
      "        -0.0963,  0.1567]) tensor([-0.0496,  0.3775, -0.1293,  0.2648, -0.5987, -0.3368, -0.3110,  0.0220,\n",
      "        -0.1942, -0.2048]) tensor([-0.0413,  0.2238,  0.1280,  0.1889, -0.0707, -0.1508, -0.2321,  0.1223,\n",
      "         0.0365,  0.1180])\n",
      "R[0]\n",
      "tensor([0.1073], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07911123409867286; R = 0.03888253523036837;                 Gamma = 0.7139216074943543; Q = 0.0021942310889717194;\n",
      "Entropy Neighbor = 0.44513845908641814;                 Entropy Random = 0.1275534592345357;                 Volume = 0.01354932590946555; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0244, -0.3074,  0.2911,  0.1593,  0.9796,  0.2501,  0.4377,  0.2421,\n",
      "        -0.3637,  0.0658]) tensor([ 0.1703, -0.1201,  0.0084,  0.3705,  0.5675,  0.0343,  0.5562,  0.0272,\n",
      "        -0.4642, -0.2907]) tensor([-0.4481, -0.4231,  0.3839,  0.1984,  1.1866,  0.4369,  0.4110,  0.2170,\n",
      "        -0.9070,  0.0394])\n",
      "R[0]\n",
      "tensor([0.1782], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.07980570018291473; R = 0.04129266534373164;                 Gamma = 0.7145638381242752; Q = 0.0023944297081325205;\n",
      "Entropy Neighbor = 0.4452975375056267;                 Entropy Random = 0.13650778286159038;                 Volume = 0.015068953689187765; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1906,  0.2583,  0.1706,  0.2167,  0.1397, -0.1416,  0.0241,  0.2123,\n",
      "         0.2434,  0.0469]) tensor([ 0.3324,  0.4567, -0.1186,  0.4063, -0.2683, -0.3516,  0.1449,  0.0330,\n",
      "         0.1304, -0.3197]) tensor([ 0.1614,  0.1560,  0.1352,  0.2373,  0.2542, -0.1270,  0.1391,  0.2199,\n",
      "         0.2319,  0.0492])\n",
      "R[0]\n",
      "tensor([0.1155], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08024705684185028; R = 0.04252232665009797;                 Gamma = 0.7146129001379014; Q = 0.002209942341723945;\n",
      "Entropy Neighbor = 0.44289161515235903;                 Entropy Random = 0.1370802482664585;                 Volume = 0.013698404349386692; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.002328724061930552\n",
      "Episode average V value: 0.6720579455494881\n",
      "epoch 8:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 131.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 130.986901309869 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0827,  0.2067,  0.1498,  0.0349,  0.0534, -0.0952, -0.2507,  0.2067,\n",
      "        -0.0470,  0.0984]) tensor([ 0.0650,  0.4294, -0.1346,  0.2515, -0.3682, -0.3002, -0.1486,  0.0401,\n",
      "        -0.1482, -0.2636]) tensor([-0.0827,  0.2067,  0.1498,  0.0349,  0.0534, -0.0952, -0.2507,  0.2067,\n",
      "        -0.0470,  0.0984])\n",
      "R[0]\n",
      "tensor([0.1094], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08064424785971641; R = 0.04247652554884553;                 Gamma = 0.713564034819603; Q = 0.0027273431858047844;\n",
      "Entropy Neighbor = 0.43740156131982805;                 Entropy Random = 0.13537940408289434;                 Volume = 0.014784607514739036; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0225,  0.3011,  0.2085,  0.1560, -0.1900, -0.1365, -0.3067,  0.1300,\n",
      "         0.0721,  0.1055]) tensor([ 0.1701,  0.5195, -0.0779,  0.3652, -0.6071, -0.3436, -0.2012, -0.0343,\n",
      "        -0.0389, -0.2576]) tensor([ 0.1735,  0.3199,  0.1848,  0.2082, -0.0450, -0.1572, -0.1532,  0.1497,\n",
      "         0.1983,  0.0598])\n",
      "R[0]\n",
      "tensor([0.1061], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08108643141388894; R = 0.043472894966602324;                 Gamma = 0.7145606904029846; Q = 0.0022433264481369407;\n",
      "Entropy Neighbor = 0.43854376262426376;                 Entropy Random = 0.1374175198674202;                 Volume = 0.013495072185993195; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3731, -0.1147,  0.1666, -0.1395,  0.4382,  0.0070, -0.1029,  0.4323,\n",
      "        -0.4568, -0.0030]) tensor([-0.2197,  0.1132, -0.1078,  0.1011,  0.0063, -0.2008, -0.0117,  0.2458,\n",
      "        -0.5583, -0.3522]) tensor([-0.1580, -0.0869,  0.0830,  0.0038,  0.5940, -0.0718,  0.1335,  0.4471,\n",
      "        -0.1817, -0.0436])\n",
      "R[0]\n",
      "tensor([0.1602], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08167594029009342; R = 0.04517945781722665;                 Gamma = 0.7146512886285782; Q = 0.002400805878220126;\n",
      "Entropy Neighbor = 0.42678394079208376;                 Entropy Random = 0.13291182808578014;                 Volume = 0.015009249523282052; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3654, -0.4142,  0.4164,  0.3466,  1.2369,  0.4793,  0.6517,  0.1416,\n",
      "        -0.8141,  0.0533]) tensor([-0.2157, -0.2121,  0.1382,  0.5741,  0.8178,  0.2630,  0.7601, -0.0764,\n",
      "        -0.8953, -0.2980]) tensor([-0.0521,  0.1811,  0.1402,  0.1079,  0.1048, -0.1055, -0.0970,  0.1944,\n",
      "         0.0226,  0.1123])\n",
      "R[0]\n",
      "tensor([0.1929], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08264528851211071; R = 0.04723795608989895;                 Gamma = 0.7146021822690963; Q = 0.002177715291036293;\n",
      "Entropy Neighbor = 0.42440639150142667;                 Entropy Random = 0.13421396766602994;                 Volume = 0.014715381678193808; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3806, -0.0863,  0.1835, -0.0756,  0.2392,  0.0122, -0.1812,  0.3318,\n",
      "        -0.4195,  0.0809]) tensor([-0.2155,  0.1852, -0.0939,  0.1986, -0.2067, -0.1981, -0.1323,  0.1819,\n",
      "        -0.5141, -0.2640]) tensor([-0.3681, -0.5094, -0.0703, -0.0766,  0.6545, -0.0647,  0.2220,  0.4395,\n",
      "        -0.3603, -0.0076])\n",
      "R[0]\n",
      "tensor([0.1010], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08314838719367981; R = 0.047667706467211246;                 Gamma = 0.7147728959321976; Q = 0.0019323831857182086;\n",
      "Entropy Neighbor = 0.41753440445661544;                 Entropy Random = 0.12680158245563508;                 Volume = 0.01691037530452013; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0022963147977832707\n",
      "Episode average V value: 0.7759314191102982\n",
      "epoch 9:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0730, -0.4412,  0.0586, -0.2489,  0.9045, -0.1004,  0.3017,  0.7530,\n",
      "        -0.2029, -0.1215]) tensor([ 0.2018, -0.2292, -0.2181, -0.0440,  0.4857, -0.3037,  0.4072,  0.5836,\n",
      "        -0.3047, -0.4869]) tensor([ 0.1732,  0.2941,  0.2045,  0.1195,  0.0908, -0.1155, -0.0858,  0.2371,\n",
      "         0.1706,  0.0682])\n",
      "R[0]\n",
      "tensor([0.0936], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08324918159842491; R = 0.04796348936110735;                 Gamma = 0.7149710056781768; Q = 0.001966897225996945;\n",
      "Entropy Neighbor = 0.4162300279736519;                 Entropy Random = 0.12573074480891228;                 Volume = 0.0169328679703176; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1370,  0.3002,  0.2215,  0.1662,  0.1502, -0.0847, -0.0294,  0.2313,\n",
      "         0.1364,  0.0434]) tensor([ 0.2805,  0.5036, -0.0666,  0.3625, -0.2615, -0.2937,  0.0867,  0.0534,\n",
      "         0.0255, -0.3214]) tensor([ 0.1870,  0.2709,  0.2296,  0.1912,  0.2800, -0.0680,  0.0930,  0.2482,\n",
      "         0.1846,  0.0425])\n",
      "R[0]\n",
      "tensor([0.1153], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08378025919198989; R = 0.049085103435441854;                 Gamma = 0.7149117990732193; Q = 0.0019646047815913333;\n",
      "Entropy Neighbor = 0.4133197631239891;                 Entropy Random = 0.11934868312627077;                 Volume = 0.018880318988114594; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 1.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2595,  0.0213,  0.0028,  0.1279, -0.3305, -0.2245, -0.3624,  0.0654,\n",
      "        -0.0049,  0.2410]) tensor([-0.1105,  0.2569, -0.2786,  0.3534, -0.7557, -0.4260, -0.2643, -0.0913,\n",
      "        -0.0984, -0.1216]) tensor([-0.0164,  0.2963,  0.2019,  0.1186,  0.0724, -0.0763, -0.1629,  0.1953,\n",
      "         0.0128,  0.0885])\n",
      "R[0]\n",
      "tensor([0.1124], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08426285941898823; R = 0.050223833670839664;                 Gamma = 0.7137513401508331; Q = 0.0018665936319739557;\n",
      "Entropy Neighbor = 0.4055084373354912;                 Entropy Random = 0.117926992662251;                 Volume = 0.01901943902671337; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3295, -0.1627, -0.0222, -0.0622,  0.1842, -0.1309, -0.0858,  0.3278,\n",
      "        -0.1961,  0.0498]) tensor([-0.1862,  0.0828, -0.2980,  0.1697, -0.2423, -0.3386, -0.0071,  0.1855,\n",
      "        -0.3049, -0.3073]) tensor([-0.4437, -0.2105,  0.1100, -0.0781,  0.3240,  0.0284, -0.0575,  0.3009,\n",
      "        -0.4201,  0.0958])\n",
      "R[0]\n",
      "tensor([0.0837], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08442536363005639; R = 0.05020185850374401;                 Gamma = 0.71448315513134; Q = 0.0019514374380232766;\n",
      "Entropy Neighbor = 0.4085559097528458;                 Entropy Random = 0.11506949484348297;                 Volume = 0.018049373880028724; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0731,  0.2655,  0.2576,  0.1284,  0.1586, -0.0673, -0.0310,  0.2779,\n",
      "         0.1071,  0.0659]) tensor([ 0.2228,  0.4599, -0.0290,  0.3336, -0.2519, -0.2852,  0.0786,  0.0893,\n",
      "        -0.0301, -0.2890]) tensor([ 0.0731,  0.2655,  0.2576,  0.1284,  0.1586, -0.0673, -0.0310,  0.2779,\n",
      "         0.1071,  0.0659])\n",
      "R[0]\n",
      "tensor([0.1522], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08523653057217598; R = 0.05272031832486391;                 Gamma = 0.7149636920690536; Q = 0.0016473650521948002;\n",
      "Entropy Neighbor = 0.3982280912399292;                 Entropy Random = 0.1131130177155137;                 Volume = 0.018894483640789987; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0018793796259560622\n",
      "Episode average V value: 0.8501908609083816\n",
      "epoch 10:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 136.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 135.986401359864 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2376, -0.2247,  0.4780,  0.3291,  0.9100,  0.4314,  0.4546,  0.0783,\n",
      "        -0.5569,  0.1549]) tensor([-0.0964, -0.0100,  0.1955,  0.5571,  0.4904,  0.2203,  0.5483, -0.0963,\n",
      "        -0.6460, -0.2060]) tensor([-0.1624, -0.1465,  0.3157,  0.3360,  0.4965,  0.1477,  0.3405,  0.1392,\n",
      "        -0.1517,  0.2060])\n",
      "R[0]\n",
      "tensor([0.1168], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08575585988163949; R = 0.05372972232662141;                 Gamma = 0.7147860589027405; Q = 0.002391118438448757;\n",
      "Entropy Neighbor = 0.3961644852757454;                 Entropy Random = 0.10986386201530694;                 Volume = 0.0220870842076838; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0501,  0.2730,  0.2449,  0.0520, -0.0345, -0.0645, -0.2776,  0.2136,\n",
      "         0.0045,  0.1187]) tensor([ 0.0944,  0.5001, -0.0399,  0.2687, -0.4506, -0.2793, -0.1950,  0.0750,\n",
      "        -0.1347, -0.2395]) tensor([-0.0623,  0.2419,  0.2180,  0.0511, -0.0490, -0.0775, -0.2755,  0.2061,\n",
      "         0.0031,  0.1263])\n",
      "R[0]\n",
      "tensor([0.0683], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08537153419852257; R = 0.05213232820667327;                 Gamma = 0.714949030995369; Q = 0.0019116718374425545;\n",
      "Entropy Neighbor = 0.4012086768746376;                 Entropy Random = 0.11392942135035991;                 Volume = 0.019724561281502247; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0366,  0.3117,  0.2509,  0.1043,  0.0467, -0.0456, -0.1955,  0.2046,\n",
      "        -0.0033,  0.0980]) tensor([ 0.1171,  0.5183, -0.0344,  0.3212, -0.3686, -0.2631, -0.0963,  0.0252,\n",
      "        -0.1395, -0.2540]) tensor([ 0.0125,  0.3354,  0.2706,  0.0470,  0.0362, -0.0725, -0.2439,  0.2742,\n",
      "         0.0239,  0.0661])\n",
      "R[0]\n",
      "tensor([0.1466], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08540582402050495; R = 0.05348700763657689;                 Gamma = 0.714968332529068; Q = 0.002078533594380133;\n",
      "Entropy Neighbor = 0.40355061101913453;                 Entropy Random = 0.11486632470041513;                 Volume = 0.02107674777135253; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0657,  0.2742,  0.2911,  0.1221,  0.2111, -0.0262, -0.0164,  0.2778,\n",
      "         0.0873,  0.0681]) tensor([ 0.2090,  0.4775,  0.0039,  0.3226, -0.2038, -0.2326,  0.0992,  0.0978,\n",
      "        -0.0190, -0.2968]) tensor([ 0.1804,  0.2853,  0.2327,  0.1148,  0.3096, -0.0859,  0.0779,  0.3305,\n",
      "         0.1741,  0.0184])\n",
      "R[0]\n",
      "tensor([0.1197], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08576316893100738; R = 0.05472689116746187;                 Gamma = 0.7160929116010666; Q = 0.0017834683296387083;\n",
      "Entropy Neighbor = 0.39886279755830767;                 Entropy Random = 0.11253535006195307;                 Volume = 0.022511794827878476; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1173, -0.7528, -0.0756, -0.4101,  0.8065, -0.1538,  0.2188,  0.8138,\n",
      "        -0.2782, -0.1606]) tensor([ 0.0115, -0.5242, -0.3450, -0.1900,  0.3771, -0.3488,  0.3183,  0.6498,\n",
      "        -0.3631, -0.5249]) tensor([-0.0807,  0.2309,  0.2390,  0.0833,  0.1260, -0.0542, -0.1033,  0.2684,\n",
      "        -0.0040,  0.1031])\n",
      "R[0]\n",
      "tensor([0.0977], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08723878639936447; R = 0.05528225397504866;                 Gamma = 0.7149598129987716; Q = 0.0018432992086163723;\n",
      "Entropy Neighbor = 0.3952990710735321;                 Entropy Random = 0.11058998921513558;                 Volume = 0.02725182918831706; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.002001618281705305\n",
      "Episode average V value: 0.8895948171806488\n",
      "epoch 11:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-4.4794e-02,  3.4715e-01,  3.4513e-01,  1.3738e-01,  1.2825e-01,\n",
      "         1.7963e-04, -1.2687e-01,  2.5663e-01, -1.3194e-03,  8.6827e-02]) tensor([ 0.1180,  0.5934,  0.0576,  0.3870, -0.3034, -0.2186, -0.0674,  0.1036,\n",
      "        -0.1249, -0.2614]) tensor([-0.1936,  0.2782,  0.2635,  0.0516,  0.1055, -0.0353, -0.1907,  0.2716,\n",
      "        -0.1154,  0.1000])\n",
      "R[0]\n",
      "tensor([0.0899], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08740072514116765; R = 0.05505685520917177;                 Gamma = 0.7154669815301895; Q = 0.0019999766182736494;\n",
      "Entropy Neighbor = 0.3923661119937897;                 Entropy Random = 0.11066897106170655;                 Volume = 0.02683261024579406; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2146,  0.3739,  0.3402,  0.1756,  0.3741, -0.0190,  0.1137,  0.3209,\n",
      "         0.1791,  0.0016]) tensor([ 0.3556,  0.5653,  0.0503,  0.3630, -0.0341, -0.2291,  0.2369,  0.1340,\n",
      "         0.0652, -0.3646]) tensor([0.1422, 0.2281, 0.3078, 0.1386, 0.4739, 0.0220, 0.1957, 0.3162, 0.0941,\n",
      "        0.0374])\n",
      "R[0]\n",
      "tensor([0.1200], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08811532334983349; R = 0.05628287208266556;                 Gamma = 0.715715868473053; Q = 0.0019949341523461043;\n",
      "Entropy Neighbor = 0.389480462372303;                 Entropy Random = 0.11074342441558838;                 Volume = 0.02964840041846037; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3051,  0.1419,  0.2674,  0.0188,  0.1530,  0.0305, -0.1571,  0.2693,\n",
      "        -0.2568,  0.1246]) tensor([-0.1592,  0.3804, -0.0122,  0.2513, -0.2724, -0.1797, -0.0804,  0.1261,\n",
      "        -0.3753, -0.2314]) tensor([-0.3423,  0.0895,  0.3752,  0.0030,  0.1410,  0.0910, -0.1553,  0.3174,\n",
      "        -0.3181,  0.1495])\n",
      "R[0]\n",
      "tensor([0.0822], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08804682306945324; R = 0.05693626624532044;                 Gamma = 0.7153288633823395; Q = 0.0019497827648883685;\n",
      "Entropy Neighbor = 0.38758678632974625;                 Entropy Random = 0.10897827015072108;                 Volume = 0.029135037917643786; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1111,  0.3496,  0.3230,  0.1171,  0.1460, -0.0197, -0.0570,  0.2552,\n",
      "         0.1114,  0.0519]) tensor([ 0.2616,  0.5427,  0.0354,  0.3221, -0.2641, -0.2384,  0.0516,  0.0673,\n",
      "        -0.0296, -0.3023]) tensor([ 0.0262,  0.2889,  0.3358,  0.1104,  0.1633, -0.0015, -0.0514,  0.2640,\n",
      "         0.0692,  0.1048])\n",
      "R[0]\n",
      "tensor([0.1503], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08845166637003422; R = 0.057007784957066175;                 Gamma = 0.7152375470399857; Q = 0.001958370985696092;\n",
      "Entropy Neighbor = 0.3841717653870583;                 Entropy Random = 0.10947957698255778;                 Volume = 0.02993997898697853; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0582,  0.2770,  0.2658,  0.0905, -0.0728, -0.0705, -0.2458,  0.2364,\n",
      "         0.0155,  0.1448]) tensor([ 0.0853,  0.5023, -0.0187,  0.3054, -0.4886, -0.2846, -0.1610,  0.0960,\n",
      "        -0.1233, -0.2141]) tensor([ 0.0385,  0.3580,  0.3094,  0.0949,  0.0393, -0.0518, -0.1790,  0.2781,\n",
      "         0.0649,  0.0778])\n",
      "R[0]\n",
      "tensor([0.0714], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08936384758353233; R = 0.05937769925408065;                 Gamma = 0.715093697309494; Q = 0.00189468793181004;\n",
      "Entropy Neighbor = 0.3813484551310539;                 Entropy Random = 0.10803508522361517;                 Volume = 0.03189799105748534; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.001959550490602851\n",
      "Episode average V value: 0.9622617355223988\n",
      "epoch 12:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1410,  0.3314,  0.3244,  0.0641,  0.0911, -0.0147, -0.1755,  0.2983,\n",
      "        -0.0714,  0.0942]) tensor([ 0.0230,  0.5847,  0.0394,  0.3198, -0.3446, -0.2318, -0.1201,  0.1474,\n",
      "        -0.1920, -0.2522]) tensor([-0.2834,  0.2040,  0.2779,  0.0178,  0.0573, -0.0083, -0.2287,  0.2873,\n",
      "        -0.1929,  0.1152])\n",
      "R[0]\n",
      "tensor([0.0898], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08957477414608002; R = 0.060139070477336645;                 Gamma = 0.7158863199949265; Q = 0.0018517279022489674;\n",
      "Entropy Neighbor = 0.38451024508476256;                 Entropy Random = 0.110325279019773;                 Volume = 0.034294454660266635; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0817,  0.3144,  0.2666,  0.0431,  0.0681, -0.0744, -0.1881,  0.3183,\n",
      "        -0.0038,  0.0759]) tensor([ 0.0708,  0.5214, -0.0173,  0.2599, -0.3493, -0.2899, -0.0882,  0.1373,\n",
      "        -0.1391, -0.2761]) tensor([-0.0743,  0.3333,  0.2743,  0.0898,  0.0829, -0.0484, -0.1675,  0.2700,\n",
      "        -0.0059,  0.0796])\n",
      "R[0]\n",
      "tensor([0.1474], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08885690374672413; R = 0.059076836455613374;                 Gamma = 0.7152497771978378; Q = 0.001801473145489581;\n",
      "Entropy Neighbor = 0.38244091379642486;                 Entropy Random = 0.11062909892946482;                 Volume = 0.03199781344085932; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4136,  0.0678,  0.2339, -0.0479,  0.1804,  0.0275, -0.1867,  0.3226,\n",
      "        -0.3827,  0.0915]) tensor([-0.2469,  0.3392, -0.0444,  0.2264, -0.2654, -0.1843, -0.1398,  0.1738,\n",
      "        -0.4826, -0.2519]) tensor([-0.2031, -0.3284,  0.0300,  0.0308,  0.5006, -0.0376,  0.2468,  0.3714,\n",
      "        -0.1706,  0.0190])\n",
      "R[0]\n",
      "tensor([0.1000], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08964410893619061; R = 0.06000598587282002;                 Gamma = 0.7153847004175187; Q = 0.0016892611577059141;\n",
      "Entropy Neighbor = 0.3762016983628273;                 Entropy Random = 0.11060051825642586;                 Volume = 0.03447952846810222; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0804,  0.2987,  0.2754,  0.0476,  0.1302, -0.0527, -0.1045,  0.3273,\n",
      "         0.0131,  0.0746]) tensor([ 0.0647,  0.5124, -0.0092,  0.2574, -0.2906, -0.2567,  0.0040,  0.1524,\n",
      "        -0.0900, -0.2881]) tensor([-0.1347,  0.2964,  0.2764,  0.0378,  0.1027, -0.0538, -0.1683,  0.3335,\n",
      "        -0.0337,  0.0770])\n",
      "R[0]\n",
      "tensor([0.1182], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.08906166343390942; R = 0.059349962515756485;                 Gamma = 0.714456496834755; Q = 0.00187569466244895;\n",
      "Entropy Neighbor = 0.3774895497560501;                 Entropy Random = 0.11019315171986818;                 Volume = 0.0336527039706707; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0785,  0.2472,  0.2652,  0.0626,  0.0364, -0.0370, -0.1985,  0.2558,\n",
      "        -0.0096,  0.1023]) tensor([ 0.0680,  0.4641, -0.0196,  0.2765, -0.3852, -0.2407, -0.0927,  0.0849,\n",
      "        -0.1120, -0.2604]) tensor([-0.0559,  0.2945,  0.2965,  0.0538,  0.0290, -0.0352, -0.2085,  0.2765,\n",
      "         0.0108,  0.0851])\n",
      "R[0]\n",
      "tensor([0.1158], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09093333446979522; R = 0.06163276131264865;                 Gamma = 0.7156196912527084; Q = 0.001951272631471511;\n",
      "Entropy Neighbor = 0.36907773816585543;                 Entropy Random = 0.10814967396855354;                 Volume = 0.03810442715883255; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0018338858998729847\n",
      "Episode average V value: 0.9888223591545939\n",
      "epoch 13:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4254,  0.0733,  0.2578, -0.0122,  0.2691,  0.0426, -0.0853,  0.3557,\n",
      "        -0.3730,  0.0855]) tensor([-0.2600,  0.3414, -0.0209,  0.2598, -0.1760, -0.1691, -0.0358,  0.2029,\n",
      "        -0.4709, -0.2588]) tensor([-0.2976, -0.2098,  0.2939,  0.1685,  0.4811,  0.1959,  0.2401,  0.1573,\n",
      "        -0.3471,  0.2394])\n",
      "R[0]\n",
      "tensor([0.1045], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.090015646353364; R = 0.06011982501670718;                 Gamma = 0.7156246424913406; Q = 0.0019575851927511392;\n",
      "Entropy Neighbor = 0.37122128933668136;                 Entropy Random = 0.10889028517156839;                 Volume = 0.03579046378284693; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0880, -0.0552,  0.1369, -0.1752,  0.3710, -0.0756,  0.0179,  0.5288,\n",
      "        -0.0714, -0.0808]) tensor([ 0.0702,  0.1976, -0.1430,  0.0776, -0.0678, -0.2872,  0.0803,  0.3687,\n",
      "        -0.1777, -0.4291]) tensor([-0.1197, -0.1274,  0.0988, -0.2134,  0.3884, -0.0915,  0.0125,  0.5636,\n",
      "        -0.1012, -0.0897])\n",
      "R[0]\n",
      "tensor([0.0978], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09027207686007023; R = 0.06273931749910117;                 Gamma = 0.7148313564062119; Q = 0.0018547387474100105;\n",
      "Entropy Neighbor = 0.3625709573626518;                 Entropy Random = 0.10342014882713556;                 Volume = 0.035257291946560146; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0484,  0.2751,  0.2988,  0.0454,  0.0408, -0.0256, -0.1926,  0.2757,\n",
      "         0.0101,  0.0844]) tensor([ 0.0975,  0.4898,  0.0137,  0.2575, -0.3803, -0.2293, -0.0857,  0.1038,\n",
      "        -0.0942, -0.2784]) tensor([-0.0484,  0.2751,  0.2988,  0.0454,  0.0408, -0.0256, -0.1926,  0.2757,\n",
      "         0.0101,  0.0844])\n",
      "R[0]\n",
      "tensor([0.1157], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0904076441079378; R = 0.06241846244223416;                 Gamma = 0.7156776373386383; Q = 0.0018573249671608209;\n",
      "Entropy Neighbor = 0.36297619980573653;                 Entropy Random = 0.10371320856362581;                 Volume = 0.03524054995551705; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3005, -0.2908,  0.2577,  0.1201,  0.5716,  0.1732,  0.2711,  0.2249,\n",
      "        -0.3760,  0.2277]) tensor([-0.1523, -0.0859, -0.0204,  0.3484,  0.1484, -0.0353,  0.3793,  0.0220,\n",
      "        -0.4693, -0.1270]) tensor([-0.0119, -0.1065,  0.5855,  0.1915,  0.9029,  0.3929,  0.4070,  0.2892,\n",
      "        -0.4187,  0.1405])\n",
      "R[0]\n",
      "tensor([0.1820], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09108722910284996; R = 0.06259202214330435;                 Gamma = 0.7151765960454941; Q = 0.001959258717834018;\n",
      "Entropy Neighbor = 0.3633973834514618;                 Entropy Random = 0.10381504451483488;                 Volume = 0.03630164466425777; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0497, -0.4734, -0.0211,  0.0456,  0.4854, -0.1264,  0.3455,  0.4156,\n",
      "         0.0585,  0.0271]) tensor([ 0.0815, -0.2602, -0.3002,  0.2509,  0.0698, -0.3315,  0.4512,  0.2509,\n",
      "        -0.0444, -0.3396]) tensor([-0.1357, -0.3044,  0.1310, -0.1161,  0.6950, -0.0265,  0.3410,  0.6120,\n",
      "        -0.1498, -0.0184])\n",
      "R[0]\n",
      "tensor([0.1023], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09151570372283459; R = 0.06357893075793981;                 Gamma = 0.7152392435073852; Q = 0.0017975699499365875;\n",
      "Entropy Neighbor = 0.3591931338310242;                 Entropy Random = 0.10373313477635383;                 Volume = 0.036460784655064346; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0018852955150185152\n",
      "Episode average V value: 1.0320211120396852\n",
      "epoch 14:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0293,  0.3811,  0.3065,  0.0737,  0.0435, -0.0636, -0.1828,  0.3034,\n",
      "         0.0045,  0.0596]) tensor([ 0.1169,  0.5957,  0.0212,  0.2824, -0.3760, -0.2693, -0.0756,  0.1312,\n",
      "        -0.1040, -0.3026]) tensor([-0.0922,  0.3057,  0.2702,  0.0389,  0.0296, -0.0779, -0.1918,  0.3211,\n",
      "        -0.0129,  0.0825])\n",
      "R[0]\n",
      "tensor([0.1127], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09160853190720081; R = 0.06372781167551875;                 Gamma = 0.7152248524427414; Q = 0.002165144625119865;\n",
      "Entropy Neighbor = 0.35778139543533327;                 Entropy Random = 0.10248285053670406;                 Volume = 0.03753773126006126; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0307,  0.2759,  0.2659,  0.0871,  0.2339, -0.0373,  0.0143,  0.3054,\n",
      "         0.0622,  0.0539]) tensor([ 0.1740,  0.4820, -0.0200,  0.2891, -0.1824, -0.2433,  0.1287,  0.1249,\n",
      "        -0.0422, -0.3101]) tensor([ 0.1087,  0.3040,  0.3233,  0.1116,  0.3321, -0.0176,  0.1142,  0.3398,\n",
      "         0.1049,  0.0493])\n",
      "R[0]\n",
      "tensor([0.1211], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0913515148460865; R = 0.0641773214172572;                 Gamma = 0.7152374920845032; Q = 0.001724459477874916;\n",
      "Entropy Neighbor = 0.35675844171643256;                 Entropy Random = 0.1036418884024024;                 Volume = 0.035700854316353794; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1353, -0.1054,  0.2634,  0.1927,  0.6854,  0.0678,  0.5048,  0.3354,\n",
      "         0.0453,  0.0872]) tensor([ 0.2776,  0.0702, -0.0216,  0.3864,  0.2793, -0.1483,  0.6337,  0.1189,\n",
      "        -0.0709, -0.2722]) tensor([ 0.1587, -0.1702,  0.4864,  0.7533,  0.3958,  0.3932,  0.5830, -0.4622,\n",
      "        -0.0677,  0.5655])\n",
      "R[0]\n",
      "tensor([0.1813], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09241923168301583; R = 0.06604471534676849;                 Gamma = 0.714649675488472; Q = 0.0020554884272860363;\n",
      "Entropy Neighbor = 0.35553369972109794;                 Entropy Random = 0.10336993031203746;                 Volume = 0.04179627786576748; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3182,  0.2352,  0.3209,  0.0147,  0.2150,  0.0248, -0.1064,  0.3633,\n",
      "        -0.2331,  0.0535]) tensor([-0.1703,  0.4628,  0.0407,  0.2410, -0.2147, -0.1759, -0.0069,  0.1895,\n",
      "        -0.3219, -0.3060]) tensor([-0.2331,  0.2655,  0.3011,  0.0391,  0.1991, -0.0091, -0.0693,  0.3506,\n",
      "        -0.1467,  0.0731])\n",
      "R[0]\n",
      "tensor([0.1253], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09156603896617889; R = 0.06504024362377822;                 Gamma = 0.7153744221925735; Q = 0.0018423443949723152;\n",
      "Entropy Neighbor = 0.35851183116436003;                 Entropy Random = 0.10501435327529907;                 Volume = 0.039728951238095764; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0539,  0.2832,  0.2749,  0.0757,  0.2495, -0.0631,  0.0563,  0.3797,\n",
      "         0.1018,  0.0156]) tensor([ 0.1925,  0.4942, -0.0111,  0.2766, -0.1612, -0.2788,  0.1516,  0.2259,\n",
      "        -0.0373, -0.3455]) tensor([ 0.1576,  0.2301,  0.2925,  0.0491,  0.3140, -0.0832,  0.1254,  0.4643,\n",
      "         0.1954, -0.0254])\n",
      "R[0]\n",
      "tensor([0.0805], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09229270204901695; R = 0.06659148207679391;                 Gamma = 0.7159800281524659; Q = 0.002016542607161682;\n",
      "Entropy Neighbor = 0.35826121655106546;                 Entropy Random = 0.10437734846025705;                 Volume = 0.04322856959700584; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.001960795906482963\n",
      "Episode average V value: 1.0437888987660409\n",
      "epoch 15:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 135.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 134.98650134986502 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.2187, 0.1248, 0.3742, 0.1467, 0.6552, 0.0533, 0.4064, 0.4301, 0.1116,\n",
      "        0.0547]) tensor([ 0.3544,  0.3083,  0.0874,  0.3300,  0.2467, -0.1538,  0.5395,  0.2276,\n",
      "         0.0111, -0.3138]) tensor([ 0.0450, -0.2536,  0.1607,  0.0796,  0.7494, -0.0161,  0.4764,  0.5000,\n",
      "        -0.0026, -0.0096])\n",
      "R[0]\n",
      "tensor([0.1384], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09163985304534435; R = 0.06512743949890137;                 Gamma = 0.7154088206291199; Q = 0.0022392483010771685;\n",
      "Entropy Neighbor = 0.3582841964364052;                 Entropy Random = 0.10630823995172978;                 Volume = 0.04079713187739253; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0110, -0.1431,  0.3329,  0.2341,  0.7354,  0.1317,  0.5567,  0.3410,\n",
      "        -0.0411,  0.1389]) tensor([ 0.1431,  0.0514,  0.0479,  0.4328,  0.3254, -0.0784,  0.6687,  0.1625,\n",
      "        -0.1492, -0.2282]) tensor([-0.0344, -0.1904,  0.2725,  0.2050,  0.7259,  0.1106,  0.5347,  0.3328,\n",
      "        -0.0887,  0.1276])\n",
      "R[0]\n",
      "tensor([0.1128], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09283020374178887; R = 0.06700498500093818;                 Gamma = 0.7151991951465607; Q = 0.002355132428638171;\n",
      "Entropy Neighbor = 0.3532612179219723;                 Entropy Random = 0.10557389482110739;                 Volume = 0.04247891217470169; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-4.9954e-05, -1.3045e-01,  5.6360e-01,  1.9411e-01,  1.0363e+00,\n",
      "         3.9011e-01,  5.9789e-01,  3.4056e-01, -3.9458e-01,  1.3295e-01]) tensor([ 0.1438,  0.0471,  0.2811,  0.4002,  0.6243,  0.1750,  0.7218,  0.1158,\n",
      "        -0.4982, -0.2232]) tensor([-0.1731, -0.2362,  0.5295,  0.2572,  1.4708,  0.5697,  0.6610,  0.2375,\n",
      "        -0.8315, -0.0588])\n",
      "R[0]\n",
      "tensor([0.1900], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09313409562408924; R = 0.06846683802455664;                 Gamma = 0.7153816884756088; Q = 0.0025911457646870984;\n",
      "Entropy Neighbor = 0.35504248398542404;                 Entropy Random = 0.10589039532095194;                 Volume = 0.04147542005777359; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1378,  0.3253,  0.3361,  0.0779,  0.1335, -0.0238, -0.0832,  0.3380,\n",
      "        -0.0544,  0.0896]) tensor([ 0.0077,  0.5406,  0.0524,  0.2902, -0.2889, -0.2271,  0.0246,  0.1618,\n",
      "        -0.1546, -0.2727]) tensor([-0.1723,  0.3317,  0.2935,  0.0375,  0.1307, -0.0490, -0.1171,  0.3477,\n",
      "        -0.0779,  0.0670])\n",
      "R[0]\n",
      "tensor([0.1215], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09236558412015439; R = 0.06676751631498337;                 Gamma = 0.715013286113739; Q = 0.0026312707935576326;\n",
      "Entropy Neighbor = 0.35662164360284804;                 Entropy Random = 0.10781330627575517;                 Volume = 0.04080468620359898; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-6.4832e-02,  3.1466e-01,  2.9029e-01,  2.2703e-02,  2.7861e-02,\n",
      "        -7.9107e-02, -1.9573e-01,  3.5227e-01,  2.0869e-04,  5.1933e-02]) tensor([ 0.0807,  0.5313,  0.0064,  0.2334, -0.3938, -0.2827, -0.0890,  0.1803,\n",
      "        -0.1055, -0.3103]) tensor([-0.0902,  0.3076,  0.2734,  0.0528,  0.0448, -0.0694, -0.1674,  0.3140,\n",
      "        -0.0242,  0.0717])\n",
      "R[0]\n",
      "tensor([0.1139], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09256251573562622; R = 0.06774079872108996;                 Gamma = 0.715674365401268; Q = 0.0021977412026608365;\n",
      "Entropy Neighbor = 0.3575468624830246;                 Entropy Random = 0.1083006582558155;                 Volume = 0.040511615224182604; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0024029076981241814\n",
      "Episode average V value: 1.0633397464513779\n",
      "epoch 16:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 135.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 134.98650134986502 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1468, -0.4940,  0.1700, -0.2885,  1.0793,  0.0917,  0.4288,  0.7533,\n",
      "        -0.4738, -0.0836]) tensor([-0.0155, -0.2732, -0.1023, -0.0667,  0.6512, -0.1073,  0.5282,  0.5787,\n",
      "        -0.5574, -0.4458]) tensor([-0.0256,  0.2773,  0.3286,  0.0445,  0.1156, -0.0194, -0.0420,  0.3242,\n",
      "         0.0144,  0.0948])\n",
      "R[0]\n",
      "tensor([0.1086], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0928132323473692; R = 0.0673449031971395;                 Gamma = 0.7152611376047134; Q = 0.0030025651350733826;\n",
      "Entropy Neighbor = 0.35531657564640046;                 Entropy Random = 0.1073349967226386;                 Volume = 0.04333573320508003; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3489, -0.2365,  0.2473,  0.0981,  0.5214,  0.1241,  0.2270,  0.3033,\n",
      "        -0.3964,  0.1687]) tensor([-0.1998, -0.0261, -0.0294,  0.3285,  0.0958, -0.0838,  0.3322,  0.1025,\n",
      "        -0.4905, -0.1846]) tensor([-0.2172, -0.1317,  0.5686,  0.1781,  0.8306,  0.3736,  0.3043,  0.3167,\n",
      "        -0.5616,  0.1400])\n",
      "R[0]\n",
      "tensor([0.1808], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09323731814324855; R = 0.06907487547025085;                 Gamma = 0.7154426096677781; Q = 0.0022030356381437743;\n",
      "Entropy Neighbor = 0.35118738234043123;                 Entropy Random = 0.10591349421441555;                 Volume = 0.04448576969280839; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0754, -0.7227,  0.0754, -0.3162,  1.2416,  0.0837,  0.4997,  0.7229,\n",
      "        -0.4942, -0.0839]) tensor([ 0.0539, -0.5047, -0.1969, -0.0959,  0.8150, -0.1143,  0.6027,  0.5458,\n",
      "        -0.5704, -0.4482]) tensor([-0.1229,  0.2786,  0.2824,  0.0671,  0.1769, -0.0329, -0.0237,  0.3420,\n",
      "        -0.0536,  0.0716])\n",
      "R[0]\n",
      "tensor([0.1096], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09336421982944011; R = 0.0701498393304646;                 Gamma = 0.7157318865060807; Q = 0.002737209755810909;\n",
      "Entropy Neighbor = 0.34932475861907003;                 Entropy Random = 0.10666107769310475;                 Volume = 0.0439635233618319; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2207,  0.3013,  0.2851,  0.0349,  0.0466, -0.0487, -0.1925,  0.3229,\n",
      "        -0.1127,  0.0731]) tensor([-0.0557,  0.5608,  0.0022,  0.2945, -0.3916, -0.2650, -0.1399,  0.1737,\n",
      "        -0.2305, -0.2720]) tensor([-0.2301,  0.2983,  0.3550,  0.0306,  0.1038,  0.0210, -0.1716,  0.3307,\n",
      "        -0.1571,  0.0639])\n",
      "R[0]\n",
      "tensor([0.0904], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09345287169516087; R = 0.0700596863180399;                 Gamma = 0.7159836796522141; Q = 0.002368900722532999;\n",
      "Entropy Neighbor = 0.3492572262883186;                 Entropy Random = 0.10328717039525509;                 Volume = 0.04399891151115298; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1033, -0.2213,  0.3372,  0.1768,  0.7734,  0.1837,  0.5261,  0.3350,\n",
      "        -0.2405,  0.1630]) tensor([ 0.0403, -0.0351,  0.0566,  0.3857,  0.3589, -0.0282,  0.6484,  0.1177,\n",
      "        -0.3409, -0.1942]) tensor([-0.0466, -0.1548,  0.5715,  0.1631,  1.0821,  0.4076,  0.6124,  0.3838,\n",
      "        -0.4976,  0.1071])\n",
      "R[0]\n",
      "tensor([0.1894], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09398535497486592; R = 0.06882983315363526;                 Gamma = 0.7153516175746918; Q = 0.0024583330837485845;\n",
      "Entropy Neighbor = 0.3428326596915722;                 Entropy Random = 0.10227358575165271;                 Volume = 0.04492450585961342; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0025540088670619296\n",
      "Episode average V value: 1.051847719091177\n",
      "epoch 17:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2467,  0.2540,  0.2886,  0.0119,  0.1274, -0.0143, -0.1275,  0.3429,\n",
      "        -0.1514,  0.0718]) tensor([-0.0823,  0.5134,  0.0065,  0.2730, -0.3121, -0.2293, -0.0744,  0.1911,\n",
      "        -0.2647, -0.2733]) tensor([-0.2940,  0.2322,  0.3273,  0.0088,  0.2191,  0.0476, -0.0792,  0.3612,\n",
      "        -0.2471,  0.0594])\n",
      "R[0]\n",
      "tensor([0.0951], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09359251753985882; R = 0.06906657340750098;                 Gamma = 0.715354007601738; Q = 0.00274514488899149;\n",
      "Entropy Neighbor = 0.3434087598025799;                 Entropy Random = 0.10373649463802576;                 Volume = 0.0440928051173687; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3025, -0.1886,  0.3410,  0.1130,  0.5334,  0.1875,  0.2423,  0.2937,\n",
      "        -0.3895,  0.1861]) tensor([-0.1633,  0.0360,  0.0628,  0.3422,  0.1079, -0.0172,  0.3334,  0.1296,\n",
      "        -0.4841, -0.1749]) tensor([-0.0870, -0.1883,  0.3041, -0.0012,  0.5175,  0.0628,  0.2632,  0.4802,\n",
      "        -0.2091,  0.0750])\n",
      "R[0]\n",
      "tensor([0.1084], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09390875229239463; R = 0.07146635141968727;                 Gamma = 0.7150677827596664; Q = 0.0031209244241472336;\n",
      "Entropy Neighbor = 0.33834013968706134;                 Entropy Random = 0.10135752554237842;                 Volume = 0.04427290900051594; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3017,  0.0868,  0.3036,  0.0604,  0.1998,  0.0590, -0.0553,  0.3046,\n",
      "        -0.2513,  0.1007]) tensor([-0.1549,  0.3129,  0.0241,  0.2869, -0.2298, -0.1402,  0.0473,  0.1281,\n",
      "        -0.3341, -0.2601]) tensor([-0.2485,  0.2555,  0.3729,  0.0082,  0.0989,  0.0355, -0.1701,  0.3554,\n",
      "        -0.1951,  0.0580])\n",
      "R[0]\n",
      "tensor([0.1316], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0931031896173954; R = 0.06969849878922105;                 Gamma = 0.7161052117347717; Q = 0.0024823639889946206;\n",
      "Entropy Neighbor = 0.3433154762089253;                 Entropy Random = 0.10438413176685572;                 Volume = 0.04073362405225635; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3415, -0.3500,  0.0312, -0.0385,  0.5233, -0.0579,  0.2738,  0.4654,\n",
      "        -0.2612,  0.0771]) tensor([-0.2050, -0.1169, -0.2427,  0.1874,  0.0965, -0.2607,  0.3651,  0.3050,\n",
      "        -0.3531, -0.2839]) tensor([-0.0542, -0.2867,  0.2233, -0.0521,  0.8350,  0.0938,  0.4464,  0.5739,\n",
      "        -0.2832, -0.0646])\n",
      "R[0]\n",
      "tensor([0.1049], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09357006993889809; R = 0.0702492133062333;                 Gamma = 0.7159654633998871; Q = 0.002476159191806801;\n",
      "Entropy Neighbor = 0.34126567310094835;                 Entropy Random = 0.10097257509827613;                 Volume = 0.043782281428575515; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0686, 0.1909, 0.3629, 0.1239, 0.4527, 0.0180, 0.2785, 0.4229, 0.0695,\n",
      "        0.0485]) tensor([ 0.2071,  0.3853,  0.0780,  0.3167,  0.0387, -0.1868,  0.4039,  0.2281,\n",
      "        -0.0295, -0.3178]) tensor([0.1742, 0.1414, 0.3902, 0.1235, 0.6242, 0.0514, 0.3860, 0.4744, 0.0780,\n",
      "        0.0038])\n",
      "R[0]\n",
      "tensor([0.1359], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09386850090324879; R = 0.07115150386095047;                 Gamma = 0.7151838258504868; Q = 0.0025528340075397864;\n",
      "Entropy Neighbor = 0.3386102448105812;                 Entropy Random = 0.10093341217935085;                 Volume = 0.04363940697163343; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0026754853002959864\n",
      "Episode average V value: 1.0770373919665814\n",
      "epoch 18:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 135.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 134.98650134986502 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0986, 0.2674, 0.3869, 0.1401, 0.4519, 0.0175, 0.2588, 0.4169, 0.0905,\n",
      "        0.0365]) tensor([ 0.2375,  0.4602,  0.1007,  0.3310,  0.0394, -0.1887,  0.3843,  0.2228,\n",
      "        -0.0125, -0.3296]) tensor([0.2350, 0.0933, 0.4108, 0.2046, 0.6489, 0.0632, 0.4520, 0.4370, 0.1122,\n",
      "        0.0490])\n",
      "R[0]\n",
      "tensor([0.1330], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09375425714254379; R = 0.06995314163714647;                 Gamma = 0.7152017886638642; Q = 0.002564889285597019;\n",
      "Entropy Neighbor = 0.3396524333357811;                 Entropy Random = 0.10539207055419683;                 Volume = 0.041674312934279444; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0545, -0.2359,  0.1961,  0.1216,  0.6246, -0.0420,  0.4612,  0.5129,\n",
      "         0.1053,  0.0026]) tensor([ 0.1840, -0.0387, -0.0871,  0.3151,  0.2145, -0.2502,  0.5743,  0.3395,\n",
      "        -0.0079, -0.3652]) tensor([-0.1309, -0.2625,  0.2078, -0.0969,  0.7876,  0.0210,  0.4190,  0.6754,\n",
      "        -0.1799, -0.0830])\n",
      "R[0]\n",
      "tensor([0.1054], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0940035321265459; R = 0.07194336642697453;                 Gamma = 0.7157043117284775; Q = 0.0026074274689308367;\n",
      "Entropy Neighbor = 0.3416874414682388;                 Entropy Random = 0.10583152817934752;                 Volume = 0.044662492137402296; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0517,  0.4254,  0.4353,  0.1311,  0.1772,  0.0290, -0.0092,  0.3144,\n",
      "         0.0510,  0.0516]) tensor([ 0.1955,  0.6279,  0.1481,  0.3318, -0.2388, -0.1773,  0.1060,  0.1327,\n",
      "        -0.0583, -0.3122]) tensor([0.0389, 0.2458, 0.3692, 0.1492, 0.3177, 0.0071, 0.1712, 0.3644, 0.0772,\n",
      "        0.0821])\n",
      "R[0]\n",
      "tensor([0.1218], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09455250562727452; R = 0.0723525522761047;                 Gamma = 0.7157957425117493; Q = 0.0026335726837278346;\n",
      "Entropy Neighbor = 0.33849419870972636;                 Entropy Random = 0.10322855950891971;                 Volume = 0.04297064501792192; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1854,  0.3511,  0.3616,  0.0596,  0.1182, -0.0012, -0.1001,  0.3469,\n",
      "        -0.1010,  0.0750]) tensor([-0.0218,  0.6049,  0.0779,  0.3157, -0.3189, -0.2174, -0.0440,  0.1929,\n",
      "        -0.2191, -0.2709]) tensor([-0.3025,  0.2508,  0.2883,  0.0359,  0.1614, -0.0146, -0.0801,  0.3392,\n",
      "        -0.1779,  0.1052])\n",
      "R[0]\n",
      "tensor([0.0943], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09446676535904408; R = 0.07152457324042916;                 Gamma = 0.7160348562002182; Q = 0.002403101862233598;\n",
      "Entropy Neighbor = 0.3405546969175339;                 Entropy Random = 0.10509177507460117;                 Volume = 0.043771449476480484; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.1349, 0.1080, 0.4008, 0.1341, 0.6197, 0.0597, 0.4388, 0.4653, 0.0693,\n",
      "        0.0967]) tensor([ 0.2702,  0.2941,  0.1160,  0.3206,  0.2082, -0.1451,  0.5716,  0.2615,\n",
      "        -0.0267, -0.2715]) tensor([-0.0967, -0.2380,  0.3291,  0.2109,  0.7452,  0.1719,  0.5510,  0.3173,\n",
      "        -0.1937,  0.1808])\n",
      "R[0]\n",
      "tensor([0.1436], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09405755174160003; R = 0.07038239556364716;                 Gamma = 0.7159596222639084; Q = 0.0022648656344390473;\n",
      "Entropy Neighbor = 0.3381148899793625;                 Entropy Random = 0.1051465668156743;                 Volume = 0.04308223350718617; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0024947713869856673\n",
      "Episode average V value: 1.0917350312888623\n",
      "epoch 19:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0953, -0.1526,  0.5747,  0.2477,  0.8829,  0.3920,  0.5591,  0.2101,\n",
      "        -0.3017,  0.2428]) tensor([ 0.2386,  0.0195,  0.2903,  0.4505,  0.4741,  0.1768,  0.6869, -0.0135,\n",
      "        -0.4082, -0.1155]) tensor([-0.2921, -0.0646,  0.7176,  0.2496,  1.2933,  0.6692,  0.4488,  0.2243,\n",
      "        -1.0019, -0.0663])\n",
      "R[0]\n",
      "tensor([0.1890], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.094033795773983; R = 0.07088561379350722;                 Gamma = 0.7158965791463852; Q = 0.0027461018555914054;\n",
      "Entropy Neighbor = 0.33812506529688835;                 Entropy Random = 0.10363047837466001;                 Volume = 0.040318491775542496; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2896, -0.1395,  0.4221,  0.2134,  0.2830,  0.1873,  0.1424,  0.1782,\n",
      "        -0.3136,  0.3256]) tensor([-0.1503,  0.0819,  0.1421,  0.4412, -0.1409, -0.0169,  0.2354,  0.0174,\n",
      "        -0.4129, -0.0372]) tensor([-0.0722,  0.2524,  0.4165,  0.1595,  0.2700,  0.0905,  0.0736,  0.2659,\n",
      "        -0.1090,  0.1132])\n",
      "R[0]\n",
      "tensor([0.1063], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09441560585796833; R = 0.07223322646319866;                 Gamma = 0.7157221512794495; Q = 0.00247903421940282;\n",
      "Entropy Neighbor = 0.33808088156580923;                 Entropy Random = 0.10518940410017967;                 Volume = 0.04190226060897112; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3160,  0.2183,  0.3187,  0.0219,  0.2468,  0.0250, -0.0266,  0.3913,\n",
      "        -0.2366,  0.0680]) tensor([-0.1523,  0.4781,  0.0379,  0.2849, -0.1946, -0.1886,  0.0275,  0.2352,\n",
      "        -0.3430, -0.2771]) tensor([-0.3464,  0.0868,  0.3413,  0.0074,  0.3425,  0.1001,  0.0295,  0.3993,\n",
      "        -0.3423,  0.0654])\n",
      "R[0]\n",
      "tensor([0.1020], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09395910672843456; R = 0.07036138165742159;                 Gamma = 0.7159415645599365; Q = 0.0026655966961407103;\n",
      "Entropy Neighbor = 0.3389456702768803;                 Entropy Random = 0.10439308782666921;                 Volume = 0.042930416729301216; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0247, -0.2659,  0.1758,  0.0390,  0.6841,  0.0023,  0.4234,  0.5195,\n",
      "        -0.0273, -0.0266]) tensor([ 0.1070, -0.0597, -0.1050,  0.2423,  0.2689, -0.2048,  0.5298,  0.3483,\n",
      "        -0.1345, -0.3919]) tensor([-0.1642, -0.2606,  0.2131, -0.1179,  0.6992,  0.0061,  0.3512,  0.6628,\n",
      "        -0.2181, -0.0273])\n",
      "R[0]\n",
      "tensor([0.1056], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09463622435927391; R = 0.07270618852600455;                 Gamma = 0.7167704362869263; Q = 0.002473197957035154;\n",
      "Entropy Neighbor = 0.34023365285992624;                 Entropy Random = 0.10712823925167322;                 Volume = 0.04327703501656652; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1051, -0.4890,  0.1808, -0.3671,  1.0878,  0.0445,  0.4081,  0.8676,\n",
      "        -0.4992, -0.1793]) tensor([ 0.0288, -0.2708, -0.0886, -0.1521,  0.6562, -0.1491,  0.5255,  0.6662,\n",
      "        -0.5599, -0.5420]) tensor([ 0.0682, -0.3527,  0.0225, -0.3661,  0.8590, -0.1572,  0.2855,  0.8575,\n",
      "        -0.2271, -0.2352])\n",
      "R[0]\n",
      "tensor([0.1452], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09434200881421566; R = 0.07028367202915252;                 Gamma = 0.715570271372795; Q = 0.003023242571391165;\n",
      "Entropy Neighbor = 0.3400872818827629;                 Entropy Random = 0.1058820813074708;                 Volume = 0.04498223430290818; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.002677434659912251\n",
      "Episode average V value: 1.092060476574315\n",
      "epoch 20:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.1191, 0.2327, 0.4071, 0.1322, 0.5097, 0.0369, 0.3115, 0.4481, 0.0851,\n",
      "        0.0485]) tensor([ 0.2529,  0.4276,  0.1196,  0.3241,  0.1021, -0.1772,  0.4189,  0.2794,\n",
      "        -0.0476, -0.3163]) tensor([0.1684, 0.0242, 0.3815, 0.2330, 0.6541, 0.0810, 0.4923, 0.3942, 0.1063,\n",
      "        0.0805])\n",
      "R[0]\n",
      "tensor([0.0941], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09454524087905884; R = 0.07240386892855168;                 Gamma = 0.7159579560756684; Q = 0.0024626867200713606;\n",
      "Entropy Neighbor = 0.33312729600071905;                 Entropy Random = 0.10622434099018574;                 Volume = 0.04244926869124174; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2357,  0.1815,  0.2715,  0.0580,  0.0776,  0.0082, -0.1447,  0.2614,\n",
      "        -0.1529,  0.1059]) tensor([-0.0815,  0.3970, -0.0093,  0.2865, -0.3457, -0.2045, -0.0494,  0.0797,\n",
      "        -0.2753, -0.2445]) tensor([-0.2829,  0.2072,  0.2705,  0.0535,  0.0368, -0.0255, -0.1605,  0.2913,\n",
      "        -0.1530,  0.1205])\n",
      "R[0]\n",
      "tensor([0.1580], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09521988473832607; R = 0.07351994979009033;                 Gamma = 0.7160440441370011; Q = 0.0028601337010622954;\n",
      "Entropy Neighbor = 0.33528040394186975;                 Entropy Random = 0.10590161281079054;                 Volume = 0.043517932921648024; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0507, -0.2469,  0.5018,  0.2304,  1.0650,  0.3614,  0.6420,  0.2845,\n",
      "        -0.3695,  0.1848]) tensor([ 0.1931, -0.0726,  0.2188,  0.4329,  0.6558,  0.1460,  0.7701,  0.0581,\n",
      "        -0.4706, -0.1733]) tensor([-0.2820, -0.0281,  0.7424,  0.3137,  1.3588,  0.7231,  0.4811,  0.1579,\n",
      "        -1.0266, -0.0803])\n",
      "R[0]\n",
      "tensor([0.1899], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09574919560551644; R = 0.07517928545176983;                 Gamma = 0.716365463733673; Q = 0.002606945507926866;\n",
      "Entropy Neighbor = 0.33221492418646814;                 Entropy Random = 0.10580122655630111;                 Volume = 0.04415804097428918; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1571, -0.2942,  0.2295,  0.1047,  0.5644,  0.0436,  0.4268,  0.4620,\n",
      "        -0.1024,  0.0586]) tensor([-0.0208, -0.0882, -0.0479,  0.3105,  0.1419, -0.1541,  0.5511,  0.2629,\n",
      "        -0.1750, -0.3077]) tensor([-0.0901, -0.2154,  0.2725,  0.0976,  0.6023,  0.0428,  0.4405,  0.5149,\n",
      "        -0.0423,  0.0347])\n",
      "R[0]\n",
      "tensor([0.1546], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09509117336571217; R = 0.07383353529311716;                 Gamma = 0.7159152457714081; Q = 0.002678089129505679;\n",
      "Entropy Neighbor = 0.32923592993617057;                 Entropy Random = 0.10338705486059188;                 Volume = 0.04234829111024738; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0173,  0.3414,  0.3866,  0.1149,  0.2217, -0.0011,  0.0779,  0.3837,\n",
      "         0.0435,  0.0469]) tensor([ 0.1562,  0.5518,  0.1010,  0.3177, -0.1905, -0.2158,  0.1735,  0.2275,\n",
      "        -0.0941, -0.3139]) tensor([ 0.0173,  0.3414,  0.3866,  0.1149,  0.2217, -0.0011,  0.0779,  0.3837,\n",
      "         0.0435,  0.0469])\n",
      "R[0]\n",
      "tensor([0.0853], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09529382298886777; R = 0.07413627308234573;                 Gamma = 0.7154389202594758; Q = 0.002436060631007422;\n",
      "Entropy Neighbor = 0.3301485042870045;                 Entropy Random = 0.10289220581948758;                 Volume = 0.04235063323378563; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0026087831379147247\n",
      "Episode average V value: 1.0903373250678903\n",
      "epoch 21:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 135.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 134.98650134986502 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0585,  0.4124,  0.3669,  0.0835,  0.1511, -0.0303, -0.0521,  0.3637,\n",
      "         0.0672, -0.0005]) tensor([ 0.2024,  0.6181,  0.0806,  0.2839, -0.2653, -0.2369,  0.0614,  0.1845,\n",
      "        -0.0440, -0.3636]) tensor([-0.0040,  0.3514,  0.3685,  0.1055,  0.2866,  0.0163,  0.1007,  0.3545,\n",
      "         0.0029,  0.0394])\n",
      "R[0]\n",
      "tensor([0.1178], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09563979966938496; R = 0.0731341240555048;                 Gamma = 0.7160592782497406; Q = 0.002638033454364631;\n",
      "Entropy Neighbor = 0.32878244504332543;                 Entropy Random = 0.10492424493283034;                 Volume = 0.04308195370435715; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1187, -0.2500,  0.2105, -0.1226,  0.7225,  0.0290,  0.3211,  0.6786,\n",
      "        -0.2818, -0.1270]) tensor([ 0.0150, -0.0290, -0.0646,  0.0928,  0.2987, -0.1752,  0.4187,  0.5099,\n",
      "        -0.3828, -0.4879]) tensor([-0.1325, -0.5495,  0.1475, -0.3709,  1.1400,  0.0651,  0.4373,  0.8573,\n",
      "        -0.5157, -0.1528])\n",
      "R[0]\n",
      "tensor([0.1035], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09645171694457531; R = 0.07505807373300195;                 Gamma = 0.7171464964151383; Q = 0.002500859904976096;\n",
      "Entropy Neighbor = 0.3254072857499123;                 Entropy Random = 0.10313490322977305;                 Volume = 0.04627635281160474; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1217,  0.3736,  0.4033,  0.0831,  0.1148,  0.0253, -0.0763,  0.3410,\n",
      "        -0.0721,  0.0673]) tensor([ 0.0243,  0.5882,  0.1196,  0.2957, -0.3080, -0.1781,  0.0312,  0.1637,\n",
      "        -0.1736, -0.2943]) tensor([-0.1260,  0.3572,  0.3710,  0.0857,  0.1564,  0.0054, -0.0405,  0.3534,\n",
      "        -0.0561,  0.0683])\n",
      "R[0]\n",
      "tensor([0.1235], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.096224410161376; R = 0.0755919145476073;                 Gamma = 0.7167055143117904; Q = 0.0022544850450358354;\n",
      "Entropy Neighbor = 0.3255141597390175;                 Entropy Random = 0.10468548902124167;                 Volume = 0.04500151957571506; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0738, 0.2692, 0.3987, 0.1419, 0.3975, 0.0149, 0.2587, 0.4236, 0.0975,\n",
      "        0.0625]) tensor([ 0.2190,  0.4508,  0.1128,  0.3386, -0.0118, -0.2013,  0.3790,  0.2185,\n",
      "        -0.0343, -0.2941]) tensor([0.1389, 0.2580, 0.3940, 0.1619, 0.4283, 0.0093, 0.3072, 0.4128, 0.1425,\n",
      "        0.0801])\n",
      "R[0]\n",
      "tensor([0.1688], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09621016499400138; R = 0.07461685670167208;                 Gamma = 0.7164591277837753; Q = 0.0025587517786188983;\n",
      "Entropy Neighbor = 0.32664823859930037;                 Entropy Random = 0.10333622100204229;                 Volume = 0.0436451651006937; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2390,  0.2908,  0.2948,  0.0074,  0.1446, -0.0153, -0.0817,  0.3569,\n",
      "        -0.1586,  0.0800]) tensor([-0.0750,  0.5495,  0.0129,  0.2672, -0.2948, -0.2304, -0.0276,  0.2032,\n",
      "        -0.2720, -0.2651]) tensor([-0.3250,  0.2442,  0.2958, -0.0085,  0.1865,  0.0317, -0.1087,  0.3529,\n",
      "        -0.2917,  0.0381])\n",
      "R[0]\n",
      "tensor([0.0963], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09572762371599675; R = 0.074586162365973;                 Gamma = 0.7165364773273468; Q = 0.0027074319630628453;\n",
      "Entropy Neighbor = 0.32462608388066294;                 Entropy Random = 0.10296990014612675;                 Volume = 0.044251610193401576; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0025319124292116613\n",
      "Episode average V value: 1.086903834912181\n",
      "epoch 22:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1214,  0.2608,  0.3400,  0.1083,  0.3359, -0.0203,  0.2230,  0.3954,\n",
      "         0.1117,  0.0631]) tensor([ 0.2603,  0.4557,  0.0545,  0.2992, -0.0770, -0.2260,  0.3481,  0.2035,\n",
      "         0.0074, -0.3030]) tensor([0.0118, 0.2136, 0.3943, 0.0917, 0.4453, 0.0375, 0.2687, 0.4562, 0.0080,\n",
      "        0.0447])\n",
      "R[0]\n",
      "tensor([0.1312], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09581183077394963; R = 0.07464368018694222;                 Gamma = 0.7162871272563934; Q = 0.0027987168052932246;\n",
      "Entropy Neighbor = 0.32326050561666486;                 Entropy Random = 0.10249333132058382;                 Volume = 0.043152062576264145; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1754,  0.2476,  0.3501,  0.1787,  0.2747, -0.0463,  0.2104,  0.3788,\n",
      "         0.2190,  0.0799]) tensor([ 0.3131,  0.4366,  0.0627,  0.3639, -0.1349, -0.2526,  0.3394,  0.1868,\n",
      "         0.1107, -0.2882]) tensor([0.0729, 0.2771, 0.3769, 0.1397, 0.3391, 0.0121, 0.1945, 0.3880, 0.0528,\n",
      "        0.0514])\n",
      "R[0]\n",
      "tensor([0.1302], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09601132346689702; R = 0.07468454623967409;                 Gamma = 0.7167873748540878; Q = 0.002612052445358131;\n",
      "Entropy Neighbor = 0.3239265707731247;                 Entropy Random = 0.10311455252766609;                 Volume = 0.04191332506760955; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3533,  0.1117,  0.3552,  0.0110,  0.3106,  0.0927,  0.0310,  0.4120,\n",
      "        -0.3136,  0.0776]) tensor([-0.1906,  0.3712,  0.0759,  0.2768, -0.1332, -0.1181,  0.0865,  0.2524,\n",
      "        -0.4127, -0.2680]) tensor([-0.3098, -0.0841,  0.4424,  0.1281,  0.4691,  0.2504,  0.2369,  0.2653,\n",
      "        -0.3959,  0.2361])\n",
      "R[0]\n",
      "tensor([0.1095], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.096125418394804; R = 0.07414724572747945;                 Gamma = 0.7168928118944168; Q = 0.002456524607958272;\n",
      "Entropy Neighbor = 0.3205670722424984;                 Entropy Random = 0.10125182943791151;                 Volume = 0.04432794698700309; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3250,  0.2105,  0.2622,  0.0092,  0.1412, -0.0026, -0.1012,  0.3368,\n",
      "        -0.2553,  0.0911]) tensor([-0.1793,  0.4505, -0.0161,  0.2399, -0.2846, -0.2131, -0.0241,  0.1921,\n",
      "        -0.3752, -0.2638]) tensor([-0.3080,  0.2545,  0.3201,  0.0378,  0.1596,  0.0260, -0.0751,  0.3446,\n",
      "        -0.2482,  0.0909])\n",
      "R[0]\n",
      "tensor([0.0840], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09631182232499122; R = 0.0758115459419787;                 Gamma = 0.7168626700639724; Q = 0.0030378204233129508;\n",
      "Entropy Neighbor = 0.320717635601759;                 Entropy Random = 0.10163042745739222;                 Volume = 0.044019536007195714; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1828,  0.3258,  0.3179,  0.0765,  0.0703, -0.0301, -0.1131,  0.3279,\n",
      "        -0.1191,  0.0797]) tensor([-0.0294,  0.5377,  0.0364,  0.2984, -0.3504, -0.2445, -0.0150,  0.1441,\n",
      "        -0.2481, -0.2707]) tensor([-0.1839,  0.3370,  0.3362,  0.0795,  0.0852, -0.0199, -0.1006,  0.3347,\n",
      "        -0.1241,  0.0755])\n",
      "R[0]\n",
      "tensor([0.1556], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09694726349413395; R = 0.07831845293194055;                 Gamma = 0.7166926760673523; Q = 0.002428232657373883;\n",
      "Entropy Neighbor = 0.3200074584186077;                 Entropy Random = 0.10121238899976015;                 Volume = 0.04553606678918004; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0026666693878592924\n",
      "Episode average V value: 1.1137286751568318\n",
      "epoch 23:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1628,  0.2327,  0.3393,  0.0920,  0.3204, -0.0560,  0.2263,  0.4409,\n",
      "         0.1920,  0.0682]) tensor([ 0.2998,  0.4231,  0.0533,  0.2783, -0.0910, -0.2610,  0.3549,  0.2478,\n",
      "         0.0854, -0.2995]) tensor([0.1408, 0.1418, 0.3510, 0.0998, 0.4886, 0.0254, 0.3461, 0.4187, 0.0776,\n",
      "        0.0897])\n",
      "R[0]\n",
      "tensor([0.1306], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09671420070528984; R = 0.0763650903068483;                 Gamma = 0.7164934743642807; Q = 0.0027068144569639117;\n",
      "Entropy Neighbor = 0.32161142900586126;                 Entropy Random = 0.1029815871566534;                 Volume = 0.04456492119282484; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4516,  0.0263,  0.3451,  0.3035,  0.4095, -0.0598,  0.4897,  0.3349,\n",
      "         0.4679,  0.1344]) tensor([ 0.5820,  0.1931,  0.0548,  0.4673,  0.0112, -0.2682,  0.6375,  0.1287,\n",
      "         0.3576, -0.2399]) tensor([0.0677, 0.2398, 0.3837, 0.1151, 0.4552, 0.0400, 0.3065, 0.4077, 0.0366,\n",
      "        0.0836])\n",
      "R[0]\n",
      "tensor([0.1403], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09669317828118801; R = 0.07637060668691993;                 Gamma = 0.7164452174901962; Q = 0.0026584667682182043;\n",
      "Entropy Neighbor = 0.3194886794388294;                 Entropy Random = 0.10133403726667166;                 Volume = 0.04476280011236668; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2521, -0.1177,  0.4397,  0.1407,  0.5275,  0.2480,  0.2786,  0.2808,\n",
      "        -0.3679,  0.2179]) tensor([-0.1040,  0.0814,  0.1606,  0.3653,  0.1051,  0.0391,  0.3888,  0.0746,\n",
      "        -0.4682, -0.1361]) tensor([-0.0144, -0.0063,  0.7087,  0.2077,  0.8743,  0.4430,  0.3818,  0.3214,\n",
      "        -0.4898,  0.1272])\n",
      "R[0]\n",
      "tensor([0.1852], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09644221027195454; R = 0.0759062291868031;                 Gamma = 0.7166119973659515; Q = 0.0025185642145806922;\n",
      "Entropy Neighbor = 0.3204026212692261;                 Entropy Random = 0.10312593243271112;                 Volume = 0.043723534632474186; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2838, -0.2743,  0.0428, -0.1100,  0.3999, -0.1135,  0.1555,  0.5483,\n",
      "        -0.1580,  0.0357]) tensor([-0.1478, -0.0424, -0.2316,  0.1122, -0.0264, -0.3162,  0.2469,  0.3918,\n",
      "        -0.2595, -0.3252]) tensor([-0.0959, -0.2061,  0.3001, -0.1138,  0.7183,  0.0943,  0.3666,  0.6670,\n",
      "        -0.2963, -0.1054])\n",
      "R[0]\n",
      "tensor([0.0974], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09682809449732303; R = 0.0770751530751586;                 Gamma = 0.7163745962381363; Q = 0.002454637688584626;\n",
      "Entropy Neighbor = 0.3196805096566677;                 Entropy Random = 0.10242962250113487;                 Volume = 0.04408261292800307; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0501,  0.4164,  0.3845,  0.0664,  0.0177, -0.0317, -0.1496,  0.3398,\n",
      "        -0.0332,  0.0517]) tensor([ 0.1021,  0.6217,  0.1012,  0.2810, -0.3997, -0.2474, -0.0480,  0.1556,\n",
      "        -0.1710, -0.2996]) tensor([ 0.0080,  0.4229,  0.4069,  0.0832, -0.0054, -0.0177, -0.1423,  0.3165,\n",
      "         0.0154,  0.0652])\n",
      "R[0]\n",
      "tensor([0.1503], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09632543893158436; R = 0.07446128001064062;                 Gamma = 0.7165211859941483; Q = 0.0023131795023218727;\n",
      "Entropy Neighbor = 0.3217580077946186;                 Entropy Random = 0.1032609759196639;                 Volume = 0.04411370861902833; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0025303325261338615\n",
      "Episode average V value: 1.093271183001995\n",
      "epoch 24:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1137,  0.1086,  0.7915,  0.3121,  1.1510,  0.6652,  0.3430,  0.1204,\n",
      "        -0.7878,  0.0099]) tensor([ 0.0410,  0.3003,  0.5060,  0.5388,  0.7349,  0.4440,  0.4466, -0.0925,\n",
      "        -0.8932, -0.3393]) tensor([ 0.0429,  0.3624,  0.3738,  0.1146,  0.1274, -0.0229, -0.0337,  0.3582,\n",
      "         0.0425,  0.0124])\n",
      "R[0]\n",
      "tensor([0.1782], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0965839336514473; R = 0.0770751284006983;                 Gamma = 0.7166262555122376; Q = 0.0028202170585282147;\n",
      "Entropy Neighbor = 0.31727783191204073;                 Entropy Random = 0.10363354633748531;                 Volume = 0.04314151947945356; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1629,  0.3165,  0.3451,  0.0407,  0.1252, -0.0031, -0.0591,  0.3641,\n",
      "        -0.0860,  0.0795]) tensor([-0.0202,  0.5426,  0.0630,  0.2585, -0.2947, -0.2155,  0.0259,  0.2155,\n",
      "        -0.2171, -0.2779]) tensor([-0.1439,  0.3091,  0.3310,  0.0759,  0.1900,  0.0081, -0.0136,  0.3493,\n",
      "        -0.1008,  0.0603])\n",
      "R[0]\n",
      "tensor([0.0828], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09707818265259266; R = 0.07900668079406023;                 Gamma = 0.7164562400579453; Q = 0.0028932941403472796;\n",
      "Entropy Neighbor = 0.3177257213294506;                 Entropy Random = 0.10248197434842586;                 Volume = 0.044775748822838066; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0816,  0.2824,  0.3774,  0.0440,  0.0461,  0.0166, -0.1430,  0.3333,\n",
      "        -0.0297,  0.0613]) tensor([ 0.0701,  0.4872,  0.0946,  0.2620, -0.3732, -0.1967, -0.0412,  0.1483,\n",
      "        -0.1622, -0.2906]) tensor([-0.0816,  0.2824,  0.3774,  0.0440,  0.0461,  0.0166, -0.1430,  0.3333,\n",
      "        -0.0297,  0.0613])\n",
      "R[0]\n",
      "tensor([0.1554], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09703307916224004; R = 0.07699738351255656;                 Gamma = 0.716945858001709; Q = 0.002731438736547716;\n",
      "Entropy Neighbor = 0.3179852936267853;                 Entropy Random = 0.10312730284780264;                 Volume = 0.046357084192335606; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.1464, 0.2582, 0.3928, 0.1140, 0.3156, 0.0065, 0.2218, 0.3965, 0.1496,\n",
      "        0.0807]) tensor([ 0.2846,  0.4494,  0.1065,  0.3034, -0.0967, -0.1986,  0.3488,  0.2033,\n",
      "         0.0442, -0.2864]) tensor([0.1517, 0.2614, 0.3921, 0.1388, 0.4293, 0.0041, 0.3008, 0.4277, 0.1174,\n",
      "        0.0582])\n",
      "R[0]\n",
      "tensor([0.1326], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09692591300606727; R = 0.07713264264538884;                 Gamma = 0.7167478700876236; Q = 0.0024001789962057956;\n",
      "Entropy Neighbor = 0.3185919579863548;                 Entropy Random = 0.10265242746472358;                 Volume = 0.04369886930659413; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2751,  0.2394,  0.3226,  0.0696,  0.1878,  0.0182, -0.0282,  0.3474,\n",
      "        -0.1860,  0.0929]) tensor([-0.1117,  0.4967,  0.0406,  0.3301, -0.2517, -0.1962,  0.0272,  0.1917,\n",
      "        -0.2952, -0.2530]) tensor([-0.3015,  0.2703,  0.3743,  0.0304,  0.2206,  0.0555, -0.0311,  0.3885,\n",
      "        -0.2296,  0.0608])\n",
      "R[0]\n",
      "tensor([0.1016], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09747882808744908; R = 0.07803488206863403;                 Gamma = 0.7168523269891739; Q = 0.0028160052925231866;\n",
      "Entropy Neighbor = 0.31546381148695946;                 Entropy Random = 0.10322983735054732;                 Volume = 0.04735823158174753; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0027322268448304386\n",
      "Episode average V value: 1.0977562043488025\n",
      "epoch 25:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3115,  0.2625,  0.3031,  0.0363,  0.1482,  0.0019, -0.0599,  0.3399,\n",
      "        -0.1943,  0.1110]) tensor([-0.1576,  0.4787,  0.0235,  0.2651, -0.2767, -0.2101,  0.0355,  0.1548,\n",
      "        -0.3147, -0.2386]) tensor([-0.2952,  0.2620,  0.3237,  0.0569,  0.1622,  0.0219, -0.0455,  0.3354,\n",
      "        -0.1984,  0.1041])\n",
      "R[0]\n",
      "tensor([0.1619], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09737267838418484; R = 0.07736089568212628;                 Gamma = 0.7164309461116791; Q = 0.0028458326215622947;\n",
      "Entropy Neighbor = 0.31482062140107153;                 Entropy Random = 0.1029261894673109;                 Volume = 0.04689262790977955; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0998, 0.3581, 0.4029, 0.1550, 0.3096, 0.0135, 0.1667, 0.3677, 0.1010,\n",
      "        0.0418]) tensor([ 0.2568,  0.5886,  0.1145,  0.3894, -0.1172, -0.2047,  0.2399,  0.2005,\n",
      "        -0.0225, -0.3097]) tensor([-0.0133,  0.3509,  0.3752,  0.1018,  0.1892,  0.0074,  0.0496,  0.3567,\n",
      "         0.0291,  0.0600])\n",
      "R[0]\n",
      "tensor([0.0992], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09749724045395851; R = 0.07763420465588569;                 Gamma = 0.7162925966978073; Q = 0.002651080704643391;\n",
      "Entropy Neighbor = 0.3134419279694557;                 Entropy Random = 0.10096955171972513;                 Volume = 0.045985030353069306; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1834, -0.4946,  0.1513, -0.3118,  1.0860,  0.0683,  0.4474,  0.8254,\n",
      "        -0.4904, -0.1231]) tensor([-0.0524, -0.2711, -0.1195, -0.0893,  0.6564, -0.1301,  0.5460,  0.6507,\n",
      "        -0.5728, -0.4846]) tensor([-0.0315,  0.3491,  0.3865,  0.0824,  0.1956,  0.0257,  0.0456,  0.3412,\n",
      "        -0.0068,  0.0743])\n",
      "R[0]\n",
      "tensor([0.1099], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0978395379781723; R = 0.07903493681922555;                 Gamma = 0.716836881518364; Q = 0.0027882598817814143;\n",
      "Entropy Neighbor = 0.31393735668063166;                 Entropy Random = 0.10035351274907589;                 Volume = 0.04673391564190388; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0099,  0.2243,  0.3740,  0.0765, -0.1061, -0.0161, -0.0830,  0.2533,\n",
      "         0.0570,  0.1500]) tensor([ 0.1528,  0.4336,  0.0904,  0.2833, -0.5266, -0.2171,  0.0317,  0.0752,\n",
      "        -0.0453, -0.2148]) tensor([ 0.0099,  0.2243,  0.3740,  0.0765, -0.1061, -0.0161, -0.0830,  0.2533,\n",
      "         0.0570,  0.1500])\n",
      "R[0]\n",
      "tensor([0.1250], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09776193554699421; R = 0.07811431021615863;                 Gamma = 0.7173724546432495; Q = 0.002636284159787465;\n",
      "Entropy Neighbor = 0.31279900470376015;                 Entropy Random = 0.1022598530575633;                 Volume = 0.046719467643648385; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0888,  0.2853,  0.3899,  0.0543,  0.0557,  0.0315, -0.1347,  0.3268,\n",
      "        -0.0408,  0.0603]) tensor([ 0.0568,  0.4999,  0.1062,  0.2680, -0.3677, -0.1707, -0.0271,  0.1511,\n",
      "        -0.1421, -0.3019]) tensor([-0.0888,  0.2853,  0.3899,  0.0543,  0.0557,  0.0315, -0.1347,  0.3268,\n",
      "        -0.0408,  0.0603])\n",
      "R[0]\n",
      "tensor([0.1225], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0971819917112589; R = 0.07763122856989503;                 Gamma = 0.7161901882886886; Q = 0.002839440226671286;\n",
      "Entropy Neighbor = 0.31251444745063783;                 Entropy Random = 0.10143302663415671;                 Volume = 0.04545602371916175; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0027521795188891703\n",
      "Episode average V value: 1.1076074227303268\n",
      "epoch 26:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0074,  0.3697,  0.4057,  0.0838,  0.1658,  0.0094, -0.0084,  0.3740,\n",
      "         0.0008,  0.0327]) tensor([ 0.1331,  0.5850,  0.1209,  0.2910, -0.2486, -0.2052,  0.0830,  0.2213,\n",
      "        -0.1376, -0.3266]) tensor([-0.0173,  0.3585,  0.3762,  0.0974,  0.1737,  0.0019,  0.0167,  0.3527,\n",
      "         0.0126,  0.0431])\n",
      "R[0]\n",
      "tensor([0.0821], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.097913829728961; R = 0.07896172466501594;                 Gamma = 0.7171174031496048; Q = 0.003141417372622527;\n",
      "Entropy Neighbor = 0.3118745744228363;                 Entropy Random = 0.10319382036477327;                 Volume = 0.0465340959765017; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0009, -0.1144,  0.3825,  0.2072,  0.6909,  0.1633,  0.5468,  0.3523,\n",
      "        -0.1240,  0.1462]) tensor([ 0.1436,  0.0654,  0.1004,  0.4084,  0.2798, -0.0501,  0.6734,  0.1331,\n",
      "        -0.2323, -0.2118]) tensor([ 0.1852, -0.1727,  0.5524,  0.5599,  0.8424,  0.3939,  0.7250, -0.0611,\n",
      "        -0.1418,  0.3444])\n",
      "R[0]\n",
      "tensor([0.1896], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09749358147382736; R = 0.07750997920706869;                 Gamma = 0.716341473698616; Q = 0.0030196994196157903;\n",
      "Entropy Neighbor = 0.3115442794263363;                 Entropy Random = 0.10139133317023516;                 Volume = 0.04469968274980783; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0194, -0.4245,  0.1970, -0.3606,  0.9765,  0.0253,  0.3981,  0.8540,\n",
      "        -0.3574, -0.1638]) tensor([ 0.1098, -0.2079, -0.0752, -0.1469,  0.5504, -0.1737,  0.5015,  0.6794,\n",
      "        -0.4500, -0.5266]) tensor([ 0.0912,  0.3465,  0.3464,  0.0921,  0.1885, -0.0286,  0.0584,  0.3329,\n",
      "         0.0694,  0.0654])\n",
      "R[0]\n",
      "tensor([0.1037], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09720435766875744; R = 0.07871998057514429;                 Gamma = 0.7166844304800034; Q = 0.0030003643902600744;\n",
      "Entropy Neighbor = 0.31260276499390605;                 Entropy Random = 0.10319595770537854;                 Volume = 0.046699767351150515; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0542,  0.3127,  0.3589,  0.0859,  0.2278, -0.0106,  0.0991,  0.3933,\n",
      "         0.0685,  0.0273]) tensor([ 0.1957,  0.5149,  0.0740,  0.2839, -0.1886, -0.2156,  0.2176,  0.2072,\n",
      "        -0.0366, -0.3369]) tensor([ 0.0809,  0.3027,  0.3840,  0.1225,  0.3220, -0.0032,  0.2059,  0.4086,\n",
      "         0.1110,  0.0570])\n",
      "R[0]\n",
      "tensor([0.1275], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0975929535627365; R = 0.08031816175580024;                 Gamma = 0.7164473140239715; Q = 0.0031928011204581707;\n",
      "Entropy Neighbor = 0.3111065402626991;                 Entropy Random = 0.10055855937302112;                 Volume = 0.046299448497593404; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0860, 0.1322, 0.3952, 0.1511, 0.4635, 0.0606, 0.3460, 0.4172, 0.0423,\n",
      "        0.0694]) tensor([ 0.2236,  0.3247,  0.1111,  0.3432,  0.0495, -0.1436,  0.4740,  0.2185,\n",
      "        -0.0537, -0.2973]) tensor([-0.0874, -0.2151,  0.2193,  0.1751,  0.5295,  0.0140,  0.4276,  0.4367,\n",
      "        -0.0208,  0.0185])\n",
      "R[0]\n",
      "tensor([0.1418], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09784272915124893; R = 0.07920727424696088;                 Gamma = 0.7170600260496139; Q = 0.0024339878701139244;\n",
      "Entropy Neighbor = 0.3098562605082989;                 Entropy Random = 0.10098930691182613;                 Volume = 0.04748399794101715; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0029576540346140973\n",
      "Episode average V value: 1.1096969570577144\n",
      "epoch 27:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0249,  0.2549,  0.3618,  0.0660,  0.1174,  0.0182, -0.0098,  0.3070,\n",
      "        -0.0116,  0.1025]) tensor([ 0.1154,  0.4722,  0.0781,  0.2767, -0.2986, -0.1943,  0.0817,  0.1548,\n",
      "        -0.1444, -0.2575]) tensor([0.0927, 0.3385, 0.3823, 0.0705, 0.1550, 0.0042, 0.0546, 0.3070, 0.0839,\n",
      "        0.1066])\n",
      "R[0]\n",
      "tensor([0.0843], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09832886618375779; R = 0.08115587286651134;                 Gamma = 0.7170143597126007; Q = 0.003098883578495588;\n",
      "Entropy Neighbor = 0.31071510967612265;                 Entropy Random = 0.10001061183959245;                 Volume = 0.04810501665621996; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0534, -0.2453,  0.2552,  0.2031,  0.6003,  0.0368,  0.4755,  0.4402,\n",
      "        -0.0355,  0.0379]) tensor([ 0.0784, -0.0418, -0.0264,  0.4051,  0.1867, -0.1709,  0.5847,  0.2663,\n",
      "        -0.1414, -0.3282]) tensor([-0.1688, -0.1281,  0.2654, -0.0232,  0.6653,  0.0617,  0.3554,  0.5998,\n",
      "        -0.2275, -0.0956])\n",
      "R[0]\n",
      "tensor([0.1114], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09815224081277847; R = 0.07863457602635025;                 Gamma = 0.7168354879617691; Q = 0.0029458719360409306;\n",
      "Entropy Neighbor = 0.3089862539768219;                 Entropy Random = 0.1018959290459752;                 Volume = 0.04655031154304743; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3013,  0.1256,  0.3260, -0.0237,  0.2656,  0.0856, -0.0124,  0.4083,\n",
      "        -0.2984,  0.0319]) tensor([-0.1482,  0.3429,  0.0487,  0.2084, -0.1624, -0.1244,  0.0834,  0.2182,\n",
      "        -0.4119, -0.3169]) tensor([-0.3165,  0.1366,  0.3711,  0.0060,  0.2797,  0.1164,  0.0122,  0.4011,\n",
      "        -0.3284,  0.0404])\n",
      "R[0]\n",
      "tensor([0.1682], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09824913132190705; R = 0.0796471005640924;                 Gamma = 0.7167433152198791; Q = 0.002865040595061146;\n",
      "Entropy Neighbor = 0.30958138799667356;                 Entropy Random = 0.10144064269214868;                 Volume = 0.04777308166399598; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0950,  0.2775,  0.3826,  0.0461,  0.0443,  0.0292, -0.1424,  0.3244,\n",
      "        -0.0470,  0.0618]) tensor([ 0.0570,  0.4833,  0.1001,  0.2655, -0.3757, -0.1840, -0.0413,  0.1395,\n",
      "        -0.1785, -0.2898]) tensor([-0.0950,  0.2775,  0.3826,  0.0461,  0.0443,  0.0292, -0.1424,  0.3244,\n",
      "        -0.0470,  0.0618])\n",
      "R[0]\n",
      "tensor([0.1563], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09852522392570973; R = 0.08164063386246562;                 Gamma = 0.717026142835617; Q = 0.0029945397998089904;\n",
      "Entropy Neighbor = 0.30903237706422804;                 Entropy Random = 0.10312683864682913;                 Volume = 0.04874177332594991; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1691,  0.3400,  0.3874,  0.0811,  0.1074,  0.0255, -0.0486,  0.3430,\n",
      "        -0.0939,  0.0868]) tensor([-0.0232,  0.5568,  0.1048,  0.2959, -0.3169, -0.1768,  0.0585,  0.1651,\n",
      "        -0.1920, -0.2746]) tensor([-0.1637,  0.3417,  0.3573,  0.0637,  0.1252,  0.0071, -0.0577,  0.3526,\n",
      "        -0.0793,  0.0717])\n",
      "R[0]\n",
      "tensor([0.1266], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09845999999344349; R = 0.07994224096462131;                 Gamma = 0.7175961391925811; Q = 0.0025255875768489203;\n",
      "Entropy Neighbor = 0.30821922731399537;                 Entropy Random = 0.10233399757742882;                 Volume = 0.046031584676355125; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.002885984697251115\n",
      "Episode average V value: 1.1194552979409695\n",
      "epoch 28:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1402,  0.3186,  0.3390,  0.0812,  0.0887, -0.0061, -0.0889,  0.3289,\n",
      "        -0.0983,  0.0711]) tensor([ 0.0230,  0.5720,  0.0553,  0.3358, -0.3474, -0.2227, -0.0316,  0.1744,\n",
      "        -0.2165, -0.2751]) tensor([-0.2392,  0.3372,  0.3546,  0.0455,  0.1283,  0.0190, -0.0854,  0.3516,\n",
      "        -0.1730,  0.0627])\n",
      "R[0]\n",
      "tensor([0.0950], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09765427468717099; R = 0.08084253751859069;                 Gamma = 0.7169969222545624; Q = 0.002890373047150206;\n",
      "Entropy Neighbor = 0.3103393856883049;                 Entropy Random = 0.10128897356241942;                 Volume = 0.044063201200217006; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2586, -0.1162,  0.4295,  0.0987,  0.4865,  0.2169,  0.2541,  0.3357,\n",
      "        -0.3465,  0.2016]) tensor([-0.1112,  0.0841,  0.1514,  0.3234,  0.0627,  0.0092,  0.3642,  0.1301,\n",
      "        -0.4472, -0.1524]) tensor([-0.1411,  0.0167,  0.6187,  0.1802,  0.7572,  0.3745,  0.3328,  0.3325,\n",
      "        -0.4988,  0.1219])\n",
      "R[0]\n",
      "tensor([0.1848], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09773967771232128; R = 0.07925813182815909;                 Gamma = 0.7168098428249359; Q = 0.002845899103267584;\n",
      "Entropy Neighbor = 0.3114250473678112;                 Entropy Random = 0.10268201445788146;                 Volume = 0.04470086569711566; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.1184, 0.1376, 0.4157, 0.1644, 0.4955, 0.0496, 0.3678, 0.4299, 0.0749,\n",
      "        0.1131]) tensor([ 0.2546,  0.3255,  0.1307,  0.3526,  0.0835, -0.1547,  0.4992,  0.2292,\n",
      "        -0.0224, -0.2551]) tensor([-0.0264, -0.1533,  0.2945,  0.2031,  0.5521,  0.0349,  0.4422,  0.4370,\n",
      "        -0.0235,  0.0580])\n",
      "R[0]\n",
      "tensor([0.1416], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09757377456128598; R = 0.07937872629612684;                 Gamma = 0.7167364773750305; Q = 0.003369581901759375;\n",
      "Entropy Neighbor = 0.3115034613907337;                 Entropy Random = 0.10135663466900587;                 Volume = 0.043371145267039536; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0242, -0.1106,  0.2955, -0.0979,  0.5873, -0.0055,  0.2005,  0.6275,\n",
      "        -0.0799, -0.0961]) tensor([ 0.1668,  0.0810,  0.0163,  0.1081,  0.1693, -0.2149,  0.3186,  0.4203,\n",
      "        -0.1958, -0.4525]) tensor([ 0.0032,  0.0051,  0.3557,  0.0398,  0.4688,  0.0714,  0.2800,  0.4775,\n",
      "        -0.0900, -0.0034])\n",
      "R[0]\n",
      "tensor([0.1690], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09797167254984379; R = 0.07917262567952275;                 Gamma = 0.7170822525024414; Q = 0.002748393650224898;\n",
      "Entropy Neighbor = 0.3095585287511349;                 Entropy Random = 0.10239537097513676;                 Volume = 0.043892077926546334; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0036,  0.2844,  0.3159,  0.0302,  0.1312, -0.0344,  0.0032,  0.3570,\n",
      "         0.0132,  0.0670]) tensor([ 0.1562,  0.5294,  0.0315,  0.2760, -0.3018, -0.2506,  0.0676,  0.1977,\n",
      "        -0.1073, -0.2816]) tensor([-0.0168,  0.3614,  0.3739,  0.0537,  0.1787, -0.0226,  0.0354,  0.3970,\n",
      "         0.0143,  0.0523])\n",
      "R[0]\n",
      "tensor([0.0955], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09867761151492596; R = 0.08041598402336239;                 Gamma = 0.7167237399816513; Q = 0.002919510982290376;\n",
      "Entropy Neighbor = 0.3065744390487671;                 Entropy Random = 0.1027731170579791;                 Volume = 0.045928352296352386; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.002954751736938488\n",
      "Episode average V value: 1.1083645969927312\n",
      "epoch 29:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0293,  0.3386,  0.3436,  0.0975,  0.2069, -0.0067,  0.0551,  0.3362,\n",
      "         0.0391,  0.0512]) tensor([ 0.1723,  0.5437,  0.0584,  0.2986, -0.2100, -0.2123,  0.1707,  0.1531,\n",
      "        -0.0659, -0.3124]) tensor([ 0.0845,  0.3114,  0.3698,  0.1031,  0.3071, -0.0007,  0.1682,  0.3725,\n",
      "         0.0816,  0.0651])\n",
      "R[0]\n",
      "tensor([0.1248], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0987057785987854; R = 0.0817191520743072;                 Gamma = 0.7172244929075241; Q = 0.003453870644210838;\n",
      "Entropy Neighbor = 0.30834140461683274;                 Entropy Random = 0.10108684765547514;                 Volume = 0.04707583542913198; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2044,  0.1611,  0.3101,  0.1205,  0.3314, -0.0698,  0.3021,  0.4281,\n",
      "         0.2498,  0.0855]) tensor([ 0.3396,  0.3477,  0.0240,  0.3025, -0.0780, -0.2749,  0.4349,  0.2319,\n",
      "         0.1441, -0.2836]) tensor([0.0814, 0.2138, 0.3818, 0.1117, 0.4541, 0.0467, 0.3192, 0.4079, 0.0291,\n",
      "        0.0859])\n",
      "R[0]\n",
      "tensor([0.1342], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09829517602920532; R = 0.07863152458146215;                 Gamma = 0.7170434726476669; Q = 0.002753169469477143;\n",
      "Entropy Neighbor = 0.30876634576916695;                 Entropy Random = 0.10477048735320568;                 Volume = 0.04600414653122425; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0617, 0.2530, 0.4472, 0.1155, 0.5040, 0.0551, 0.3410, 0.4986, 0.0222,\n",
      "        0.0284]) tensor([ 0.1996,  0.4462,  0.1632,  0.3074,  0.0893, -0.1495,  0.4676,  0.2998,\n",
      "        -0.0767, -0.3373]) tensor([-0.1270, -0.0883,  0.4146,  0.1823,  0.6379,  0.1815,  0.4947,  0.3673,\n",
      "        -0.2095,  0.1773])\n",
      "R[0]\n",
      "tensor([0.1399], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09845477585494518; R = 0.08015033079311251;                 Gamma = 0.7171372547149658; Q = 0.0030600894549279475;\n",
      "Entropy Neighbor = 0.30623727256059646;                 Entropy Random = 0.10270803855359555;                 Volume = 0.04764105287566781; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3012,  0.2698,  0.3717,  0.0371,  0.2305,  0.0583, -0.0244,  0.3879,\n",
      "        -0.2343,  0.0533]) tensor([-0.1568,  0.5029,  0.0920,  0.2643, -0.1943, -0.1524,  0.0559,  0.2381,\n",
      "        -0.3556, -0.3023]) tensor([-0.2802,  0.2970,  0.3924,  0.0328,  0.2303,  0.0669, -0.0127,  0.3919,\n",
      "        -0.2317,  0.0527])\n",
      "R[0]\n",
      "tensor([0.0886], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09876743985712529; R = 0.08154503692686557;                 Gamma = 0.7171042742729187; Q = 0.003044913282210473;\n",
      "Entropy Neighbor = 0.30574756664037706;                 Entropy Random = 0.10452294187247753;                 Volume = 0.04550780226290226; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0243, 0.2451, 0.4082, 0.1064, 0.3827, 0.0581, 0.2364, 0.3964, 0.0122,\n",
      "        0.0754]) tensor([ 0.1644,  0.4434,  0.1240,  0.3043, -0.0340, -0.1459,  0.3585,  0.2034,\n",
      "        -0.0859, -0.2897]) tensor([ 0.0377,  0.1351,  0.4226,  0.1131,  0.5039,  0.0617,  0.3245,  0.4712,\n",
      "        -0.0085,  0.0717])\n",
      "R[0]\n",
      "tensor([0.1364], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09834976489841939; R = 0.07954904021322727;                 Gamma = 0.7165133991241455; Q = 0.003271291345183272;\n",
      "Entropy Neighbor = 0.30455181291699407;                 Entropy Random = 0.10137016846984624;                 Volume = 0.046861173257231714; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0031166668392019346\n",
      "Episode average V value: 1.0948671819258329\n",
      "epoch 30:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2774,  0.2922,  0.3198,  0.0301,  0.1563, -0.0011, -0.0429,  0.3647,\n",
      "        -0.1689,  0.0948]) tensor([-0.1136,  0.5505,  0.0382,  0.2904, -0.2836, -0.2155,  0.0118,  0.2097,\n",
      "        -0.2802, -0.2504]) tensor([-0.2995,  0.2915,  0.3691,  0.0221,  0.2112,  0.0605, -0.0472,  0.3798,\n",
      "        -0.2407,  0.0508])\n",
      "R[0]\n",
      "tensor([0.0996], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0986839664876461; R = 0.08013889997825027;                 Gamma = 0.7167694953680038; Q = 0.0032750839094514957;\n",
      "Entropy Neighbor = 0.3056538131535053;                 Entropy Random = 0.1015729507431388;                 Volume = 0.045583044186234475; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0409,  0.3709,  0.3914,  0.0545,  0.1749,  0.0179,  0.0212,  0.3492,\n",
      "        -0.0199,  0.0757]) tensor([ 0.1030,  0.5798,  0.1073,  0.2610, -0.2454, -0.1860,  0.1338,  0.1673,\n",
      "        -0.1226, -0.2870]) tensor([ 0.0066,  0.2996,  0.3872,  0.1091,  0.3190,  0.0499,  0.1868,  0.3406,\n",
      "        -0.0132,  0.1026])\n",
      "R[0]\n",
      "tensor([0.1256], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09845211902260781; R = 0.07875309327617287;                 Gamma = 0.7167638735771179; Q = 0.0028536780229769646;\n",
      "Entropy Neighbor = 0.3044351208806038;                 Entropy Random = 0.10062492144852876;                 Volume = 0.044659842122346166; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3116, -0.2539,  0.3567,  0.2107,  0.2083,  0.2058,  0.1591,  0.0853,\n",
      "        -0.3742,  0.3681]) tensor([-0.1714, -0.0266,  0.0790,  0.4438, -0.2178,  0.0030,  0.2505, -0.0748,\n",
      "        -0.4668,  0.0059]) tensor([ 0.1764, -0.0531,  0.4354,  0.1577,  0.1622,  0.0776,  0.2006,  0.2957,\n",
      "         0.0457,  0.1952])\n",
      "R[0]\n",
      "tensor([0.1098], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09893691611289979; R = 0.0804798439051956;                 Gamma = 0.7172739846706391; Q = 0.0030309814992942846;\n",
      "Entropy Neighbor = 0.3042704592943192;                 Entropy Random = 0.10166608087718487;                 Volume = 0.04791733112558722; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3128, -0.0565,  0.4771,  0.1126,  0.4885,  0.2768,  0.2468,  0.2849,\n",
      "        -0.4222,  0.2311]) tensor([-0.1538,  0.1911,  0.1968,  0.3760,  0.0463,  0.0683,  0.3112,  0.1139,\n",
      "        -0.5098, -0.1181]) tensor([-0.2319, -0.1352,  0.4694,  0.1030,  0.4891,  0.2352,  0.2466,  0.3482,\n",
      "        -0.3705,  0.2167])\n",
      "R[0]\n",
      "tensor([0.1258], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09850749623775482; R = 0.08012791757658123;                 Gamma = 0.7166082661151886; Q = 0.0033960053722839802;\n",
      "Entropy Neighbor = 0.3048801574110985;                 Entropy Random = 0.10300246287882328;                 Volume = 0.04492479483410716; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2662,  0.3143,  0.3692,  0.0349,  0.1582,  0.0288, -0.0594,  0.3783,\n",
      "        -0.1846,  0.0647]) tensor([-0.1022,  0.5721,  0.0875,  0.2954, -0.2820, -0.1857, -0.0051,  0.2229,\n",
      "        -0.2970, -0.2801]) tensor([-0.3097,  0.2600,  0.4016,  0.0243,  0.2130,  0.0940, -0.0518,  0.3742,\n",
      "        -0.2647,  0.0569])\n",
      "R[0]\n",
      "tensor([0.0992], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09931051662564278; R = 0.08085608883574605;                 Gamma = 0.7177439305782318; Q = 0.0029340482161496766;\n",
      "Entropy Neighbor = 0.3032543603777885;                 Entropy Random = 0.09989155507832766;                 Volume = 0.04803724628314376; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0030979594040312806\n",
      "Episode average V value: 1.0951678283303976\n",
      "epoch 31:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2849,  0.1584,  0.2709,  0.0604,  0.0468, -0.0063, -0.1420,  0.2855,\n",
      "        -0.1782,  0.1191]) tensor([-0.1373,  0.3862, -0.0093,  0.2857, -0.3819, -0.2063, -0.0409,  0.1138,\n",
      "        -0.2670, -0.2416]) tensor([-0.1592,  0.2813,  0.3298,  0.0187, -0.0030, -0.0382, -0.1753,  0.3550,\n",
      "        -0.0828,  0.0823])\n",
      "R[0]\n",
      "tensor([0.1257], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09895063363015652; R = 0.07981426366046071;                 Gamma = 0.7166433475017547; Q = 0.00358382836706005;\n",
      "Entropy Neighbor = 0.3044057426154613;                 Entropy Random = 0.10252796851098538;                 Volume = 0.04786895842477679; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0416,  0.4042,  0.3946,  0.0379,  0.0390, -0.0145, -0.1596,  0.3649,\n",
      "        -0.0273,  0.0209]) tensor([ 0.1212,  0.6539,  0.1100,  0.2881, -0.3955, -0.2320, -0.1011,  0.2111,\n",
      "        -0.1536, -0.3253]) tensor([-0.2005,  0.3120,  0.3458,  0.0497,  0.0801,  0.0092, -0.1169,  0.3278,\n",
      "        -0.1272,  0.0660])\n",
      "R[0]\n",
      "tensor([0.0886], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09930200120806694; R = 0.08068741369619965;                 Gamma = 0.7171015565395356; Q = 0.0033724047195282767;\n",
      "Entropy Neighbor = 0.301498735666275;                 Entropy Random = 0.1007851693034172;                 Volume = 0.04872918600589037; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3250, -0.1435,  0.3925,  0.1022,  0.5107,  0.1844,  0.2668,  0.3642,\n",
      "        -0.3947,  0.2022]) tensor([-0.1775,  0.0605,  0.1157,  0.3290,  0.0854, -0.0225,  0.3757,  0.1589,\n",
      "        -0.4917, -0.1515]) tensor([-0.2085,  0.0803,  0.7475,  0.2404,  0.7622,  0.4800,  0.2727,  0.2830,\n",
      "        -0.5867,  0.1221])\n",
      "R[0]\n",
      "tensor([0.1854], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09941458150744438; R = 0.08065617137402296;                 Gamma = 0.7168510251045227; Q = 0.0038427879164228216;\n",
      "Entropy Neighbor = 0.30032035502791404;                 Entropy Random = 0.0994245166555047;                 Volume = 0.048854207661002874; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1063,  0.2181,  0.3570,  0.0962,  0.4411, -0.0103,  0.3353,  0.4721,\n",
      "         0.1016,  0.0546]) tensor([ 0.2433,  0.4104,  0.0727,  0.2848,  0.0280, -0.2151,  0.4635,  0.2747,\n",
      "         0.0007, -0.3120]) tensor([0.0882, 0.2029, 0.4044, 0.1194, 0.5278, 0.0503, 0.3803, 0.4688, 0.0433,\n",
      "        0.0644])\n",
      "R[0]\n",
      "tensor([0.1374], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09936859312653541; R = 0.0821806730851531;                 Gamma = 0.7167959671020507; Q = 0.0037346113689127377;\n",
      "Entropy Neighbor = 0.3022412900328636;                 Entropy Random = 0.10164356872439384;                 Volume = 0.047047391157597304; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0091,  0.3610,  0.4413,  0.1239,  0.2223,  0.0093,  0.0660,  0.4115,\n",
      "         0.0115,  0.0406]) tensor([ 0.1296,  0.5717,  0.1560,  0.3277, -0.1909, -0.2048,  0.1614,  0.2548,\n",
      "        -0.1254, -0.3201]) tensor([-0.0091,  0.3610,  0.4413,  0.1239,  0.2223,  0.0093,  0.0660,  0.4115,\n",
      "         0.0115,  0.0406])\n",
      "R[0]\n",
      "tensor([0.0859], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09924936626851559; R = 0.08131276249885559;                 Gamma = 0.7162531449794769; Q = 0.004029149951820727;\n",
      "Entropy Neighbor = 0.30249538254737857;                 Entropy Random = 0.10076913641393184;                 Volume = 0.04615129438042641; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0037125564647489226\n",
      "Episode average V value: 1.1189127606928349\n",
      "epoch 32:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0099, 0.3153, 0.3659, 0.1087, 0.2987, 0.0079, 0.1799, 0.3665, 0.0390,\n",
      "        0.0955]) tensor([ 0.1510,  0.5162,  0.0812,  0.3072, -0.1177, -0.1968,  0.2998,  0.1776,\n",
      "        -0.0623, -0.2690]) tensor([0.0476, 0.2663, 0.3822, 0.1237, 0.4309, 0.0305, 0.3001, 0.4169, 0.0394,\n",
      "        0.0868])\n",
      "R[0]\n",
      "tensor([0.1317], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09937259212136268; R = 0.08074065243452787;                 Gamma = 0.7178631558418274; Q = 0.0028171943015768194;\n",
      "Entropy Neighbor = 0.30263017109036444;                 Entropy Random = 0.10058434956520795;                 Volume = 0.047569659307599065; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.1050, 0.2448, 0.3769, 0.1131, 0.4419, 0.0037, 0.3275, 0.4647, 0.0847,\n",
      "        0.0486]) tensor([ 0.2387,  0.4426,  0.0911,  0.3051,  0.0334, -0.2100,  0.4345,  0.2963,\n",
      "        -0.0479, -0.3155]) tensor([0.0337, 0.2563, 0.4023, 0.1118, 0.4252, 0.0405, 0.2988, 0.4448, 0.0269,\n",
      "        0.0687])\n",
      "R[0]\n",
      "tensor([0.0950], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09917641732096671; R = 0.08121328366175294;                 Gamma = 0.7173439251184464; Q = 0.003813925362424925;\n",
      "Entropy Neighbor = 0.30208556750416754;                 Entropy Random = 0.10304680512100459;                 Volume = 0.04554174830764532; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1462,  0.3914,  0.4291,  0.0913,  0.0637,  0.0468, -0.1074,  0.3221,\n",
      "        -0.0972,  0.0755]) tensor([ 0.0176,  0.6432,  0.1449,  0.3466, -0.3730, -0.1696, -0.0507,  0.1675,\n",
      "        -0.2175, -0.2703]) tensor([-0.2281,  0.3214,  0.3823,  0.0701,  0.1566,  0.0336, -0.0290,  0.3664,\n",
      "        -0.1350,  0.0782])\n",
      "R[0]\n",
      "tensor([0.0955], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09983602897822857; R = 0.08206346931308509;                 Gamma = 0.7165409959554673; Q = 0.0038769013176788575;\n",
      "Entropy Neighbor = 0.3008433306515217;                 Entropy Random = 0.1011107262596488;                 Volume = 0.04700973670557141; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0273, 0.3369, 0.3676, 0.1071, 0.2283, 0.0116, 0.0868, 0.3388, 0.0259,\n",
      "        0.0601]) tensor([ 0.1765,  0.5303,  0.0827,  0.3133, -0.1847, -0.2051,  0.1974,  0.1436,\n",
      "        -0.1081, -0.2935]) tensor([-3.0831e-04,  3.6339e-01,  3.8394e-01,  1.1718e-01,  2.1643e-01,\n",
      "         1.1462e-02,  7.0109e-02,  3.6861e-01,  2.1965e-02,  3.7861e-02])\n",
      "R[0]\n",
      "tensor([0.1610], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09930349372327328; R = 0.08035490878671407;                 Gamma = 0.7163180602788926; Q = 0.004010167200816795;\n",
      "Entropy Neighbor = 0.30254107534885405;                 Entropy Random = 0.10123590580374002;                 Volume = 0.04568692147359252; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2972,  0.1745,  0.3674, -0.0287,  0.3144,  0.0899,  0.0350,  0.4554,\n",
      "        -0.3049,  0.0154]) tensor([-0.1344,  0.4337,  0.0884,  0.2350, -0.1290, -0.1220,  0.0905,  0.2949,\n",
      "        -0.4077, -0.3293]) tensor([-0.2239, -0.3660,  0.0962,  0.0428,  0.4748, -0.0521,  0.3275,  0.4937,\n",
      "        -0.1605,  0.0369])\n",
      "R[0]\n",
      "tensor([0.1068], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09994251142442226; R = 0.08175559224933386;                 Gamma = 0.7171776139736176; Q = 0.0035869608755456283;\n",
      "Entropy Neighbor = 0.3003575681746006;                 Entropy Random = 0.1016992828398943;                 Volume = 0.04767989046126604; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.003621029811608605\n",
      "Episode average V value: 1.0972502455174924\n",
      "epoch 33:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2862,  0.2951,  0.3262,  0.0428,  0.1487,  0.0122, -0.0470,  0.3444,\n",
      "        -0.1766,  0.0971]) tensor([-0.1220,  0.5539,  0.0445,  0.3041, -0.2913, -0.2024,  0.0071,  0.1898,\n",
      "        -0.2878, -0.2479]) tensor([-0.3389,  0.2473,  0.3531,  0.0213,  0.2264,  0.0584, -0.0174,  0.3873,\n",
      "        -0.2621,  0.0700])\n",
      "R[0]\n",
      "tensor([0.1001], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09976053594052792; R = 0.08183151984214783;                 Gamma = 0.7167328095436096; Q = 0.004217548418324441;\n",
      "Entropy Neighbor = 0.2972580508291721;                 Entropy Random = 0.09989809389784932;                 Volume = 0.047710428781807424; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3048,  0.2981,  0.3320,  0.0289,  0.1590,  0.0151, -0.0636,  0.3602,\n",
      "        -0.2123,  0.0886]) tensor([-0.1402,  0.5585,  0.0508,  0.2916, -0.2819, -0.1994, -0.0107,  0.2060,\n",
      "        -0.3228, -0.2559]) tensor([-0.3133,  0.2690,  0.3815,  0.0233,  0.2366,  0.0733, -0.0403,  0.3865,\n",
      "        -0.2776,  0.0518])\n",
      "R[0]\n",
      "tensor([0.0995], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.10017347440123558; R = 0.08388630344718695;                 Gamma = 0.7166328333616256; Q = 0.004333978195732925;\n",
      "Entropy Neighbor = 0.3001151252686977;                 Entropy Random = 0.10187093221396208;                 Volume = 0.04869325968995691; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1064,  0.1960,  0.3456,  0.1269,  0.3292, -0.0015,  0.2529,  0.3678,\n",
      "         0.1160,  0.0940]) tensor([ 0.2447,  0.3900,  0.0604,  0.3186, -0.0840, -0.2061,  0.3792,  0.1745,\n",
      "         0.0150, -0.2728]) tensor([0.0408, 0.2422, 0.3838, 0.1198, 0.4115, 0.0361, 0.2890, 0.4042, 0.0227,\n",
      "        0.0930])\n",
      "R[0]\n",
      "tensor([0.1348], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.10043371234834195; R = 0.08427871522307397;                 Gamma = 0.7166407237052917; Q = 0.0042853230186156;\n",
      "Entropy Neighbor = 0.29708271753787996;                 Entropy Random = 0.10221902934461832;                 Volume = 0.05002735245600343; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0806, 0.2123, 0.4379, 0.1481, 0.5535, 0.0633, 0.3870, 0.4852, 0.0486,\n",
      "        0.0303]) tensor([ 0.2178,  0.4027,  0.1533,  0.3377,  0.1403, -0.1419,  0.5157,  0.2845,\n",
      "        -0.0497, -0.3361]) tensor([-0.0072, -0.2203,  0.2515,  0.0931,  0.6701,  0.0109,  0.4588,  0.5632,\n",
      "        -0.0098, -0.0154])\n",
      "R[0]\n",
      "tensor([0.1419], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09997999522089958; R = 0.0837523815073073;                 Gamma = 0.7170242730379105; Q = 0.0038459946181392296;\n",
      "Entropy Neighbor = 0.29678185972571375;                 Entropy Random = 0.09951750993728638;                 Volume = 0.04868878347426653; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0787, -0.2663,  0.2522, -0.1097,  0.7745,  0.0653,  0.4080,  0.6847,\n",
      "        -0.2882, -0.0901]) tensor([ 0.0534, -0.0506, -0.0230,  0.1027,  0.3517, -0.1382,  0.5098,  0.5113,\n",
      "        -0.3874, -0.4521]) tensor([-0.1804, -0.4250,  0.2643, -0.2920,  1.1235,  0.1561,  0.4854,  0.8128,\n",
      "        -0.5977, -0.1408])\n",
      "R[0]\n",
      "tensor([0.1080], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09986099290847779; R = 0.08053397991880774;                 Gamma = 0.7173709306716919; Q = 0.00383522996713873;\n",
      "Entropy Neighbor = 0.2973948858678341;                 Entropy Random = 0.10214566316455603;                 Volume = 0.04871267694234848; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004103614843590185\n",
      "Episode average V value: 1.1016280544102193\n",
      "epoch 34:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 1.1712e-04,  8.2101e-02,  2.5868e-01,  6.0526e-02,  1.8483e-01,\n",
      "        -3.1256e-02,  1.2599e-01,  3.5369e-01,  1.0090e-01,  9.9010e-02]) tensor([ 0.1366,  0.2934, -0.0248,  0.2652, -0.2294, -0.2417,  0.2246,  0.1965,\n",
      "        -0.0272, -0.2639]) tensor([-0.4940, -0.4326, -0.1079,  0.0480, -0.0572, -0.1466,  0.0023,  0.2146,\n",
      "        -0.1849,  0.1515])\n",
      "R[0]\n",
      "tensor([0.0908], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09997751231491565; R = 0.08319425443559884;                 Gamma = 0.7170494999885559; Q = 0.004402962254651356;\n",
      "Entropy Neighbor = 0.3006095194518566;                 Entropy Random = 0.10175308519601822;                 Volume = 0.04959225368499756; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4544, -0.0562,  0.3094,  0.2533,  0.3761, -0.0902,  0.4695,  0.3707,\n",
      "         0.4545,  0.1221]) tensor([ 0.5838,  0.1125,  0.0206,  0.4178, -0.0236, -0.2970,  0.6175,  0.1649,\n",
      "         0.3464, -0.2525]) tensor([0.0133, 0.3031, 0.3818, 0.0945, 0.3660, 0.0278, 0.2394, 0.4039, 0.0107,\n",
      "        0.0760])\n",
      "R[0]\n",
      "tensor([0.1401], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.10012535974383355; R = 0.08246062782779336;                 Gamma = 0.7175367592573166; Q = 0.003451402078673709;\n",
      "Entropy Neighbor = 0.2986837141215801;                 Entropy Random = 0.10215494200587273;                 Volume = 0.04927541054412723; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0100, -0.2730,  0.2428,  0.1100,  0.6470,  0.0246,  0.4841,  0.5208,\n",
      "        -0.0151,  0.0038]) tensor([ 0.1203, -0.0712, -0.0381,  0.3101,  0.2329, -0.1818,  0.5947,  0.3457,\n",
      "        -0.1214, -0.3626]) tensor([-0.1965, -0.1975,  0.2765, -0.1099,  0.7495,  0.0603,  0.4062,  0.6950,\n",
      "        -0.2667, -0.0427])\n",
      "R[0]\n",
      "tensor([0.1108], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09955360381305217; R = 0.083532380618155;                 Gamma = 0.717105187535286; Q = 0.00445329176884843;\n",
      "Entropy Neighbor = 0.3009190390110016;                 Entropy Random = 0.10227178578823805;                 Volume = 0.047841815404593944; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4456, -0.0590,  0.3117,  0.2540,  0.3823, -0.0838,  0.4717,  0.3686,\n",
      "         0.4431,  0.1244]) tensor([ 0.5752,  0.1101,  0.0230,  0.4191, -0.0177, -0.2905,  0.6195,  0.1628,\n",
      "         0.3356, -0.2501]) tensor([0.0114, 0.2971, 0.3852, 0.0978, 0.3799, 0.0343, 0.2509, 0.4044, 0.0050,\n",
      "        0.0767])\n",
      "R[0]\n",
      "tensor([0.1405], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09951833987236022; R = 0.08166282669454814;                 Gamma = 0.716742437005043; Q = 0.004353147368878126;\n",
      "Entropy Neighbor = 0.2997006308734417;                 Entropy Random = 0.10400963101536036;                 Volume = 0.047142202123999596; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3651, -0.1100,  0.6686,  0.1329,  1.2805,  0.6105,  0.3360,  0.3413,\n",
      "        -1.0554, -0.1184]) tensor([-0.2105,  0.1011,  0.3912,  0.3734,  0.8531,  0.3947,  0.4308,  0.1293,\n",
      "        -1.1453, -0.4641]) tensor([-0.0337,  0.3292,  0.3579,  0.0950,  0.1420, -0.0191,  0.0194,  0.3688,\n",
      "         0.0084,  0.0414])\n",
      "R[0]\n",
      "tensor([0.1808], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.10012249106168747; R = 0.08339467997103929;                 Gamma = 0.7171789219379425; Q = 0.004356285242014564;\n",
      "Entropy Neighbor = 0.2958383162617683;                 Entropy Random = 0.10130224951356649;                 Volume = 0.046905866842716935; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0042034177426132375\n",
      "Episode average V value: 1.1025836262762547\n",
      "epoch 35:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1052, -0.1587,  0.2796,  0.1180,  0.6291,  0.0534,  0.4401,  0.4956,\n",
      "        -0.1199,  0.0304]) tensor([ 3.7895e-02,  3.1473e-02,  2.5403e-04,  3.2462e-01,  2.1288e-01,\n",
      "        -1.5733e-01,  5.6115e-01,  2.8208e-01, -2.2633e-01, -3.2617e-01]) tensor([-0.1818, -0.1876,  0.1957,  0.1214,  0.6138,  0.0454,  0.4306,  0.4427,\n",
      "        -0.1810, -0.0103])\n",
      "R[0]\n",
      "tensor([0.1860], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.10077220456302166; R = 0.08638393099233509;                 Gamma = 0.7176505808830261; Q = 0.0040960134541383015;\n",
      "Entropy Neighbor = 0.29477955934405325;                 Entropy Random = 0.10055364229530096;                 Volume = 0.050850992772728205; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0274,  0.1747,  0.4544,  0.1425,  0.5620,  0.0968,  0.3446,  0.4672,\n",
      "        -0.0463,  0.0460]) tensor([ 0.1657,  0.3691,  0.1707,  0.3378,  0.1463, -0.1073,  0.4704,  0.2678,\n",
      "        -0.1403, -0.3197]) tensor([-0.1484, -0.1893,  0.1942,  0.0854,  0.6245,  0.0219,  0.4253,  0.4977,\n",
      "        -0.1527, -0.0330])\n",
      "R[0]\n",
      "tensor([0.1422], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0997958400696516; R = 0.08032646866887808;                 Gamma = 0.717330364704132; Q = 0.0036987843984388744;\n",
      "Entropy Neighbor = 0.2972037474513054;                 Entropy Random = 0.10217262103408575;                 Volume = 0.04825021167099476; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1242, -0.0122,  0.2826, -0.0298,  0.5407,  0.0078,  0.2688,  0.5985,\n",
      "        -0.1533, -0.0461]) tensor([ 0.0209,  0.1865,  0.0047,  0.1820,  0.1201, -0.2022,  0.3823,  0.3919,\n",
      "        -0.2658, -0.3999]) tensor([-0.1351, -0.0054,  0.1982, -0.0923,  0.2718, -0.0988,  0.0686,  0.5915,\n",
      "        -0.0350, -0.0372])\n",
      "R[0]\n",
      "tensor([0.1758], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.1002503578811884; R = 0.08319763867929578;                 Gamma = 0.716934760928154; Q = 0.004163596446684096;\n",
      "Entropy Neighbor = 0.2983253160715103;                 Entropy Random = 0.10335287243127823;                 Volume = 0.04935306441411376; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.1287, 0.2054, 0.5101, 0.1863, 0.5254, 0.0912, 0.3593, 0.4881, 0.0274,\n",
      "        0.0344]) tensor([ 0.2654,  0.3929,  0.2251,  0.3742,  0.1132, -0.1138,  0.4900,  0.2861,\n",
      "        -0.0720, -0.3327]) tensor([-0.0189, -0.2553,  0.2215,  0.0995,  0.6261,  0.0100,  0.4411,  0.5059,\n",
      "         0.0046, -0.0096])\n",
      "R[0]\n",
      "tensor([0.1418], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09963759385049344; R = 0.08206083387508989;                 Gamma = 0.7168509937524795; Q = 0.00445335239416454;\n",
      "Entropy Neighbor = 0.2973650721013546;                 Entropy Random = 0.10302359430491924;                 Volume = 0.047442164473235605; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0505, 0.3033, 0.3832, 0.1060, 0.3870, 0.0123, 0.2489, 0.4301, 0.0613,\n",
      "        0.0611]) tensor([ 0.1864,  0.5060,  0.0973,  0.3030, -0.0233, -0.2018,  0.3509,  0.2659,\n",
      "        -0.0726, -0.3015]) tensor([0.0533, 0.2681, 0.3868, 0.1303, 0.3984, 0.0083, 0.2829, 0.4481, 0.0386,\n",
      "        0.0477])\n",
      "R[0]\n",
      "tensor([0.0919], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09999396470189094; R = 0.0832669960707426;                 Gamma = 0.7173853414058685; Q = 0.0042846689448924734;\n",
      "Entropy Neighbor = 0.29874727258086203;                 Entropy Random = 0.10416649249196053;                 Volume = 0.04807515411451459; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004139283127663657\n",
      "Episode average V value: 1.0990356682389975\n",
      "epoch 36:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 140.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 139.98600139986002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_env.py:320: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3435,  0.1553,  0.4260,  0.0034,  0.2907,  0.1564,  0.0185,  0.3769,\n",
      "        -0.3444,  0.0965]) tensor([-0.1802,  0.4142,  0.1465,  0.2709, -0.1538, -0.0543,  0.0732,  0.2169,\n",
      "        -0.4444, -0.2485]) tensor([-0.2535, -0.0713,  0.4425,  0.1111,  0.4771,  0.2153,  0.2541,  0.3408,\n",
      "        -0.3580,  0.1952])\n",
      "R[0]\n",
      "tensor([0.1103], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.1004647610783577; R = 0.08343044790253043;                 Gamma = 0.7171525371074676; Q = 0.004416846320731566;\n",
      "Entropy Neighbor = 0.294104270786047;                 Entropy Random = 0.1014782331287861;                 Volume = 0.04861234221607447; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.0589, 0.3270, 0.4028, 0.1434, 0.3096, 0.0070, 0.1629, 0.4045, 0.0948,\n",
      "        0.0339]) tensor([ 0.2059,  0.5129,  0.1166,  0.3432, -0.1007, -0.2098,  0.2790,  0.2046,\n",
      "        -0.0403, -0.3215]) tensor([0.0412, 0.3372, 0.4085, 0.1456, 0.2889, 0.0099, 0.1344, 0.3985, 0.0781,\n",
      "        0.0348])\n",
      "R[0]\n",
      "tensor([0.1640], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.09977884556353092; R = 0.082676842097193;                 Gamma = 0.7170718187093734; Q = 0.00448499573150184;\n",
      "Entropy Neighbor = 0.2971932849884033;                 Entropy Random = 0.10228185390681029;                 Volume = 0.04703714847192168; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0551,  0.1753,  0.4296,  0.1188,  0.5248,  0.0687,  0.3390,  0.4688,\n",
      "        -0.0150,  0.0600]) tensor([ 0.2086,  0.4019,  0.1438,  0.3534,  0.0958, -0.1455,  0.4181,  0.2918,\n",
      "        -0.1255, -0.2931]) tensor([0.0687, 0.2053, 0.4142, 0.1464, 0.4470, 0.0262, 0.3127, 0.4632, 0.0787,\n",
      "        0.0562])\n",
      "R[0]\n",
      "tensor([0.1100], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.10077803201973438; R = 0.08520532398670912;                 Gamma = 0.7175664781332016; Q = 0.0041407080669887365;\n",
      "Entropy Neighbor = 0.2937134245634079;                 Entropy Random = 0.1006684060394764;                 Volume = 0.04986589635536075; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3079, -0.0061,  0.8100,  0.2827,  1.2859,  0.6881,  0.4204,  0.2862,\n",
      "        -0.9430, -0.0527]) tensor([-0.1632,  0.2114,  0.5283,  0.5196,  0.8610,  0.4754,  0.5058,  0.1070,\n",
      "        -1.0319, -0.4082]) tensor([-0.1298,  0.0544,  0.6536,  0.1653,  0.7599,  0.3782,  0.2841,  0.3591,\n",
      "        -0.4671,  0.0766])\n",
      "R[0]\n",
      "tensor([0.1181], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.100925357401371; R = 0.08730225069820881;                 Gamma = 0.7173962894678115; Q = 0.003944500830431934;\n",
      "Entropy Neighbor = 0.29540020221471786;                 Entropy Random = 0.10249086160957813;                 Volume = 0.05166270399466157; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0822, -0.1242,  0.3567,  0.1702,  0.6714,  0.1623,  0.5213,  0.3649,\n",
      "        -0.2061,  0.1518]) tensor([ 0.0616,  0.0625,  0.0766,  0.3774,  0.2566, -0.0497,  0.6438,  0.1477,\n",
      "        -0.3105, -0.2047]) tensor([-0.0420, -0.0365,  0.5984,  0.1165,  0.9042,  0.3749,  0.5302,  0.3916,\n",
      "        -0.4638,  0.1462])\n",
      "R[0]\n",
      "tensor([0.1900], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"params\")\n",
    "except Exception:\n",
    "    pass\n",
    "dump(vars(parameters), \"params/\" + fname + \".jldump\")\n",
    "#agent.gathering_data=False\n",
    "if set_network is not None:\n",
    "    agent.setNetwork(\n",
    "        f'{set_network[0]}/fname', nEpoch=set_network[1],\n",
    "        encoder_only=set_network[2]\n",
    "        )\n",
    "agent.run(parameters.epochs, parameters.steps_per_epoch)\n",
    "\n",
    "# --- Show results ---\n",
    "basename = \"scores/\" + fname\n",
    "scores = load(basename + \"_scores.jldump\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent._learning_algo.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.setNetwork(fname, nEpoch=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent._in_episode = True\n",
    "agent._mode = 0 # Testing mode with plan_depth=0\n",
    "initState = env.reset(agent._mode)\n",
    "inputDims = env.inputDimensions()\n",
    "\n",
    "for i in range(len(inputDims)):\n",
    "    if inputDims[i][0] > 1:\n",
    "        agent._state[i][1:] = initState[i][1:]\n",
    "agent._Vs_on_last_episode = []\n",
    "is_terminal = False\n",
    "reward = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for i in range(100):\n",
    "    obs = env.observe()\n",
    "    _obs = obs[0].reshape((env.WIDTH, env.HEIGHT))\n",
    "    plt.figure()\n",
    "    plt.imshow(np.flip(_obs.squeeze()))\n",
    "    plt.show()\n",
    "    for i in range(len(obs)):\n",
    "        agent._state[i][0:-1] = agent._state[i][1:]\n",
    "        agent._state[i][-1] = obs[i]\n",
    "    V, action, reward, _ = agent._step()\n",
    "    print(action)\n",
    "    agent._Vs_on_last_episode.append(V)\n",
    "    is_terminal = env.inTerminalState()\n",
    "    if is_terminal: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "obs = env.observe()\n",
    "_obs = obs[0].reshape((env.WIDTH, env.HEIGHT))\n",
    "_obs = np.flip(_obs.squeeze())\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "im = ax.imshow(np.zeros(_obs.shape))\n",
    "\n",
    "def init():\n",
    "    plt.cla()\n",
    "    im = ax.imshow(_obs)\n",
    "    return [im]\n",
    "\n",
    "def animate(i, *args, **kwargs):\n",
    "    plt.cla()\n",
    "    obs = env.observe()\n",
    "    _obs = obs[0].reshape((env.WIDTH, env.HEIGHT))\n",
    "    _obs = np.flip(_obs.squeeze())\n",
    "    im = ax.imshow(_obs)\n",
    "    for i in range(len(obs)):\n",
    "        agent._state[i][0:-1] = agent._state[i][1:]\n",
    "        agent._state[i][-1] = obs[i]\n",
    "        V, action, reward, _ = agent._step()\n",
    "        agent._Vs_on_last_episode.append(V)\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, init_func=init, \n",
    "     frames=100, blit=False, repeat=True)\n",
    "ani.save(f'figs/{fname}/behavior.gif', writer=\"ffmpeg\", fps = 15)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
