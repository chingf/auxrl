{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "import yaml\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import hash, dump, load\n",
    "import os\n",
    "\n",
    "from deer.default_parser import process_args\n",
    "from deer.agent import NeuralAgent\n",
    "from deer.learning_algos.CRAR_torch import CRAR\n",
    "from simple_maze_env import MyEnv as simple_maze_env\n",
    "import deer.experiment.base_controllers as bc\n",
    "\n",
    "from deer.policies import EpsilonGreedyPolicy, FixedFigure8Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_yaml = 'network_simpler.yaml'\n",
    "internal_dim = 5\n",
    "fname = 'foraging_test'\n",
    "set_network = None #['foraging_mb', 30, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'nn_yaml': nn_yaml,\n",
    "    'higher_dim_obs': True,\n",
    "    'internal_dim': internal_dim,\n",
    "    'fname': fname,\n",
    "    'steps_per_epoch': 1000,\n",
    "    'epochs': 40,\n",
    "    'steps_per_test': 1000,\n",
    "    'period_btw_summary_perfs': 1,\n",
    "    'encoder_type': 'regular',\n",
    "    'frame_skip': 2,\n",
    "    'learning_rate': 1*1E-4,\n",
    "    'learning_rate_decay': 1.0,\n",
    "    'discount': 0.9,\n",
    "    'epsilon_start': 1.0,\n",
    "    'epsilon_min': 1.0,\n",
    "    'epsilon_decay': 1000,\n",
    "    'update_frequency': 1,\n",
    "    'replay_memory_size': 100000, #50000\n",
    "    'batch_size': 64,\n",
    "    'freeze_interval': 1000,\n",
    "    'deterministic': False,\n",
    "    #'loss_weights': [0, 1E-3, 1E-3, 0, 0, 1E-2, 1., 0],\n",
    "    #'loss_weights': [0, 0, 0, 0, 0, 0, 1., 0.],\n",
    "    'loss_weights': [1E-2, 1E-3, 1E-3, 0, 0, 1E-2, 1., 0],\n",
    "    'foraging_give_rewards': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState()\n",
    "env = simple_maze_env(\n",
    "    rng, reward=parameters['foraging_give_rewards'],\n",
    "    higher_dim_obs=parameters['higher_dim_obs'], plotfig=False\n",
    "    )\n",
    "\n",
    "# Algorithm\n",
    "learning_algo = CRAR(\n",
    "    env, parameters['freeze_interval'], parameters['batch_size'], rng,\n",
    "    high_int_dim=False, internal_dim=parameters['internal_dim'],\n",
    "    lr=parameters['learning_rate'], nn_yaml=parameters['nn_yaml'],\n",
    "    double_Q=True, loss_weights=parameters['loss_weights'],\n",
    "    encoder_type=parameters['encoder_type']\n",
    "    )\n",
    "\n",
    "# Policies\n",
    "train_policy = EpsilonGreedyPolicy(learning_algo, env.nActions(), rng, 0.2)\n",
    "test_policy = EpsilonGreedyPolicy(learning_algo, env.nActions(), rng, 0.)\n",
    "\n",
    "# Initialize Agent\n",
    "agent = NeuralAgent(\n",
    "    env, learning_algo, parameters['replay_memory_size'], 1,\n",
    "    parameters['batch_size'], rng,\n",
    "    train_policy=train_policy, test_policy=test_policy)\n",
    "if set_network is not None:\n",
    "    agent.setNetwork(\n",
    "        f'{set_network[0]}/fname', nEpoch=set_network[1],\n",
    "        encoder_only=set_network[2]\n",
    "        )\n",
    "agent.run(10, 500)\n",
    "\n",
    "# Attach controllers\n",
    "agent.attach(bc.VerboseController( evaluate_on='epoch', periodicity=1))\n",
    "agent.attach(bc.LearningRateController(\n",
    "    initial_learning_rate=parameters['learning_rate'],\n",
    "    learning_rate_decay=parameters['learning_rate_decay'],\n",
    "    periodicity=1))\n",
    "agent.attach(bc.TrainerController(\n",
    "    evaluate_on='action', periodicity=parameters['update_frequency'],\n",
    "    show_episode_avg_V_value=True, show_avg_Bellman_residual=True))\n",
    "best_controller = bc.FindBestController(\n",
    "    validationID=simple_maze_env.VALIDATION_MODE,\n",
    "    testID=None, unique_fname=fname, savefrequency=5)\n",
    "agent.attach(best_controller)\n",
    "agent.attach(bc.InterleavedTestEpochController(\n",
    "    id=simple_maze_env.VALIDATION_MODE, epoch_length=parameters['steps_per_test'],\n",
    "    periodicity=1, show_score=True, summarize_every=1, unique_fname=fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent._learning_algo.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0807, -0.0857, -0.0057, -0.1554,  0.1192], device='cuda:0') tensor([ 0.3330, -0.1851, -0.3336,  0.0647,  0.0738], device='cuda:0') tensor([ 0.0807, -0.0857, -0.0057, -0.1554,  0.1192], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0546], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003415740124904358\n",
      "Episode average V value: 0.15570264694591363\n",
      "Average (on the epoch) training loss: 0.00336809992131748\n",
      "Episode average V value: 0.12012501060962677\n",
      "LOSSES\n",
      "T = 0.1447041718661785; R = 0.0017219588218722493;                 Gamma = 0.5316034160256385; Q = 0.0038452901601121994;\n",
      "Entropy Neighbor = 0.9753812888860702;                 Entropy Random = 0.8842864360809326;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2007,  0.1148,  0.7434, -0.5910,  0.0882], device='cuda:0') tensor([ 0.2877, -0.1522, -0.2315, -0.0697, -0.0075], device='cuda:0') tensor([ 0.2007,  0.1148,  0.7434, -0.5910,  0.0882], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0353], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003140466749801613\n",
      "Episode average V value: 0.09072752130640006\n",
      "LOSSES\n",
      "T = 0.10645812009833754; R = 0.0006977122026719371;                 Gamma = 0.5284364985227585; Q = 0.0037672088056860957;\n",
      "Entropy Neighbor = 0.950197811961174;                 Entropy Random = 0.7640155068635941;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0038062494828991476\n",
      "Episode average V value: 0.12748794398459373\n",
      "epoch 1:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cf2794/.conda/envs/auxrl/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:125: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  torch.tensor(all_possib_inp).float().to(device)\n",
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2121, -0.0374,  0.3912, -0.2887, -0.3220], device='cuda:0') tensor([ 0.1794, -0.0789,  0.0722, -0.2562, -0.1784], device='cuda:0') tensor([ 0.2121, -0.0374,  0.3912, -0.2887, -0.3220], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0226], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0011157518253201782\n",
      "Episode average V value: 0.022620867830248956\n",
      "Average (on the epoch) training loss: 0.001068353596645011\n",
      "Episode average V value: 0.023358764592558146\n",
      "LOSSES\n",
      "T = 0.019412142321467398; R = 0.0006311563738136101;                 Gamma = 0.5297325732707977; Q = 0.000994754245310105;\n",
      "Entropy Neighbor = 0.9396863489151001;                 Entropy Random = 0.7070710716247559;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0394, -0.2012,  0.2537, -0.2633, -0.2109], device='cuda:0') tensor([ 0.1549, -0.1416,  0.0726, -0.2598, -0.1810], device='cuda:0') tensor([ 0.0394, -0.2012,  0.2537, -0.2633, -0.2109], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0073], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.008607223169878124; R = 0.0008884017215732456;                 Gamma = 0.5295275589227676; Q = 0.00089204748179327;\n",
      "Entropy Neighbor = 0.9220670526027679;                 Entropy Random = 0.6178747752904892;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0009434008635516875\n",
      "Episode average V value: 0.020618968891600767\n",
      "epoch 2:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1832, -0.0626,  0.2608, -0.2436, -0.1876], device='cuda:0') tensor([ 0.1462, -0.1366,  0.1215, -0.2559, -0.1791], device='cuda:0') tensor([ 0.1832, -0.0626,  0.2608, -0.2436, -0.1876], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0029], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0006158487173380509\n",
      "Episode average V value: 0.025879337900240003\n",
      "Average (on the epoch) training loss: 0.0006796388617871383\n",
      "Episode average V value: 0.020292935860261582\n",
      "Average (on the epoch) training loss: 0.0009785544291870403\n",
      "Episode average V value: 0.020118787010878693\n",
      "Average (on the epoch) training loss: 0.0009706661870739213\n",
      "Episode average V value: 0.03069954179227352\n",
      "Average (on the epoch) training loss: 0.0010011748847656358\n",
      "Episode average V value: 0.026308803579636983\n",
      "Average (on the epoch) training loss: 0.0009545004666987926\n",
      "Episode average V value: 0.019966412542594805\n",
      "LOSSES\n",
      "T = 0.005496944561600685; R = 0.000948778026006039;                 Gamma = 0.5294132698774338; Q = 0.0009386515826045069;\n",
      "Entropy Neighbor = 0.8962500668764114;                 Entropy Random = 0.5352266714572906;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2698,  0.0208,  0.2517, -0.2262, -0.1629], device='cuda:0') tensor([ 0.1461, -0.0788,  0.2104, -0.2436, -0.1751], device='cuda:0') tensor([ 0.2698,  0.0208,  0.2517, -0.2262, -0.1629], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0018], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0009756749279514418\n",
      "Episode average V value: 0.0186123804710174\n",
      "Average (on the epoch) training loss: 0.001017107090373414\n",
      "Episode average V value: 0.02628522419503757\n",
      "Average (on the epoch) training loss: 0.0010089932675992619\n",
      "Episode average V value: 0.023430004259761498\n",
      "Average (on the epoch) training loss: 0.0009899142980314551\n",
      "Episode average V value: 0.020461596118716095\n",
      "LOSSES\n",
      "T = 0.005672881154343486; R = 0.0021415321781169043;                 Gamma = 0.5269497524499893; Q = 0.0020900611875840696;\n",
      "Entropy Neighbor = 0.8768645646572113;                 Entropy Random = 0.47382153618335726;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0015143563850942882\n",
      "Episode average V value: 0.021628129190287074\n",
      "epoch 3:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1191, -0.1208,  0.2249, -0.2505, -0.1828], device='cuda:0') tensor([ 0.1209, -0.1446,  0.2149, -0.2637, -0.1964], device='cuda:0') tensor([ 0.1191, -0.1208,  0.2249, -0.2505, -0.1828], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0054], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0021708169560544993\n",
      "Episode average V value: 0.024980076911611172\n",
      "Average (on the epoch) training loss: 0.0022680880620787065\n",
      "Episode average V value: 0.04467085985974832\n",
      "Average (on the epoch) training loss: 0.0022381280033292824\n",
      "Episode average V value: 0.04159701863924662\n",
      "Average (on the epoch) training loss: 0.00219921362372692\n",
      "Episode average V value: 0.03469030745327473\n",
      "LOSSES\n",
      "T = 0.006762711969204247; R = 0.002021521997558011;                 Gamma = 0.5265376247167587; Q = 0.00195788349997747;\n",
      "Entropy Neighbor = 0.8581308038234711;                 Entropy Random = 0.4325809414386749;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3247,  0.0672,  0.2539, -0.2194, -0.1640], device='cuda:0') tensor([ 0.0842, -0.1429,  0.1365, -0.2267, -0.1734], device='cuda:0') tensor([ 0.0841, -0.1516,  0.2246, -0.2605, -0.2026], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0144], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.008076875997707247; R = 0.0022564483552814634;                 Gamma = 0.5275607280731202; Q = 0.00215169024649731;\n",
      "Entropy Neighbor = 0.839573162317276;                 Entropy Random = 0.40438549655675887;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.00205478687323739\n",
      "Episode average V value: 0.024366014964983498\n",
      "epoch 4:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1758, -0.0704,  0.2349, -0.2444, -0.1852], device='cuda:0') tensor([ 0.0893, -0.1581,  0.1538, -0.2055, -0.2060], device='cuda:0') tensor([-0.0306, -0.2458,  0.1762, -0.2616, -0.1690], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0017], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.001095410440289665\n",
      "Episode average V value: 0.02853213709134322\n",
      "LOSSES\n",
      "T = 0.009220626018941403; R = 0.0020673516713577557;                 Gamma = 0.5279184619188309; Q = 0.0019480241778146593;\n",
      "Entropy Neighbor = 0.8187795532941818;                 Entropy Random = 0.3761663890480995;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0514, -0.1750,  0.2092, -0.2628, -0.2010], device='cuda:0') tensor([ 0.0600, -0.1423,  0.2043, -0.2688, -0.2105], device='cuda:0') tensor([ 0.0514, -0.1750,  0.2092, -0.2628, -0.2010], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0066], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.002102186936244834\n",
      "Episode average V value: 0.028287627351654725\n",
      "Average (on the epoch) training loss: 0.002092640217944941\n",
      "Episode average V value: 0.051511503756046295\n",
      "LOSSES\n",
      "T = 0.010086535075679422; R = 0.0025762125187175117;                 Gamma = 0.5283391048908234; Q = 0.00238723703296273;\n",
      "Entropy Neighbor = 0.7988141349554062;                 Entropy Random = 0.3555598002076149;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0021676306053886947\n",
      "Episode average V value: 0.029732342328756087\n",
      "epoch 5:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0988, -0.1313,  0.1964, -0.2461, -0.1697], device='cuda:0') tensor([ 0.0889, -0.1470,  0.1721, -0.2210, -0.2104], device='cuda:0') tensor([ 0.2668,  0.0172,  0.2055, -0.2107, -0.1273], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0018], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.002367636465525521\n",
      "Episode average V value: 0.037427869357474865\n",
      "Average (on the epoch) training loss: 0.0023829565880639425\n",
      "Episode average V value: 0.04597703693434596\n",
      "Average (on the epoch) training loss: 0.0023690438686744695\n",
      "Episode average V value: 0.11223797500133514\n",
      "Average (on the epoch) training loss: 0.002401662538939617\n",
      "Episode average V value: 0.05678929481655359\n",
      "Average (on the epoch) training loss: 0.0023253679093736385\n",
      "Episode average V value: 0.061991965770721434\n",
      "Average (on the epoch) training loss: 0.0023128674653976277\n",
      "Episode average V value: 0.11528162658214569\n",
      "Average (on the epoch) training loss: 0.0023887500360110104\n",
      "Episode average V value: 0.04204664592232023\n",
      "Average (on the epoch) training loss: 0.002389753982844897\n",
      "Episode average V value: 0.04304443051417669\n",
      "Average (on the epoch) training loss: 0.002175949522261432\n",
      "Episode average V value: 0.04382275875347356\n",
      "Average (on the epoch) training loss: 0.0021332698551448184\n",
      "Episode average V value: 0.04744670478006204\n",
      "Average (on the epoch) training loss: 0.0023678837908074034\n",
      "Episode average V value: 0.05386139505675861\n",
      "Average (on the epoch) training loss: 0.002344287453670017\n",
      "Episode average V value: 0.061510080471634865\n",
      "Average (on the epoch) training loss: 0.0023275689743215222\n",
      "Episode average V value: 0.03522726069939764\n",
      "Average (on the epoch) training loss: 0.002381169038422543\n",
      "Episode average V value: 0.042590504022021046\n",
      "Average (on the epoch) training loss: 0.0023231193665512744\n",
      "Episode average V value: 0.04533868655562401\n",
      "Average (on the epoch) training loss: 0.002459019079279469\n",
      "Episode average V value: 0.0458451546728611\n",
      "Average (on the epoch) training loss: 0.0024437887148925927\n",
      "Episode average V value: 0.06094053015112877\n",
      "LOSSES\n",
      "T = 0.010357365341857076; R = 0.0027742086443249716;                 Gamma = 0.5268723930120468; Q = 0.0024700244292689606;\n",
      "Entropy Neighbor = 0.7740421123504638;                 Entropy Random = 0.3406584566235542;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0258, -0.1941,  0.1876, -0.2667, -0.2009], device='cuda:0') tensor([ 0.0631, -0.1375,  0.2316, -0.2664, -0.2120], device='cuda:0') tensor([ 0.0258, -0.1941,  0.1876, -0.2667, -0.2009], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0119], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.002526495800149631\n",
      "Episode average V value: 0.038509631567463586\n",
      "Average (on the epoch) training loss: 0.002512659022393393\n",
      "Episode average V value: 0.0429916741947333\n",
      "Average (on the epoch) training loss: 0.0025304794475345727\n",
      "Episode average V value: 0.10074713826179504\n",
      "Average (on the epoch) training loss: 0.002563100762488455\n",
      "Episode average V value: 0.03951119534947254\n",
      "Average (on the epoch) training loss: 0.0025577720978388558\n",
      "Episode average V value: 0.06689456903508731\n",
      "Average (on the epoch) training loss: 0.002522107945823919\n",
      "Episode average V value: 0.05090800465808974\n",
      "Average (on the epoch) training loss: 0.002492437484201778\n",
      "Episode average V value: 0.04173297823096315\n",
      "Average (on the epoch) training loss: 0.002477551069220827\n",
      "Episode average V value: 0.07848951344688733\n",
      "Average (on the epoch) training loss: 0.0025525166581665663\n",
      "Episode average V value: 0.04448796218882004\n",
      "Average (on the epoch) training loss: 0.0027050353533669487\n",
      "Episode average V value: 0.04216753300584731\n",
      "Average (on the epoch) training loss: 0.0027335056538212443\n",
      "Episode average V value: 0.03996639116667211\n",
      "Average (on the epoch) training loss: 0.0028468540612137483\n",
      "Episode average V value: 0.05197621402995927\n",
      "Average (on the epoch) training loss: 0.002851946823505803\n",
      "Episode average V value: 0.06728302873671055\n",
      "Average (on the epoch) training loss: 0.0028790936149240116\n",
      "Episode average V value: 0.056826148401288426\n",
      "Average (on the epoch) training loss: 0.00288189614721593\n",
      "Episode average V value: 0.07487913717826207\n",
      "Average (on the epoch) training loss: 0.00292022186208368\n",
      "Episode average V value: 0.04715442802343103\n",
      "LOSSES\n",
      "T = 0.01055249753408134; R = 0.004125441465519544;                 Gamma = 0.5242011622190476; Q = 0.003553252565405273;\n",
      "Entropy Neighbor = 0.7535647466182709;                 Entropy Random = 0.3355544366836548;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.003011638497337117\n",
      "Episode average V value: 0.041794113193949066\n",
      "epoch 6:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0741, -0.1595,  0.2174, -0.2862, -0.2450], device='cuda:0') tensor([ 0.0831, -0.1202,  0.1956, -0.2748, -0.1843], device='cuda:0') tensor([ 0.0741, -0.1595,  0.2174, -0.2862, -0.2450], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0037], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0027500419959583917\n",
      "Episode average V value: 0.03304612583347729\n",
      "Average (on the epoch) training loss: 0.0035596128685651102\n",
      "Episode average V value: 0.06202330546719687\n",
      "Average (on the epoch) training loss: 0.0034463696471085945\n",
      "Episode average V value: 0.14308108389377594\n",
      "Average (on the epoch) training loss: 0.003442948034457264\n",
      "Episode average V value: 0.06410240568220615\n",
      "Average (on the epoch) training loss: 0.0033151990859735542\n",
      "Episode average V value: 0.06817193577686946\n",
      "Average (on the epoch) training loss: 0.003184468188717599\n",
      "Episode average V value: 0.07947217424710591\n",
      "Average (on the epoch) training loss: 0.0030658234970178454\n",
      "Episode average V value: 0.11183025191227595\n",
      "Average (on the epoch) training loss: 0.003676755607438795\n",
      "Episode average V value: 0.056339632062351\n",
      "Average (on the epoch) training loss: 0.003863712006196547\n",
      "Episode average V value: 0.051316554920795635\n",
      "Average (on the epoch) training loss: 0.003868730301664433\n",
      "Episode average V value: 0.06143277552392748\n",
      "Average (on the epoch) training loss: 0.0038530922491377285\n",
      "Episode average V value: 0.07233976200222969\n",
      "Average (on the epoch) training loss: 0.0038546737698022505\n",
      "Episode average V value: 0.06133649945259094\n",
      "Average (on the epoch) training loss: 0.003950397456832701\n",
      "Episode average V value: 0.059778986126184465\n",
      "Average (on the epoch) training loss: 0.0038684073711958973\n",
      "Episode average V value: 0.06127144396305084\n",
      "Average (on the epoch) training loss: 0.003837980988047699\n",
      "Episode average V value: 0.07354066371917725\n",
      "Average (on the epoch) training loss: 0.003936218556443443\n",
      "Episode average V value: 0.07177759541405572\n",
      "Average (on the epoch) training loss: 0.004052785154306968\n",
      "Episode average V value: 0.09757203112045924\n",
      "Average (on the epoch) training loss: 0.004192114880455495\n",
      "Episode average V value: 0.050558965156475705\n",
      "Average (on the epoch) training loss: 0.004248871352580336\n",
      "Episode average V value: 0.07185433059930801\n",
      "Average (on the epoch) training loss: 0.0044556693335848895\n",
      "Episode average V value: 0.048269521445035934\n",
      "Average (on the epoch) training loss: 0.0044672927853806705\n",
      "Episode average V value: 0.06338674575090408\n",
      "Average (on the epoch) training loss: 0.00442549613513269\n",
      "Episode average V value: 0.04924026504158974\n",
      "Average (on the epoch) training loss: 0.0044790077922712305\n",
      "Episode average V value: 0.09380824754877788\n",
      "Average (on the epoch) training loss: 0.0044293224334268355\n",
      "Episode average V value: 0.08582536808469078\n",
      "Average (on the epoch) training loss: 0.004416847931220263\n",
      "Episode average V value: 0.060067354503906135\n",
      "Average (on the epoch) training loss: 0.004453838811942154\n",
      "Episode average V value: 0.09347230195999146\n",
      "Average (on the epoch) training loss: 0.004432499381169584\n",
      "Episode average V value: 0.16493944451212883\n",
      "Average (on the epoch) training loss: 0.004568849089582086\n",
      "Episode average V value: 0.06807630229741335\n",
      "Average (on the epoch) training loss: 0.004510235124632379\n",
      "Episode average V value: 0.08663671215375264\n",
      "Average (on the epoch) training loss: 0.004539233098910507\n",
      "Episode average V value: 0.1728552095592022\n",
      "Average (on the epoch) training loss: 0.004661860749387479\n",
      "Episode average V value: 0.048794373869895935\n",
      "Average (on the epoch) training loss: 0.004601580262338745\n",
      "Episode average V value: 0.05792827584913799\n",
      "Average (on the epoch) training loss: 0.004603215980338263\n",
      "Episode average V value: 0.08961910009384155\n",
      "Average (on the epoch) training loss: 0.004727587783152222\n",
      "Episode average V value: 0.06915960325436159\n",
      "LOSSES\n",
      "T = 0.010848518281243742; R = 0.005945100280659972;                 Gamma = 0.5218146770000458; Q = 0.004728157491757884;\n",
      "Entropy Neighbor = 0.7365174518823624;                 Entropy Random = 0.3220609048306942;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3392,  0.0779,  0.2035, -0.2160, -0.1435], device='cuda:0') tensor([ 0.2027, -0.0641,  0.1483, -0.2367, -0.1209], device='cuda:0') tensor([ 0.3392,  0.0779,  0.2035, -0.2160, -0.1435], device='cuda:0')\n",
      "R[0]\n",
      "tensor([9.0133e-05], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0046469441141688056\n",
      "Episode average V value: 0.05500250411304561\n",
      "Average (on the epoch) training loss: 0.004672249537923009\n",
      "Episode average V value: 0.05905872231180018\n",
      "Average (on the epoch) training loss: 0.0046565346370884535\n",
      "Episode average V value: 0.1012158989906311\n",
      "Average (on the epoch) training loss: 0.004697289090448042\n",
      "Episode average V value: 0.08421554962793985\n",
      "Average (on the epoch) training loss: 0.004717452078502887\n",
      "Episode average V value: 0.05846934061911371\n",
      "Average (on the epoch) training loss: 0.00475516753647463\n",
      "Episode average V value: 0.25702595710754395\n",
      "Average (on the epoch) training loss: 0.004786355433380231\n",
      "Episode average V value: 0.10752485692501068\n",
      "Average (on the epoch) training loss: 0.004783897317997039\n",
      "Episode average V value: 0.13676060922443867\n",
      "Average (on the epoch) training loss: 0.004785941225840384\n",
      "Episode average V value: 0.1527870111167431\n",
      "Average (on the epoch) training loss: 0.004794681504867957\n",
      "Episode average V value: 0.07890281307377986\n",
      "Average (on the epoch) training loss: 0.00478469685161691\n",
      "Episode average V value: 0.06216807119749688\n",
      "Average (on the epoch) training loss: 0.0047910203965959115\n",
      "Episode average V value: 0.06681462026694242\n",
      "Average (on the epoch) training loss: 0.0048725328122893865\n",
      "Episode average V value: 0.061309580535938345\n",
      "Average (on the epoch) training loss: 0.00485114254373072\n",
      "Episode average V value: 0.04951016591829166\n",
      "Average (on the epoch) training loss: 0.004849962163665895\n",
      "Episode average V value: 0.07659419460429086\n",
      "Average (on the epoch) training loss: 0.004865801125598394\n",
      "Episode average V value: 0.05589618305323504\n",
      "Average (on the epoch) training loss: 0.004859096572944712\n",
      "Episode average V value: 0.18318027506271997\n",
      "LOSSES\n",
      "T = 0.010849345497786999; R = 0.00668361425997864;                 Gamma = 0.5228400134444237; Q = 0.004918103182397317;\n",
      "Entropy Neighbor = 0.7222756022214889;                 Entropy Random = 0.31158545303344726;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0048231303370776\n",
      "Episode average V value: 0.04974668650400071\n",
      "epoch 7:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0490, -0.2259,  0.1527, -0.3191, -0.2520], device='cuda:0') tensor([ 0.0977, -0.1057,  0.2205, -0.2998, -0.2354], device='cuda:0') tensor([-0.0490, -0.2259,  0.1527, -0.3191, -0.2520], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0104], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0034953727528253303\n",
      "Episode average V value: 0.08340725196259362\n",
      "Average (on the epoch) training loss: 0.0039864106929599075\n",
      "Episode average V value: 0.244130939245224\n",
      "Average (on the epoch) training loss: 0.00587994579756115\n",
      "Episode average V value: 0.11910569444298744\n",
      "Average (on the epoch) training loss: 0.005927880249253255\n",
      "Episode average V value: 0.13369435320297876\n",
      "Average (on the epoch) training loss: 0.004904226583780603\n",
      "Episode average V value: 0.0592288852862592\n",
      "Average (on the epoch) training loss: 0.005674636976227003\n",
      "Episode average V value: 0.09787656227126718\n",
      "Average (on the epoch) training loss: 0.005577903427897496\n",
      "Episode average V value: 0.21345935761928558\n",
      "Average (on the epoch) training loss: 0.005391397362169907\n",
      "Episode average V value: 0.06891508274477162\n",
      "Average (on the epoch) training loss: 0.005399660983183936\n",
      "Episode average V value: 0.09659676812589169\n",
      "Average (on the epoch) training loss: 0.005387424231191139\n",
      "Episode average V value: 0.08499847804861409\n",
      "Average (on the epoch) training loss: 0.005512932131254024\n",
      "Episode average V value: 0.09606760854904468\n",
      "Average (on the epoch) training loss: 0.005517504636470788\n",
      "Episode average V value: 0.34215304255485535\n",
      "LOSSES\n",
      "T = 0.011206242899410426; R = 0.008243705615052022;                 Gamma = 0.5235823036432267; Q = 0.005428210506826872;\n",
      "Entropy Neighbor = 0.7031473737955093;                 Entropy Random = 0.30909892919659615;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3055,  0.0667,  0.1958, -0.2377, -0.1716], device='cuda:0') tensor([ 0.2014, -0.0125,  0.1561, -0.2524, -0.1970], device='cuda:0') tensor([ 0.3055,  0.0667,  0.1958, -0.2377, -0.1716], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0058], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.005480563370934366\n",
      "Episode average V value: 0.07655193696419398\n",
      "Average (on the epoch) training loss: 0.00552455957550161\n",
      "Episode average V value: 0.08008256049334318\n",
      "Average (on the epoch) training loss: 0.005532363682974027\n",
      "Episode average V value: 0.4751051664352417\n",
      "Average (on the epoch) training loss: 0.005543050917575563\n",
      "Episode average V value: 0.2937948405742645\n",
      "Average (on the epoch) training loss: 0.005538967670896431\n",
      "Episode average V value: 0.15717112024625143\n",
      "Average (on the epoch) training loss: 0.005530317599576919\n",
      "Episode average V value: 0.39363786578178406\n",
      "Average (on the epoch) training loss: 0.005502825164752858\n",
      "Episode average V value: 0.15214221086353064\n",
      "Average (on the epoch) training loss: 0.005572528320747744\n",
      "Episode average V value: 0.13008891753852367\n",
      "Average (on the epoch) training loss: 0.005551995168479787\n",
      "Episode average V value: 0.21230638027191162\n",
      "Average (on the epoch) training loss: 0.0055224219342397355\n",
      "Episode average V value: 0.14798904872602886\n",
      "Average (on the epoch) training loss: 0.005507138847198378\n",
      "Episode average V value: 0.2978200713793437\n",
      "LOSSES\n",
      "T = 0.012001800127327442; R = 0.008161956029041902;                 Gamma = 0.5281599147319793; Q = 0.004774093506217468;\n",
      "Entropy Neighbor = 0.6891733554601669;                 Entropy Random = 0.30328611424565316;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.00510115200652217\n",
      "Episode average V value: 0.06145994608837461\n",
      "epoch 8:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3219,  0.0926,  0.2542, -0.2965, -0.2895], device='cuda:0') tensor([ 0.2729,  0.0405,  0.2366, -0.2984, -0.2412], device='cuda:0') tensor([ 0.3219,  0.0926,  0.2542, -0.2965, -0.2895], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0007], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.005584765070428451\n",
      "Episode average V value: 0.2212674253516727\n",
      "Average (on the epoch) training loss: 0.005163016135338694\n",
      "Episode average V value: 0.6014223694801331\n",
      "Average (on the epoch) training loss: 0.0056870227453072325\n",
      "Episode average V value: 0.1408503269776702\n",
      "Average (on the epoch) training loss: 0.005637331197871582\n",
      "Episode average V value: 0.450775682926178\n",
      "Average (on the epoch) training loss: 0.005809006484923884\n",
      "Episode average V value: 0.4918360114097595\n",
      "Average (on the epoch) training loss: 0.004847290117042855\n",
      "Episode average V value: 0.16717929943748142\n",
      "Average (on the epoch) training loss: 0.004995732183202303\n",
      "Episode average V value: 0.1342107653617859\n",
      "Average (on the epoch) training loss: 0.005006036462873453\n",
      "Episode average V value: 0.16730014234781265\n",
      "Average (on the epoch) training loss: 0.004963831737993306\n",
      "Episode average V value: 0.15391481295228004\n",
      "Average (on the epoch) training loss: 0.005197800906669153\n",
      "Episode average V value: 0.22554564972718558\n",
      "Average (on the epoch) training loss: 0.005268499675701011\n",
      "Episode average V value: 0.18865353614091873\n",
      "Average (on the epoch) training loss: 0.00521132123373848\n",
      "Episode average V value: 0.18990397879055568\n",
      "Average (on the epoch) training loss: 0.005251351330229197\n",
      "Episode average V value: 0.23039853738413918\n",
      "Average (on the epoch) training loss: 0.005228683625670871\n",
      "Episode average V value: 0.2728462715943654\n",
      "Average (on the epoch) training loss: 0.005125098808990162\n",
      "Episode average V value: 0.1650060032095228\n",
      "Average (on the epoch) training loss: 0.00514516230737029\n",
      "Episode average V value: 0.13609897419810296\n",
      "Average (on the epoch) training loss: 0.00526920139998046\n",
      "Episode average V value: 0.1902329090696115\n",
      "Average (on the epoch) training loss: 0.005161150784632048\n",
      "Episode average V value: 0.11449480056762695\n",
      "Average (on the epoch) training loss: 0.005064658922185524\n",
      "Episode average V value: 0.105990188877757\n",
      "Average (on the epoch) training loss: 0.005139109601310773\n",
      "Episode average V value: 0.09065786477119203\n",
      "Average (on the epoch) training loss: 0.004669979548333401\n",
      "Episode average V value: 0.09512279954753391\n",
      "LOSSES\n",
      "T = 0.012699600500054658; R = 0.007977754211839055;                 Gamma = 0.5294322738051415; Q = 0.004638586197805126;\n",
      "Entropy Neighbor = 0.6847112799882888;                 Entropy Random = 0.2965562950372696;                 Volume = 0.001457311872392893; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0542, -0.2065,  0.0648, -0.2885, -0.1568], device='cuda:0') tensor([ 0.1124, -0.0680,  0.1624, -0.3047, -0.3161], device='cuda:0') tensor([-0.6329, -0.6518,  0.0083, -0.5253, -0.4625], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0188], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004636599278000182\n",
      "Episode average V value: 0.21980690636805125\n",
      "Average (on the epoch) training loss: 0.004567503646556463\n",
      "Episode average V value: 0.1370500753875132\n",
      "Average (on the epoch) training loss: 0.004549528851696125\n",
      "Episode average V value: 0.11043200551560431\n",
      "LOSSES\n",
      "T = 0.01350258021429181; R = 0.007996509505828727;                 Gamma = 0.5331532204151154; Q = 0.004150418288889341;\n",
      "Entropy Neighbor = 0.6673914436101913;                 Entropy Random = 0.27734349739551545;                 Volume = 0.004035648196935654; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004394502243347233\n",
      "Episode average V value: 0.08603180511531854\n",
      "epoch 9:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3556,  0.1446,  0.2702, -0.3277, -0.3359], device='cuda:0') tensor([ 0.3033,  0.0855,  0.2524, -0.3289, -0.3027], device='cuda:0') tensor([ 0.3556,  0.1446,  0.2702, -0.3277, -0.3359], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0008], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.005496015859534964\n",
      "Episode average V value: 0.17641893308609724\n",
      "Average (on the epoch) training loss: 0.004465419256073227\n",
      "Episode average V value: 0.08948791322900969\n",
      "Average (on the epoch) training loss: 0.004565976330518929\n",
      "Episode average V value: 0.1596349959190075\n",
      "Average (on the epoch) training loss: 0.004674011689325374\n",
      "Episode average V value: 0.5410306503375372\n",
      "Average (on the epoch) training loss: 0.004667867327113457\n",
      "Episode average V value: 0.28856719827110117\n",
      "Average (on the epoch) training loss: 0.004440884339638297\n",
      "Episode average V value: 0.1429627743713996\n",
      "Average (on the epoch) training loss: 0.004519845541793409\n",
      "Episode average V value: 0.15400282973828522\n",
      "Average (on the epoch) training loss: 0.004409241309132946\n",
      "Episode average V value: 0.15256889006405167\n",
      "LOSSES\n",
      "T = 0.01403730015642941; R = 0.007425349660901702;                 Gamma = 0.5357571760416031; Q = 0.00433772816794226;\n",
      "Entropy Neighbor = 0.6568959357738495;                 Entropy Random = 0.2728684536218643;                 Volume = 0.007086682591587305; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5333,  0.3142,  0.3319, -0.3227, -0.3832], device='cuda:0') tensor([ 0.4012,  0.1757,  0.2779, -0.3305, -0.3125], device='cuda:0') tensor([ 0.5333,  0.3142,  0.3319, -0.3227, -0.3832], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0070], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.01473272713739425; R = 0.007919729655390256;                 Gamma = 0.5399473311901093; Q = 0.004180515372776426;\n",
      "Entropy Neighbor = 0.6517222397327423;                 Entropy Random = 0.26230575633049014;                 Volume = 0.009764859545975923; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0042591217703593426\n",
      "Episode average V value: 0.09038473722508095\n",
      "epoch 10:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.75 (average over 4 episode(s))\n",
      "== Mean score per episode is 0.7499812504687383 over 4 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3837,  0.1974,  0.2983, -0.3655, -0.4116], device='cuda:0') tensor([ 0.3315,  0.1351,  0.2788, -0.3614, -0.3663], device='cuda:0') tensor([ 0.3837,  0.1974,  0.2983, -0.3655, -0.4116], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0010], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0022602766153535674\n",
      "Episode average V value: 0.2529403418302536\n",
      "Average (on the epoch) training loss: 0.002423216309398413\n",
      "Episode average V value: 0.23980329930782318\n",
      "Average (on the epoch) training loss: 0.0043180729809267045\n",
      "Episode average V value: 0.09773928717924998\n",
      "Average (on the epoch) training loss: 0.004270644037594163\n",
      "Episode average V value: 0.1763679965637451\n",
      "Average (on the epoch) training loss: 0.004306196043906725\n",
      "Episode average V value: 0.19326168447732925\n",
      "LOSSES\n",
      "T = 0.014930966480635107; R = 0.007028455542109441;                 Gamma = 0.5449505915641785; Q = 0.0043169033401063645;\n",
      "Entropy Neighbor = 0.6602318456172943;                 Entropy Random = 0.25724221098423006;                 Volume = 0.012136892195791006; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5938,  0.3918,  0.3661, -0.3379, -0.4164], device='cuda:0') tensor([ 0.4933,  0.2758,  0.3193, -0.3305, -0.3576], device='cuda:0') tensor([ 0.3795,  0.1939,  0.2766, -0.3434, -0.3653], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0010], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.014582661956548691; R = 0.006980939347733511;                 Gamma = 0.5477398977279663; Q = 0.003934828750760061;\n",
      "Entropy Neighbor = 0.6650067683458328;                 Entropy Random = 0.2535793157815933;                 Volume = 0.014025637250393628; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004125866045433213\n",
      "Episode average V value: 0.08369397807565301\n",
      "epoch 11:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1996,  0.0374,  0.2222, -0.3796, -0.3758], device='cuda:0') tensor([ 0.2282,  0.0653,  0.2337, -0.3863, -0.4160], device='cuda:0') tensor([ 0.1996,  0.0374,  0.2222, -0.3796, -0.3758], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0052], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0034198850167180914\n",
      "Episode average V value: 0.19057122349739075\n",
      "Average (on the epoch) training loss: 0.003979669357161789\n",
      "Episode average V value: 0.4192718416452408\n",
      "Average (on the epoch) training loss: 0.0040865955500824684\n",
      "Episode average V value: 0.189978585961987\n",
      "Average (on the epoch) training loss: 0.004166900009671548\n",
      "Episode average V value: 0.3179785318672657\n",
      "Average (on the epoch) training loss: 0.0046421720094213465\n",
      "Episode average V value: 0.2053858641357649\n",
      "LOSSES\n",
      "T = 0.013573902087751775; R = 0.0074721220431092665;                 Gamma = 0.5494279758930206; Q = 0.004276026935898699;\n",
      "Entropy Neighbor = 0.6682664376497268;                 Entropy Random = 0.24578288573026658;                 Volume = 0.01830151243135333; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5228,  0.3405,  0.3397, -0.3529, -0.4156], device='cuda:0') tensor([ 0.5328,  0.3459,  0.3501, -0.3456, -0.3952], device='cuda:0') tensor([ 0.5228,  0.3405,  0.3397, -0.3529, -0.4156], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0046], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.013220343824941664; R = 0.0073014385619899255;                 Gamma = 0.5511380885839462; Q = 0.0038189388280152345;\n",
      "Entropy Neighbor = 0.6540312047004699;                 Entropy Random = 0.23833804658055305;                 Volume = 0.020548401948064565; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0040474828819569665\n",
      "Episode average V value: 0.08932776876763587\n",
      "epoch 12:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2121,  0.0551,  0.2564, -0.4254, -0.4695], device='cuda:0') tensor([ 0.2871,  0.1443,  0.2820, -0.4123, -0.4579], device='cuda:0') tensor([ 0.5229,  0.3466,  0.3620, -0.3810, -0.4694], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0070], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.005551512265064491\n",
      "Episode average V value: 0.15840109456808138\n",
      "LOSSES\n",
      "T = 0.01309868018887937; R = 0.007231193540035747;                 Gamma = 0.5526385610103607; Q = 0.004069116991915507;\n",
      "Entropy Neighbor = 0.6488736245632172;                 Entropy Random = 0.2403759893476963;                 Volume = 0.02349916346743703; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5268,  0.3546,  0.3531, -0.3712, -0.4533], device='cuda:0') tensor([ 0.5060,  0.3190,  0.3463, -0.3751, -0.4703], device='cuda:0') tensor([ 0.5268,  0.3546,  0.3531, -0.3712, -0.4533], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0093], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0039586789503967355\n",
      "Episode average V value: 0.10102129457436661\n",
      "Average (on the epoch) training loss: 0.0039471342849522785\n",
      "Episode average V value: 0.6659425735473633\n",
      "Average (on the epoch) training loss: 0.003927166141946292\n",
      "Episode average V value: 0.15294218515711172\n",
      "Average (on the epoch) training loss: 0.003922966718204105\n",
      "Episode average V value: 0.1340635981824663\n",
      "Average (on the epoch) training loss: 0.003931246450842473\n",
      "Episode average V value: 0.20250348097855045\n",
      "Average (on the epoch) training loss: 0.003926621546316231\n",
      "Episode average V value: 1.0111949443817139\n",
      "LOSSES\n",
      "T = 0.013017876157537103; R = 0.006756463866477134;                 Gamma = 0.5548814737796783; Q = 0.003721674191823695;\n",
      "Entropy Neighbor = 0.6407091189026832;                 Entropy Random = 0.23924389146268368;                 Volume = 0.02322035414353013; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.003895395591869601\n",
      "Episode average V value: 0.08276733482370571\n",
      "epoch 13:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6311,  0.4615,  0.4058, -0.3826, -0.4979], device='cuda:0') tensor([ 0.6428,  0.4662,  0.4290, -0.3869, -0.4859], device='cuda:0') tensor([ 0.6311,  0.4615,  0.4058, -0.3826, -0.4979], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0036], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003519433899782598\n",
      "Episode average V value: 0.3299292163415389\n",
      "Average (on the epoch) training loss: 0.0034179640157769122\n",
      "Episode average V value: 0.5725761502981186\n",
      "Average (on the epoch) training loss: 0.004235986742871598\n",
      "Episode average V value: 0.17743254616856574\n",
      "Average (on the epoch) training loss: 0.0036528669936434096\n",
      "Episode average V value: 0.12216611734280984\n",
      "Average (on the epoch) training loss: 0.003751452841243008\n",
      "Episode average V value: 0.2366066469300178\n",
      "Average (on the epoch) training loss: 0.0037309419167035358\n",
      "Episode average V value: 0.5051517486572266\n",
      "Average (on the epoch) training loss: 0.0035382473176796708\n",
      "Episode average V value: 0.2061358269523172\n",
      "LOSSES\n",
      "T = 0.013310235273092986; R = 0.006741464592632838;                 Gamma = 0.5554405534267426; Q = 0.0038987852371064947;\n",
      "Entropy Neighbor = 0.6354949557185173;                 Entropy Random = 0.24213730388879776;                 Volume = 0.028076105140149594; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6678,  0.5038,  0.4262, -0.3948, -0.5298], device='cuda:0') tensor([ 0.5399,  0.3706,  0.3761, -0.4079, -0.5217], device='cuda:0') tensor([ 0.4426,  0.2849,  0.3382, -0.4123, -0.5063], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0034], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.013198015144094825; R = 0.0068618888946366495;                 Gamma = 0.5564943588972092; Q = 0.004057977758988272;\n",
      "Entropy Neighbor = 0.6218411601781845;                 Entropy Random = 0.2429007616341114;                 Volume = 0.026178375609219075; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.003978381498047383\n",
      "Episode average V value: 0.10400383722774713\n",
      "epoch 14:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.8333333333333334 (average over 6 episode(s))\n",
      "== Mean score per episode is 0.8333194446759221 over 6 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6998,  0.5387,  0.4389, -0.3943, -0.5325], device='cuda:0') tensor([ 0.6820,  0.4968,  0.4288, -0.3899, -0.5314], device='cuda:0') tensor([ 0.6998,  0.5387,  0.4389, -0.3943, -0.5325], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0006], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004402882842368436\n",
      "Episode average V value: 0.16711335809066377\n",
      "Average (on the epoch) training loss: 0.004108767813733338\n",
      "Episode average V value: 0.14785977800204916\n",
      "Average (on the epoch) training loss: 0.0039993085175197805\n",
      "Episode average V value: 0.2066078581089197\n",
      "Average (on the epoch) training loss: 0.003971252086097902\n",
      "Episode average V value: 0.19702201721997098\n",
      "Average (on the epoch) training loss: 0.003980745264323823\n",
      "Episode average V value: 0.7038738876581192\n",
      "Average (on the epoch) training loss: 0.003967672195311333\n",
      "Episode average V value: 0.9585146009922028\n",
      "Average (on the epoch) training loss: 0.0038531153772827097\n",
      "Episode average V value: 0.17229873210191726\n",
      "Average (on the epoch) training loss: 0.0038535958909805077\n",
      "Episode average V value: 0.14845624146983027\n",
      "Average (on the epoch) training loss: 0.003855014196648665\n",
      "Episode average V value: 0.6801463663578033\n",
      "Average (on the epoch) training loss: 0.0038679469927395665\n",
      "Episode average V value: 0.2856739497184753\n",
      "Average (on the epoch) training loss: 0.003863731847862558\n",
      "Episode average V value: 0.7034778296947479\n",
      "Average (on the epoch) training loss: 0.0038931371184262615\n",
      "Episode average V value: 0.6361246705055237\n",
      "Average (on the epoch) training loss: 0.0038870103219984056\n",
      "Episode average V value: 0.34446658996435314\n",
      "Average (on the epoch) training loss: 0.0038881360669620335\n",
      "Episode average V value: 1.0466880798339844\n",
      "LOSSES\n",
      "T = 0.01321942275390029; R = 0.007115384840377373;                 Gamma = 0.5560253014564515; Q = 0.003887470215675421;\n",
      "Entropy Neighbor = 0.6104908897280693;                 Entropy Random = 0.23900961197912693;                 Volume = 0.03228254621103406; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6848,  0.5392,  0.4559, -0.4414, -0.6098], device='cuda:0') tensor([ 0.6300,  0.4587,  0.4323, -0.4368, -0.5775], device='cuda:0') tensor([ 0.6848,  0.5392,  0.4559, -0.4414, -0.6098], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0166], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0037874841809640695\n",
      "Episode average V value: 0.15083331540226935\n",
      "Average (on the epoch) training loss: 0.003783817408651474\n",
      "Episode average V value: 0.3038365127993565\n",
      "Average (on the epoch) training loss: 0.0037778529843871017\n",
      "Episode average V value: 0.1438934542773443\n",
      "Average (on the epoch) training loss: 0.0037499739211660148\n",
      "Episode average V value: 0.14431532293109967\n",
      "Average (on the epoch) training loss: 0.003752155905857241\n",
      "Episode average V value: 0.6896225064992905\n",
      "LOSSES\n",
      "T = 0.012976702514104545; R = 0.007017147797276266;                 Gamma = 0.5552897336483001; Q = 0.003613047356833704;\n",
      "Entropy Neighbor = 0.599422681093216;                 Entropy Random = 0.23459520068764686;                 Volume = 0.03223867743834853; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0037502587862545626\n",
      "Episode average V value: 0.10617790108217913\n",
      "epoch 15:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.75 (average over 4 episode(s))\n",
      "== Mean score per episode is 0.7499812504687383 over 4 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5823,  0.4370,  0.4061, -0.4346, -0.5698], device='cuda:0') tensor([ 0.5737,  0.4075,  0.3976, -0.4342, -0.5715], device='cuda:0') tensor([ 0.5823,  0.4370,  0.4061, -0.4346, -0.5698], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0015], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0008299458713736385\n",
      "Episode average V value: 0.9413624703884125\n",
      "Average (on the epoch) training loss: 0.004509419654452897\n",
      "Episode average V value: 0.28221026472016875\n",
      "Average (on the epoch) training loss: 0.003918095875997096\n",
      "Episode average V value: 0.22622597457901125\n",
      "Average (on the epoch) training loss: 0.0038775328857616146\n",
      "Episode average V value: 0.4400127132733663\n",
      "Average (on the epoch) training loss: 0.003945841426438828\n",
      "Episode average V value: 0.19187696292152945\n",
      "Average (on the epoch) training loss: 0.0039170050073880705\n",
      "Episode average V value: 1.0024169981479645\n",
      "Average (on the epoch) training loss: 0.003929613048094325\n",
      "Episode average V value: 0.2009674713623767\n",
      "Average (on the epoch) training loss: 0.0039338860240082565\n",
      "Episode average V value: 0.5083238929510117\n",
      "Average (on the epoch) training loss: 0.0038466356335910127\n",
      "Episode average V value: 0.17191307413057216\n",
      "Average (on the epoch) training loss: 0.003778951210723575\n",
      "Episode average V value: 0.1900447398131969\n",
      "Average (on the epoch) training loss: 0.0038081909472818835\n",
      "Episode average V value: 0.22472376401225727\n",
      "LOSSES\n",
      "T = 0.013000119434669614; R = 0.0073873900765902365;                 Gamma = 0.5551346142292023; Q = 0.003791430429992033;\n",
      "Entropy Neighbor = 0.5910082383155822;                 Entropy Random = 0.23242380720376968;                 Volume = 0.03553058716282249; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.7334, -1.7541, -0.2933, -0.9745, -1.0308], device='cuda:0') tensor([-1.1884, -1.2853, -0.0826, -0.9351, -1.1302], device='cuda:0') tensor([ 0.0213, -0.1855, -0.0105, -0.1744,  0.0454], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.4151], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0037726732257701294\n",
      "Episode average V value: 0.22274530395155862\n",
      "Average (on the epoch) training loss: 0.003848578055774952\n",
      "Episode average V value: 0.19397719731697668\n",
      "Average (on the epoch) training loss: 0.00382895609714253\n",
      "Episode average V value: 0.18804473702500507\n",
      "Average (on the epoch) training loss: 0.0038204325269219504\n",
      "Episode average V value: 0.39652550646236967\n",
      "Average (on the epoch) training loss: 0.003799001286229284\n",
      "Episode average V value: 0.3287497339905172\n",
      "Average (on the epoch) training loss: 0.0037412897945446498\n",
      "Episode average V value: 0.23590430728298553\n",
      "Average (on the epoch) training loss: 0.0037291054631912795\n",
      "Episode average V value: 0.27591252646275927\n",
      "Average (on the epoch) training loss: 0.0037225869799110845\n",
      "Episode average V value: 0.2936715121070544\n",
      "Average (on the epoch) training loss: 0.00371781681091767\n",
      "Episode average V value: 0.23866873674772002\n",
      "Average (on the epoch) training loss: 0.0037115491632380812\n",
      "Episode average V value: 0.5124033689498901\n",
      "Average (on the epoch) training loss: 0.0037232984730836195\n",
      "Episode average V value: 0.18505929793630327\n",
      "LOSSES\n",
      "T = 0.012891322623007; R = 0.007779237048700452;                 Gamma = 0.554974720954895; Q = 0.0036727867322042585;\n",
      "Entropy Neighbor = 0.5797343184947967;                 Entropy Random = 0.23148124402761458;                 Volume = 0.03894882847368717; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0037321085810981458\n",
      "Episode average V value: 0.12178925797343254\n",
      "epoch 16:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.5 (average over 2 episode(s))\n",
      "== Mean score per episode is 0.49997500124993743 over 2 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3683,  0.2337,  0.3298, -0.4725, -0.5809], device='cuda:0') tensor([ 0.4655,  0.3349,  0.3737, -0.4700, -0.5910], device='cuda:0') tensor([ 0.5168,  0.3745,  0.3742, -0.4374, -0.5500], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0087], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003761881835392463\n",
      "Episode average V value: 0.17491270131186434\n",
      "Average (on the epoch) training loss: 0.00375297127495287\n",
      "Episode average V value: 0.8847726881504059\n",
      "Average (on the epoch) training loss: 0.0037019408412631424\n",
      "Episode average V value: 0.8702238351106644\n",
      "Average (on the epoch) training loss: 0.003634662247488358\n",
      "Episode average V value: 0.20020317838147836\n",
      "Average (on the epoch) training loss: 0.003760334882091239\n",
      "Episode average V value: 0.19661456644535064\n",
      "Average (on the epoch) training loss: 0.003802745348404537\n",
      "Episode average V value: 0.4607124901734866\n",
      "Average (on the epoch) training loss: 0.0038141513104885914\n",
      "Episode average V value: 0.5522482693195343\n",
      "Average (on the epoch) training loss: 0.00380829167844808\n",
      "Episode average V value: 0.8802507072687149\n",
      "Average (on the epoch) training loss: 0.00389621988117763\n",
      "Episode average V value: 0.4202530767236437\n",
      "Average (on the epoch) training loss: 0.003977057502823103\n",
      "Episode average V value: 0.3384611904621124\n",
      "Average (on the epoch) training loss: 0.003947767066345693\n",
      "Episode average V value: 0.6229731837908427\n",
      "Average (on the epoch) training loss: 0.0037122446715856265\n",
      "Episode average V value: 0.26847703960435143\n",
      "Average (on the epoch) training loss: 0.0037184603980911094\n",
      "Episode average V value: 0.2355472563455502\n",
      "Average (on the epoch) training loss: 0.0037352949857663857\n",
      "Episode average V value: 0.691429485877355\n",
      "Average (on the epoch) training loss: 0.003666526296491484\n",
      "Episode average V value: 0.34506197921607806\n",
      "Average (on the epoch) training loss: 0.0037073306440406715\n",
      "Episode average V value: 0.3760607592761517\n",
      "Average (on the epoch) training loss: 0.003792356095800642\n",
      "Episode average V value: 0.20146170052988777\n",
      "Average (on the epoch) training loss: 0.0037827958269432806\n",
      "Episode average V value: 0.40344467759132385\n",
      "Average (on the epoch) training loss: 0.0037566017686118404\n",
      "Episode average V value: 0.17774232075764582\n",
      "Average (on the epoch) training loss: 0.003753499719522675\n",
      "Episode average V value: 0.5154789537191391\n",
      "Average (on the epoch) training loss: 0.0037641769664018216\n",
      "Episode average V value: 0.3914593309164047\n",
      "LOSSES\n",
      "T = 0.01384760827384889; R = 0.007630530106252991;                 Gamma = 0.5541187381744385; Q = 0.0037762655739788896;\n",
      "Entropy Neighbor = 0.5740565338730812;                 Entropy Random = 0.22615887776017188;                 Volume = 0.043646812070161106; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4866,  0.3574,  0.3841, -0.4836, -0.6239], device='cuda:0') tensor([ 0.4815,  0.3373,  0.3801, -0.4861, -0.6309], device='cuda:0') tensor([ 0.4866,  0.3574,  0.3841, -0.4836, -0.6239], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0023], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0037796358527206367\n",
      "Episode average V value: 0.5488444779600415\n",
      "Average (on the epoch) training loss: 0.003792546670472069\n",
      "Episode average V value: 0.9952288568019867\n",
      "Average (on the epoch) training loss: 0.0037878721223292685\n",
      "Episode average V value: 1.0893571376800537\n",
      "Average (on the epoch) training loss: 0.003797181767197344\n",
      "Episode average V value: 0.4229707345366478\n",
      "Average (on the epoch) training loss: 0.00379239181493738\n",
      "Episode average V value: 0.5148678541183471\n",
      "Average (on the epoch) training loss: 0.00378466126935867\n",
      "Episode average V value: 0.5866126056228366\n",
      "Average (on the epoch) training loss: 0.0037797756749844693\n",
      "Episode average V value: 0.8828198512395223\n",
      "Average (on the epoch) training loss: 0.0038178398525000458\n",
      "Episode average V value: 0.44744352251291275\n",
      "Average (on the epoch) training loss: 0.0038293837125578938\n",
      "Episode average V value: 0.5555367767810822\n",
      "Average (on the epoch) training loss: 0.0038579889680952738\n",
      "Episode average V value: 0.7771020084619522\n",
      "Average (on the epoch) training loss: 0.0038584108451354985\n",
      "Episode average V value: 1.0848305225372314\n",
      "Average (on the epoch) training loss: 0.0038482676844895734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0038460274691685973\n",
      "Episode average V value: 0.5046490207314491\n",
      "Average (on the epoch) training loss: 0.003801524603012837\n",
      "Episode average V value: 0.37238703344179236\n",
      "Average (on the epoch) training loss: 0.0038251957663548333\n",
      "Episode average V value: 0.33073253066916214\n",
      "Average (on the epoch) training loss: 0.0038266923381352143\n",
      "Episode average V value: 0.5540730059146881\n",
      "Average (on the epoch) training loss: 0.003830162649117949\n",
      "Episode average V value: 0.4982922077178955\n",
      "Average (on the epoch) training loss: 0.0038443176908176274\n",
      "Episode average V value: 0.3640727170489051\n",
      "Average (on the epoch) training loss: 0.0038464958775322883\n",
      "Episode average V value: 0.50396728515625\n",
      "Average (on the epoch) training loss: 0.003836602706617489\n",
      "Episode average V value: 0.9331411918004354\n",
      "Average (on the epoch) training loss: 0.0038395958480579415\n",
      "Episode average V value: 0.8002499043941498\n",
      "Average (on the epoch) training loss: 0.0038167114758219283\n",
      "Episode average V value: 0.369428741304498\n",
      "Average (on the epoch) training loss: 0.0038159917802275153\n",
      "Episode average V value: 0.5022400349378586\n",
      "Average (on the epoch) training loss: 0.00383227412197015\n",
      "Episode average V value: 0.5749839060008526\n",
      "Average (on the epoch) training loss: 0.0038553172447340577\n",
      "Episode average V value: 0.30348205426707864\n",
      "Average (on the epoch) training loss: 0.003863546217129039\n",
      "Episode average V value: 0.45643700872148785\n",
      "Average (on the epoch) training loss: 0.003867654480823142\n",
      "Episode average V value: 0.6216519773006439\n",
      "Average (on the epoch) training loss: 0.0038644496696011305\n",
      "Episode average V value: 0.9437596201896667\n",
      "Average (on the epoch) training loss: 0.00386741932669794\n",
      "Episode average V value: 0.6525758773088455\n",
      "Average (on the epoch) training loss: 0.0038546565773594547\n",
      "Episode average V value: 0.5980429401000341\n",
      "Average (on the epoch) training loss: 0.003847745613050596\n",
      "Episode average V value: 0.6850747346878052\n",
      "Average (on the epoch) training loss: 0.003853166318034144\n",
      "Episode average V value: 0.533488854765892\n",
      "Average (on the epoch) training loss: 0.003853902885857822\n",
      "Episode average V value: 0.43828089435895284\n",
      "Average (on the epoch) training loss: 0.00384259903266401\n",
      "Episode average V value: 0.7573751509189606\n",
      "Average (on the epoch) training loss: 0.0038334829287479484\n",
      "Episode average V value: 0.5033645033836365\n",
      "Average (on the epoch) training loss: 0.0038550195037206415\n",
      "Episode average V value: 0.3011758356325088\n",
      "Average (on the epoch) training loss: 0.0038694156338865667\n",
      "Episode average V value: 0.6730011284351349\n",
      "Average (on the epoch) training loss: 0.003879114514894779\n",
      "Episode average V value: 0.41655444640379685\n",
      "Average (on the epoch) training loss: 0.0038723304829033525\n",
      "Episode average V value: 0.5644443134466807\n",
      "Average (on the epoch) training loss: 0.0038896363495737585\n",
      "Episode average V value: 0.873701016108195\n",
      "Average (on the epoch) training loss: 0.003877466901590546\n",
      "Episode average V value: 0.5800230354070663\n",
      "Average (on the epoch) training loss: 0.0038703545559398973\n",
      "Episode average V value: 0.3619959428906441\n",
      "Average (on the epoch) training loss: 0.003884864155179084\n",
      "Episode average V value: 0.4476464065638455\n",
      "Average (on the epoch) training loss: 0.003882522383602867\n",
      "Episode average V value: 0.38989293326934177\n",
      "Average (on the epoch) training loss: 0.003877290794561203\n",
      "Episode average V value: 0.805627989768982\n",
      "Average (on the epoch) training loss: 0.003863585398103957\n",
      "Episode average V value: 0.27711582069213575\n",
      "Average (on the epoch) training loss: 0.0038764664304670243\n",
      "Episode average V value: 0.8391094009081522\n",
      "Average (on the epoch) training loss: 0.00387351137500124\n",
      "Episode average V value: 0.45633663875716074\n",
      "Average (on the epoch) training loss: 0.0038645454610914164\n",
      "Episode average V value: 0.6723122795422872\n",
      "Average (on the epoch) training loss: 0.003877942392362014\n",
      "Episode average V value: 0.5275839907782418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.003869470584741206\n",
      "Episode average V value: 0.6134549230337143\n",
      "Average (on the epoch) training loss: 0.0038947338980506174\n",
      "Episode average V value: 0.41993216921885806\n",
      "Average (on the epoch) training loss: 0.0038805295204451845\n",
      "Episode average V value: 0.3522790792313489\n",
      "Average (on the epoch) training loss: 0.0038768326552777203\n",
      "Episode average V value: 0.30455300956964493\n",
      "Average (on the epoch) training loss: 0.0038742392009296646\n",
      "Episode average V value: 0.5670344233512878\n",
      "Average (on the epoch) training loss: 0.0038739447534214396\n",
      "Episode average V value: 0.5273059085011482\n",
      "Average (on the epoch) training loss: 0.003872333149017516\n",
      "Episode average V value: 0.30401166155934334\n",
      "Average (on the epoch) training loss: 0.0038592492848574618\n",
      "Episode average V value: 0.40618630312383175\n",
      "Average (on the epoch) training loss: 0.0038635901576145122\n",
      "Episode average V value: 0.5993259698152542\n",
      "LOSSES\n",
      "T = 0.01458141648583114; R = 0.007846260443970096;                 Gamma = 0.5535476766824722; Q = 0.00396930448198691;\n",
      "Entropy Neighbor = 0.566653564453125;                 Entropy Random = 0.21911364141106607;                 Volume = 0.04868920104578137; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0038727850279829\n",
      "Episode average V value: 0.1446092203259468\n",
      "epoch 17:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9375 (average over 16 episode(s))\n",
      "== Mean score per episode is 0.9374941406616208 over 16 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5226,  0.3938,  0.3935, -0.4757, -0.6132], device='cuda:0') tensor([ 0.5233,  0.3763,  0.3892, -0.4789, -0.6262], device='cuda:0') tensor([ 0.6898,  0.5643,  0.4738, -0.4841, -0.6654], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0001], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0053495539098300715\n",
      "Episode average V value: 0.30504013056104834\n",
      "Average (on the epoch) training loss: 0.005192289788586398\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.004192244514877743\n",
      "Episode average V value: 0.633566927909851\n",
      "Average (on the epoch) training loss: 0.004074214738793671\n",
      "Episode average V value: 0.37768677165431364\n",
      "Average (on the epoch) training loss: 0.003948618023423478\n",
      "Episode average V value: 0.5771826148033142\n",
      "Average (on the epoch) training loss: 0.003934066453384179\n",
      "Episode average V value: 0.5179463773965836\n",
      "Average (on the epoch) training loss: 0.004048094063561976\n",
      "Episode average V value: 0.3903074157238007\n",
      "Average (on the epoch) training loss: 0.003994080090286354\n",
      "Episode average V value: 0.42793757536194543\n",
      "Average (on the epoch) training loss: 0.0039633302745131545\n",
      "Episode average V value: 0.4330677628517151\n",
      "Average (on the epoch) training loss: 0.00386904761986807\n",
      "Episode average V value: 0.43801659941673277\n",
      "Average (on the epoch) training loss: 0.00420915440398468\n",
      "Episode average V value: 0.4477034022410711\n",
      "Average (on the epoch) training loss: 0.004246204522675262\n",
      "Episode average V value: 0.36355171953478166\n",
      "Average (on the epoch) training loss: 0.004227653806696513\n",
      "Episode average V value: 0.7722345590591431\n",
      "Average (on the epoch) training loss: 0.0042511782918709445\n",
      "Episode average V value: 1.0255975723266602\n",
      "Average (on the epoch) training loss: 0.004252571450585189\n",
      "Episode average V value: 0.9401088158289591\n",
      "Average (on the epoch) training loss: 0.004205704630257036\n",
      "Episode average V value: 0.3386250416437785\n",
      "Average (on the epoch) training loss: 0.004183008148130484\n",
      "Episode average V value: 0.4269210133287642\n",
      "Average (on the epoch) training loss: 0.00417839900640762\n",
      "Episode average V value: 0.47910766303539276\n",
      "Average (on the epoch) training loss: 0.004188890210947736\n",
      "Episode average V value: 0.3381494698779924\n",
      "Average (on the epoch) training loss: 0.004179341976914816\n",
      "Episode average V value: 1.0277830362319946\n",
      "Average (on the epoch) training loss: 0.004243304039339853\n",
      "Episode average V value: 0.47728875776131946\n",
      "Average (on the epoch) training loss: 0.004213346560636373\n",
      "Episode average V value: 0.5555844008922577\n",
      "Average (on the epoch) training loss: 0.00424415000440878\n",
      "Episode average V value: 0.4175269061868841\n",
      "Average (on the epoch) training loss: 0.004241821972369287\n",
      "Episode average V value: 0.39978404715657234\n",
      "Average (on the epoch) training loss: 0.0042785193161349955\n",
      "Episode average V value: 0.7780377715826035\n",
      "Average (on the epoch) training loss: 0.004265187820850837\n",
      "Episode average V value: 1.0729905366897583\n",
      "Average (on the epoch) training loss: 0.004323961342209213\n",
      "Episode average V value: 0.25940757989883423\n",
      "Average (on the epoch) training loss: 0.004335817158350657\n",
      "Episode average V value: 0.3174515122717077\n",
      "Average (on the epoch) training loss: 0.0042959712483410795\n",
      "Episode average V value: 0.372159901418184\n",
      "Average (on the epoch) training loss: 0.004341651635592298\n",
      "Episode average V value: 0.34022079010804496\n",
      "Average (on the epoch) training loss: 0.004383808527245883\n",
      "Episode average V value: 0.3859242188930512\n",
      "Average (on the epoch) training loss: 0.004390925334684487\n",
      "Episode average V value: 0.8556328217188517\n",
      "Average (on the epoch) training loss: 0.004398974731045131\n",
      "Episode average V value: 0.415551559491591\n",
      "Average (on the epoch) training loss: 0.004390705155421291\n",
      "Episode average V value: 0.5598886907100677\n",
      "Average (on the epoch) training loss: 0.004378280008211732\n",
      "Episode average V value: 0.23677823692560196\n",
      "Average (on the epoch) training loss: 0.00437474601264847\n",
      "Episode average V value: 0.7613357305526733\n",
      "Average (on the epoch) training loss: 0.004373625293494077\n",
      "Episode average V value: 0.38606629201344084\n",
      "Average (on the epoch) training loss: 0.004392812912052108\n",
      "Episode average V value: 0.5024807211011648\n",
      "Average (on the epoch) training loss: 0.004384259091414235\n",
      "Episode average V value: 0.5006102304905653\n",
      "Average (on the epoch) training loss: 0.004388703630490269\n",
      "Episode average V value: 0.7759578675031662\n",
      "Average (on the epoch) training loss: 0.004387924609107584\n",
      "Episode average V value: 0.9993931651115417\n",
      "Average (on the epoch) training loss: 0.004388991494748543\n",
      "Episode average V value: 0.9539891183376312\n",
      "Average (on the epoch) training loss: 0.004378257402953442\n",
      "Episode average V value: 0.49171614026029903\n",
      "Average (on the epoch) training loss: 0.00437298723089587\n",
      "Episode average V value: 0.5753017365932465\n",
      "Average (on the epoch) training loss: 0.004360513841590721\n",
      "Episode average V value: 0.6964971025784811\n",
      "Average (on the epoch) training loss: 0.004340139998903749\n",
      "Episode average V value: 0.5634584469454629\n",
      "Average (on the epoch) training loss: 0.004342809816409878\n",
      "Episode average V value: 0.5361445676535368\n",
      "Average (on the epoch) training loss: 0.004318403214517075\n",
      "Episode average V value: 0.3687389237540109\n",
      "Average (on the epoch) training loss: 0.004322981013463489\n",
      "Episode average V value: 0.5777375400066376\n",
      "Average (on the epoch) training loss: 0.004324461396129539\n",
      "Episode average V value: 0.6100170413653055\n",
      "Average (on the epoch) training loss: 0.004307805294386261\n",
      "Episode average V value: 0.5671452482541403\n",
      "Average (on the epoch) training loss: 0.004298792570840703\n",
      "Episode average V value: 0.8531398971875509\n",
      "Average (on the epoch) training loss: 0.00428141398707177\n",
      "Episode average V value: 0.8184979081153869\n",
      "LOSSES\n",
      "T = 0.01488901498913765; R = 0.00946549204312032;                 Gamma = 0.5505223313570022; Q = 0.0042791991562116894;\n",
      "Entropy Neighbor = 0.557295738697052;                 Entropy Random = 0.21457995676994324;                 Volume = 0.05658101530373096; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0373, -0.0537,  0.2583, -0.6263, -0.7841], device='cuda:0') tensor([ 0.0083, -0.0618,  0.2626, -0.6095, -0.7574], device='cuda:0') tensor([ 0.0373, -0.0537,  0.2583, -0.6263, -0.7841], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0042], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004282627344185379\n",
      "Episode average V value: 0.6089208722114563\n",
      "Average (on the epoch) training loss: 0.0042720011482195045\n",
      "Episode average V value: 0.40354564785957336\n",
      "Average (on the epoch) training loss: 0.00426796417666446\n",
      "Episode average V value: 0.6638120532035827\n",
      "Average (on the epoch) training loss: 0.004256436230207328\n",
      "Episode average V value: 0.6515329957008362\n",
      "Average (on the epoch) training loss: 0.00425651274053962\n",
      "Episode average V value: 0.38458426855504513\n",
      "Average (on the epoch) training loss: 0.004250346258881369\n",
      "Episode average V value: 0.6073355972766876\n",
      "Average (on the epoch) training loss: 0.0042577880799432\n",
      "Episode average V value: 0.3834183529019356\n",
      "Average (on the epoch) training loss: 0.0043906893007833875\n",
      "Episode average V value: 0.34972797915702913\n",
      "Average (on the epoch) training loss: 0.004383553124809499\n",
      "Episode average V value: 0.41510019451379776\n",
      "Average (on the epoch) training loss: 0.004385924968653573\n",
      "Episode average V value: 0.609432985385259\n",
      "Average (on the epoch) training loss: 0.004376318347725388\n",
      "Episode average V value: 0.6593812306722006\n",
      "Average (on the epoch) training loss: 0.004392568451424916\n",
      "Episode average V value: 0.36199286580085754\n",
      "Average (on the epoch) training loss: 0.004367426082431435\n",
      "Episode average V value: 0.5093609258532524\n",
      "Average (on the epoch) training loss: 0.004360186343204559\n",
      "Episode average V value: 0.9855995774269104\n",
      "Average (on the epoch) training loss: 0.004363686352600019\n",
      "Episode average V value: 0.5414874628186226\n",
      "Average (on the epoch) training loss: 0.004354255939264306\n",
      "Episode average V value: 0.5427516954285758\n",
      "Average (on the epoch) training loss: 0.00435937388443011\n",
      "Episode average V value: 0.7733836024999619\n",
      "Average (on the epoch) training loss: 0.004360648609110594\n",
      "Episode average V value: 0.945957601070404\n",
      "Average (on the epoch) training loss: 0.004360148598434714\n",
      "Episode average V value: 0.8140641689300537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004362412506610259\n",
      "Episode average V value: 0.5492376652028825\n",
      "Average (on the epoch) training loss: 0.004358448242524789\n",
      "Episode average V value: 0.5018601218859354\n",
      "Average (on the epoch) training loss: 0.004355140313976272\n",
      "Episode average V value: 0.4555214014318254\n",
      "Average (on the epoch) training loss: 0.0043517330378897885\n",
      "Episode average V value: 0.8885000646114349\n",
      "Average (on the epoch) training loss: 0.00434756470615772\n",
      "Episode average V value: 0.6600697636604309\n",
      "Average (on the epoch) training loss: 0.004353488475749176\n",
      "Episode average V value: 0.5058608220683204\n",
      "Average (on the epoch) training loss: 0.004342648153470074\n",
      "Episode average V value: 0.7515333394209543\n",
      "Average (on the epoch) training loss: 0.004330447420353126\n",
      "Episode average V value: 0.31179367479952896\n",
      "Average (on the epoch) training loss: 0.004329323248117875\n",
      "Episode average V value: 0.58638896048069\n",
      "Average (on the epoch) training loss: 0.004332160029816501\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.004340568054407739\n",
      "Episode average V value: 0.8036471307277679\n",
      "Average (on the epoch) training loss: 0.004338147110629215\n",
      "Episode average V value: 0.3936671550784792\n",
      "Average (on the epoch) training loss: 0.004352843167007337\n",
      "Episode average V value: 1.0130711793899536\n",
      "Average (on the epoch) training loss: 0.004370627747120857\n",
      "Episode average V value: 0.423734736111429\n",
      "Average (on the epoch) training loss: 0.004373413178773274\n",
      "Episode average V value: 0.8884633630514145\n",
      "Average (on the epoch) training loss: 0.004371108115609544\n",
      "Episode average V value: 0.3350693608323733\n",
      "Average (on the epoch) training loss: 0.004364754639692693\n",
      "Episode average V value: 0.5094579812139273\n",
      "Average (on the epoch) training loss: 0.0043703287887986\n",
      "Episode average V value: 0.5995242553097861\n",
      "Average (on the epoch) training loss: 0.004373341766196875\n",
      "Episode average V value: 0.3511575808127721\n",
      "Average (on the epoch) training loss: 0.004368681316712966\n",
      "Episode average V value: 0.6860031485557556\n",
      "Average (on the epoch) training loss: 0.00436392090189507\n",
      "Episode average V value: 0.7752208709716797\n",
      "Average (on the epoch) training loss: 0.004366079317637056\n",
      "Episode average V value: 0.8153811931610108\n",
      "Average (on the epoch) training loss: 0.004351172308313663\n",
      "Episode average V value: 0.3456420799096425\n",
      "Average (on the epoch) training loss: 0.004369787729257918\n",
      "Episode average V value: 0.5301771104335785\n",
      "Average (on the epoch) training loss: 0.0043793146669526455\n",
      "Episode average V value: 0.6732627630233765\n",
      "Average (on the epoch) training loss: 0.004388671772626432\n",
      "Episode average V value: 0.5895260870456696\n",
      "Average (on the epoch) training loss: 0.004388478741012737\n",
      "Episode average V value: 0.7766231372952461\n",
      "Average (on the epoch) training loss: 0.004410877062347592\n",
      "Episode average V value: 0.6138294424329486\n",
      "Average (on the epoch) training loss: 0.0044365498697857345\n",
      "Episode average V value: 0.4611861929297447\n",
      "Average (on the epoch) training loss: 0.004445723671845668\n",
      "Episode average V value: 0.5202785693109035\n",
      "Average (on the epoch) training loss: 0.004443009016089611\n",
      "Episode average V value: 0.38728925127249497\n",
      "Average (on the epoch) training loss: 0.004445648896297559\n",
      "Episode average V value: 0.5210196137428283\n",
      "Average (on the epoch) training loss: 0.004437129011599034\n",
      "Episode average V value: 0.4001857716786234\n",
      "Average (on the epoch) training loss: 0.004434427099264971\n",
      "Episode average V value: 0.9708749353885651\n",
      "LOSSES\n",
      "T = 0.015539189078845083; R = 0.01076139062125003;                 Gamma = 0.5487731306552887; Q = 0.00458845801348798;\n",
      "Entropy Neighbor = 0.5502182478904725;                 Entropy Random = 0.2015178496390581;                 Volume = 0.06572386659309268; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004433828584849834\n",
      "Episode average V value: 0.5039195835590362\n",
      "epoch 18:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.6666666666666666 (average over 3 episode(s))\n",
      "== Mean score per episode is 0.6666444451851604 over 3 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3537,  0.2412,  0.3385, -0.5231, -0.6604], device='cuda:0') tensor([ 0.3538,  0.2363,  0.3423, -0.5255, -0.6734], device='cuda:0') tensor([ 0.3537,  0.2412,  0.3385, -0.5231, -0.6604], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0008], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.006650151817926339\n",
      "Episode average V value: 0.637269934018453\n",
      "Average (on the epoch) training loss: 0.005579737775648633\n",
      "Episode average V value: 0.5917459626992544\n",
      "Average (on the epoch) training loss: 0.004958319497983093\n",
      "Episode average V value: 0.6562777757644653\n",
      "Average (on the epoch) training loss: 0.004764812655943947\n",
      "Episode average V value: 0.41946365607195885\n",
      "Average (on the epoch) training loss: 0.004690667813305151\n",
      "Episode average V value: 0.5037640929222107\n",
      "Average (on the epoch) training loss: 0.00436958155395197\n",
      "Episode average V value: 0.4182618036866188\n",
      "Average (on the epoch) training loss: 0.0043819173426729524\n",
      "Episode average V value: 1.002781480550766\n",
      "Average (on the epoch) training loss: 0.004195744482592303\n",
      "Episode average V value: 0.3941186639395627\n",
      "Average (on the epoch) training loss: 0.00411619766430017\n",
      "Episode average V value: 0.8761413991451263\n",
      "Average (on the epoch) training loss: 0.004080736169477327\n",
      "Episode average V value: 0.5025974679738283\n",
      "Average (on the epoch) training loss: 0.004069272812812754\n",
      "Episode average V value: 1.0709152221679688\n",
      "Average (on the epoch) training loss: 0.004072621213907206\n",
      "Episode average V value: 0.7080217997233073\n",
      "Average (on the epoch) training loss: 0.0041089162868245144\n",
      "Episode average V value: 0.6477279543876648\n",
      "Average (on the epoch) training loss: 0.004210179413725012\n",
      "Episode average V value: 1.0131311416625977\n",
      "Average (on the epoch) training loss: 0.0041739725092788515\n",
      "Episode average V value: 0.32078416347503663\n",
      "Average (on the epoch) training loss: 0.004185496524736532\n",
      "Episode average V value: 0.41954569135393416\n",
      "Average (on the epoch) training loss: 0.004276733393951892\n",
      "Episode average V value: 0.40709018165414984\n",
      "Average (on the epoch) training loss: 0.004314662040261928\n",
      "Episode average V value: 0.39639745354652406\n",
      "Average (on the epoch) training loss: 0.00437481625365959\n",
      "Episode average V value: 0.38149175855020684\n",
      "Average (on the epoch) training loss: 0.004372865212899192\n",
      "Episode average V value: 0.6241845786571503\n",
      "Average (on the epoch) training loss: 0.0043493098994531465\n",
      "Episode average V value: 0.38460966600821567\n",
      "Average (on the epoch) training loss: 0.004314386116886644\n",
      "Episode average V value: 0.4299024587327784\n",
      "Average (on the epoch) training loss: 0.004304632522373298\n",
      "Episode average V value: 0.5171171724796295\n",
      "Average (on the epoch) training loss: 0.004258794635719584\n",
      "Episode average V value: 0.36226758590111363\n",
      "Average (on the epoch) training loss: 0.0043734037851060805\n",
      "Episode average V value: 0.3995486833155155\n",
      "Average (on the epoch) training loss: 0.004425585640223884\n",
      "Episode average V value: 0.5942746758460998\n",
      "Average (on the epoch) training loss: 0.00441688357186022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.004376809271911398\n",
      "Episode average V value: 0.44222989512814415\n",
      "Average (on the epoch) training loss: 0.004373691319509219\n",
      "Episode average V value: 1.0688447952270508\n",
      "Average (on the epoch) training loss: 0.004442449565597991\n",
      "Episode average V value: 0.5362856884797415\n",
      "Average (on the epoch) training loss: 0.0044320144896274625\n",
      "Episode average V value: 0.6824933290481567\n",
      "Average (on the epoch) training loss: 0.004411019827666729\n",
      "Episode average V value: 0.3946618318557739\n",
      "Average (on the epoch) training loss: 0.004441718126731252\n",
      "Episode average V value: 0.7357275724411011\n",
      "Average (on the epoch) training loss: 0.004419279062542204\n",
      "Episode average V value: 0.35920590588024687\n",
      "Average (on the epoch) training loss: 0.004461485968951265\n",
      "Episode average V value: 0.6877836088339487\n",
      "Average (on the epoch) training loss: 0.004473197178759923\n",
      "Episode average V value: 1.0085424184799194\n",
      "Average (on the epoch) training loss: 0.004451417870127204\n",
      "Episode average V value: 0.6600277125835419\n",
      "Average (on the epoch) training loss: 0.004417098416243536\n",
      "Episode average V value: 0.6356688439846039\n",
      "Average (on the epoch) training loss: 0.0044320521939446595\n",
      "Episode average V value: 0.6143713474273682\n",
      "Average (on the epoch) training loss: 0.004406795710212035\n",
      "Episode average V value: 0.7094037234783173\n",
      "Average (on the epoch) training loss: 0.00439406351225237\n",
      "Episode average V value: 0.9846810400485992\n",
      "Average (on the epoch) training loss: 0.0044212007480525116\n",
      "Episode average V value: 0.484464807169778\n",
      "Average (on the epoch) training loss: 0.004403614000263836\n",
      "Episode average V value: 0.3992872145026922\n",
      "Average (on the epoch) training loss: 0.004385667155472923\n",
      "Episode average V value: 0.4625648276673423\n",
      "Average (on the epoch) training loss: 0.00439235847942265\n",
      "Episode average V value: 0.7584877908229828\n",
      "Average (on the epoch) training loss: 0.00443425042064265\n",
      "Episode average V value: 0.41015321919412323\n",
      "Average (on the epoch) training loss: 0.004449432888746955\n",
      "Episode average V value: 0.6376447031895319\n",
      "Average (on the epoch) training loss: 0.004459488561389994\n",
      "Episode average V value: 0.89035265147686\n",
      "LOSSES\n",
      "T = 0.015997977961786092; R = 0.011001906632096506;                 Gamma = 0.5467642201185227; Q = 0.004459462773287669;\n",
      "Entropy Neighbor = 0.5486496237516403;                 Entropy Random = 0.19807265892624856;                 Volume = 0.07337565789371729; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2822,  0.1808,  0.3236, -0.5632, -0.7204], device='cuda:0') tensor([ 0.3415,  0.2543,  0.3524, -0.5486, -0.6784], device='cuda:0') tensor([ 0.5411,  0.4306,  0.4115, -0.5145, -0.6870], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0073], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004461060092457293\n",
      "Episode average V value: 0.6077653467655182\n",
      "Average (on the epoch) training loss: 0.004470516245073571\n",
      "Episode average V value: 0.3995171977627662\n",
      "Average (on the epoch) training loss: 0.004472019860800851\n",
      "Episode average V value: 1.0057812929153442\n",
      "Average (on the epoch) training loss: 0.004484565626947512\n",
      "Episode average V value: 0.6016492247581482\n",
      "Average (on the epoch) training loss: 0.0044887070301617375\n",
      "Episode average V value: 0.7146820227305094\n",
      "Average (on the epoch) training loss: 0.004497651273745436\n",
      "Episode average V value: 0.5271194837987423\n",
      "Average (on the epoch) training loss: 0.004483908319364105\n",
      "Episode average V value: 0.6141242980957031\n",
      "Average (on the epoch) training loss: 0.004493810646997427\n",
      "Episode average V value: 0.7176687121391296\n",
      "Average (on the epoch) training loss: 0.004477267104693095\n",
      "Episode average V value: 0.34216164238750935\n",
      "Average (on the epoch) training loss: 0.004460856385842937\n",
      "Episode average V value: 0.4288116544485092\n",
      "Average (on the epoch) training loss: 0.004456118119710553\n",
      "Episode average V value: 0.6886162757873535\n",
      "Average (on the epoch) training loss: 0.004451942260940921\n",
      "Episode average V value: 0.6886354684829712\n",
      "Average (on the epoch) training loss: 0.004439847507524278\n",
      "Episode average V value: 0.6317051095621926\n",
      "Average (on the epoch) training loss: 0.004439343819271402\n",
      "Episode average V value: 0.8711142092943192\n",
      "Average (on the epoch) training loss: 0.0044411454965861945\n",
      "Episode average V value: 0.7110493694032941\n",
      "Average (on the epoch) training loss: 0.004461440010219002\n",
      "Episode average V value: 0.2615631459615169\n",
      "Average (on the epoch) training loss: 0.004446097867359007\n",
      "Episode average V value: 0.7690547555685043\n",
      "Average (on the epoch) training loss: 0.004427090818526243\n",
      "Episode average V value: 0.8635223692371732\n",
      "Average (on the epoch) training loss: 0.004440126328784198\n",
      "Episode average V value: 0.48773124136708\n",
      "Average (on the epoch) training loss: 0.00447043396633291\n",
      "Episode average V value: 0.669433754351404\n",
      "Average (on the epoch) training loss: 0.004484080610542178\n",
      "Episode average V value: 0.5600549028469965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004482810047085139\n",
      "Episode average V value: 0.6712539196014404\n",
      "Average (on the epoch) training loss: 0.004489553824575841\n",
      "Episode average V value: 0.93736132979393\n",
      "Average (on the epoch) training loss: 0.004486758774314344\n",
      "Episode average V value: 0.2890008375758216\n",
      "Average (on the epoch) training loss: 0.004463326033837504\n",
      "Episode average V value: 0.3717188693228222\n",
      "Average (on the epoch) training loss: 0.00446419492594053\n",
      "Episode average V value: 0.5113744458981923\n",
      "Average (on the epoch) training loss: 0.004473329968444332\n",
      "Episode average V value: 0.5478407690922419\n",
      "Average (on the epoch) training loss: 0.004477552839845617\n",
      "Episode average V value: 1.0621429681777954\n",
      "Average (on the epoch) training loss: 0.0044914789961135095\n",
      "Episode average V value: 0.4141229081612367\n",
      "Average (on the epoch) training loss: 0.00449957288337582\n",
      "Episode average V value: 0.46584078669548035\n",
      "Average (on the epoch) training loss: 0.004491784104953279\n",
      "Episode average V value: 0.6993949770927429\n",
      "Average (on the epoch) training loss: 0.00449373983741446\n",
      "Episode average V value: 0.3370244734817081\n",
      "Average (on the epoch) training loss: 0.00451390335893795\n",
      "Episode average V value: 0.4013179138302803\n",
      "Average (on the epoch) training loss: 0.004508352062860089\n",
      "Episode average V value: 0.4320601001381874\n",
      "Average (on the epoch) training loss: 0.004501841398349072\n",
      "Episode average V value: 0.5739298197958205\n",
      "Average (on the epoch) training loss: 0.004511513348188982\n",
      "Episode average V value: 0.39738337630810944\n",
      "Average (on the epoch) training loss: 0.004493206199660406\n",
      "Episode average V value: 0.33661737386137247\n",
      "Average (on the epoch) training loss: 0.004506695929804376\n",
      "Episode average V value: 0.49688767844980414\n",
      "LOSSES\n",
      "T = 0.01630028420407325; R = 0.011715984123758972;                 Gamma = 0.5456605793237687; Q = 0.00455078946868889;\n",
      "Entropy Neighbor = 0.5498043352365494;                 Entropy Random = 0.19245784449577333;                 Volume = 0.07745957803353667; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004505126120988279\n",
      "Episode average V value: 0.3767871856689453\n",
      "epoch 19:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.8 (average over 5 episode(s))\n",
      "== Mean score per episode is 0.7999840003199936 over 5 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2560, -0.3610,  0.0890, -0.5760, -0.6255], device='cuda:0') tensor([-0.2115, -0.3316,  0.0853, -0.6040, -0.7391], device='cuda:0') tensor([-0.3456, -0.4376,  0.0808, -0.6314, -0.7075], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0166], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0032453968500097594\n",
      "Episode average V value: 0.9046541651089987\n",
      "Average (on the epoch) training loss: 0.005634914897382259\n",
      "Episode average V value: 0.9406766295433044\n",
      "Average (on the epoch) training loss: 0.0038147393631963776\n",
      "Episode average V value: 0.4582672845572233\n",
      "Average (on the epoch) training loss: 0.0037363922391604218\n",
      "Episode average V value: 0.7882049083709717\n",
      "Average (on the epoch) training loss: 0.0038320846448186784\n",
      "Episode average V value: 0.5792785286903381\n",
      "Average (on the epoch) training loss: 0.003978229300874109\n",
      "Episode average V value: 0.2846955262562808\n",
      "Average (on the epoch) training loss: 0.003964825907522547\n",
      "Episode average V value: 0.7289727807044983\n",
      "Average (on the epoch) training loss: 0.0040646625530658936\n",
      "Episode average V value: 0.7797748545805613\n",
      "Average (on the epoch) training loss: 0.0042799266952427166\n",
      "Episode average V value: 0.40562919713556767\n",
      "Average (on the epoch) training loss: 0.004358295222239879\n",
      "Episode average V value: 1.0037916898727417\n",
      "Average (on the epoch) training loss: 0.004380239221467895\n",
      "Episode average V value: 0.43781331554055214\n",
      "Average (on the epoch) training loss: 0.004280688765720697\n",
      "Episode average V value: 0.5821884444781712\n",
      "Average (on the epoch) training loss: 0.004368092514836797\n",
      "Episode average V value: 0.5267579002039773\n",
      "Average (on the epoch) training loss: 0.0042937282250932185\n",
      "Episode average V value: 0.4774050662914912\n",
      "Average (on the epoch) training loss: 0.004551629060650336\n",
      "Episode average V value: 0.43911615816446453\n",
      "Average (on the epoch) training loss: 0.004524869560377627\n",
      "Episode average V value: 0.702754020690918\n",
      "Average (on the epoch) training loss: 0.004456165516820118\n",
      "Episode average V value: 0.6343924626708031\n",
      "Average (on the epoch) training loss: 0.00448320219594744\n",
      "Episode average V value: 0.4150860048830509\n",
      "Average (on the epoch) training loss: 0.0045446141530631175\n",
      "Episode average V value: 0.4354046046733856\n",
      "Average (on the epoch) training loss: 0.0045763649303151525\n",
      "Episode average V value: 0.6638241708278656\n",
      "Average (on the epoch) training loss: 0.004650516349500505\n",
      "Episode average V value: 0.37491109415336893\n",
      "Average (on the epoch) training loss: 0.004665354062563966\n",
      "Episode average V value: 0.5549524767058236\n",
      "Average (on the epoch) training loss: 0.00467188107490563\n",
      "Episode average V value: 0.39599858252507336\n",
      "Average (on the epoch) training loss: 0.004659763797470349\n",
      "Episode average V value: 0.868334968884786\n",
      "Average (on the epoch) training loss: 0.004645219728189084\n",
      "Episode average V value: 0.8237126022577286\n",
      "Average (on the epoch) training loss: 0.00468239367459731\n",
      "Episode average V value: 0.9902071952819824\n",
      "Average (on the epoch) training loss: 0.004728114383714643\n",
      "Episode average V value: 0.7399634122848511\n",
      "Average (on the epoch) training loss: 0.004733768216034031\n",
      "Episode average V value: 0.6256300721849714\n",
      "Average (on the epoch) training loss: 0.004753223077157683\n",
      "Episode average V value: 0.9130345582962036\n",
      "Average (on the epoch) training loss: 0.004804463604193347\n",
      "Episode average V value: 0.4414237652506147\n",
      "Average (on the epoch) training loss: 0.004806891822637143\n",
      "Episode average V value: 0.5613704447944959\n",
      "Average (on the epoch) training loss: 0.004842427965632959\n",
      "Episode average V value: 0.480145432732322\n",
      "Average (on the epoch) training loss: 0.004829162911006153\n",
      "Episode average V value: 0.7990871593356133\n",
      "Average (on the epoch) training loss: 0.004823290702500912\n",
      "Episode average V value: 0.6008604913949966\n",
      "Average (on the epoch) training loss: 0.0048259189665819015\n",
      "Episode average V value: 1.043131709098816\n",
      "Average (on the epoch) training loss: 0.004844323509177102\n",
      "Episode average V value: 0.607902143150568\n",
      "Average (on the epoch) training loss: 0.004852734007392197\n",
      "Episode average V value: 0.39577486366033554\n",
      "Average (on the epoch) training loss: 0.004802647228288839\n",
      "Episode average V value: 0.4419183845703418\n",
      "Average (on the epoch) training loss: 0.004836190215948071\n",
      "Episode average V value: 0.5817837491631508\n",
      "Average (on the epoch) training loss: 0.004899630425982669\n",
      "Episode average V value: 0.6628008961677552\n",
      "Average (on the epoch) training loss: 0.004908899642351459\n",
      "Episode average V value: 1.0461649894714355\n",
      "Average (on the epoch) training loss: 0.0048976877377095536\n",
      "Episode average V value: 0.7256558537483215\n",
      "Average (on the epoch) training loss: 0.004886325249579347\n",
      "Episode average V value: 0.405624447124345\n",
      "Average (on the epoch) training loss: 0.0048913758042832154\n",
      "Episode average V value: 0.93279896179835\n",
      "Average (on the epoch) training loss: 0.0048989933567710085\n",
      "Episode average V value: 0.620631217956543\n",
      "Average (on the epoch) training loss: 0.004867912090334677\n",
      "Episode average V value: 0.4067907477063792\n",
      "Average (on the epoch) training loss: 0.004878916414728498\n",
      "Episode average V value: 0.586201936006546\n",
      "Average (on the epoch) training loss: 0.004879457920163306\n",
      "Episode average V value: 0.4533576841155688\n",
      "LOSSES\n",
      "T = 0.016034974745474755; R = 0.013750642488361336;                 Gamma = 0.5421443111896515; Q = 0.00484047158784233;\n",
      "Entropy Neighbor = 0.5485646343827247;                 Entropy Random = 0.18717592895030977;                 Volume = 0.09082077863067388; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3706, -0.4580,  0.0713, -0.6423, -0.7265], device='cuda:0') tensor([-0.4059, -0.5092,  0.0421, -0.6771, -0.7940], device='cuda:0') tensor([-0.2869, -0.3872,  0.0778, -0.5880, -0.6447], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0053], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004889784713316894\n",
      "Episode average V value: 0.3715150879418596\n",
      "Average (on the epoch) training loss: 0.004904676819712045\n",
      "Episode average V value: 0.6686253717967442\n",
      "Average (on the epoch) training loss: 0.004896666055898814\n",
      "Episode average V value: 0.46000939756631853\n",
      "Average (on the epoch) training loss: 0.004890125732151874\n",
      "Episode average V value: 0.9022438923517863\n",
      "Average (on the epoch) training loss: 0.004911400095402819\n",
      "Episode average V value: 0.381383787501942\n",
      "Average (on the epoch) training loss: 0.004906241881073593\n",
      "Episode average V value: 0.9956968426704407\n",
      "Average (on the epoch) training loss: 0.004891728249751031\n",
      "Episode average V value: 0.39763454782466096\n",
      "Average (on the epoch) training loss: 0.004885824688069813\n",
      "Episode average V value: 0.39203398620210045\n",
      "Average (on the epoch) training loss: 0.004896595293709563\n",
      "Episode average V value: 0.5284444913268089\n",
      "Average (on the epoch) training loss: 0.004887022300082368\n",
      "Episode average V value: 0.9769109785556793\n",
      "Average (on the epoch) training loss: 0.004883294921371068\n",
      "Episode average V value: 0.41551196575164795\n",
      "Average (on the epoch) training loss: 0.004886609615696242\n",
      "Episode average V value: 0.6801119387149811\n",
      "Average (on the epoch) training loss: 0.004893462743041743\n",
      "Episode average V value: 0.7078347980976105\n",
      "Average (on the epoch) training loss: 0.004892848354453842\n",
      "Episode average V value: 0.7039721012115479\n",
      "Average (on the epoch) training loss: 0.004894010584331794\n",
      "Episode average V value: 0.8608668247858683\n",
      "Average (on the epoch) training loss: 0.004906742467019375\n",
      "Episode average V value: 0.30968525012334186\n",
      "Average (on the epoch) training loss: 0.00490185201662988\n",
      "Episode average V value: 0.41880418525801766\n",
      "Average (on the epoch) training loss: 0.0049056297160107\n",
      "Episode average V value: 0.5599708722697364\n",
      "Average (on the epoch) training loss: 0.004902305913504448\n",
      "Episode average V value: 0.9210630059242249\n",
      "Average (on the epoch) training loss: 0.004909671538012304\n",
      "Episode average V value: 0.4315424673259258\n",
      "Average (on the epoch) training loss: 0.004916749579185961\n",
      "Episode average V value: 0.3867657134930293\n",
      "Average (on the epoch) training loss: 0.004913385271168752\n",
      "Episode average V value: 0.7058713436126709\n",
      "Average (on the epoch) training loss: 0.004906985839049703\n",
      "Episode average V value: 0.40362236797809603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004905144662905118\n",
      "Episode average V value: 0.6409156819184622\n",
      "Average (on the epoch) training loss: 0.004909173540733898\n",
      "Episode average V value: 0.7733811388413111\n",
      "Average (on the epoch) training loss: 0.004914877948552892\n",
      "Episode average V value: 0.3920801877975464\n",
      "Average (on the epoch) training loss: 0.0048991243331663785\n",
      "Episode average V value: 0.5079555577701993\n",
      "Average (on the epoch) training loss: 0.004910387193040571\n",
      "Episode average V value: 0.5712324955633709\n",
      "Average (on the epoch) training loss: 0.004910164295226598\n",
      "Episode average V value: 0.4751826723416646\n",
      "Average (on the epoch) training loss: 0.004902099527312259\n",
      "Episode average V value: 0.9200356006622314\n",
      "Average (on the epoch) training loss: 0.004913136639659238\n",
      "Episode average V value: 0.9757903814315796\n",
      "Average (on the epoch) training loss: 0.004912908870563985\n",
      "Episode average V value: 0.4997933308283488\n",
      "Average (on the epoch) training loss: 0.0048995414771306174\n",
      "Episode average V value: 0.6139573206504186\n",
      "Average (on the epoch) training loss: 0.004917405697219545\n",
      "Episode average V value: 0.4499228563573625\n",
      "Average (on the epoch) training loss: 0.004907598919416415\n",
      "Episode average V value: 0.7936795353889465\n",
      "Average (on the epoch) training loss: 0.004890594013850897\n",
      "Episode average V value: 0.7709616124629974\n",
      "Average (on the epoch) training loss: 0.004892968000623457\n",
      "Episode average V value: 1.0301872491836548\n",
      "Average (on the epoch) training loss: 0.004888988288295084\n",
      "Episode average V value: 0.3928096824222141\n",
      "Average (on the epoch) training loss: 0.004891874589841016\n",
      "Episode average V value: 0.4602883458137512\n",
      "Average (on the epoch) training loss: 0.00487835911247412\n",
      "Episode average V value: 0.5751525372266769\n",
      "Average (on the epoch) training loss: 0.004879126478899313\n",
      "Episode average V value: 0.8811008930206299\n",
      "Average (on the epoch) training loss: 0.004879692715621786\n",
      "Episode average V value: 0.9704979360103607\n",
      "Average (on the epoch) training loss: 0.004875496729331209\n",
      "Episode average V value: 0.7136422276496888\n",
      "Average (on the epoch) training loss: 0.004875504846291537\n",
      "Episode average V value: 0.8280781626701355\n",
      "Average (on the epoch) training loss: 0.004888130030921862\n",
      "Episode average V value: 0.3430347094933192\n",
      "Average (on the epoch) training loss: 0.004888768484598476\n",
      "Episode average V value: 0.6531835744778315\n",
      "Average (on the epoch) training loss: 0.0048791562061364984\n",
      "Episode average V value: 0.6601831763982773\n",
      "Average (on the epoch) training loss: 0.004868285499218599\n",
      "Episode average V value: 0.4551423696371225\n",
      "Average (on the epoch) training loss: 0.004868723140711526\n",
      "Episode average V value: 0.9311387836933136\n",
      "Average (on the epoch) training loss: 0.0048674618789429\n",
      "Episode average V value: 0.9910096526145935\n",
      "Average (on the epoch) training loss: 0.0048616721283844715\n",
      "Episode average V value: 0.3927779619892438\n",
      "Average (on the epoch) training loss: 0.004876566907491992\n",
      "Episode average V value: 0.4051131804784139\n",
      "Average (on the epoch) training loss: 0.004864230819228043\n",
      "Episode average V value: 0.39333095917334926\n",
      "Average (on the epoch) training loss: 0.004880190881108817\n",
      "Episode average V value: 0.4022526989380519\n",
      "Average (on the epoch) training loss: 0.004883310573272958\n",
      "Episode average V value: 0.9295445084571838\n",
      "Average (on the epoch) training loss: 0.00490901282890888\n",
      "Episode average V value: 0.5592446625232697\n",
      "LOSSES\n",
      "T = 0.016291791860945523; R = 0.013795493357407394;                 Gamma = 0.5402918655872345; Q = 0.004984066147473641;\n",
      "Entropy Neighbor = 0.5426667370796203;                 Entropy Random = 0.18444649820029735;                 Volume = 0.0906901728399098; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004912268867657985\n",
      "Episode average V value: 0.4012683071196079\n",
      "epoch 20:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.8888888888888888 (average over 9 episode(s))\n",
      "== Mean score per episode is 0.8888790124554172 over 9 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0662, -0.0148,  0.2623, -0.6376, -0.8058], device='cuda:0') tensor([ 0.0437, -0.0224,  0.2690, -0.6243, -0.7857], device='cuda:0') tensor([ 0.0662, -0.0148,  0.2623, -0.6376, -0.8058], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0066], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0035305685363709927\n",
      "Episode average V value: 0.7059205830097198\n",
      "Average (on the epoch) training loss: 0.0037201743439904283\n",
      "Episode average V value: 0.9828693270683289\n",
      "Average (on the epoch) training loss: 0.00432062641872714\n",
      "Episode average V value: 0.7839601814746857\n",
      "Average (on the epoch) training loss: 0.004424492871664741\n",
      "Episode average V value: 0.43609899495329174\n",
      "Average (on the epoch) training loss: 0.004866608884185553\n",
      "Episode average V value: 0.4684924767775969\n",
      "Average (on the epoch) training loss: 0.004857685482736839\n",
      "Episode average V value: 0.7928362011909484\n",
      "Average (on the epoch) training loss: 0.005107920991057264\n",
      "Episode average V value: 0.52064069211483\n",
      "Average (on the epoch) training loss: 0.005055077723227441\n",
      "Episode average V value: 0.43366827070713043\n",
      "Average (on the epoch) training loss: 0.005090891337966094\n",
      "Episode average V value: 0.4466717764735222\n",
      "Average (on the epoch) training loss: 0.005012567694405023\n",
      "Episode average V value: 0.47715091705322266\n",
      "Average (on the epoch) training loss: 0.005016679762629792\n",
      "Episode average V value: 0.4266286449772971\n",
      "Average (on the epoch) training loss: 0.004812760675788372\n",
      "Episode average V value: 0.3748797636206557\n",
      "Average (on the epoch) training loss: 0.004778180738228273\n",
      "Episode average V value: 0.6914649034539858\n",
      "Average (on the epoch) training loss: 0.004857035708317364\n",
      "Episode average V value: 0.40452365489567027\n",
      "Average (on the epoch) training loss: 0.004848462940880365\n",
      "Episode average V value: 0.3491002784834968\n",
      "Average (on the epoch) training loss: 0.004744851122749238\n",
      "Episode average V value: 0.4418794683047703\n",
      "Average (on the epoch) training loss: 0.004768950997421765\n",
      "Episode average V value: 0.7415385365486145\n",
      "Average (on the epoch) training loss: 0.004773071845652385\n",
      "Episode average V value: 0.8368293642997742\n",
      "Average (on the epoch) training loss: 0.004779007583753357\n",
      "Episode average V value: 0.5545882701873779\n",
      "Average (on the epoch) training loss: 0.004700663862983879\n",
      "Episode average V value: 0.7776645024617513\n",
      "Average (on the epoch) training loss: 0.004768930163787582\n",
      "Episode average V value: 0.7977797091007233\n",
      "Average (on the epoch) training loss: 0.004757546992789179\n",
      "Episode average V value: 0.7287436894008091\n",
      "Average (on the epoch) training loss: 0.004746938343330463\n",
      "Episode average V value: 0.4589859589934349\n",
      "Average (on the epoch) training loss: 0.004799539262198948\n",
      "Episode average V value: 0.4335200637578964\n",
      "Average (on the epoch) training loss: 0.0048019834273798885\n",
      "Episode average V value: 0.8956039994955063\n",
      "Average (on the epoch) training loss: 0.004776769432491391\n",
      "Episode average V value: 0.6979354992508888\n",
      "Average (on the epoch) training loss: 0.004754207847496502\n",
      "Episode average V value: 0.5558611750602722\n",
      "Average (on the epoch) training loss: 0.004733477771624852\n",
      "Episode average V value: 0.9390551149845123\n",
      "Average (on the epoch) training loss: 0.004754302789751154\n",
      "Episode average V value: 0.5535181479321586\n",
      "Average (on the epoch) training loss: 0.004720123439939719\n",
      "Episode average V value: 0.3853476643562317\n",
      "Average (on the epoch) training loss: 0.004743634411427844\n",
      "Episode average V value: 0.448068767786026\n",
      "Average (on the epoch) training loss: 0.004735736062910074\n",
      "Episode average V value: 0.40439921120802563\n",
      "Average (on the epoch) training loss: 0.004726971975634956\n",
      "Episode average V value: 0.5694258771836758\n",
      "Average (on the epoch) training loss: 0.004731087261292444\n",
      "Episode average V value: 1.036757230758667\n",
      "Average (on the epoch) training loss: 0.004703101612420984\n",
      "Episode average V value: 0.3802743315696716\n",
      "Average (on the epoch) training loss: 0.0047527682505140246\n",
      "Episode average V value: 0.3787794093290965\n",
      "Average (on the epoch) training loss: 0.004783324032678253\n",
      "Episode average V value: 0.461899995803833\n",
      "Average (on the epoch) training loss: 0.0047834629963369344\n",
      "Episode average V value: 0.6305547257264456\n",
      "Average (on the epoch) training loss: 0.004782673626035074\n",
      "Episode average V value: 1.0295507907867432\n",
      "Average (on the epoch) training loss: 0.004795942208252802\n",
      "Episode average V value: 0.42946022207086737\n",
      "Average (on the epoch) training loss: 0.004838364627810837\n",
      "Episode average V value: 0.5590169727802277\n",
      "Average (on the epoch) training loss: 0.004816594827652552\n",
      "Episode average V value: 0.8327823132276535\n",
      "Average (on the epoch) training loss: 0.00484266151633784\n",
      "Episode average V value: 0.45919489047744055\n",
      "Average (on the epoch) training loss: 0.004839686959431592\n",
      "Episode average V value: 0.9948874711990356\n",
      "Average (on the epoch) training loss: 0.004837716247327419\n",
      "Episode average V value: 0.42582505610254073\n",
      "Average (on the epoch) training loss: 0.004837203475232185\n",
      "Episode average V value: 0.5433223446210226\n",
      "Average (on the epoch) training loss: 0.004823621028226922\n",
      "Episode average V value: 0.3645902710991937\n",
      "Average (on the epoch) training loss: 0.004815702561183197\n",
      "Episode average V value: 0.4767047166824341\n",
      "LOSSES\n",
      "T = 0.016001826749183237; R = 0.015501126533490606;                 Gamma = 0.5379568566679954; Q = 0.004821464329375885;\n",
      "Entropy Neighbor = 0.5492325180768967;                 Entropy Random = 0.18438427191972734;                 Volume = 0.0997495469301939; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2605,  0.1542,  0.2731, -0.5163, -0.6279], device='cuda:0') tensor([ 0.3560,  0.2654,  0.3152, -0.5156, -0.6605], device='cuda:0') tensor([ 0.2605,  0.1542,  0.2731, -0.5163, -0.6279], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0082], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004808714714111431\n",
      "Episode average V value: 0.4394647866487503\n",
      "Average (on the epoch) training loss: 0.004809948501949873\n",
      "Episode average V value: 0.922794759273529\n",
      "Average (on the epoch) training loss: 0.004812968641179983\n",
      "Episode average V value: 0.564468213253551\n",
      "Average (on the epoch) training loss: 0.0047209764821577425\n",
      "Episode average V value: 0.38133739957622453\n",
      "Average (on the epoch) training loss: 0.004727879527653121\n",
      "Episode average V value: 0.9208544294039408\n",
      "Average (on the epoch) training loss: 0.004736269418972559\n",
      "Episode average V value: 0.6761158406734467\n",
      "Average (on the epoch) training loss: 0.004720180485572596\n",
      "Episode average V value: 0.5436625480651855\n",
      "Average (on the epoch) training loss: 0.004732410796374703\n",
      "Episode average V value: 0.4051331306497256\n",
      "Average (on the epoch) training loss: 0.004710352876462227\n",
      "Episode average V value: 0.6966887891292572\n",
      "Average (on the epoch) training loss: 0.004718287083537583\n",
      "Episode average V value: 0.38181077284985276\n",
      "Average (on the epoch) training loss: 0.004719540218867356\n",
      "Episode average V value: 0.5727934196591378\n",
      "Average (on the epoch) training loss: 0.004729313765532414\n",
      "Episode average V value: 0.925908366839091\n",
      "Average (on the epoch) training loss: 0.004723705959308443\n",
      "Episode average V value: 0.523892188614065\n",
      "Average (on the epoch) training loss: 0.004730336131275381\n",
      "Episode average V value: 0.4901064410805702\n",
      "Average (on the epoch) training loss: 0.004735057965905778\n",
      "Episode average V value: 0.6524288455645243\n",
      "Average (on the epoch) training loss: 0.0047437887530820955\n",
      "Episode average V value: 0.38632626169257694\n",
      "Average (on the epoch) training loss: 0.004762009400589597\n",
      "Episode average V value: 0.3637700242300828\n",
      "Average (on the epoch) training loss: 0.004772739201308552\n",
      "Episode average V value: 0.6850598113877433\n",
      "Average (on the epoch) training loss: 0.0047613614087382615\n",
      "Episode average V value: 0.43983427967344013\n",
      "Average (on the epoch) training loss: 0.004764262215163675\n",
      "Episode average V value: 0.6473088711500168\n",
      "Average (on the epoch) training loss: 0.004756558470114175\n",
      "Episode average V value: 0.5383914790370248\n",
      "Average (on the epoch) training loss: 0.0047363323951611\n",
      "Episode average V value: 0.5072441399097443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004741170159104513\n",
      "Episode average V value: 0.5247291699051857\n",
      "Average (on the epoch) training loss: 0.004752991605912232\n",
      "Episode average V value: 0.5003384530544281\n",
      "Average (on the epoch) training loss: 0.004751106476405545\n",
      "Episode average V value: 0.5278020054101944\n",
      "Average (on the epoch) training loss: 0.004743760346506996\n",
      "Episode average V value: 0.5692309364676476\n",
      "Average (on the epoch) training loss: 0.004746865291615199\n",
      "Episode average V value: 0.49264850839972496\n",
      "Average (on the epoch) training loss: 0.004755291219907493\n",
      "Episode average V value: 0.46718340665102004\n",
      "Average (on the epoch) training loss: 0.004739361109710566\n",
      "Episode average V value: 0.3403041415117882\n",
      "Average (on the epoch) training loss: 0.004742776105136995\n",
      "Episode average V value: 0.8478854596614838\n",
      "Average (on the epoch) training loss: 0.004735136328482146\n",
      "Episode average V value: 0.4570399522781372\n",
      "Average (on the epoch) training loss: 0.00473637388043015\n",
      "Episode average V value: 0.4080608973900477\n",
      "Average (on the epoch) training loss: 0.004746155388151421\n",
      "Episode average V value: 0.5989594409863154\n",
      "Average (on the epoch) training loss: 0.004741844012570977\n",
      "Episode average V value: 0.5699024498462677\n",
      "Average (on the epoch) training loss: 0.004737512516943228\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.004727160925712897\n",
      "Episode average V value: 0.5698530657423867\n",
      "Average (on the epoch) training loss: 0.004729758331778299\n",
      "Episode average V value: 0.45118255019187925\n",
      "Average (on the epoch) training loss: 0.004741893919553551\n",
      "Episode average V value: 0.5480631068348885\n",
      "Average (on the epoch) training loss: 0.004731434871759752\n",
      "Episode average V value: 0.2822612076997757\n",
      "LOSSES\n",
      "T = 0.015678619794547557; R = 0.016206737668195272;                 Gamma = 0.5361338481903076; Q = 0.0046509676261339335;\n",
      "Entropy Neighbor = 0.5525651300549507;                 Entropy Random = 0.1833020221889019;                 Volume = 0.10385003577917815; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004736215977754909\n",
      "Episode average V value: 0.6319202184677124\n",
      "epoch 21:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1992,  0.1076,  0.2816, -0.5818, -0.7291], device='cuda:0') tensor([ 0.0407, -0.0406,  0.2409, -0.6223, -0.7437], device='cuda:0') tensor([-0.1550, -0.2209,  0.1942, -0.7074, -0.8821], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0145], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.006733424321282655\n",
      "Episode average V value: 0.5799818933010101\n",
      "Average (on the epoch) training loss: 0.005579331216202783\n",
      "Episode average V value: 0.7424440383911133\n",
      "Average (on the epoch) training loss: 0.005361153385601938\n",
      "Episode average V value: 0.5471944004297257\n",
      "Average (on the epoch) training loss: 0.005462843408167828\n",
      "Episode average V value: 0.6874851839882987\n",
      "Average (on the epoch) training loss: 0.005112550546121048\n",
      "Episode average V value: 0.5014949291944504\n",
      "Average (on the epoch) training loss: 0.00526713542455003\n",
      "Episode average V value: 0.6810000836849213\n",
      "Average (on the epoch) training loss: 0.005106153765051924\n",
      "Episode average V value: 0.42357824370265007\n",
      "Average (on the epoch) training loss: 0.005071927529382359\n",
      "Episode average V value: 0.8392711877822876\n",
      "Average (on the epoch) training loss: 0.004960905326853364\n",
      "Episode average V value: 0.40469036799556807\n",
      "Average (on the epoch) training loss: 0.004903313890197354\n",
      "Episode average V value: 0.4621440917253494\n",
      "Average (on the epoch) training loss: 0.00500058406451717\n",
      "Episode average V value: 0.3369109233220418\n",
      "Average (on the epoch) training loss: 0.004759712416790021\n",
      "Episode average V value: 0.32795328878123187\n",
      "Average (on the epoch) training loss: 0.0046692077531978226\n",
      "Episode average V value: 0.48893262445926666\n",
      "Average (on the epoch) training loss: 0.004696671924371596\n",
      "Episode average V value: 0.49800279289484023\n",
      "Average (on the epoch) training loss: 0.004675618345285521\n",
      "Episode average V value: 0.6626337766647339\n",
      "Average (on the epoch) training loss: 0.004736864687335428\n",
      "Episode average V value: 0.3894769114416999\n",
      "Average (on the epoch) training loss: 0.004744288793216848\n",
      "Episode average V value: 0.4919484928250313\n",
      "Average (on the epoch) training loss: 0.004684529597827075\n",
      "Episode average V value: 0.5264731808142229\n",
      "Average (on the epoch) training loss: 0.0046738990760323675\n",
      "Episode average V value: 0.4482177032364739\n",
      "Average (on the epoch) training loss: 0.004680073956081036\n",
      "Episode average V value: 0.8759622971216837\n",
      "Average (on the epoch) training loss: 0.004682907047913513\n",
      "Episode average V value: 0.9343983232975006\n",
      "Average (on the epoch) training loss: 0.004699256181667902\n",
      "Episode average V value: 0.6268085638682047\n",
      "Average (on the epoch) training loss: 0.0047342847863311235\n",
      "Episode average V value: 0.2756092185154557\n",
      "Average (on the epoch) training loss: 0.004795466737720601\n",
      "Episode average V value: 0.9261020620663961\n",
      "Average (on the epoch) training loss: 0.004762771138152813\n",
      "Episode average V value: 0.849875009059906\n",
      "Average (on the epoch) training loss: 0.004760960633015761\n",
      "Episode average V value: 0.6053222417831421\n",
      "Average (on the epoch) training loss: 0.004773328512450044\n",
      "Episode average V value: 0.4355513989925385\n",
      "Average (on the epoch) training loss: 0.004824786189612539\n",
      "Episode average V value: 0.5300905495882035\n",
      "Average (on the epoch) training loss: 0.004811206127472708\n",
      "Episode average V value: 0.7266623914241791\n",
      "Average (on the epoch) training loss: 0.0047770324800254236\n",
      "Episode average V value: 0.5051339839895567\n",
      "Average (on the epoch) training loss: 0.004780237913854018\n",
      "Episode average V value: 0.9187303185462952\n",
      "Average (on the epoch) training loss: 0.004764942050857007\n",
      "Episode average V value: 0.5633363085133689\n",
      "Average (on the epoch) training loss: 0.0047574507583501855\n",
      "Episode average V value: 0.7381231784820557\n",
      "Average (on the epoch) training loss: 0.004754912780304516\n",
      "Episode average V value: 0.9638938009738922\n",
      "Average (on the epoch) training loss: 0.004784054995124119\n",
      "Episode average V value: 0.3907149796900542\n",
      "Average (on the epoch) training loss: 0.00477537193071905\n",
      "Episode average V value: 0.6646964102983475\n",
      "Average (on the epoch) training loss: 0.004763743060814363\n",
      "Episode average V value: 0.773361066977183\n",
      "Average (on the epoch) training loss: 0.004792532338041036\n",
      "Episode average V value: 0.5537810176610947\n",
      "Average (on the epoch) training loss: 0.004781512914934681\n",
      "Episode average V value: 0.34389808177948\n",
      "Average (on the epoch) training loss: 0.004794772612612036\n",
      "Episode average V value: 0.57694371342659\n",
      "Average (on the epoch) training loss: 0.004790309135348874\n",
      "Episode average V value: 0.57558355294168\n",
      "Average (on the epoch) training loss: 0.004779479027454547\n",
      "Episode average V value: 0.6511057257652283\n",
      "Average (on the epoch) training loss: 0.004783266092502337\n",
      "Episode average V value: 0.44701636066803563\n",
      "Average (on the epoch) training loss: 0.004801925821623538\n",
      "Episode average V value: 0.44513487815856934\n",
      "Average (on the epoch) training loss: 0.004816883336011611\n",
      "Episode average V value: 0.5395630300045013\n",
      "Average (on the epoch) training loss: 0.00481570640430701\n",
      "Episode average V value: 0.5324754814306895\n",
      "LOSSES\n",
      "T = 0.015681892625056208; R = 0.016845020831446164;                 Gamma = 0.5347675827145576; Q = 0.004802214080700651;\n",
      "Entropy Neighbor = 0.5580091835856438;                 Entropy Random = 0.18180466359853745;                 Volume = 0.10527803260833025; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2885,  0.1933,  0.2979, -0.5500, -0.6964], device='cuda:0') tensor([ 0.1423,  0.0492,  0.2567, -0.5895, -0.7223], device='cuda:0') tensor([ 0.4252,  0.3371,  0.3646, -0.5622, -0.7483], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0103], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004804973624611344\n",
      "Episode average V value: 0.6307461907466253\n",
      "Average (on the epoch) training loss: 0.004844420187997135\n",
      "Episode average V value: 0.39920323424869114\n",
      "Average (on the epoch) training loss: 0.00484465435324007\n",
      "Episode average V value: 0.6195347085595131\n",
      "Average (on the epoch) training loss: 0.004853244831518973\n",
      "Episode average V value: 0.5197597687894647\n",
      "Average (on the epoch) training loss: 0.004877023694818437\n",
      "Episode average V value: 0.51907754316926\n",
      "Average (on the epoch) training loss: 0.004883758428901353\n",
      "Episode average V value: 0.8329345732927322\n",
      "Average (on the epoch) training loss: 0.004889861639406133\n",
      "Episode average V value: 0.6576689146459103\n",
      "Average (on the epoch) training loss: 0.004910704492712799\n",
      "Episode average V value: 0.450872141122818\n",
      "Average (on the epoch) training loss: 0.00488803320005378\n",
      "Episode average V value: 0.3014946688305248\n",
      "Average (on the epoch) training loss: 0.004874094762025055\n",
      "Episode average V value: 0.43264142104557585\n",
      "Average (on the epoch) training loss: 0.0048510115096824374\n",
      "Episode average V value: 0.8734957575798035\n",
      "Average (on the epoch) training loss: 0.004846573922473968\n",
      "Episode average V value: 0.5467857923358679\n",
      "Average (on the epoch) training loss: 0.004866428846943881\n",
      "Episode average V value: 0.4745805338025093\n",
      "Average (on the epoch) training loss: 0.004823364497240499\n",
      "Episode average V value: 0.3995856850043587\n",
      "Average (on the epoch) training loss: 0.004828039481672666\n",
      "Episode average V value: 0.45434667766094206\n",
      "Average (on the epoch) training loss: 0.004841282532378164\n",
      "Episode average V value: 0.46081995591521263\n",
      "Average (on the epoch) training loss: 0.004842010127052803\n",
      "Episode average V value: 0.38635403248998856\n",
      "Average (on the epoch) training loss: 0.00483671612224391\n",
      "Episode average V value: 0.6997090578079224\n",
      "Average (on the epoch) training loss: 0.0048318171774318075\n",
      "Episode average V value: 0.8746720353762308\n",
      "Average (on the epoch) training loss: 0.004828808491265197\n",
      "Episode average V value: 0.27305242121219636\n",
      "Average (on the epoch) training loss: 0.00482276193437729\n",
      "Episode average V value: 0.512333584683282\n",
      "Average (on the epoch) training loss: 0.004804462524973445\n",
      "Episode average V value: 0.3879963140934706\n",
      "Average (on the epoch) training loss: 0.004802819300259434\n",
      "Episode average V value: 0.6553968446595329\n",
      "Average (on the epoch) training loss: 0.004806943729971772\n",
      "Episode average V value: 0.5758416712284088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004814179227793109\n",
      "Episode average V value: 0.9096502065658569\n",
      "Average (on the epoch) training loss: 0.004814861645915897\n",
      "Episode average V value: 0.5260801687836647\n",
      "Average (on the epoch) training loss: 0.004811833114222515\n",
      "Episode average V value: 0.5458472867806753\n",
      "Average (on the epoch) training loss: 0.004808405710290386\n",
      "Episode average V value: 0.9181098341941833\n",
      "Average (on the epoch) training loss: 0.004778891449748743\n",
      "Episode average V value: 0.3450108766555786\n",
      "Average (on the epoch) training loss: 0.004778187978496116\n",
      "Episode average V value: 0.33795598575047087\n",
      "Average (on the epoch) training loss: 0.0047764188802623736\n",
      "Episode average V value: 0.6190703685084978\n",
      "Average (on the epoch) training loss: 0.004757265274740811\n",
      "Episode average V value: 0.5483989417552948\n",
      "Average (on the epoch) training loss: 0.004739977045184267\n",
      "Episode average V value: 0.5575584660876881\n",
      "Average (on the epoch) training loss: 0.004730128568154192\n",
      "Episode average V value: 0.6488320529460907\n",
      "Average (on the epoch) training loss: 0.004736031532397296\n",
      "Episode average V value: 0.4991224408149719\n",
      "Average (on the epoch) training loss: 0.004726037238946273\n",
      "Episode average V value: 0.5567025691270828\n",
      "Average (on the epoch) training loss: 0.004714874657093908\n",
      "Episode average V value: 0.5441367663443089\n",
      "Average (on the epoch) training loss: 0.004715340676690069\n",
      "Episode average V value: 0.9313563406467438\n",
      "Average (on the epoch) training loss: 0.0047061532306501026\n",
      "Episode average V value: 0.4186272313197454\n",
      "Average (on the epoch) training loss: 0.004719597136734852\n",
      "Episode average V value: 0.5011350125074386\n",
      "Average (on the epoch) training loss: 0.0047156370624592955\n",
      "Episode average V value: 0.7326587677001953\n",
      "Average (on the epoch) training loss: 0.0047131362002694145\n",
      "Episode average V value: 0.3964328142729672\n",
      "Average (on the epoch) training loss: 0.00471339469027803\n",
      "Episode average V value: 0.726094651222229\n",
      "Average (on the epoch) training loss: 0.004711608880251232\n",
      "Episode average V value: 0.6659773290157318\n",
      "Average (on the epoch) training loss: 0.004719314892473101\n",
      "Episode average V value: 0.3621775073849637\n",
      "Average (on the epoch) training loss: 0.004718835880816339\n",
      "Episode average V value: 0.541681433096528\n",
      "Average (on the epoch) training loss: 0.0047292792810701405\n",
      "Episode average V value: 0.5965474843978882\n",
      "Average (on the epoch) training loss: 0.004731198058258048\n",
      "Episode average V value: 1.007648229598999\n",
      "Average (on the epoch) training loss: 0.0047369671181328715\n",
      "Episode average V value: 0.6303383111953735\n",
      "Average (on the epoch) training loss: 0.004746624510899135\n",
      "Episode average V value: 0.41311294957995415\n",
      "Average (on the epoch) training loss: 0.004745366279681583\n",
      "Episode average V value: 0.6628307700157166\n",
      "Average (on the epoch) training loss: 0.004771080373434652\n",
      "Episode average V value: 0.3397963521657167\n",
      "Average (on the epoch) training loss: 0.0047717380182861705\n",
      "Episode average V value: 0.5516442000865937\n",
      "LOSSES\n",
      "T = 0.015689238945022225; R = 0.017577588198473677;                 Gamma = 0.5325008781552315; Q = 0.0047520891024032605;\n",
      "Entropy Neighbor = 0.5593498128652573;                 Entropy Random = 0.18213317885994912;                 Volume = 0.11096053348109126; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004777151591551956\n",
      "Episode average V value: 0.4466078616678715\n",
      "epoch 22:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.875 (average over 8 episode(s))\n",
      "== Mean score per episode is 0.874989062636717 over 8 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3894, -0.4705,  0.0656, -0.6715, -0.7708], device='cuda:0') tensor([-0.4231, -0.5207,  0.0398, -0.7089, -0.8424], device='cuda:0') tensor([-0.3339, -0.4270,  0.0632, -0.6221, -0.6925], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0024], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.006427932081611029\n",
      "Episode average V value: 0.685516778911863\n",
      "Average (on the epoch) training loss: 0.004494634491172345\n",
      "Episode average V value: 0.4095897376537323\n",
      "Average (on the epoch) training loss: 0.004298504972313013\n",
      "Episode average V value: 0.4684257358312607\n",
      "Average (on the epoch) training loss: 0.004309187245477612\n",
      "Episode average V value: 0.5971356162003109\n",
      "Average (on the epoch) training loss: 0.004171241185245797\n",
      "Episode average V value: 0.9254078467686971\n",
      "Average (on the epoch) training loss: 0.004105002999616166\n",
      "Episode average V value: 0.6926941970984141\n",
      "Average (on the epoch) training loss: 0.0043728297258404875\n",
      "Episode average V value: 0.4875578085581462\n",
      "Average (on the epoch) training loss: 0.004528985121997737\n",
      "Episode average V value: 0.690384858420917\n",
      "Average (on the epoch) training loss: 0.004426386847626418\n",
      "Episode average V value: 0.5041547179222107\n",
      "Average (on the epoch) training loss: 0.004316296930591673\n",
      "Episode average V value: 0.9196041822433472\n",
      "Average (on the epoch) training loss: 0.004462077417921224\n",
      "Episode average V value: 0.7708633124828339\n",
      "Average (on the epoch) training loss: 0.004431182116580506\n",
      "Episode average V value: 0.938584953546524\n",
      "Average (on the epoch) training loss: 0.004500499078039046\n",
      "Episode average V value: 0.43758072869645226\n",
      "Average (on the epoch) training loss: 0.004554551577426656\n",
      "Episode average V value: 0.3767239646269725\n",
      "Average (on the epoch) training loss: 0.004541852075925709\n",
      "Episode average V value: 0.5214013059933981\n",
      "Average (on the epoch) training loss: 0.004552081134973158\n",
      "Episode average V value: 0.8609203398227692\n",
      "Average (on the epoch) training loss: 0.004555059078459938\n",
      "Episode average V value: 0.7695147097110748\n",
      "Average (on the epoch) training loss: 0.004506891020273249\n",
      "Episode average V value: 0.7342727422714234\n",
      "Average (on the epoch) training loss: 0.004492037861071574\n",
      "Episode average V value: 0.9174391825993856\n",
      "Average (on the epoch) training loss: 0.004488100477465196\n",
      "Episode average V value: 0.934906005859375\n",
      "Average (on the epoch) training loss: 0.004490653820846409\n",
      "Episode average V value: 0.7079548478126526\n",
      "Average (on the epoch) training loss: 0.004442339603773799\n",
      "Episode average V value: 0.4642605887992041\n",
      "Average (on the epoch) training loss: 0.004422028642269681\n",
      "Episode average V value: 0.4080478962924745\n",
      "Average (on the epoch) training loss: 0.004415878255553928\n",
      "Episode average V value: 0.6077298323313395\n",
      "Average (on the epoch) training loss: 0.004393340310029837\n",
      "Episode average V value: 0.38756247361501056\n",
      "Average (on the epoch) training loss: 0.004350072239170607\n",
      "Episode average V value: 0.6427755157152811\n",
      "Average (on the epoch) training loss: 0.004357830529395295\n",
      "Episode average V value: 0.5392701221363885\n",
      "Average (on the epoch) training loss: 0.004370202959139128\n",
      "Episode average V value: 0.6495082974433899\n",
      "Average (on the epoch) training loss: 0.004358290679970974\n",
      "Episode average V value: 0.583083720670806\n",
      "Average (on the epoch) training loss: 0.0044312438649403586\n",
      "Episode average V value: 0.44343111250135636\n",
      "Average (on the epoch) training loss: 0.004419476089623353\n",
      "Episode average V value: 0.9910725951194763\n",
      "Average (on the epoch) training loss: 0.004435581893706501\n",
      "Episode average V value: 0.6223284155130386\n",
      "Average (on the epoch) training loss: 0.004415478154626955\n",
      "Episode average V value: 0.7824202537536621\n",
      "Average (on the epoch) training loss: 0.004372593946298402\n",
      "Episode average V value: 0.6319032112757365\n",
      "Average (on the epoch) training loss: 0.00439124201761503\n",
      "Episode average V value: 0.34114161821512073\n",
      "Average (on the epoch) training loss: 0.004391744013845572\n",
      "Episode average V value: 0.5632844179868698\n",
      "Average (on the epoch) training loss: 0.004393544162817192\n",
      "Episode average V value: 1.0151476860046387\n",
      "Average (on the epoch) training loss: 0.0044049348840876695\n",
      "Episode average V value: 0.5280704514847862\n",
      "Average (on the epoch) training loss: 0.004463831821553507\n",
      "Episode average V value: 0.3913958347760714\n",
      "Average (on the epoch) training loss: 0.004471799619137147\n",
      "Episode average V value: 0.9138278762499491\n",
      "Average (on the epoch) training loss: 0.004477348001017116\n",
      "Episode average V value: 0.5630297362804413\n",
      "Average (on the epoch) training loss: 0.004483598197602374\n",
      "Episode average V value: 0.4637566804885864\n",
      "Average (on the epoch) training loss: 0.004493993138382082\n",
      "Episode average V value: 0.9098020593325297\n",
      "Average (on the epoch) training loss: 0.004535706404967348\n",
      "Episode average V value: 0.46143945363851696\n",
      "Average (on the epoch) training loss: 0.004522756242689741\n",
      "Episode average V value: 0.7334765136241913\n",
      "Average (on the epoch) training loss: 0.004525858135298042\n",
      "Episode average V value: 0.9931349754333496\n",
      "Average (on the epoch) training loss: 0.004478687820795333\n",
      "Episode average V value: 0.5161879658699036\n",
      "Average (on the epoch) training loss: 0.0044744938488182175\n",
      "Episode average V value: 0.8787057995796204\n",
      "Average (on the epoch) training loss: 0.004472303080914608\n",
      "Episode average V value: 0.9901493787765503\n",
      "Average (on the epoch) training loss: 0.0044704003497886185\n",
      "Episode average V value: 0.820224866271019\n",
      "Average (on the epoch) training loss: 0.004471657788577344\n",
      "Episode average V value: 0.46865247438351315\n",
      "Average (on the epoch) training loss: 0.004471402258292687\n",
      "Episode average V value: 0.5558682481447855\n",
      "Average (on the epoch) training loss: 0.004470619014665597\n",
      "Episode average V value: 0.9913028478622437\n",
      "Average (on the epoch) training loss: 0.004493414733688125\n",
      "Episode average V value: 0.6598220467567444\n",
      "Average (on the epoch) training loss: 0.004498287742539519\n",
      "Episode average V value: 0.4502504641811053\n",
      "Average (on the epoch) training loss: 0.004516532312510989\n",
      "Episode average V value: 0.6453906297683716\n",
      "Average (on the epoch) training loss: 0.004503302822051795\n",
      "Episode average V value: 0.6061159372329712\n",
      "Average (on the epoch) training loss: 0.00449290418487278\n",
      "Episode average V value: 0.8239611685276031\n",
      "Average (on the epoch) training loss: 0.004485321647240291\n",
      "Episode average V value: 0.7580826282501221\n",
      "Average (on the epoch) training loss: 0.004500809407694951\n",
      "Episode average V value: 0.4707811661064625\n",
      "Average (on the epoch) training loss: 0.004533358655319983\n",
      "Episode average V value: 0.3369743431156332\n",
      "Average (on the epoch) training loss: 0.004537558329962042\n",
      "Episode average V value: 0.6430004835128784\n",
      "LOSSES\n",
      "T = 0.015468982479535043; R = 0.018289053834741935;                 Gamma = 0.5321629923582077; Q = 0.004536598243517801;\n",
      "Entropy Neighbor = 0.5596247949004173;                 Entropy Random = 0.18480378139019013;                 Volume = 0.11603849531710148; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3401, -0.4291,  0.0578, -0.6271, -0.7066], device='cuda:0') tensor([-0.4622, -0.5236,  0.0309, -0.6913, -0.7987], device='cuda:0') tensor([-0.3401, -0.4291,  0.0578, -0.6271, -0.7066], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0282], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004534447624228231\n",
      "Episode average V value: 0.49005493707954884\n",
      "Average (on the epoch) training loss: 0.004568573793194274\n",
      "Episode average V value: 0.46313521802425384\n",
      "Average (on the epoch) training loss: 0.004596336894216033\n",
      "Episode average V value: 0.7311752140522003\n",
      "Average (on the epoch) training loss: 0.004571175284652871\n",
      "Episode average V value: 0.3918665974186017\n",
      "Average (on the epoch) training loss: 0.004551927053925396\n",
      "Episode average V value: 0.8011594861745834\n",
      "Average (on the epoch) training loss: 0.004561056991761702\n",
      "Episode average V value: 0.5992826989718846\n",
      "Average (on the epoch) training loss: 0.004542156936790628\n",
      "Episode average V value: 0.4009566229802591\n",
      "Average (on the epoch) training loss: 0.004530047542238374\n",
      "Episode average V value: 0.6467577219009399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004516663600315246\n",
      "Episode average V value: 0.548251234822803\n",
      "Average (on the epoch) training loss: 0.004492958878663019\n",
      "Episode average V value: 0.41182035952806473\n",
      "Average (on the epoch) training loss: 0.004490085329620563\n",
      "Episode average V value: 0.9878698587417603\n",
      "Average (on the epoch) training loss: 0.00445751124571177\n",
      "Episode average V value: 0.49865798013550894\n",
      "Average (on the epoch) training loss: 0.004467673101893592\n",
      "Episode average V value: 1.0064221620559692\n",
      "Average (on the epoch) training loss: 0.004487771315261879\n",
      "Episode average V value: 0.5448880845850165\n",
      "Average (on the epoch) training loss: 0.004490033995189282\n",
      "Episode average V value: 0.44777580433421665\n",
      "Average (on the epoch) training loss: 0.004481688801039106\n",
      "Episode average V value: 0.7891509930292765\n",
      "Average (on the epoch) training loss: 0.004490259333950072\n",
      "Episode average V value: 0.4332671821117401\n",
      "Average (on the epoch) training loss: 0.004488836293538651\n",
      "Episode average V value: 0.4565761203949268\n",
      "Average (on the epoch) training loss: 0.004512864904229545\n",
      "Episode average V value: 0.7204006810983022\n",
      "Average (on the epoch) training loss: 0.004529661889641793\n",
      "Episode average V value: 0.5176592040807009\n",
      "Average (on the epoch) training loss: 0.004551482399796343\n",
      "Episode average V value: 0.5220205698694501\n",
      "Average (on the epoch) training loss: 0.00456213491979604\n",
      "Episode average V value: 0.8665444552898407\n",
      "Average (on the epoch) training loss: 0.00456374609106881\n",
      "Episode average V value: 0.6802052557468414\n",
      "Average (on the epoch) training loss: 0.004558652755880448\n",
      "Episode average V value: 0.5405906364321709\n",
      "Average (on the epoch) training loss: 0.004560408666354394\n",
      "Episode average V value: 0.43507307171821596\n",
      "Average (on the epoch) training loss: 0.004560787959814505\n",
      "Episode average V value: 0.5455855599471501\n",
      "Average (on the epoch) training loss: 0.0045642421894311214\n",
      "Episode average V value: 0.4449314773082733\n",
      "Average (on the epoch) training loss: 0.004583147874014058\n",
      "Episode average V value: 0.5043986201286316\n",
      "Average (on the epoch) training loss: 0.004573949454108873\n",
      "Episode average V value: 0.8385890245437622\n",
      "Average (on the epoch) training loss: 0.004576375164397177\n",
      "Episode average V value: 0.744866156578064\n",
      "Average (on the epoch) training loss: 0.004582380348918144\n",
      "Episode average V value: 0.4048926749012687\n",
      "Average (on the epoch) training loss: 0.0045929776073314905\n",
      "Episode average V value: 0.689857135216395\n",
      "Average (on the epoch) training loss: 0.004589587090217625\n",
      "Episode average V value: 0.8052390515804291\n",
      "Average (on the epoch) training loss: 0.004612749506576986\n",
      "Episode average V value: 0.4843469522893429\n",
      "Average (on the epoch) training loss: 0.004602740712406476\n",
      "Episode average V value: 0.8229548186063766\n",
      "Average (on the epoch) training loss: 0.004616116919115921\n",
      "Episode average V value: 0.5990893798215049\n",
      "Average (on the epoch) training loss: 0.0046228927990724115\n",
      "Episode average V value: 0.7397033174832662\n",
      "Average (on the epoch) training loss: 0.004617862685034041\n",
      "Episode average V value: 0.8343809366226196\n",
      "Average (on the epoch) training loss: 0.0046150962481294406\n",
      "Episode average V value: 0.5263612369696299\n",
      "Average (on the epoch) training loss: 0.004605704643172286\n",
      "Episode average V value: 0.42955194579230416\n",
      "Average (on the epoch) training loss: 0.004616140206167328\n",
      "Episode average V value: 0.3955913186073303\n",
      "Average (on the epoch) training loss: 0.00461659397619466\n",
      "Episode average V value: 0.7830383876959482\n",
      "Average (on the epoch) training loss: 0.00462184908515085\n",
      "Episode average V value: 0.64860733350118\n",
      "Average (on the epoch) training loss: 0.004620761556622109\n",
      "Episode average V value: 0.4150049388408661\n",
      "Average (on the epoch) training loss: 0.004628881950462158\n",
      "Episode average V value: 0.45755675435066223\n",
      "Average (on the epoch) training loss: 0.004602568383602337\n",
      "Episode average V value: 0.44981730977694195\n",
      "Average (on the epoch) training loss: 0.0046122522650161035\n",
      "Episode average V value: 0.6302539259195328\n",
      "Average (on the epoch) training loss: 0.004619211184228951\n",
      "Episode average V value: 0.46937738358974457\n",
      "Average (on the epoch) training loss: 0.004620688276176018\n",
      "Episode average V value: 0.3816104382276535\n",
      "Average (on the epoch) training loss: 0.00461351336700274\n",
      "Episode average V value: 0.24851039797067642\n",
      "Average (on the epoch) training loss: 0.004609111757085464\n",
      "Episode average V value: 0.9522818624973297\n",
      "LOSSES\n",
      "T = 0.01553304046485573; R = 0.020282071399735285;                 Gamma = 0.5298443549275398; Q = 0.004665036302874796;\n",
      "Entropy Neighbor = 0.5603109155893325;                 Entropy Random = 0.1792814078181982;                 Volume = 0.12372964586690069; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004600817273196299\n",
      "Episode average V value: 0.5973206957181295\n",
      "epoch 23:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9375 (average over 16 episode(s))\n",
      "== Mean score per episode is 0.9374941406616208 over 16 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0729, -0.0095,  0.2256, -0.6044, -0.7564], device='cuda:0') tensor([-0.0753, -0.1410,  0.1952, -0.6509, -0.7848], device='cuda:0') tensor([-0.2136, -0.3059,  0.1012, -0.6046, -0.6930], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0236], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.006852302816696465\n",
      "Episode average V value: 0.8771610856056213\n",
      "Average (on the epoch) training loss: 0.0044170648252475075\n",
      "Episode average V value: 0.4770146856705348\n",
      "Average (on the epoch) training loss: 0.004133607154590604\n",
      "Episode average V value: 0.48011120160420734\n",
      "Average (on the epoch) training loss: 0.004444270804073782\n",
      "Episode average V value: 0.6900284503187452\n",
      "Average (on the epoch) training loss: 0.004468616799891202\n",
      "Episode average V value: 0.5551316618919373\n",
      "Average (on the epoch) training loss: 0.00434222153022087\n",
      "Episode average V value: 0.48306797444820404\n",
      "Average (on the epoch) training loss: 0.004426870084203342\n",
      "Episode average V value: 0.45644567693982807\n",
      "Average (on the epoch) training loss: 0.004423604836150751\n",
      "Episode average V value: 0.41305844858288765\n",
      "Average (on the epoch) training loss: 0.0043143792790942825\n",
      "Episode average V value: 0.7360818982124329\n",
      "Average (on the epoch) training loss: 0.004254037338862385\n",
      "Episode average V value: 0.5497096836566925\n",
      "Average (on the epoch) training loss: 0.004201789127869738\n",
      "Episode average V value: 0.9565391540527344\n",
      "Average (on the epoch) training loss: 0.004421510780230164\n",
      "Episode average V value: 0.5178896486759186\n",
      "Average (on the epoch) training loss: 0.004559883056683656\n",
      "Episode average V value: 0.48286867141723633\n",
      "Average (on the epoch) training loss: 0.004539092806495588\n",
      "Episode average V value: 0.35002010464668276\n",
      "Average (on the epoch) training loss: 0.004444404083689482\n",
      "Episode average V value: 0.6332199759781361\n",
      "Average (on the epoch) training loss: 0.00438920014944338\n",
      "Episode average V value: 0.9567968249320984\n",
      "Average (on the epoch) training loss: 0.004243775104698619\n",
      "Episode average V value: 0.5605907142162323\n",
      "Average (on the epoch) training loss: 0.004276306500994704\n",
      "Episode average V value: 0.5350410558960654\n",
      "Average (on the epoch) training loss: 0.0042634925576513286\n",
      "Episode average V value: 0.3193184526430236\n",
      "Average (on the epoch) training loss: 0.004306463306249284\n",
      "Episode average V value: 0.6598555035889149\n",
      "Average (on the epoch) training loss: 0.004303642069377626\n",
      "Episode average V value: 0.4985108271241188\n",
      "Average (on the epoch) training loss: 0.004311780366214879\n",
      "Episode average V value: 0.6290241650172642\n",
      "Average (on the epoch) training loss: 0.004349084981580878\n",
      "Episode average V value: 0.5441884795824686\n",
      "Average (on the epoch) training loss: 0.004315776515967336\n",
      "Episode average V value: 0.5414880812168121\n",
      "Average (on the epoch) training loss: 0.004332000060125031\n",
      "Episode average V value: 0.9871394634246826\n",
      "Average (on the epoch) training loss: 0.004352723417083515\n",
      "Episode average V value: 0.3782694677893932\n",
      "Average (on the epoch) training loss: 0.004337699962411371\n",
      "Episode average V value: 0.3790760702557034\n",
      "Average (on the epoch) training loss: 0.004344526751185083\n",
      "Episode average V value: 0.5216160342097282\n",
      "Average (on the epoch) training loss: 0.004347217773642656\n",
      "Episode average V value: 0.633622118168407\n",
      "Average (on the epoch) training loss: 0.004357126251165832\n",
      "Episode average V value: 0.7351752902780261\n",
      "Average (on the epoch) training loss: 0.004298629793447087\n",
      "Episode average V value: 0.37907775714993475\n",
      "Average (on the epoch) training loss: 0.0043042597390844355\n",
      "Episode average V value: 0.616634909595762\n",
      "Average (on the epoch) training loss: 0.004336479155600511\n",
      "Episode average V value: 0.6814124782880148\n",
      "Average (on the epoch) training loss: 0.004345917194846945\n",
      "Episode average V value: 0.6342078804969787\n",
      "Average (on the epoch) training loss: 0.0043525313939799335\n",
      "Episode average V value: 0.41569341041825036\n",
      "Average (on the epoch) training loss: 0.00434341010901909\n",
      "Episode average V value: 0.8371412754058838\n",
      "Average (on the epoch) training loss: 0.004327822322412939\n",
      "Episode average V value: 0.5540141122681754\n",
      "Average (on the epoch) training loss: 0.004311697246535248\n",
      "Episode average V value: 0.5833885371685028\n",
      "Average (on the epoch) training loss: 0.004296488890262148\n",
      "Episode average V value: 0.5186530997355779\n",
      "Average (on the epoch) training loss: 0.004293053977511377\n",
      "Episode average V value: 0.47020138502120973\n",
      "Average (on the epoch) training loss: 0.004286790957392063\n",
      "Episode average V value: 0.8294836759567261\n",
      "Average (on the epoch) training loss: 0.004294893815896238\n",
      "Episode average V value: 0.8637194335460663\n",
      "Average (on the epoch) training loss: 0.004309961316640327\n",
      "Episode average V value: 0.6548703809579214\n",
      "Average (on the epoch) training loss: 0.004300176290843379\n",
      "Episode average V value: 0.41494207746452755\n",
      "Average (on the epoch) training loss: 0.004299896777746989\n",
      "Episode average V value: 0.4937242766221364\n",
      "Average (on the epoch) training loss: 0.004285234475659495\n",
      "Episode average V value: 0.4345783591270447\n",
      "Average (on the epoch) training loss: 0.004289905074605044\n",
      "Episode average V value: 0.9249417185783386\n",
      "Average (on the epoch) training loss: 0.004304892914276176\n",
      "Episode average V value: 0.4382808903853099\n",
      "LOSSES\n",
      "T = 0.015391098604537547; R = 0.02058758142357692;                 Gamma = 0.5290998356938362; Q = 0.0043353222486330195;\n",
      "Entropy Neighbor = 0.5575694726109505;                 Entropy Random = 0.17811056208610535;                 Volume = 0.1281492440290749; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0043353222486330195\n",
      "Episode average V value: 0.3816217173028875\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1197,  0.0443,  0.2459, -0.6123, -0.7864], device='cuda:0') tensor([ 0.1744,  0.1181,  0.2731, -0.5997, -0.7526], device='cuda:0') tensor([ 0.2383,  0.1555,  0.2753, -0.5706, -0.7359], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0045], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0043430619829255964\n",
      "Episode average V value: 0.4591690784408933\n",
      "Average (on the epoch) training loss: 0.004359676326706606\n",
      "Episode average V value: 0.6079934792859214\n",
      "Average (on the epoch) training loss: 0.004373828626119293\n",
      "Episode average V value: 0.442485664378513\n",
      "Average (on the epoch) training loss: 0.004375419568334871\n",
      "Episode average V value: 0.4437910160597633\n",
      "Average (on the epoch) training loss: 0.004388546592622924\n",
      "Episode average V value: 0.6589590509732565\n",
      "Average (on the epoch) training loss: 0.004390094368044479\n",
      "Episode average V value: 0.37385268315025\n",
      "Average (on the epoch) training loss: 0.00443259379604012\n",
      "Episode average V value: 0.6629390070835749\n",
      "Average (on the epoch) training loss: 0.004419021004574331\n",
      "Episode average V value: 0.4859135761857033\n",
      "Average (on the epoch) training loss: 0.0044160462141146035\n",
      "Episode average V value: 0.44119685659041774\n",
      "Average (on the epoch) training loss: 0.004429291449684276\n",
      "Episode average V value: 0.3986780097087224\n",
      "Average (on the epoch) training loss: 0.004417741336217223\n",
      "Episode average V value: 0.6815854268414634\n",
      "Average (on the epoch) training loss: 0.004417760469936319\n",
      "Episode average V value: 0.7683473229408264\n",
      "Average (on the epoch) training loss: 0.004428332177779943\n",
      "Episode average V value: 0.5563802785343595\n",
      "Average (on the epoch) training loss: 0.004442022221438654\n",
      "Episode average V value: 0.5681509460721698\n",
      "Average (on the epoch) training loss: 0.004450672843514065\n",
      "Episode average V value: 0.46635766415035024\n",
      "Average (on the epoch) training loss: 0.004446809572234706\n",
      "Episode average V value: 0.9993563890457153\n",
      "Average (on the epoch) training loss: 0.004446771802751574\n",
      "Episode average V value: 0.9985694885253906\n",
      "Average (on the epoch) training loss: 0.0044616140311158825\n",
      "Episode average V value: 0.45132275223731994\n",
      "Average (on the epoch) training loss: 0.004460638709468018\n",
      "Episode average V value: 0.6307500004768372\n",
      "Average (on the epoch) training loss: 0.004508479839280591\n",
      "Episode average V value: 0.4035397797822952\n",
      "Average (on the epoch) training loss: 0.004521926477413629\n",
      "Episode average V value: 0.514958659807841\n",
      "Average (on the epoch) training loss: 0.0045162227468830834\n",
      "Episode average V value: 0.6979397535324097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004518536696539951\n",
      "Episode average V value: 0.7821343541145325\n",
      "Average (on the epoch) training loss: 0.00451614441710331\n",
      "Episode average V value: 0.5811511874198914\n",
      "Average (on the epoch) training loss: 0.0045097319893824175\n",
      "Episode average V value: 0.40879467791981167\n",
      "Average (on the epoch) training loss: 0.004505699735594309\n",
      "Episode average V value: 0.9974801540374756\n",
      "Average (on the epoch) training loss: 0.004502728404446803\n",
      "Episode average V value: 0.47522328116677026\n",
      "Average (on the epoch) training loss: 0.0045020888859134125\n",
      "Episode average V value: 0.9468867778778076\n",
      "Average (on the epoch) training loss: 0.004491328559687693\n",
      "Episode average V value: 0.502413632778021\n",
      "Average (on the epoch) training loss: 0.004502033894335881\n",
      "Episode average V value: 0.4577588886022568\n",
      "Average (on the epoch) training loss: 0.004503195679403296\n",
      "Episode average V value: 0.5719050318002701\n",
      "Average (on the epoch) training loss: 0.004533550303298542\n",
      "Episode average V value: 0.514924105670717\n",
      "Average (on the epoch) training loss: 0.004535627187991632\n",
      "Episode average V value: 0.8769749999046326\n",
      "Average (on the epoch) training loss: 0.004526880615325117\n",
      "Episode average V value: 0.4806897168358167\n",
      "Average (on the epoch) training loss: 0.004527880847545868\n",
      "Episode average V value: 0.6749440208077431\n",
      "Average (on the epoch) training loss: 0.004520114524128088\n",
      "Episode average V value: 0.4155849419078048\n",
      "Average (on the epoch) training loss: 0.004524936277619344\n",
      "Episode average V value: 0.6445153951644897\n",
      "Average (on the epoch) training loss: 0.004513908404412309\n",
      "Episode average V value: 0.42833311511920047\n",
      "Average (on the epoch) training loss: 0.004508729724727489\n",
      "Episode average V value: 0.6963202729821205\n",
      "Average (on the epoch) training loss: 0.004523872561942049\n",
      "Episode average V value: 0.4102732092142105\n",
      "Average (on the epoch) training loss: 0.004516201474743479\n",
      "Episode average V value: 0.7669367730617523\n",
      "Average (on the epoch) training loss: 0.004500930720259836\n",
      "Episode average V value: 0.40564500689506533\n",
      "Average (on the epoch) training loss: 0.004517018649762376\n",
      "Episode average V value: 0.44951333850622177\n",
      "Average (on the epoch) training loss: 0.0045241704096208694\n",
      "Episode average V value: 0.3554530844092369\n",
      "LOSSES\n",
      "T = 0.015770127023570238; R = 0.021510989096714183;                 Gamma = 0.5275631932020187; Q = 0.0047077103579649705;\n",
      "Entropy Neighbor = 0.5554482419490814;                 Entropy Random = 0.17696800222992898;                 Volume = 0.12915318727120756; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004521516303298995\n",
      "Episode average V value: 0.27921294172604877\n",
      "epoch 24:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.5 (average over 2 episode(s))\n",
      "== Mean score per episode is 0.49997500124993743 over 2 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0795,  0.0133,  0.2474, -0.6482, -0.8445], device='cuda:0') tensor([-0.0894, -0.1305,  0.2235, -0.6864, -0.8434], device='cuda:0') tensor([-0.3231, -0.3978,  0.0872, -0.6739, -0.8007], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0012], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0044859530018201395\n",
      "Episode average V value: 0.4321091666414931\n",
      "Average (on the epoch) training loss: 0.004498468288418619\n",
      "Episode average V value: 0.5598534776104821\n",
      "Average (on the epoch) training loss: 0.0044528237586764965\n",
      "Episode average V value: 0.6030701398849487\n",
      "Average (on the epoch) training loss: 0.0047465498448486946\n",
      "Episode average V value: 0.39056860587813635\n",
      "Average (on the epoch) training loss: 0.004739484421338942\n",
      "Episode average V value: 0.6710699747006098\n",
      "Average (on the epoch) training loss: 0.0046648552461930025\n",
      "Episode average V value: 0.6064727348940713\n",
      "Average (on the epoch) training loss: 0.0045491644385037945\n",
      "Episode average V value: 0.6633345186710358\n",
      "Average (on the epoch) training loss: 0.004603086910503623\n",
      "Episode average V value: 0.37379394637213814\n",
      "Average (on the epoch) training loss: 0.004617731117418614\n",
      "Episode average V value: 0.6912007331848145\n",
      "Average (on the epoch) training loss: 0.0045539970288972385\n",
      "Episode average V value: 0.47954533166355556\n",
      "Average (on the epoch) training loss: 0.004554159515051662\n",
      "Episode average V value: 0.6407802700996399\n",
      "Average (on the epoch) training loss: 0.004628789151860961\n",
      "Episode average V value: 0.39825577484933955\n",
      "Average (on the epoch) training loss: 0.004652233756739103\n",
      "Episode average V value: 0.566061235136456\n",
      "Average (on the epoch) training loss: 0.004712178951594978\n",
      "Episode average V value: 0.551261380314827\n",
      "Average (on the epoch) training loss: 0.004616912064218038\n",
      "Episode average V value: 0.37290554683087235\n",
      "Average (on the epoch) training loss: 0.004622838679756484\n",
      "Episode average V value: 0.513784897327423\n",
      "Average (on the epoch) training loss: 0.004687864645786262\n",
      "Episode average V value: 0.6248683248247419\n",
      "Average (on the epoch) training loss: 0.004727286263043386\n",
      "Episode average V value: 0.5101508162915707\n",
      "Average (on the epoch) training loss: 0.004790430446119877\n",
      "Episode average V value: 0.42363631216491143\n",
      "Average (on the epoch) training loss: 0.004769207423204314\n",
      "Episode average V value: 0.4472126603126526\n",
      "Average (on the epoch) training loss: 0.004770436666041865\n",
      "Episode average V value: 0.7802019715309143\n",
      "Average (on the epoch) training loss: 0.004752055987815505\n",
      "Episode average V value: 0.4544770934365012\n",
      "Average (on the epoch) training loss: 0.004756415040317503\n",
      "Episode average V value: 0.6985484004020691\n",
      "Average (on the epoch) training loss: 0.004756637559810246\n",
      "Episode average V value: 0.5637204547723135\n",
      "Average (on the epoch) training loss: 0.004750862431253219\n",
      "Episode average V value: 0.7819818258285522\n",
      "Average (on the epoch) training loss: 0.004743536673655679\n",
      "Episode average V value: 0.636774523390664\n",
      "Average (on the epoch) training loss: 0.004737002303098235\n",
      "Episode average V value: 0.6686190466086069\n",
      "Average (on the epoch) training loss: 0.004735705870700451\n",
      "Episode average V value: 0.44967335036822725\n",
      "Average (on the epoch) training loss: 0.004719708125126739\n",
      "Episode average V value: 0.3694700529942146\n",
      "Average (on the epoch) training loss: 0.004712453422019676\n",
      "Episode average V value: 0.6410943468411764\n",
      "Average (on the epoch) training loss: 0.004707921531681585\n",
      "Episode average V value: 0.38972601982263416\n",
      "Average (on the epoch) training loss: 0.004684434081895362\n",
      "Episode average V value: 0.5389274424976773\n",
      "Average (on the epoch) training loss: 0.004680660503931773\n",
      "Episode average V value: 0.6206617169082165\n",
      "LOSSES\n",
      "T = 0.015896621021442115; R = 0.02203872076002881;                 Gamma = 0.5266674510240554; Q = 0.004680662411265075;\n",
      "Entropy Neighbor = 0.5535406070351601;                 Entropy Random = 0.17728804022073746;                 Volume = 0.1344007843323052; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2314,  0.1523,  0.2716, -0.5755, -0.7492], device='cuda:0') tensor([ 0.2821,  0.2254,  0.2851, -0.5578, -0.7330], device='cuda:0') tensor([ 0.3115,  0.2288,  0.2935, -0.5516, -0.7231], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0031], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.00469351689483503\n",
      "Episode average V value: 0.3929652728140354\n",
      "Average (on the epoch) training loss: 0.004714955146865625\n",
      "Episode average V value: 0.5922638058662415\n",
      "Average (on the epoch) training loss: 0.004716751530194439\n",
      "Episode average V value: 0.6914754807949066\n",
      "Average (on the epoch) training loss: 0.004690015022881711\n",
      "Episode average V value: 0.40335523269393225\n",
      "Average (on the epoch) training loss: 0.004669146647084626\n",
      "Episode average V value: 0.6727731078863144\n",
      "Average (on the epoch) training loss: 0.004662977752139636\n",
      "Episode average V value: 0.5176546275615692\n",
      "Average (on the epoch) training loss: 0.004654566752211543\n",
      "Episode average V value: 0.9218810498714447\n",
      "Average (on the epoch) training loss: 0.0046355778412697345\n",
      "Episode average V value: 0.4347230110849653\n",
      "Average (on the epoch) training loss: 0.004615420669560896\n",
      "Episode average V value: 0.47901166569102893\n",
      "Average (on the epoch) training loss: 0.0046121730235539225\n",
      "Episode average V value: 0.8939620057741801\n",
      "Average (on the epoch) training loss: 0.004619765949921094\n",
      "Episode average V value: 0.9861152768135071\n",
      "Average (on the epoch) training loss: 0.004582332824319897\n",
      "Episode average V value: 0.43440698290413077\n",
      "Average (on the epoch) training loss: 0.0045992144048636625\n",
      "Episode average V value: 0.5348453649452755\n",
      "Average (on the epoch) training loss: 0.004599881050096558\n",
      "Episode average V value: 0.4555428117513657\n",
      "Average (on the epoch) training loss: 0.004597474041974662\n",
      "Episode average V value: 0.6106632724404335\n",
      "Average (on the epoch) training loss: 0.004587941137853461\n",
      "Episode average V value: 0.3899959087371826\n",
      "Average (on the epoch) training loss: 0.00459066681483259\n",
      "Episode average V value: 0.7831746339797974\n",
      "Average (on the epoch) training loss: 0.00457821054021235\n",
      "Episode average V value: 0.45042439443724497\n",
      "Average (on the epoch) training loss: 0.004575570688447965\n",
      "Episode average V value: 0.5345765550931295\n",
      "Average (on the epoch) training loss: 0.004563675204892911\n",
      "Episode average V value: 0.3783605496088664\n",
      "Average (on the epoch) training loss: 0.004564259767883264\n",
      "Episode average V value: 0.8933429718017578\n",
      "Average (on the epoch) training loss: 0.004556241159400822\n",
      "Episode average V value: 0.5688843488693237\n",
      "Average (on the epoch) training loss: 0.004554410273689897\n",
      "Episode average V value: 0.9415711462497711\n",
      "Average (on the epoch) training loss: 0.004526401600625039\n",
      "Episode average V value: 0.43667630199342966\n",
      "Average (on the epoch) training loss: 0.004522884611397055\n",
      "Episode average V value: 0.5726119637489319\n",
      "Average (on the epoch) training loss: 0.0045304604463858485\n",
      "Episode average V value: 0.48961974893297466\n",
      "Average (on the epoch) training loss: 0.004532354313811092\n",
      "Episode average V value: 0.925513505935669\n",
      "Average (on the epoch) training loss: 0.00453204691191345\n",
      "Episode average V value: 0.6024375557899475\n",
      "Average (on the epoch) training loss: 0.004537241531514208\n",
      "Episode average V value: 0.6373685002326965\n",
      "Average (on the epoch) training loss: 0.004536486161647389\n",
      "Episode average V value: 0.6860164020742688\n",
      "Average (on the epoch) training loss: 0.004539353275867409\n",
      "Episode average V value: 0.5868110273565564\n",
      "Average (on the epoch) training loss: 0.004538033954682491\n",
      "Episode average V value: 0.40173819310524883\n",
      "Average (on the epoch) training loss: 0.004553140025120761\n",
      "Episode average V value: 0.46951090544462204\n",
      "Average (on the epoch) training loss: 0.004540143650096566\n",
      "Episode average V value: 0.6683456798394521\n",
      "Average (on the epoch) training loss: 0.00455041220397398\n",
      "Episode average V value: 0.38147827320628697\n",
      "Average (on the epoch) training loss: 0.004560346665909479\n",
      "Episode average V value: 0.5659619678150524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004549933915270742\n",
      "Episode average V value: 0.634422991424799\n",
      "Average (on the epoch) training loss: 0.004570954431337707\n",
      "Episode average V value: 0.6174396233899253\n",
      "Average (on the epoch) training loss: 0.004569080238749649\n",
      "Episode average V value: 0.682414174079895\n",
      "Average (on the epoch) training loss: 0.004560307446416349\n",
      "Episode average V value: 0.4230457223378695\n",
      "Average (on the epoch) training loss: 0.004561835939362412\n",
      "Episode average V value: 0.5839888155460358\n",
      "Average (on the epoch) training loss: 0.004566696839240744\n",
      "Episode average V value: 0.6751342564821243\n",
      "Average (on the epoch) training loss: 0.0045796403791516635\n",
      "Episode average V value: 0.545502997106976\n",
      "Average (on the epoch) training loss: 0.0045758509011596\n",
      "Episode average V value: 0.9429457783699036\n",
      "Average (on the epoch) training loss: 0.004571699700816184\n",
      "Episode average V value: 0.640551233291626\n",
      "Average (on the epoch) training loss: 0.004574042749075348\n",
      "Episode average V value: 0.7817939519882202\n",
      "Average (on the epoch) training loss: 0.004573201725877799\n",
      "Episode average V value: 0.6107725117887769\n",
      "Average (on the epoch) training loss: 0.0045719068476868605\n",
      "Episode average V value: 0.775169163942337\n",
      "LOSSES\n",
      "T = 0.015489955201745034; R = 0.021798882248345763;                 Gamma = 0.527039205133915; Q = 0.004457917376654222;\n",
      "Entropy Neighbor = 0.557156532227993;                 Entropy Random = 0.17617009122669697;                 Volume = 0.13425918443128468; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004569289893959649\n",
      "Episode average V value: 0.8099236687024435\n",
      "epoch 25:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9761904761904762 (average over 42 episode(s))\n",
      "== Mean score per episode is 0.9761881519329715 over 42 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1045,  0.0316,  0.2399, -0.6195, -0.8033], device='cuda:0') tensor([ 0.1064,  0.0309,  0.2462, -0.6166, -0.7999], device='cuda:0') tensor([ 0.1045,  0.0316,  0.2399, -0.6195, -0.8033], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0067], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.005362307326868177\n",
      "Episode average V value: 0.3924830138683319\n",
      "Average (on the epoch) training loss: 0.005028461382607929\n",
      "Episode average V value: 0.5656295310367238\n",
      "Average (on the epoch) training loss: 0.005448493246070068\n",
      "Episode average V value: 0.5920170247554779\n",
      "Average (on the epoch) training loss: 0.0055479703088557085\n",
      "Episode average V value: 0.6396822571754456\n",
      "Average (on the epoch) training loss: 0.005593343870714307\n",
      "Episode average V value: 0.46878125944307875\n",
      "Average (on the epoch) training loss: 0.005514296972089343\n",
      "Episode average V value: 0.881888747215271\n",
      "Average (on the epoch) training loss: 0.005315316671874585\n",
      "Episode average V value: 0.5162827707827091\n",
      "Average (on the epoch) training loss: 0.005158484988792449\n",
      "Episode average V value: 0.4749412201344967\n",
      "Average (on the epoch) training loss: 0.005255979321612073\n",
      "Episode average V value: 0.6686527381340662\n",
      "Average (on the epoch) training loss: 0.005193926860444401\n",
      "Episode average V value: 0.6004662573337555\n",
      "Average (on the epoch) training loss: 0.0050985832313904765\n",
      "Episode average V value: 0.562023831738366\n",
      "Average (on the epoch) training loss: 0.0049562558166818755\n",
      "Episode average V value: 0.6137981755392892\n",
      "Average (on the epoch) training loss: 0.004875729517054854\n",
      "Episode average V value: 0.8014565855264664\n",
      "Average (on the epoch) training loss: 0.004793244500155085\n",
      "Episode average V value: 0.823715889453888\n",
      "Average (on the epoch) training loss: 0.004735850740915834\n",
      "Episode average V value: 0.7395665526390076\n",
      "Average (on the epoch) training loss: 0.004696887183870951\n",
      "Episode average V value: 0.5479594724518912\n",
      "Average (on the epoch) training loss: 0.004721871655337882\n",
      "Episode average V value: 0.7853256464004517\n",
      "Average (on the epoch) training loss: 0.004724767930684206\n",
      "Episode average V value: 0.8594233393669128\n",
      "Average (on the epoch) training loss: 0.0049200598255456345\n",
      "Episode average V value: 0.7403958678245545\n",
      "Average (on the epoch) training loss: 0.0048666515517759865\n",
      "Episode average V value: 0.5736615598201752\n",
      "Average (on the epoch) training loss: 0.004851798694816998\n",
      "Episode average V value: 0.4366192492571744\n",
      "Average (on the epoch) training loss: 0.004826518408663105\n",
      "Episode average V value: 0.6286239127318064\n",
      "Average (on the epoch) training loss: 0.0047656375505826685\n",
      "Episode average V value: 0.5787884667515755\n",
      "Average (on the epoch) training loss: 0.0047232485914166684\n",
      "Episode average V value: 0.5164142598708471\n",
      "Average (on the epoch) training loss: 0.004666965288817193\n",
      "Episode average V value: 0.8969118396441141\n",
      "Average (on the epoch) training loss: 0.004679061640802372\n",
      "Episode average V value: 0.518538107474645\n",
      "Average (on the epoch) training loss: 0.004770015010400272\n",
      "Episode average V value: 0.6595530331134796\n",
      "Average (on the epoch) training loss: 0.004755281058445187\n",
      "Episode average V value: 0.9885228872299194\n",
      "Average (on the epoch) training loss: 0.004745963252325718\n",
      "Episode average V value: 0.4004889756441116\n",
      "Average (on the epoch) training loss: 0.004775192730920148\n",
      "Episode average V value: 0.7158288870538984\n",
      "Average (on the epoch) training loss: 0.004765435352478877\n",
      "Episode average V value: 0.4846266657114029\n",
      "Average (on the epoch) training loss: 0.0047529629820458694\n",
      "Episode average V value: 0.6310883419854301\n",
      "Average (on the epoch) training loss: 0.004758140426837251\n",
      "Episode average V value: 0.5947334878146648\n",
      "Average (on the epoch) training loss: 0.004735379386799555\n",
      "Episode average V value: 0.8744809627532959\n",
      "Average (on the epoch) training loss: 0.004759500215468546\n",
      "Episode average V value: 0.3507782369852066\n",
      "Average (on the epoch) training loss: 0.004823052518049929\n",
      "Episode average V value: 0.5412158071994781\n",
      "Average (on the epoch) training loss: 0.004776992377655048\n",
      "Episode average V value: 0.6617233097553253\n",
      "Average (on the epoch) training loss: 0.004741146284665208\n",
      "Episode average V value: 0.4990164362467252\n",
      "Average (on the epoch) training loss: 0.004753990781010185\n",
      "Episode average V value: 0.5100035534964668\n",
      "Average (on the epoch) training loss: 0.0047201876138765995\n",
      "Episode average V value: 0.8963604172070821\n",
      "Average (on the epoch) training loss: 0.004767991560511291\n",
      "Episode average V value: 0.6597141623497009\n",
      "Average (on the epoch) training loss: 0.00475146669502321\n",
      "Episode average V value: 0.48133568465709686\n",
      "Average (on the epoch) training loss: 0.004731952691523822\n",
      "Episode average V value: 0.5909573100507259\n",
      "Average (on the epoch) training loss: 0.004724987470074663\n",
      "Episode average V value: 0.4785257237298148\n",
      "Average (on the epoch) training loss: 0.004691005814612245\n",
      "Episode average V value: 0.5805485347906748\n",
      "Average (on the epoch) training loss: 0.004689570411796545\n",
      "Episode average V value: 0.7887046337127686\n",
      "Average (on the epoch) training loss: 0.004645956460164365\n",
      "Episode average V value: 0.4579545085628827\n",
      "Average (on the epoch) training loss: 0.004634291288130593\n",
      "Episode average V value: 0.799694374203682\n",
      "Average (on the epoch) training loss: 0.004664962201203753\n",
      "Episode average V value: 0.4039824406305949\n",
      "Average (on the epoch) training loss: 0.004677076381257852\n",
      "Episode average V value: 0.27298749685287477\n",
      "Average (on the epoch) training loss: 0.00467149624692379\n",
      "Episode average V value: 0.996347188949585\n",
      "Average (on the epoch) training loss: 0.004661471601795768\n",
      "Episode average V value: 0.710616409778595\n",
      "Average (on the epoch) training loss: 0.004631911360245219\n",
      "Episode average V value: 0.6000765604632241\n",
      "Average (on the epoch) training loss: 0.004588924226877482\n",
      "Episode average V value: 0.32518027767990576\n",
      "Average (on the epoch) training loss: 0.004595446376944307\n",
      "Episode average V value: 0.4846257609980447\n",
      "Average (on the epoch) training loss: 0.004590877283142129\n",
      "Episode average V value: 0.8903135061264038\n",
      "Average (on the epoch) training loss: 0.004606025276556791\n",
      "Episode average V value: 0.473240313204852\n",
      "Average (on the epoch) training loss: 0.004606776845225784\n",
      "Episode average V value: 0.6510864992936453\n",
      "Average (on the epoch) training loss: 0.004617075568232773\n",
      "Episode average V value: 0.6110464334487915\n",
      "Average (on the epoch) training loss: 0.004626966369983434\n",
      "Episode average V value: 0.7884902954101562\n",
      "Average (on the epoch) training loss: 0.0046064584583287195\n",
      "Episode average V value: 0.7403872966766357\n",
      "Average (on the epoch) training loss: 0.004612776718434246\n",
      "Episode average V value: 0.5174625913302103\n",
      "Average (on the epoch) training loss: 0.004622110670563979\n",
      "Episode average V value: 0.35813969373703003\n",
      "Average (on the epoch) training loss: 0.004644678514746933\n",
      "Episode average V value: 0.4225725391331841\n",
      "Average (on the epoch) training loss: 0.004648053062455488\n",
      "Episode average V value: 0.5225172638893127\n",
      "Average (on the epoch) training loss: 0.004636845259275883\n",
      "Episode average V value: 0.7343686938285827\n",
      "Average (on the epoch) training loss: 0.0046233373606810345\n",
      "Episode average V value: 0.46404625339941546\n",
      "Average (on the epoch) training loss: 0.00462151182436784\n",
      "Episode average V value: 0.6222175870622907\n",
      "Average (on the epoch) training loss: 0.004608714173814286\n",
      "Episode average V value: 0.6640653908252716\n",
      "LOSSES\n",
      "T = 0.015350328369997442; R = 0.022472040676046162;                 Gamma = 0.5257321521043777; Q = 0.004599604250397533;\n",
      "Entropy Neighbor = 0.5564614387750626;                 Entropy Random = 0.1771043301820755;                 Volume = 0.13899444000050426; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004599604250397533\n",
      "Episode average V value: 0.5419576508658273\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2060,  0.1293,  0.2597, -0.5816, -0.7619], device='cuda:0') tensor([ 0.1678,  0.0715,  0.2486, -0.6019, -0.7824], device='cuda:0') tensor([ 0.3113,  0.2506,  0.3239, -0.6197, -0.8578], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0130], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004599805382695159\n",
      "Episode average V value: 0.40306328733762103\n",
      "Average (on the epoch) training loss: 0.00456526166214814\n",
      "Episode average V value: 0.472704017162323\n",
      "Average (on the epoch) training loss: 0.0045663425830963\n",
      "Episode average V value: 0.7896255850791931\n",
      "Average (on the epoch) training loss: 0.0045688020247737614\n",
      "Episode average V value: 0.5817969888448715\n",
      "Average (on the epoch) training loss: 0.004569617772084108\n",
      "Episode average V value: 0.47639668529683893\n",
      "Average (on the epoch) training loss: 0.0045572433594252655\n",
      "Episode average V value: 0.7318337142467499\n",
      "Average (on the epoch) training loss: 0.0045597940394774055\n",
      "Episode average V value: 0.9916378259658813\n",
      "Average (on the epoch) training loss: 0.004560975275272804\n",
      "Episode average V value: 0.5677121633833105\n",
      "Average (on the epoch) training loss: 0.0045471867194080496\n",
      "Episode average V value: 0.8956333597501119\n",
      "Average (on the epoch) training loss: 0.004547186019155942\n",
      "Episode average V value: 0.9945987462997437\n",
      "Average (on the epoch) training loss: 0.004557909773680786\n",
      "Episode average V value: 0.7897576093673706\n",
      "Average (on the epoch) training loss: 0.004547599564804777\n",
      "Episode average V value: 0.8541347831487656\n",
      "Average (on the epoch) training loss: 0.004541156869381666\n",
      "Episode average V value: 0.5849793195724488\n",
      "Average (on the epoch) training loss: 0.00454033159946533\n",
      "Episode average V value: 0.8951935768127441\n",
      "Average (on the epoch) training loss: 0.004536495679701796\n",
      "Episode average V value: 0.4507826566696167\n",
      "Average (on the epoch) training loss: 0.004535951139128661\n",
      "Episode average V value: 0.891441822052002\n",
      "Average (on the epoch) training loss: 0.0045583054723520216\n",
      "Episode average V value: 0.41405924492412144\n",
      "Average (on the epoch) training loss: 0.004554460287750799\n",
      "Episode average V value: 0.43900168273184037\n",
      "Average (on the epoch) training loss: 0.00455477906796112\n",
      "Episode average V value: 0.4149329327046871\n",
      "Average (on the epoch) training loss: 0.004547770847303552\n",
      "Episode average V value: 0.7732896447181702\n",
      "Average (on the epoch) training loss: 0.004544450079463422\n",
      "Episode average V value: 0.6603263735771179\n",
      "Average (on the epoch) training loss: 0.00454483168875976\n",
      "Episode average V value: 0.40515334407488507\n",
      "Average (on the epoch) training loss: 0.004540018102306931\n",
      "Episode average V value: 0.5665722754266527\n",
      "Average (on the epoch) training loss: 0.004519951904597051\n",
      "Episode average V value: 0.6677395445959908\n",
      "Average (on the epoch) training loss: 0.004517950957467101\n",
      "Episode average V value: 0.7905759811401367\n",
      "Average (on the epoch) training loss: 0.00450930214028797\n",
      "Episode average V value: 0.5555181635750664\n",
      "Average (on the epoch) training loss: 0.0045061969882292\n",
      "Episode average V value: 0.39780475199222565\n",
      "Average (on the epoch) training loss: 0.0045120679466650665\n",
      "Episode average V value: 0.8014283776283264\n",
      "Average (on the epoch) training loss: 0.004491547129970093\n",
      "Episode average V value: 0.5508762697378794\n",
      "Average (on the epoch) training loss: 0.004492681225603392\n",
      "Episode average V value: 0.616443908876843\n",
      "Average (on the epoch) training loss: 0.004509968985568582\n",
      "Episode average V value: 0.6593889832496643\n",
      "Average (on the epoch) training loss: 0.004510121454966982\n",
      "Episode average V value: 0.5598121993243694\n",
      "Average (on the epoch) training loss: 0.004509767816164234\n",
      "Episode average V value: 0.6997986137866974\n",
      "Average (on the epoch) training loss: 0.004495825768813868\n",
      "Episode average V value: 0.7127560615539551\n",
      "Average (on the epoch) training loss: 0.004491420259406079\n",
      "Episode average V value: 0.5946447040353503\n",
      "Average (on the epoch) training loss: 0.004488119443814303\n",
      "Episode average V value: 0.5230388641357422\n",
      "Average (on the epoch) training loss: 0.004483350339979136\n",
      "Episode average V value: 0.49966472616562474\n",
      "Average (on the epoch) training loss: 0.004488444488297355\n",
      "Episode average V value: 0.5046489867899153\n",
      "Average (on the epoch) training loss: 0.004488844168777105\n",
      "Episode average V value: 0.9888588190078735\n",
      "Average (on the epoch) training loss: 0.0044870182204412145\n",
      "Episode average V value: 0.7900965213775635\n",
      "Average (on the epoch) training loss: 0.00448710354744453\n",
      "Episode average V value: 0.5912828743457794\n",
      "Average (on the epoch) training loss: 0.004481284956296255\n",
      "Episode average V value: 0.4649980664253235\n",
      "Average (on the epoch) training loss: 0.004484779719173623\n",
      "Episode average V value: 0.8765643835067749\n",
      "Average (on the epoch) training loss: 0.0044683043090940665\n",
      "Episode average V value: 0.5192063053448995\n",
      "Average (on the epoch) training loss: 0.004463851900732855\n",
      "Episode average V value: 0.6897959351539612\n",
      "Average (on the epoch) training loss: 0.004461191195825828\n",
      "Episode average V value: 0.9878123998641968\n",
      "Average (on the epoch) training loss: 0.0044690215173450645\n",
      "Episode average V value: 0.4615399181842804\n",
      "Average (on the epoch) training loss: 0.004468240013432573\n",
      "Episode average V value: 0.7014759182929993\n",
      "Average (on the epoch) training loss: 0.004470446660959276\n",
      "Episode average V value: 0.8410302400588989\n",
      "Average (on the epoch) training loss: 0.00447352664522534\n",
      "Episode average V value: 0.5322623882028792\n",
      "Average (on the epoch) training loss: 0.004478726942635262\n",
      "Episode average V value: 0.39966370537877083\n",
      "Average (on the epoch) training loss: 0.0044828366674539545\n",
      "Episode average V value: 0.8964935143788656\n",
      "Average (on the epoch) training loss: 0.004476201204581928\n",
      "Episode average V value: 0.5269583761692047\n",
      "Average (on the epoch) training loss: 0.004463728361841967\n",
      "Episode average V value: 0.6496961968285697\n",
      "Average (on the epoch) training loss: 0.00447302403633852\n",
      "Episode average V value: 0.6198857043470655\n",
      "Average (on the epoch) training loss: 0.004474633739354093\n",
      "Episode average V value: 0.9913949966430664\n",
      "Average (on the epoch) training loss: 0.004479069674040524\n",
      "Episode average V value: 0.9454648494720459\n",
      "Average (on the epoch) training loss: 0.004472253332294897\n",
      "Episode average V value: 0.5487622953951359\n",
      "Average (on the epoch) training loss: 0.0044721027394936655\n",
      "Episode average V value: 0.9284931719303131\n",
      "Average (on the epoch) training loss: 0.004489952961357379\n",
      "Episode average V value: 0.49177948385477066\n",
      "Average (on the epoch) training loss: 0.004477395277182736\n",
      "Episode average V value: 0.3546333722770214\n",
      "Average (on the epoch) training loss: 0.004474330324769062\n",
      "Episode average V value: 0.464866578578949\n",
      "Average (on the epoch) training loss: 0.004469490865733048\n",
      "Episode average V value: 0.5950304908411843\n",
      "Average (on the epoch) training loss: 0.004468386586461685\n",
      "Episode average V value: 0.5721583962440491\n",
      "Average (on the epoch) training loss: 0.004469749485895426\n",
      "Episode average V value: 0.6997867325941721\n",
      "Average (on the epoch) training loss: 0.004470503601643987\n",
      "Episode average V value: 0.8413422405719757\n",
      "Average (on the epoch) training loss: 0.004473635710933618\n",
      "Episode average V value: 0.7133824910436358\n",
      "Average (on the epoch) training loss: 0.0044699794974052956\n",
      "Episode average V value: 0.5194856785237789\n",
      "Average (on the epoch) training loss: 0.004470805394891146\n",
      "Episode average V value: 0.696034163236618\n",
      "Average (on the epoch) training loss: 0.00446871203941203\n",
      "Episode average V value: 0.735036987066269\n",
      "Average (on the epoch) training loss: 0.0044605166031091575\n",
      "Episode average V value: 0.5519903227686882\n",
      "Average (on the epoch) training loss: 0.0044683855346419905\n",
      "Episode average V value: 0.4797341227531433\n",
      "Average (on the epoch) training loss: 0.004473978683545226\n",
      "Episode average V value: 0.575393307954073\n",
      "Average (on the epoch) training loss: 0.004471963337127971\n",
      "Episode average V value: 0.6982949078083038\n",
      "Average (on the epoch) training loss: 0.0044676848309278755\n",
      "Episode average V value: 0.643559068441391\n",
      "Average (on the epoch) training loss: 0.004461708527338929\n",
      "Episode average V value: 0.944220095872879\n",
      "Average (on the epoch) training loss: 0.004454788413402118\n",
      "Episode average V value: 0.541267566382885\n",
      "Average (on the epoch) training loss: 0.004451814995233699\n",
      "Episode average V value: 0.5552228142817816\n",
      "Average (on the epoch) training loss: 0.004459621195893665\n",
      "Episode average V value: 0.7065785005688667\n",
      "Average (on the epoch) training loss: 0.004463060229068245\n",
      "Episode average V value: 0.6696370045344034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004470082730171624\n",
      "Episode average V value: 0.5257992094213312\n",
      "Average (on the epoch) training loss: 0.004465906498655079\n",
      "Episode average V value: 0.6021359041333199\n",
      "LOSSES\n",
      "T = 0.015726023047231138; R = 0.024170329228974878;                 Gamma = 0.5235414222478867; Q = 0.004334788489621133;\n",
      "Entropy Neighbor = 0.5448691015839576;                 Entropy Random = 0.17002345256507398;                 Volume = 0.14776688699424267; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004467196370009333\n",
      "Episode average V value: 0.6149815320968628\n",
      "epoch 26:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.8888888888888888 (average over 9 episode(s))\n",
      "== Mean score per episode is 0.8888790124554172 over 9 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2072,  0.1245,  0.2477, -0.5590, -0.7201], device='cuda:0') tensor([ 0.2729,  0.2124,  0.2681, -0.5496, -0.7339], device='cuda:0') tensor([ 0.2072,  0.1245,  0.2477, -0.5590, -0.7201], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0023], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004355514202163451\n",
      "Episode average V value: 0.5848123654723167\n",
      "Average (on the epoch) training loss: 0.003922320967831183\n",
      "Episode average V value: 0.5739928952285221\n",
      "Average (on the epoch) training loss: 0.0038192478148266675\n",
      "Episode average V value: 0.5683301587899526\n",
      "Average (on the epoch) training loss: 0.004216505692173273\n",
      "Episode average V value: 0.559554894055639\n",
      "Average (on the epoch) training loss: 0.004312400994378896\n",
      "Episode average V value: 0.45451660950978595\n",
      "Average (on the epoch) training loss: 0.004160018815823337\n",
      "Episode average V value: 0.5714313499629498\n",
      "Average (on the epoch) training loss: 0.004181320352169375\n",
      "Episode average V value: 0.4548659026622772\n",
      "Average (on the epoch) training loss: 0.004166073952640952\n",
      "Episode average V value: 0.6366704404354095\n",
      "Average (on the epoch) training loss: 0.004106272439487645\n",
      "Episode average V value: 0.6016116142272949\n",
      "Average (on the epoch) training loss: 0.004247445061516303\n",
      "Episode average V value: 0.715153843164444\n",
      "Average (on the epoch) training loss: 0.004397286122907208\n",
      "Episode average V value: 0.5970461443066597\n",
      "Average (on the epoch) training loss: 0.004479582900928922\n",
      "Episode average V value: 0.901833732922872\n",
      "Average (on the epoch) training loss: 0.004505396471358836\n",
      "Episode average V value: 0.7364137530326843\n",
      "Average (on the epoch) training loss: 0.004624639844438166\n",
      "Episode average V value: 0.7520249287287394\n",
      "Average (on the epoch) training loss: 0.004646005799376064\n",
      "Episode average V value: 0.5732417603333791\n",
      "Average (on the epoch) training loss: 0.004616076133970637\n",
      "Episode average V value: 0.5943287556821649\n",
      "Average (on the epoch) training loss: 0.004602329512412676\n",
      "Episode average V value: 0.7053385376930237\n",
      "Average (on the epoch) training loss: 0.004531922387347246\n",
      "Episode average V value: 0.7814924716949463\n",
      "Average (on the epoch) training loss: 0.00447981820996994\n",
      "Episode average V value: 0.5491209268569947\n",
      "Average (on the epoch) training loss: 0.004444248354008054\n",
      "Episode average V value: 0.5196023413113185\n",
      "Average (on the epoch) training loss: 0.004462410585055578\n",
      "Episode average V value: 0.5501148328185081\n",
      "Average (on the epoch) training loss: 0.004440257011295913\n",
      "Episode average V value: 0.5860379238923391\n",
      "Average (on the epoch) training loss: 0.004445086731605089\n",
      "Episode average V value: 0.31048502524693805\n",
      "Average (on the epoch) training loss: 0.004438760724284132\n",
      "Episode average V value: 0.795782208442688\n",
      "Average (on the epoch) training loss: 0.004491298739438408\n",
      "Episode average V value: 0.6105119287967682\n",
      "Average (on the epoch) training loss: 0.004541774723856222\n",
      "Episode average V value: 0.7249013930559158\n",
      "Average (on the epoch) training loss: 0.00453907084119107\n",
      "Episode average V value: 0.5100895961125692\n",
      "Average (on the epoch) training loss: 0.004530893997132276\n",
      "Episode average V value: 0.8995840748151144\n",
      "Average (on the epoch) training loss: 0.004605112983927488\n",
      "Episode average V value: 0.3791191609282243\n",
      "Average (on the epoch) training loss: 0.004591444301028179\n",
      "Episode average V value: 0.7969808578491211\n",
      "Average (on the epoch) training loss: 0.0045871432578727936\n",
      "Episode average V value: 0.9469848573207855\n",
      "Average (on the epoch) training loss: 0.0045855335727257905\n",
      "Episode average V value: 0.7798465967178345\n",
      "Average (on the epoch) training loss: 0.004600336236762814\n",
      "Episode average V value: 0.7750386794408163\n",
      "Average (on the epoch) training loss: 0.004602900294320624\n",
      "Episode average V value: 0.6514346063137054\n",
      "Average (on the epoch) training loss: 0.004591868109573439\n",
      "Episode average V value: 0.3805202841758728\n",
      "Average (on the epoch) training loss: 0.00458333603387473\n",
      "Episode average V value: 0.46010751128196714\n",
      "Average (on the epoch) training loss: 0.004621815085028945\n",
      "Episode average V value: 0.4729001422723134\n",
      "Average (on the epoch) training loss: 0.004620713174220202\n",
      "Episode average V value: 0.7175421246460506\n",
      "Average (on the epoch) training loss: 0.004610341826271293\n",
      "Episode average V value: 0.7126177474856377\n",
      "Average (on the epoch) training loss: 0.0046008702872718694\n",
      "Episode average V value: 0.7972509860992432\n",
      "Average (on the epoch) training loss: 0.004567191657880354\n",
      "Episode average V value: 0.6965659976005554\n",
      "Average (on the epoch) training loss: 0.004555280007938105\n",
      "Episode average V value: 0.5729278862476349\n",
      "Average (on the epoch) training loss: 0.004579563581113083\n",
      "Episode average V value: 0.4700537345239094\n",
      "Average (on the epoch) training loss: 0.00455167773198732\n",
      "Episode average V value: 0.779093062877655\n",
      "Average (on the epoch) training loss: 0.004553100672319929\n",
      "Episode average V value: 0.5994272232055664\n",
      "Average (on the epoch) training loss: 0.004600638488178163\n",
      "Episode average V value: 0.8297127038240433\n",
      "Average (on the epoch) training loss: 0.004588615972271684\n",
      "Episode average V value: 0.6771055658658346\n",
      "Average (on the epoch) training loss: 0.00459383044210149\n",
      "Episode average V value: 0.47772880146900815\n",
      "Average (on the epoch) training loss: 0.00458502654588508\n",
      "Episode average V value: 0.527233362197876\n",
      "Average (on the epoch) training loss: 0.004590422286474634\n",
      "Episode average V value: 0.4683215022087097\n",
      "Average (on the epoch) training loss: 0.004570854630228946\n",
      "Episode average V value: 0.6560945063829422\n",
      "Average (on the epoch) training loss: 0.004549633189552713\n",
      "Episode average V value: 0.7153388932347298\n",
      "Average (on the epoch) training loss: 0.004527952551804695\n",
      "Episode average V value: 0.5747913002967835\n",
      "Average (on the epoch) training loss: 0.004496952042103272\n",
      "Episode average V value: 0.6806453913450241\n",
      "Average (on the epoch) training loss: 0.00447443257587071\n",
      "Episode average V value: 0.512287312746048\n",
      "Average (on the epoch) training loss: 0.00451260506070591\n",
      "Episode average V value: 0.7118062451481819\n",
      "Average (on the epoch) training loss: 0.0045019001971722756\n",
      "Episode average V value: 0.34958548843860626\n",
      "Average (on the epoch) training loss: 0.0045077150895897495\n",
      "Episode average V value: 0.898478627204895\n",
      "Average (on the epoch) training loss: 0.004519009775928377\n",
      "Episode average V value: 0.4970090687274933\n",
      "Average (on the epoch) training loss: 0.0044989115839876755\n",
      "Episode average V value: 0.4970362186431885\n",
      "Average (on the epoch) training loss: 0.004470991830413158\n",
      "Episode average V value: 0.41112840601376127\n",
      "Average (on the epoch) training loss: 0.004461440549323415\n",
      "Episode average V value: 0.507468581199646\n",
      "Average (on the epoch) training loss: 0.0044526655277034735\n",
      "Episode average V value: 0.719675624370575\n",
      "Average (on the epoch) training loss: 0.004467283170691779\n",
      "Episode average V value: 0.5103074580430984\n",
      "Average (on the epoch) training loss: 0.00446240781640701\n",
      "Episode average V value: 0.4406057162718339\n",
      "Average (on the epoch) training loss: 0.004474892883915373\n",
      "Episode average V value: 0.3375935362918036\n",
      "Average (on the epoch) training loss: 0.004480519984116901\n",
      "Episode average V value: 0.5616977976428138\n",
      "Average (on the epoch) training loss: 0.004474558203262003\n",
      "Episode average V value: 0.5978886352645026\n",
      "Average (on the epoch) training loss: 0.00447907124541138\n",
      "Episode average V value: 0.5339813753962517\n",
      "Average (on the epoch) training loss: 0.004468010343056971\n",
      "Episode average V value: 0.5320302993059158\n",
      "Average (on the epoch) training loss: 0.00447078240141573\n",
      "Episode average V value: 0.7031301259994507\n",
      "LOSSES\n",
      "T = 0.01616411710996181; R = 0.025890224829781802;                 Gamma = 0.5221379105448722; Q = 0.004467680848669261;\n",
      "Entropy Neighbor = 0.5398322266340255;                 Entropy Random = 0.16597069035470485;                 Volume = 0.16205401978641748; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0638, -1.0967, -0.1090, -0.9239, -1.1114], device='cuda:0') tensor([-0.8899, -0.9572, -0.0521, -0.9424, -1.1047], device='cuda:0') tensor([-0.5307, -0.5868,  0.0332, -0.7593, -0.9280], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1546], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004459557301800934\n",
      "Episode average V value: 0.5799965113401413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004492691666970808\n",
      "Episode average V value: 0.4200086858537462\n",
      "Average (on the epoch) training loss: 0.004505173283526621\n",
      "Episode average V value: 0.5324952602386475\n",
      "Average (on the epoch) training loss: 0.004504962793660851\n",
      "Episode average V value: 0.455379135078854\n",
      "Average (on the epoch) training loss: 0.004483975658039434\n",
      "Episode average V value: 0.580908477306366\n",
      "Average (on the epoch) training loss: 0.004485328327504921\n",
      "Episode average V value: 0.5417988349994024\n",
      "Average (on the epoch) training loss: 0.0045186779884941845\n",
      "Episode average V value: 0.6846124189240592\n",
      "Average (on the epoch) training loss: 0.004518943692902926\n",
      "Episode average V value: 0.4639157148507925\n",
      "Average (on the epoch) training loss: 0.004537199886762497\n",
      "Episode average V value: 0.5388965507348379\n",
      "Average (on the epoch) training loss: 0.004541593607149841\n",
      "Episode average V value: 0.8560185730457306\n",
      "Average (on the epoch) training loss: 0.00453748751227632\n",
      "Episode average V value: 0.929945170879364\n",
      "Average (on the epoch) training loss: 0.004538688529516418\n",
      "Episode average V value: 0.6175412791115897\n",
      "Average (on the epoch) training loss: 0.004545268101536185\n",
      "Episode average V value: 0.49161936780985666\n",
      "Average (on the epoch) training loss: 0.004540692701159415\n",
      "Episode average V value: 0.8821165561676025\n",
      "Average (on the epoch) training loss: 0.004523517861444917\n",
      "Episode average V value: 0.47689046642997046\n",
      "Average (on the epoch) training loss: 0.004530240259667355\n",
      "Episode average V value: 0.8965127865473429\n",
      "Average (on the epoch) training loss: 0.004517626397177664\n",
      "Episode average V value: 0.3667885586619377\n",
      "Average (on the epoch) training loss: 0.004534935680524862\n",
      "Episode average V value: 0.7158870100975037\n",
      "Average (on the epoch) training loss: 0.004530865487584296\n",
      "Episode average V value: 0.4420453888528487\n",
      "Average (on the epoch) training loss: 0.004516514554339741\n",
      "Episode average V value: 0.5004077309911902\n",
      "Average (on the epoch) training loss: 0.004527181817588376\n",
      "Episode average V value: 0.43728521237006557\n",
      "Average (on the epoch) training loss: 0.004509655899250559\n",
      "Episode average V value: 0.4465639054775238\n",
      "Average (on the epoch) training loss: 0.0045088792189836024\n",
      "Episode average V value: 0.8779037992159525\n",
      "Average (on the epoch) training loss: 0.004510110305750339\n",
      "Episode average V value: 0.6396878494156731\n",
      "Average (on the epoch) training loss: 0.004499278493580948\n",
      "Episode average V value: 0.8445235788822174\n",
      "Average (on the epoch) training loss: 0.004498769700532036\n",
      "Episode average V value: 0.5956861045625474\n",
      "Average (on the epoch) training loss: 0.004488935230837501\n",
      "Episode average V value: 0.5189958612124125\n",
      "Average (on the epoch) training loss: 0.004496902683523225\n",
      "Episode average V value: 0.743550980091095\n",
      "Average (on the epoch) training loss: 0.0045053638437774724\n",
      "Episode average V value: 0.31546132266521454\n",
      "Average (on the epoch) training loss: 0.0045042895950653805\n",
      "Episode average V value: 0.574807845056057\n",
      "Average (on the epoch) training loss: 0.004496764456141358\n",
      "Episode average V value: 0.8065246939659119\n",
      "Average (on the epoch) training loss: 0.004488953812661008\n",
      "Episode average V value: 0.48752603360584806\n",
      "Average (on the epoch) training loss: 0.004489718099171929\n",
      "Episode average V value: 0.7090762183070183\n",
      "Average (on the epoch) training loss: 0.00449855715267791\n",
      "Episode average V value: 0.8050062209367752\n",
      "Average (on the epoch) training loss: 0.004494565772178699\n",
      "Episode average V value: 0.9938326478004456\n",
      "Average (on the epoch) training loss: 0.0044920339621490465\n",
      "Episode average V value: 0.5192515055338541\n",
      "Average (on the epoch) training loss: 0.0045039150533461554\n",
      "Episode average V value: 0.5401932380416177\n",
      "Average (on the epoch) training loss: 0.004497603242634795\n",
      "Episode average V value: 0.4971071481704712\n",
      "Average (on the epoch) training loss: 0.004491034302521835\n",
      "Episode average V value: 0.6145515271595546\n",
      "Average (on the epoch) training loss: 0.004484721941221286\n",
      "Episode average V value: 0.9405185878276825\n",
      "Average (on the epoch) training loss: 0.004487819193211542\n",
      "Episode average V value: 0.7446136325597763\n",
      "Average (on the epoch) training loss: 0.004492862738549808\n",
      "Episode average V value: 0.39881472786267597\n",
      "Average (on the epoch) training loss: 0.004500056588527179\n",
      "Episode average V value: 0.6762895087401072\n",
      "Average (on the epoch) training loss: 0.004498231920207246\n",
      "Episode average V value: 0.7915129661560059\n",
      "Average (on the epoch) training loss: 0.004495454680595649\n",
      "Episode average V value: 0.7114563584327698\n",
      "Average (on the epoch) training loss: 0.004483695208900011\n",
      "Episode average V value: 0.8465910404920578\n",
      "Average (on the epoch) training loss: 0.004478971267912146\n",
      "Episode average V value: 0.6697440505027771\n",
      "Average (on the epoch) training loss: 0.0044789107990524\n",
      "Episode average V value: 0.5087254775895013\n",
      "Average (on the epoch) training loss: 0.0044863380210191945\n",
      "Episode average V value: 0.6764487822850546\n",
      "Average (on the epoch) training loss: 0.00449636787470708\n",
      "Episode average V value: 0.8949785629908243\n",
      "Average (on the epoch) training loss: 0.0045119319452194195\n",
      "Episode average V value: 0.39737125113606453\n",
      "Average (on the epoch) training loss: 0.004506447139694659\n",
      "Episode average V value: 0.7065145713942391\n",
      "Average (on the epoch) training loss: 0.0045087672301461134\n",
      "Episode average V value: 0.8966751098632812\n",
      "Average (on the epoch) training loss: 0.004505992344426033\n",
      "Episode average V value: 0.3974102543933051\n",
      "Average (on the epoch) training loss: 0.004496755364915188\n",
      "Episode average V value: 0.580984577536583\n",
      "Average (on the epoch) training loss: 0.004513685993642355\n",
      "Episode average V value: 0.4068911522626877\n",
      "Average (on the epoch) training loss: 0.004508407003172874\n",
      "Episode average V value: 0.46601219177246095\n",
      "Average (on the epoch) training loss: 0.004511268204137778\n",
      "Episode average V value: 0.812036857008934\n",
      "Average (on the epoch) training loss: 0.0045093920831038945\n",
      "Episode average V value: 0.47810643911361694\n",
      "Average (on the epoch) training loss: 0.004509530851234727\n",
      "Episode average V value: 0.47762054204940796\n",
      "LOSSES\n",
      "T = 0.016234659767709672; R = 0.025462055605836212;                 Gamma = 0.5229769828915596; Q = 0.004523732097237371;\n",
      "Entropy Neighbor = 0.5380575995445251;                 Entropy Random = 0.16787745825946332;                 Volume = 0.1595056394264102; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004495706472953316\n",
      "Episode average V value: 0.3312680008618728\n",
      "epoch 27:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.75 (average over 4 episode(s))\n",
      "== Mean score per episode is 0.7499812504687383 over 4 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4677, -0.5077,  0.0802, -0.8017, -1.0264], device='cuda:0') tensor([-0.4901, -0.5162,  0.0770, -0.7840, -1.0258], device='cuda:0') tensor([-0.4677, -0.5077,  0.0802, -0.8017, -1.0264], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0142], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0039622562989178635\n",
      "Episode average V value: 0.6199928753905826\n",
      "Average (on the epoch) training loss: 0.0040024315676419064\n",
      "Episode average V value: 0.7461385031541189\n",
      "Average (on the epoch) training loss: 0.003552817294673462\n",
      "Episode average V value: 0.5438395023345948\n",
      "Average (on the epoch) training loss: 0.003572508759680204\n",
      "Episode average V value: 0.4708751017848651\n",
      "Average (on the epoch) training loss: 0.0036670816019371464\n",
      "Episode average V value: 0.6011553960187095\n",
      "Average (on the epoch) training loss: 0.0037932532673733213\n",
      "Episode average V value: 0.5417440295219421\n",
      "Average (on the epoch) training loss: 0.0037789946923462246\n",
      "Episode average V value: 0.7170417904853821\n",
      "Average (on the epoch) training loss: 0.0038345577727471078\n",
      "Episode average V value: 0.8141867876052856\n",
      "Average (on the epoch) training loss: 0.004090448103651598\n",
      "Episode average V value: 0.6939525902271271\n",
      "Average (on the epoch) training loss: 0.004081197927007452\n",
      "Episode average V value: 0.9037904342015585\n",
      "Average (on the epoch) training loss: 0.0041176759363973844\n",
      "Episode average V value: 0.7277888834476471\n",
      "Average (on the epoch) training loss: 0.004120424567049162\n",
      "Episode average V value: 0.7489444017410278\n",
      "Average (on the epoch) training loss: 0.004209901699921049\n",
      "Episode average V value: 0.3737436703273228\n",
      "Average (on the epoch) training loss: 0.004193247697802017\n",
      "Episode average V value: 0.626318633556366\n",
      "Average (on the epoch) training loss: 0.004165783840361372\n",
      "Episode average V value: 0.7078286835125515\n",
      "Average (on the epoch) training loss: 0.0041134240642908635\n",
      "Episode average V value: 0.745291405916214\n",
      "Average (on the epoch) training loss: 0.004068601147598351\n",
      "Episode average V value: 0.7174362540245056\n",
      "Average (on the epoch) training loss: 0.004097766867258318\n",
      "Episode average V value: 0.5273856123288473\n",
      "Average (on the epoch) training loss: 0.004027701628154083\n",
      "Episode average V value: 0.6027061972353194\n",
      "Average (on the epoch) training loss: 0.004013965663034469\n",
      "Episode average V value: 0.6896605747086662\n",
      "Average (on the epoch) training loss: 0.004003765728046391\n",
      "Episode average V value: 0.929396003484726\n",
      "Average (on the epoch) training loss: 0.003990825532677736\n",
      "Episode average V value: 0.3942323877261235\n",
      "Average (on the epoch) training loss: 0.003994377248261885\n",
      "Episode average V value: 0.45984548330307007\n",
      "Average (on the epoch) training loss: 0.004042242021124037\n",
      "Episode average V value: 0.683353011806806\n",
      "Average (on the epoch) training loss: 0.004055670613582295\n",
      "Episode average V value: 0.9435597062110901\n",
      "Average (on the epoch) training loss: 0.0041215052264026155\n",
      "Episode average V value: 0.5194888710975647\n",
      "Average (on the epoch) training loss: 0.004079894703958851\n",
      "Episode average V value: 0.6820242702960968\n",
      "Average (on the epoch) training loss: 0.004138684924073283\n",
      "Episode average V value: 0.8174695372581482\n",
      "Average (on the epoch) training loss: 0.004094850147209529\n",
      "Episode average V value: 0.5694542460971408\n",
      "Average (on the epoch) training loss: 0.0041070309796163605\n",
      "Episode average V value: 0.5509699694812298\n",
      "Average (on the epoch) training loss: 0.0040940097309869776\n",
      "Episode average V value: 0.628067889383861\n",
      "Average (on the epoch) training loss: 0.004076355615500205\n",
      "Episode average V value: 0.6418729296752385\n",
      "Average (on the epoch) training loss: 0.004072210153147656\n",
      "Episode average V value: 0.9920367002487183\n",
      "Average (on the epoch) training loss: 0.0040942354878349095\n",
      "Episode average V value: 0.4510915384573095\n",
      "Average (on the epoch) training loss: 0.004090660303734454\n",
      "Episode average V value: 0.6321174630096981\n",
      "Average (on the epoch) training loss: 0.004185162822042393\n",
      "Episode average V value: 0.4620714783668518\n",
      "Average (on the epoch) training loss: 0.0041799883515732\n",
      "Episode average V value: 0.8785785039265951\n",
      "Average (on the epoch) training loss: 0.004175385221545276\n",
      "Episode average V value: 0.36730317026376724\n",
      "Average (on the epoch) training loss: 0.004152624628470047\n",
      "Episode average V value: 0.6576384504636129\n",
      "Average (on the epoch) training loss: 0.004141305155247788\n",
      "Episode average V value: 0.8494026213884354\n",
      "Average (on the epoch) training loss: 0.004106821266229616\n",
      "Episode average V value: 0.8436473608016968\n",
      "Average (on the epoch) training loss: 0.004116803198008463\n",
      "Episode average V value: 0.713885383946555\n",
      "Average (on the epoch) training loss: 0.00413878526934053\n",
      "Episode average V value: 0.6786753386259079\n",
      "Average (on the epoch) training loss: 0.004134205520499007\n",
      "Episode average V value: 0.4627978205680847\n",
      "Average (on the epoch) training loss: 0.004167574321589735\n",
      "Episode average V value: 0.6314050810677665\n",
      "Average (on the epoch) training loss: 0.004165984397090609\n",
      "Episode average V value: 0.387207289536794\n",
      "Average (on the epoch) training loss: 0.004162438712820552\n",
      "Episode average V value: 0.5121782779693603\n",
      "Average (on the epoch) training loss: 0.004170373202068731\n",
      "Episode average V value: 0.5816035687923431\n",
      "Average (on the epoch) training loss: 0.004240431458314943\n",
      "Episode average V value: 0.4440864622592926\n",
      "Average (on the epoch) training loss: 0.004240255449399081\n",
      "Episode average V value: 0.6056134760379791\n",
      "Average (on the epoch) training loss: 0.004244310867817452\n",
      "Episode average V value: 0.6834196845690409\n",
      "Average (on the epoch) training loss: 0.00422159367143852\n",
      "Episode average V value: 0.4224888357249173\n",
      "Average (on the epoch) training loss: 0.004213142599892859\n",
      "Episode average V value: 0.559803718328476\n",
      "Average (on the epoch) training loss: 0.004215650012814382\n",
      "Episode average V value: 0.43888205620977616\n",
      "Average (on the epoch) training loss: 0.004229623289619794\n",
      "Episode average V value: 0.47406764328479767\n",
      "Average (on the epoch) training loss: 0.004228763313576894\n",
      "Episode average V value: 0.5905733965337276\n",
      "Average (on the epoch) training loss: 0.004221733522012928\n",
      "Episode average V value: 0.9286061525344849\n",
      "Average (on the epoch) training loss: 0.004261611302644496\n",
      "Episode average V value: 0.4881959623760647\n",
      "Average (on the epoch) training loss: 0.004247754916366138\n",
      "Episode average V value: 0.43599097728729247\n",
      "Average (on the epoch) training loss: 0.004245482400279149\n",
      "Episode average V value: 0.6291553527116776\n",
      "Average (on the epoch) training loss: 0.0042461755189420235\n",
      "Episode average V value: 0.7809579014778137\n",
      "Average (on the epoch) training loss: 0.004234401267027139\n",
      "Episode average V value: 0.5955969542264938\n",
      "Average (on the epoch) training loss: 0.004232902231706248\n",
      "Episode average V value: 0.6184587081273397\n",
      "Average (on the epoch) training loss: 0.00422601303567685\n",
      "Episode average V value: 0.5366543978452682\n",
      "Average (on the epoch) training loss: 0.004216807766977738\n",
      "Episode average V value: 0.5210839509963989\n",
      "Average (on the epoch) training loss: 0.004203744517416786\n",
      "Episode average V value: 0.6831481792032719\n",
      "Average (on the epoch) training loss: 0.004194407352527681\n",
      "Episode average V value: 0.5363959159169879\n",
      "Average (on the epoch) training loss: 0.0041909034863954675\n",
      "Episode average V value: 0.8073771595954895\n",
      "Average (on the epoch) training loss: 0.004168332342714147\n",
      "Episode average V value: 0.6016738348537021\n",
      "LOSSES\n",
      "T = 0.01592115236725658; R = 0.025799737721215934;                 Gamma = 0.5220009039640426; Q = 0.004161985805258155;\n",
      "Entropy Neighbor = 0.5353779786229134;                 Entropy Random = 0.1665426136702299;                 Volume = 0.1667903582006693; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1749,  0.1059,  0.2419, -0.5913, -0.7867], device='cuda:0') tensor([ 0.1854,  0.0961,  0.2412, -0.5901, -0.7921], device='cuda:0') tensor([ 0.1749,  0.1059,  0.2419, -0.5913, -0.7867], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0040], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004176691289531045\n",
      "Episode average V value: 0.44371497631073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004159078219835781\n",
      "Episode average V value: 0.4506906255295402\n",
      "Average (on the epoch) training loss: 0.004161961398176139\n",
      "Episode average V value: 0.4583597183227539\n",
      "Average (on the epoch) training loss: 0.004179081657864713\n",
      "Episode average V value: 0.5335779711604118\n",
      "Average (on the epoch) training loss: 0.004191210273622051\n",
      "Episode average V value: 0.8452824354171753\n",
      "Average (on the epoch) training loss: 0.004184828400339461\n",
      "Episode average V value: 0.6154472440481186\n",
      "Average (on the epoch) training loss: 0.004191113335976654\n",
      "Episode average V value: 0.6068345189094544\n",
      "Average (on the epoch) training loss: 0.004190585721053381\n",
      "Episode average V value: 0.5108291208744049\n",
      "Average (on the epoch) training loss: 0.004183703336633103\n",
      "Episode average V value: 0.5313250422477722\n",
      "Average (on the epoch) training loss: 0.004184487302829279\n",
      "Episode average V value: 0.3489296048879623\n",
      "Average (on the epoch) training loss: 0.004198983867770927\n",
      "Episode average V value: 0.9431182742118835\n",
      "Average (on the epoch) training loss: 0.004203145515165781\n",
      "Episode average V value: 0.6831728667020798\n",
      "Average (on the epoch) training loss: 0.0042057214220531085\n",
      "Episode average V value: 0.892371416091919\n",
      "Average (on the epoch) training loss: 0.004199569550933264\n",
      "Episode average V value: 0.4946110759462629\n",
      "Average (on the epoch) training loss: 0.00419726389698869\n",
      "Episode average V value: 0.8479926884174347\n",
      "Average (on the epoch) training loss: 0.004194257245095695\n",
      "Episode average V value: 0.40872664252916974\n",
      "Average (on the epoch) training loss: 0.004169982501897356\n",
      "Episode average V value: 0.4461833472762789\n",
      "Average (on the epoch) training loss: 0.00419445320452288\n",
      "Episode average V value: 0.5216045677661896\n",
      "Average (on the epoch) training loss: 0.004191370735351492\n",
      "Episode average V value: 0.5769744455814362\n",
      "Average (on the epoch) training loss: 0.004188507140542452\n",
      "Episode average V value: 0.8514201641082764\n",
      "Average (on the epoch) training loss: 0.0041902489729866545\n",
      "Episode average V value: 0.4820389747619629\n",
      "Average (on the epoch) training loss: 0.004202129106971468\n",
      "Episode average V value: 0.5631282542433057\n",
      "Average (on the epoch) training loss: 0.004205709813216144\n",
      "Episode average V value: 0.4617728392283122\n",
      "Average (on the epoch) training loss: 0.00419900327381727\n",
      "Episode average V value: 0.8931896090507507\n",
      "Average (on the epoch) training loss: 0.004214438080935665\n",
      "Episode average V value: 0.9453967213630676\n",
      "Average (on the epoch) training loss: 0.004217137236798392\n",
      "Episode average V value: 0.5546400414572822\n",
      "Average (on the epoch) training loss: 0.00421973621365573\n",
      "Episode average V value: 0.7189361453056335\n",
      "Average (on the epoch) training loss: 0.004219569631670818\n",
      "Episode average V value: 0.5040190257132053\n",
      "Average (on the epoch) training loss: 0.0042353290014086695\n",
      "Episode average V value: 0.5517831817269325\n",
      "Average (on the epoch) training loss: 0.004246076981706376\n",
      "Episode average V value: 0.6418718014444623\n",
      "Average (on the epoch) training loss: 0.004254820212524033\n",
      "Episode average V value: 0.6335052592413766\n",
      "Average (on the epoch) training loss: 0.004250870379079497\n",
      "Episode average V value: 0.8331506699323654\n",
      "Average (on the epoch) training loss: 0.004244968575075393\n",
      "Episode average V value: 0.7470004498958588\n",
      "Average (on the epoch) training loss: 0.004242527529533053\n",
      "Episode average V value: 0.8489027172327042\n",
      "Average (on the epoch) training loss: 0.004246942449969296\n",
      "Episode average V value: 0.6098237676279885\n",
      "Average (on the epoch) training loss: 0.0042482836712303615\n",
      "Episode average V value: 0.9969587326049805\n",
      "Average (on the epoch) training loss: 0.004245031288703992\n",
      "Episode average V value: 0.8880321979522705\n",
      "Average (on the epoch) training loss: 0.004267420740679197\n",
      "Episode average V value: 0.4608912567297618\n",
      "Average (on the epoch) training loss: 0.004295644053375188\n",
      "Episode average V value: 0.44577968716621397\n",
      "Average (on the epoch) training loss: 0.0042839849538865256\n",
      "Episode average V value: 0.49930195916782727\n",
      "Average (on the epoch) training loss: 0.004280164677065995\n",
      "Episode average V value: 0.5902369022369385\n",
      "Average (on the epoch) training loss: 0.004277090367621333\n",
      "Episode average V value: 0.8470802158117294\n",
      "Average (on the epoch) training loss: 0.004285587143460217\n",
      "Episode average V value: 0.6490928158164024\n",
      "Average (on the epoch) training loss: 0.004309691597671163\n",
      "Episode average V value: 0.5729396397417242\n",
      "Average (on the epoch) training loss: 0.004297924267643309\n",
      "Episode average V value: 0.6702584822972616\n",
      "Average (on the epoch) training loss: 0.004303242537031988\n",
      "Episode average V value: 0.7244303598999977\n",
      "Average (on the epoch) training loss: 0.00430463634390982\n",
      "Episode average V value: 0.5160487161742316\n",
      "Average (on the epoch) training loss: 0.004307872092170638\n",
      "Episode average V value: 0.6117212772369385\n",
      "Average (on the epoch) training loss: 0.0043330813379972985\n",
      "Episode average V value: 0.5062551021575927\n",
      "Average (on the epoch) training loss: 0.004331061574136556\n",
      "Episode average V value: 0.47460073232650757\n",
      "Average (on the epoch) training loss: 0.004331606603269735\n",
      "Episode average V value: 0.5972893039385477\n",
      "Average (on the epoch) training loss: 0.004327811823222589\n",
      "Episode average V value: 0.9401284754276276\n",
      "Average (on the epoch) training loss: 0.004323263657669207\n",
      "Episode average V value: 0.581661110574549\n",
      "Average (on the epoch) training loss: 0.004333006639040653\n",
      "Episode average V value: 0.38213281167878044\n",
      "Average (on the epoch) training loss: 0.004333475422500014\n",
      "Episode average V value: 0.8067999720573426\n",
      "Average (on the epoch) training loss: 0.004336802920944796\n",
      "Episode average V value: 0.4534379566709201\n",
      "Average (on the epoch) training loss: 0.004336042218768786\n",
      "Episode average V value: 0.40110717217127484\n",
      "Average (on the epoch) training loss: 0.004336107934012071\n",
      "Episode average V value: 0.7352336645126343\n",
      "Average (on the epoch) training loss: 0.0043357265575202095\n",
      "Episode average V value: 0.6583674550056458\n",
      "Average (on the epoch) training loss: 0.004341141979465272\n",
      "Episode average V value: 0.9899718761444092\n",
      "Average (on the epoch) training loss: 0.004361437186616968\n",
      "Episode average V value: 0.5493746454065497\n",
      "Average (on the epoch) training loss: 0.004363437532511667\n",
      "Episode average V value: 0.4921130873262882\n",
      "Average (on the epoch) training loss: 0.004361438153660472\n",
      "Episode average V value: 0.565430635213852\n",
      "Average (on the epoch) training loss: 0.0043646658809545135\n",
      "Episode average V value: 0.6025409797827402\n",
      "Average (on the epoch) training loss: 0.004354564264959462\n",
      "Episode average V value: 0.5309337708685133\n",
      "Average (on the epoch) training loss: 0.004355113780733992\n",
      "Episode average V value: 0.6715532541275024\n",
      "Average (on the epoch) training loss: 0.00435887145137345\n",
      "Episode average V value: 0.3619565178047527\n",
      "Average (on the epoch) training loss: 0.004371144243479265\n",
      "Episode average V value: 0.5351877182722091\n",
      "Average (on the epoch) training loss: 0.004377193039770317\n",
      "Episode average V value: 0.890155037244161\n",
      "Average (on the epoch) training loss: 0.004389085078612455\n",
      "Episode average V value: 0.680578758319219\n",
      "Average (on the epoch) training loss: 0.004386299676991394\n",
      "Episode average V value: 0.5902436934411526\n",
      "Average (on the epoch) training loss: 0.004388329122752293\n",
      "Episode average V value: 0.7113305628299713\n",
      "Average (on the epoch) training loss: 0.0044006062420137125\n",
      "Episode average V value: 0.4730124831199646\n",
      "Average (on the epoch) training loss: 0.004394990901930733\n",
      "Episode average V value: 0.4283030355970065\n",
      "Average (on the epoch) training loss: 0.004409632813178461\n",
      "Episode average V value: 0.8781105875968933\n",
      "LOSSES\n",
      "T = 0.01658084813784808; R = 0.02687379739037715;                 Gamma = 0.5205181273221969; Q = 0.004663443460711278;\n",
      "Entropy Neighbor = 0.5279954381585121;                 Entropy Random = 0.1631402573287487;                 Volume = 0.17219483072310687; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004412714632984717\n",
      "Episode average V value: 0.7890551090240479\n",
      "epoch 28:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9926470588235294 (average over 136 episode(s))\n",
      "== Mean score per episode is 0.9926463289365228 over 136 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1185, -0.1695,  0.1736, -0.7021, -0.9269], device='cuda:0') tensor([-0.1313, -0.1810,  0.1741, -0.6903, -0.9167], device='cuda:0') tensor([-0.1185, -0.1695,  0.1736, -0.7021, -0.9269], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0124], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.00554345125731613\n",
      "Episode average V value: 0.36794515592711313\n",
      "Average (on the epoch) training loss: 0.00507302741136621\n",
      "Episode average V value: 0.5132877469062805\n",
      "Average (on the epoch) training loss: 0.004472272431788345\n",
      "Episode average V value: 0.7960324883460999\n",
      "Average (on the epoch) training loss: 0.004453977506097046\n",
      "Episode average V value: 0.5535033742586771\n",
      "Average (on the epoch) training loss: 0.0044632105996380705\n",
      "Episode average V value: 0.4779309928417206\n",
      "Average (on the epoch) training loss: 0.0044263827663218215\n",
      "Episode average V value: 0.5420354902744293\n",
      "Average (on the epoch) training loss: 0.004112594777293373\n",
      "Episode average V value: 0.4704345097908607\n",
      "Average (on the epoch) training loss: 0.003992865797044942\n",
      "Episode average V value: 0.5092804517064776\n",
      "Average (on the epoch) training loss: 0.003895511322746604\n",
      "Episode average V value: 0.5138791160924094\n",
      "Average (on the epoch) training loss: 0.003927797205202903\n",
      "Episode average V value: 0.8123632669448853\n",
      "Average (on the epoch) training loss: 0.00408709382555813\n",
      "Episode average V value: 0.6134188217776162\n",
      "Average (on the epoch) training loss: 0.004134311105272817\n",
      "Episode average V value: 0.5316098862224155\n",
      "Average (on the epoch) training loss: 0.004170087337689965\n",
      "Episode average V value: 0.6918022504874638\n",
      "Average (on the epoch) training loss: 0.004110333755878466\n",
      "Episode average V value: 0.44628379940986634\n",
      "Average (on the epoch) training loss: 0.004076137407639316\n",
      "Episode average V value: 0.8894245028495789\n",
      "Average (on the epoch) training loss: 0.004052977347256322\n",
      "Episode average V value: 0.3308209826548894\n",
      "Average (on the epoch) training loss: 0.004058520194206737\n",
      "Episode average V value: 0.8103188276290894\n",
      "Average (on the epoch) training loss: 0.003967819551453848\n",
      "Episode average V value: 0.4487596062513498\n",
      "Average (on the epoch) training loss: 0.003990347617029868\n",
      "Episode average V value: 0.8495567589998245\n",
      "Average (on the epoch) training loss: 0.003995029770723906\n",
      "Episode average V value: 0.48980920182334053\n",
      "Average (on the epoch) training loss: 0.003999641971563958\n",
      "Episode average V value: 0.5104482918977737\n",
      "Average (on the epoch) training loss: 0.004015659137075999\n",
      "Episode average V value: 0.3961210449536641\n",
      "Average (on the epoch) training loss: 0.004022647201997676\n",
      "Episode average V value: 0.7390146106481552\n",
      "Average (on the epoch) training loss: 0.004023048204197991\n",
      "Episode average V value: 0.713991791009903\n",
      "Average (on the epoch) training loss: 0.0040843800840607986\n",
      "Episode average V value: 0.5170166224241257\n",
      "Average (on the epoch) training loss: 0.00407504149916349\n",
      "Episode average V value: 0.5475325021478865\n",
      "Average (on the epoch) training loss: 0.004048635107465088\n",
      "Episode average V value: 0.6350813210010529\n",
      "Average (on the epoch) training loss: 0.004054367401192121\n",
      "Episode average V value: 0.9441116154193878\n",
      "Average (on the epoch) training loss: 0.004070320470829404\n",
      "Episode average V value: 0.4077917422567095\n",
      "Average (on the epoch) training loss: 0.00402980130431324\n",
      "Episode average V value: 0.5473075211048126\n",
      "Average (on the epoch) training loss: 0.00401068313917874\n",
      "Episode average V value: 0.8886673450469971\n",
      "Average (on the epoch) training loss: 0.00402785850976138\n",
      "Episode average V value: 0.8077531814575195\n",
      "Average (on the epoch) training loss: 0.004046197167184219\n",
      "Episode average V value: 0.74709153175354\n",
      "Average (on the epoch) training loss: 0.0040452065991192325\n",
      "Episode average V value: 0.5322309732437134\n",
      "Average (on the epoch) training loss: 0.00402104657940028\n",
      "Episode average V value: 0.7937195797761282\n",
      "Average (on the epoch) training loss: 0.003999989883141097\n",
      "Episode average V value: 0.6041010235037122\n",
      "Average (on the epoch) training loss: 0.004060758814972804\n",
      "Episode average V value: 0.6889113734165827\n",
      "Average (on the epoch) training loss: 0.004070037455333151\n",
      "Episode average V value: 0.4800994396209717\n",
      "Average (on the epoch) training loss: 0.004038870242516418\n",
      "Episode average V value: 0.5565052703022957\n",
      "Average (on the epoch) training loss: 0.004026934166229667\n",
      "Episode average V value: 0.8966617385546366\n",
      "Average (on the epoch) training loss: 0.004018965268148892\n",
      "Episode average V value: 0.5768883228302002\n",
      "Average (on the epoch) training loss: 0.004027614921020965\n",
      "Episode average V value: 0.7358303666114807\n",
      "Average (on the epoch) training loss: 0.004021420645433107\n",
      "Episode average V value: 0.4857003688812256\n",
      "Average (on the epoch) training loss: 0.004002793134277944\n",
      "Episode average V value: 0.5648636519908905\n",
      "Average (on the epoch) training loss: 0.003984835330960668\n",
      "Episode average V value: 0.47840480506420135\n",
      "Average (on the epoch) training loss: 0.003995519092742113\n",
      "Episode average V value: 0.5169382989406586\n",
      "Average (on the epoch) training loss: 0.003992036547729025\n",
      "Episode average V value: 0.4567692130804062\n",
      "Average (on the epoch) training loss: 0.00399648563022384\n",
      "Episode average V value: 0.6166447214782238\n",
      "Average (on the epoch) training loss: 0.004003327714256648\n",
      "Episode average V value: 0.8971004486083984\n",
      "Average (on the epoch) training loss: 0.004026814532474524\n",
      "Episode average V value: 0.5952635332942009\n",
      "Average (on the epoch) training loss: 0.004018755460141651\n",
      "Episode average V value: 0.7510235905647278\n",
      "Average (on the epoch) training loss: 0.004011121045385318\n",
      "Episode average V value: 0.4654924511909485\n",
      "Average (on the epoch) training loss: 0.004040874714622599\n",
      "Episode average V value: 0.5979266092181206\n",
      "Average (on the epoch) training loss: 0.004045379548868971\n",
      "Episode average V value: 0.45459753504166234\n",
      "Average (on the epoch) training loss: 0.004064328597394103\n",
      "Episode average V value: 0.5667591128084395\n",
      "Average (on the epoch) training loss: 0.004095151502555475\n",
      "Episode average V value: 0.6370744407176971\n",
      "Average (on the epoch) training loss: 0.004097855742248631\n",
      "Episode average V value: 0.7146243453025818\n",
      "Average (on the epoch) training loss: 0.004082919025968294\n",
      "Episode average V value: 0.4864947646856308\n",
      "Average (on the epoch) training loss: 0.0040855293682308435\n",
      "Episode average V value: 0.5961764256159464\n",
      "Average (on the epoch) training loss: 0.0040875614201989095\n",
      "Episode average V value: 0.6416407108306885\n",
      "Average (on the epoch) training loss: 0.004065524471978493\n",
      "Episode average V value: 0.47034528851509094\n",
      "Average (on the epoch) training loss: 0.00404893454515122\n",
      "Episode average V value: 0.6166301634576585\n",
      "Average (on the epoch) training loss: 0.004043517000073652\n",
      "Episode average V value: 0.6555797159671783\n",
      "Average (on the epoch) training loss: 0.004053968390087701\n",
      "Episode average V value: 0.43410542607307434\n",
      "Average (on the epoch) training loss: 0.004086223515206138\n",
      "Episode average V value: 0.5646445870399475\n",
      "Average (on the epoch) training loss: 0.004084697871729331\n",
      "Episode average V value: 0.6928096860647202\n",
      "Average (on the epoch) training loss: 0.004081477575399029\n",
      "Episode average V value: 0.5220030148824056\n",
      "Average (on the epoch) training loss: 0.0040682785649851115\n",
      "Episode average V value: 0.6286485086787831\n",
      "Average (on the epoch) training loss: 0.004071941067269988\n",
      "Episode average V value: 0.882585604985555\n",
      "Average (on the epoch) training loss: 0.004075988234876834\n",
      "Episode average V value: 0.5802104217665536\n",
      "Average (on the epoch) training loss: 0.004071345280385548\n",
      "Episode average V value: 0.8917603194713593\n",
      "LOSSES\n",
      "T = 0.016140659887343645; R = 0.027456010606139898;                 Gamma = 0.5195452241897583; Q = 0.004072090169647709;\n",
      "Entropy Neighbor = 0.525478575527668;                 Entropy Random = 0.16297685649991037;                 Volume = 0.1792958713620901; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3883, -0.4558,  0.0501, -0.6892, -0.8359], device='cuda:0') tensor([-0.5173, -0.5468,  0.0337, -0.7461, -0.9163], device='cuda:0') tensor([-0.3883, -0.4558,  0.0501, -0.6892, -0.8359], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0246], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004060867559822058\n",
      "Episode average V value: 0.7126404742399851\n",
      "Average (on the epoch) training loss: 0.004100055593484469\n",
      "Episode average V value: 0.5529474561864679\n",
      "Average (on the epoch) training loss: 0.00409879785650455\n",
      "Episode average V value: 0.993341863155365\n",
      "Average (on the epoch) training loss: 0.004106074269552916\n",
      "Episode average V value: 0.6238466389477253\n",
      "Average (on the epoch) training loss: 0.0041105485065737885\n",
      "Episode average V value: 0.6713324844837188\n",
      "Average (on the epoch) training loss: 0.004126979353062424\n",
      "Episode average V value: 0.4119652509689331\n",
      "Average (on the epoch) training loss: 0.0041290113211959086\n",
      "Episode average V value: 0.53705925562165\n",
      "Average (on the epoch) training loss: 0.004124675344640666\n",
      "Episode average V value: 0.4571949988603592\n",
      "Average (on the epoch) training loss: 0.004124462914616469\n",
      "Episode average V value: 0.893150269985199\n",
      "Average (on the epoch) training loss: 0.004148382298372896\n",
      "Episode average V value: 0.4759717360138893\n",
      "Average (on the epoch) training loss: 0.004135356418535321\n",
      "Episode average V value: 0.7166643440723419\n",
      "Average (on the epoch) training loss: 0.004143775080045965\n",
      "Episode average V value: 0.8479864597320557\n",
      "Average (on the epoch) training loss: 0.004144629120308253\n",
      "Episode average V value: 0.8976181348164877\n",
      "Average (on the epoch) training loss: 0.004138996642450055\n",
      "Episode average V value: 0.692812442779541\n",
      "Average (on the epoch) training loss: 0.0041616713224051\n",
      "Episode average V value: 0.5725762210786343\n",
      "Average (on the epoch) training loss: 0.004177901435324256\n",
      "Episode average V value: 0.5197349220514298\n",
      "Average (on the epoch) training loss: 0.004176357428054632\n",
      "Episode average V value: 0.5349978357553482\n",
      "Average (on the epoch) training loss: 0.004183115536872316\n",
      "Episode average V value: 0.5573604963719845\n",
      "Average (on the epoch) training loss: 0.004180287460428828\n",
      "Episode average V value: 0.9923137426376343\n",
      "Average (on the epoch) training loss: 0.0041798360258971734\n",
      "Episode average V value: 0.7161369323730469\n",
      "Average (on the epoch) training loss: 0.004166997973578384\n",
      "Episode average V value: 0.4357905252413316\n",
      "Average (on the epoch) training loss: 0.004172853414214902\n",
      "Episode average V value: 0.5034193098545074\n",
      "Average (on the epoch) training loss: 0.004166020735554536\n",
      "Episode average V value: 0.44399045194898334\n",
      "Average (on the epoch) training loss: 0.004165628229528033\n",
      "Episode average V value: 0.6917091210683187\n",
      "Average (on the epoch) training loss: 0.004164445850377282\n",
      "Episode average V value: 0.5074773505330086\n",
      "Average (on the epoch) training loss: 0.004179971454128086\n",
      "Episode average V value: 0.6175611466169357\n",
      "Average (on the epoch) training loss: 0.004191912506468352\n",
      "Episode average V value: 0.48610972116390866\n",
      "Average (on the epoch) training loss: 0.004190974594148085\n",
      "Episode average V value: 0.5963743776082993\n",
      "Average (on the epoch) training loss: 0.004191252376549107\n",
      "Episode average V value: 0.6959779620170593\n",
      "Average (on the epoch) training loss: 0.0041914452342746555\n",
      "Episode average V value: 0.4911907911300659\n",
      "Average (on the epoch) training loss: 0.004195300922488561\n",
      "Episode average V value: 0.693130224943161\n",
      "Average (on the epoch) training loss: 0.00418975377384779\n",
      "Episode average V value: 0.5760064820448557\n",
      "Average (on the epoch) training loss: 0.004186285282103174\n",
      "Episode average V value: 0.9918572902679443\n",
      "Average (on the epoch) training loss: 0.0041872013591452905\n",
      "Episode average V value: 0.8959053158760071\n",
      "Average (on the epoch) training loss: 0.004186014581198302\n",
      "Episode average V value: 0.7371513247489929\n",
      "Average (on the epoch) training loss: 0.004178223145159524\n",
      "Episode average V value: 0.5438892245292664\n",
      "Average (on the epoch) training loss: 0.0041717331524103365\n",
      "Episode average V value: 0.6940788626670837\n",
      "Average (on the epoch) training loss: 0.004164143690156865\n",
      "Episode average V value: 0.6755655884742737\n",
      "Average (on the epoch) training loss: 0.004163430019940699\n",
      "Episode average V value: 0.7513914465904236\n",
      "Average (on the epoch) training loss: 0.004154056110618281\n",
      "Episode average V value: 0.37153170151369913\n",
      "Average (on the epoch) training loss: 0.004142161636986828\n",
      "Episode average V value: 0.4809134155511856\n",
      "Average (on the epoch) training loss: 0.004132242711281802\n",
      "Episode average V value: 0.8466398417949677\n",
      "Average (on the epoch) training loss: 0.00413274805981246\n",
      "Episode average V value: 0.6913631707429886\n",
      "Average (on the epoch) training loss: 0.0041501288911951015\n",
      "Episode average V value: 0.7713405191898346\n",
      "Average (on the epoch) training loss: 0.004143541689859201\n",
      "Episode average V value: 0.6398178722177233\n",
      "Average (on the epoch) training loss: 0.004153302840993037\n",
      "Episode average V value: 0.8062474012374878\n",
      "Average (on the epoch) training loss: 0.0041395530583544175\n",
      "Episode average V value: 0.6338689369814736\n",
      "Average (on the epoch) training loss: 0.004144506724369283\n",
      "Episode average V value: 0.9315915107727051\n",
      "Average (on the epoch) training loss: 0.00412774951676206\n",
      "Episode average V value: 0.4635866016149521\n",
      "Average (on the epoch) training loss: 0.004126860926459942\n",
      "Episode average V value: 0.7255193889141083\n",
      "Average (on the epoch) training loss: 0.004155586785179751\n",
      "Episode average V value: 0.5284231275320053\n",
      "Average (on the epoch) training loss: 0.004170948352005776\n",
      "Episode average V value: 0.6327139470312331\n",
      "Average (on the epoch) training loss: 0.004173008873276052\n",
      "Episode average V value: 0.6916737159093221\n",
      "Average (on the epoch) training loss: 0.004172164059873488\n",
      "Episode average V value: 0.44776471455891925\n",
      "Average (on the epoch) training loss: 0.004169788511842049\n",
      "Episode average V value: 0.6059603095054626\n",
      "Average (on the epoch) training loss: 0.004173428496156754\n",
      "Episode average V value: 0.9935303330421448\n",
      "Average (on the epoch) training loss: 0.004181634434012416\n",
      "Episode average V value: 0.6640436291694641\n",
      "Average (on the epoch) training loss: 0.004176907940107747\n",
      "Episode average V value: 0.4617141584555308\n",
      "Average (on the epoch) training loss: 0.004172854339492499\n",
      "Episode average V value: 0.8165231943130493\n",
      "Average (on the epoch) training loss: 0.004171792095507718\n",
      "Episode average V value: 0.5943826362490654\n",
      "Average (on the epoch) training loss: 0.004182586627108837\n",
      "Episode average V value: 0.5195877403020859\n",
      "Average (on the epoch) training loss: 0.004179811529235518\n",
      "Episode average V value: 0.6927007834116617\n",
      "Average (on the epoch) training loss: 0.004186537318097547\n",
      "Episode average V value: 0.4891688625017802\n",
      "Average (on the epoch) training loss: 0.004202325547729353\n",
      "Episode average V value: 0.4784052934911516\n",
      "Average (on the epoch) training loss: 0.004207926566667128\n",
      "Episode average V value: 0.18623566627502441\n",
      "Average (on the epoch) training loss: 0.004203824889621977\n",
      "Episode average V value: 0.4177592694759369\n",
      "Average (on the epoch) training loss: 0.004211356896011046\n",
      "Episode average V value: 0.4787660340468089\n",
      "Average (on the epoch) training loss: 0.004206329492544996\n",
      "Episode average V value: 0.8445073664188385\n",
      "Average (on the epoch) training loss: 0.004206929151541528\n",
      "Episode average V value: 0.5791058412619999\n",
      "Average (on the epoch) training loss: 0.004211139055379249\n",
      "Episode average V value: 0.5162820319334666\n",
      "Average (on the epoch) training loss: 0.004220542405683889\n",
      "Episode average V value: 0.6640883833169937\n",
      "Average (on the epoch) training loss: 0.004218271305588515\n",
      "Episode average V value: 0.815790057182312\n",
      "Average (on the epoch) training loss: 0.004205022438435098\n",
      "Episode average V value: 0.36789470452528733\n",
      "Average (on the epoch) training loss: 0.004211901215309839\n",
      "Episode average V value: 0.43685856088995934\n",
      "Average (on the epoch) training loss: 0.004215667695487928\n",
      "Episode average V value: 0.5338841825723648\n",
      "Average (on the epoch) training loss: 0.004225730330248172\n",
      "Episode average V value: 0.4254393783899454\n",
      "Average (on the epoch) training loss: 0.004223157113112204\n",
      "Episode average V value: 0.6656418293714523\n",
      "LOSSES\n",
      "T = 0.0164897934878245; R = 0.029066544897388667;                 Gamma = 0.5172854280471801; Q = 0.00437768478342332;\n",
      "Entropy Neighbor = 0.5186580718755722;                 Entropy Random = 0.15855773532390594;                 Volume = 0.18963857463002204; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004224887476535514\n",
      "Episode average V value: 0.5065532326698303\n",
      "epoch 29:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 0.9090909090909091 (average over 11 episode(s))\n",
      "== Mean score per episode is 0.90908264470323 over 11 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5945, -0.6177,  0.0540, -0.8725, -1.1331], device='cuda:0') tensor([-0.6838, -0.7515,  0.0048, -0.8909, -1.0768], device='cuda:0') tensor([-0.8106, -0.8279, -0.0078, -0.9301, -1.1893], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1272], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003985004499554634\n",
      "Episode average V value: 0.8795667290687561\n",
      "Average (on the epoch) training loss: 0.004202663463850816\n",
      "Episode average V value: 0.4551409035921097\n",
      "Average (on the epoch) training loss: 0.005584625338780738\n",
      "Episode average V value: 0.5515737036863962\n",
      "Average (on the epoch) training loss: 0.005507527957282339\n",
      "Episode average V value: 0.6976337631543478\n",
      "Average (on the epoch) training loss: 0.0053717367297324995\n",
      "Episode average V value: 0.9490860998630524\n",
      "Average (on the epoch) training loss: 0.0058695881964703055\n",
      "Episode average V value: 0.8996536731719971\n",
      "Average (on the epoch) training loss: 0.0053292740363088485\n",
      "Episode average V value: 0.4785077108277215\n",
      "Average (on the epoch) training loss: 0.0053026130546492585\n",
      "Episode average V value: 0.5511480055072091\n",
      "Average (on the epoch) training loss: 0.005060890663841392\n",
      "Episode average V value: 0.6247375011444092\n",
      "Average (on the epoch) training loss: 0.004984612429713006\n",
      "Episode average V value: 0.9371784627437592\n",
      "Average (on the epoch) training loss: 0.00476848368054709\n",
      "Episode average V value: 0.42626088857650757\n",
      "Average (on the epoch) training loss: 0.004699367075533557\n",
      "Episode average V value: 0.9516054391860962\n",
      "Average (on the epoch) training loss: 0.004797588206157543\n",
      "Episode average V value: 0.7782609562079111\n",
      "Average (on the epoch) training loss: 0.004647698460612446\n",
      "Episode average V value: 0.42653672728273606\n",
      "Average (on the epoch) training loss: 0.004677219688245613\n",
      "Episode average V value: 0.6268367916345596\n",
      "Average (on the epoch) training loss: 0.004599786922335624\n",
      "Episode average V value: 0.5839020439556667\n",
      "Average (on the epoch) training loss: 0.004618451245786513\n",
      "Episode average V value: 0.8142280876636505\n",
      "Average (on the epoch) training loss: 0.004678321323350413\n",
      "Episode average V value: 0.5304229880372683\n",
      "Average (on the epoch) training loss: 0.004691867016758906\n",
      "Episode average V value: 0.6002513468265533\n",
      "Average (on the epoch) training loss: 0.004675397779104994\n",
      "Episode average V value: 0.5652364467581114\n",
      "Average (on the epoch) training loss: 0.004769973518751278\n",
      "Episode average V value: 0.655296765267849\n",
      "Average (on the epoch) training loss: 0.004801632875266175\n",
      "Episode average V value: 0.5171708837151527\n",
      "Average (on the epoch) training loss: 0.004692361837258206\n",
      "Episode average V value: 0.6056599318981171\n",
      "Average (on the epoch) training loss: 0.004676403701179535\n",
      "Episode average V value: 0.5749814425195966\n",
      "Average (on the epoch) training loss: 0.004638585273642093\n",
      "Episode average V value: 0.8524321168661118\n",
      "Average (on the epoch) training loss: 0.004624723267775106\n",
      "Episode average V value: 0.8164703249931335\n",
      "Average (on the epoch) training loss: 0.004577837987716182\n",
      "Episode average V value: 0.6116605069902208\n",
      "Average (on the epoch) training loss: 0.004599111466422283\n",
      "Episode average V value: 0.7257507294416428\n",
      "Average (on the epoch) training loss: 0.004571448398687179\n",
      "Episode average V value: 0.39449594020843504\n",
      "Average (on the epoch) training loss: 0.004556814092713216\n",
      "Episode average V value: 0.6275655664503574\n",
      "Average (on the epoch) training loss: 0.0045572684351847\n",
      "Episode average V value: 0.4718853256532124\n",
      "Average (on the epoch) training loss: 0.004546292024315335\n",
      "Episode average V value: 0.8941986560821533\n",
      "Average (on the epoch) training loss: 0.00449346534076932\n",
      "Episode average V value: 0.6407847915376935\n",
      "Average (on the epoch) training loss: 0.004490226861785284\n",
      "Episode average V value: 0.6711518963177999\n",
      "Average (on the epoch) training loss: 0.004473826627831738\n",
      "Episode average V value: 0.6467321634292602\n",
      "Average (on the epoch) training loss: 0.004479742721555904\n",
      "Episode average V value: 0.6560415582997459\n",
      "Average (on the epoch) training loss: 0.004461187765920548\n",
      "Episode average V value: 0.4539905364314715\n",
      "Average (on the epoch) training loss: 0.004471082303119957\n",
      "Episode average V value: 0.6549971784864154\n",
      "Average (on the epoch) training loss: 0.004450594170803958\n",
      "Episode average V value: 0.6261118153731028\n",
      "Average (on the epoch) training loss: 0.004458178205582135\n",
      "Episode average V value: 0.8929317792256674\n",
      "Average (on the epoch) training loss: 0.004443349816126548\n",
      "Episode average V value: 0.6862115025520324\n",
      "Average (on the epoch) training loss: 0.004412903681429653\n",
      "Episode average V value: 0.47817791321060876\n",
      "Average (on the epoch) training loss: 0.004379716267702675\n",
      "Episode average V value: 0.5543582567146846\n",
      "Average (on the epoch) training loss: 0.004382406660462143\n",
      "Episode average V value: 0.4069623164832592\n",
      "Average (on the epoch) training loss: 0.004394649984175737\n",
      "Episode average V value: 0.5977910816669464\n",
      "Average (on the epoch) training loss: 0.00440220343495485\n",
      "Episode average V value: 0.5137221693992615\n",
      "Average (on the epoch) training loss: 0.004404636728670947\n",
      "Episode average V value: 0.6199760089317957\n",
      "Average (on the epoch) training loss: 0.004405041703323245\n",
      "Episode average V value: 0.47494145376341684\n",
      "Average (on the epoch) training loss: 0.004411547753351414\n",
      "Episode average V value: 0.4706249162554741\n",
      "Average (on the epoch) training loss: 0.004371439925041894\n",
      "Episode average V value: 0.5870356758435568\n",
      "Average (on the epoch) training loss: 0.004375920586513369\n",
      "Episode average V value: 0.6057222411036491\n",
      "Average (on the epoch) training loss: 0.0043759335988467615\n",
      "Episode average V value: 0.4933723211288452\n",
      "Average (on the epoch) training loss: 0.004348861662454459\n",
      "Episode average V value: 0.5172913322846094\n",
      "Average (on the epoch) training loss: 0.00435338684880218\n",
      "Episode average V value: 0.895579993724823\n",
      "Average (on the epoch) training loss: 0.004349248309424169\n",
      "Episode average V value: 0.823246955871582\n",
      "Average (on the epoch) training loss: 0.0043591666452264845\n",
      "Episode average V value: 0.6917840341726939\n",
      "Average (on the epoch) training loss: 0.004348793045259682\n",
      "Episode average V value: 0.5253119319677353\n",
      "Average (on the epoch) training loss: 0.004335936905238316\n",
      "Episode average V value: 0.8828693826993307\n",
      "Average (on the epoch) training loss: 0.004332352713583886\n",
      "Episode average V value: 0.6898171901702881\n",
      "Average (on the epoch) training loss: 0.004321153939718901\n",
      "Episode average V value: 0.6971524059772491\n",
      "Average (on the epoch) training loss: 0.004320633399968841\n",
      "Episode average V value: 0.9961934685707092\n",
      "Average (on the epoch) training loss: 0.004334054543192153\n",
      "Episode average V value: 0.6481854677200317\n",
      "Average (on the epoch) training loss: 0.004338989375905204\n",
      "Episode average V value: 0.9931187033653259\n",
      "Average (on the epoch) training loss: 0.004349304040176833\n",
      "Episode average V value: 0.5077185690402984\n",
      "Average (on the epoch) training loss: 0.004341577910398776\n",
      "Episode average V value: 0.5666382568223136\n",
      "Average (on the epoch) training loss: 0.004330757613748153\n",
      "Episode average V value: 0.5435664772987365\n",
      "LOSSES\n",
      "T = 0.017013675641268492; R = 0.029194030288141222;                 Gamma = 0.517184006690979; Q = 0.00431911650893744;\n",
      "Entropy Neighbor = 0.5173632485866546;                 Entropy Random = 0.16057002598047257;                 Volume = 0.19540962984412907; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.00431911650893744\n",
      "Episode average V value: 0.6963371464184352\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0677, -0.1199,  0.1732, -0.6756, -0.8917], device='cuda:0') tensor([-0.0723, -0.1303,  0.1741, -0.6696, -0.8934], device='cuda:0') tensor([-0.0935, -0.1389,  0.1753, -0.7022, -0.9359], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0129], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004340042476657102\n",
      "Episode average V value: 0.6246642470359802\n",
      "Average (on the epoch) training loss: 0.004340367064073002\n",
      "Episode average V value: 0.9423305988311768\n",
      "Average (on the epoch) training loss: 0.004331549469639267\n",
      "Episode average V value: 0.7703076303005219\n",
      "Average (on the epoch) training loss: 0.00432654682060927\n",
      "Episode average V value: 0.738792359828949\n",
      "Average (on the epoch) training loss: 0.004331031288554163\n",
      "Episode average V value: 0.9390928149223328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.0043457791170638796\n",
      "Episode average V value: 0.8896814982096354\n",
      "Average (on the epoch) training loss: 0.004357125139050009\n",
      "Episode average V value: 0.700909157594045\n",
      "Average (on the epoch) training loss: 0.004348789631797634\n",
      "Episode average V value: 0.8938535749912262\n",
      "Average (on the epoch) training loss: 0.0043550707321584545\n",
      "Episode average V value: 0.6256478130817413\n",
      "Average (on the epoch) training loss: 0.004355679454284499\n",
      "Episode average V value: 0.702898253997167\n",
      "Average (on the epoch) training loss: 0.00435361596864423\n",
      "Episode average V value: 0.47418583432833356\n",
      "Average (on the epoch) training loss: 0.004373356376485781\n",
      "Episode average V value: 0.6270013153553009\n",
      "Average (on the epoch) training loss: 0.004371858177615637\n",
      "Episode average V value: 0.8179114311933517\n",
      "Average (on the epoch) training loss: 0.004358931901219754\n",
      "Episode average V value: 0.47471462686856586\n",
      "Average (on the epoch) training loss: 0.004364196574897505\n",
      "Episode average V value: 0.7973725398381551\n",
      "Average (on the epoch) training loss: 0.004351392552327783\n",
      "Episode average V value: 0.5261204689741135\n",
      "Average (on the epoch) training loss: 0.004350234386718741\n",
      "Episode average V value: 0.8932658235232035\n",
      "Average (on the epoch) training loss: 0.004347542255236038\n",
      "Episode average V value: 0.5028931034935845\n",
      "Average (on the epoch) training loss: 0.004347275465001157\n",
      "Episode average V value: 0.8241003155708313\n",
      "Average (on the epoch) training loss: 0.004331187775468451\n",
      "Episode average V value: 0.6641817263194493\n",
      "Average (on the epoch) training loss: 0.004327938681332549\n",
      "Episode average V value: 0.5466739207506179\n",
      "Average (on the epoch) training loss: 0.004332902669997757\n",
      "Episode average V value: 0.6725279353559017\n",
      "Average (on the epoch) training loss: 0.004328987784740957\n",
      "Episode average V value: 0.7242326140403748\n",
      "Average (on the epoch) training loss: 0.004332969601380606\n",
      "Episode average V value: 0.7964816490809122\n",
      "Average (on the epoch) training loss: 0.004334297145217167\n",
      "Episode average V value: 0.932978093624115\n",
      "Average (on the epoch) training loss: 0.0043409185812131245\n",
      "Episode average V value: 0.41236575775676304\n",
      "Average (on the epoch) training loss: 0.004354079378858436\n",
      "Episode average V value: 0.4163055270910263\n",
      "Average (on the epoch) training loss: 0.004356826754904191\n",
      "Episode average V value: 0.4961112563808759\n",
      "Average (on the epoch) training loss: 0.004355748766892046\n",
      "Episode average V value: 0.5463007525964216\n",
      "Average (on the epoch) training loss: 0.0043513119461394915\n",
      "Episode average V value: 0.5493016441663107\n",
      "Average (on the epoch) training loss: 0.00435481024627542\n",
      "Episode average V value: 0.42121267318725586\n",
      "Average (on the epoch) training loss: 0.004352336207913791\n",
      "Episode average V value: 0.8822365204493204\n",
      "Average (on the epoch) training loss: 0.004354890232250243\n",
      "Episode average V value: 0.4985066056251526\n",
      "Average (on the epoch) training loss: 0.004360678078879157\n",
      "Episode average V value: 0.7865422129631042\n",
      "Average (on the epoch) training loss: 0.004379505523308737\n",
      "Episode average V value: 0.6665050685405731\n",
      "Average (on the epoch) training loss: 0.004370064800121504\n",
      "Episode average V value: 0.30944667756557465\n",
      "Average (on the epoch) training loss: 0.004364725796948352\n",
      "Episode average V value: 0.640730253287724\n",
      "Average (on the epoch) training loss: 0.00436090377865713\n",
      "Episode average V value: 0.5698086619377136\n",
      "Average (on the epoch) training loss: 0.004350901629074046\n",
      "Episode average V value: 0.7520909070968628\n",
      "Average (on the epoch) training loss: 0.0043368142620389735\n",
      "Episode average V value: 0.5939610481262207\n",
      "Average (on the epoch) training loss: 0.004352511520525114\n",
      "Episode average V value: 0.5583482517136468\n",
      "Average (on the epoch) training loss: 0.0043709378058001515\n",
      "Episode average V value: 0.46008041501045227\n",
      "Average (on the epoch) training loss: 0.004374868093475274\n",
      "Episode average V value: 0.7230256497859955\n",
      "Average (on the epoch) training loss: 0.004364120136144126\n",
      "Episode average V value: 0.6632691621780396\n",
      "Average (on the epoch) training loss: 0.004358605331465999\n",
      "Episode average V value: 0.429899787902832\n",
      "Average (on the epoch) training loss: 0.004359957343420957\n",
      "Episode average V value: 0.4887005537748337\n",
      "Average (on the epoch) training loss: 0.004349543986855153\n",
      "Episode average V value: 0.5032876594500109\n",
      "Average (on the epoch) training loss: 0.004346232864959813\n",
      "Episode average V value: 0.6326555212338766\n",
      "Average (on the epoch) training loss: 0.004343541184014374\n",
      "Episode average V value: 0.8045730233192444\n",
      "Average (on the epoch) training loss: 0.004343528364923723\n",
      "Episode average V value: 0.8806755940119425\n",
      "Average (on the epoch) training loss: 0.004338445733653328\n",
      "Episode average V value: 0.5529635287821293\n",
      "Average (on the epoch) training loss: 0.004335348972725036\n",
      "Episode average V value: 0.6590104177594185\n",
      "Average (on the epoch) training loss: 0.004332142799362895\n",
      "Episode average V value: 0.8904270132382711\n",
      "Average (on the epoch) training loss: 0.004336086355685962\n",
      "Episode average V value: 0.6400859015328544\n",
      "Average (on the epoch) training loss: 0.004343400504412017\n",
      "Episode average V value: 0.8472737371921539\n",
      "Average (on the epoch) training loss: 0.004335672603593807\n",
      "Episode average V value: 0.4275188172856967\n",
      "Average (on the epoch) training loss: 0.004323900198954523\n",
      "Episode average V value: 0.4958241375593039\n",
      "Average (on the epoch) training loss: 0.004309504915935427\n",
      "Episode average V value: 0.5320248658006842\n",
      "Average (on the epoch) training loss: 0.004311986820138948\n",
      "Episode average V value: 0.7543944358825684\n",
      "Average (on the epoch) training loss: 0.004306518052870412\n",
      "Episode average V value: 0.4269434750080109\n",
      "Average (on the epoch) training loss: 0.004312636871242199\n",
      "Episode average V value: 0.7861238121986389\n",
      "Average (on the epoch) training loss: 0.004309405101551198\n",
      "Episode average V value: 0.9908632040023804\n",
      "Average (on the epoch) training loss: 0.00430657063163503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.004290652790591079\n",
      "Episode average V value: 0.5849857709624551\n",
      "Average (on the epoch) training loss: 0.0042854655224860445\n",
      "Episode average V value: 0.3565597442480234\n",
      "Average (on the epoch) training loss: 0.004288577214069262\n",
      "Episode average V value: 0.4053604180614154\n",
      "Average (on the epoch) training loss: 0.004286846013351405\n",
      "Episode average V value: 0.7484782536824545\n",
      "Average (on the epoch) training loss: 0.004289654019496675\n",
      "Episode average V value: 0.8820207317670187\n",
      "Average (on the epoch) training loss: 0.004289666768844292\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.004280837973102239\n",
      "Episode average V value: 0.4976067394018173\n",
      "Average (on the epoch) training loss: 0.004281429198886551\n",
      "Episode average V value: 0.8044934868812561\n",
      "Average (on the epoch) training loss: 0.004288739226588708\n",
      "Episode average V value: 0.44522351026535034\n",
      "Average (on the epoch) training loss: 0.004312994573059735\n",
      "Episode average V value: 0.38665638864040375\n",
      "Average (on the epoch) training loss: 0.004315391219279263\n",
      "Episode average V value: 0.9963678121566772\n",
      "Average (on the epoch) training loss: 0.004316489345750169\n",
      "Episode average V value: 0.483858984708786\n",
      "Average (on the epoch) training loss: 0.0043168196647648555\n",
      "Episode average V value: 0.9434514045715332\n",
      "Average (on the epoch) training loss: 0.0043104983273746\n",
      "Episode average V value: 0.5371180921792984\n",
      "LOSSES\n",
      "T = 0.01701040480006486; R = 0.030367053193040193;                 Gamma = 0.5152940602302551; Q = 0.004298162289313041;\n",
      "Entropy Neighbor = 0.5068950883150101;                 Entropy Random = 0.1571103907674551;                 Volume = 0.20201910775899887; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004308639399125241\n",
      "Episode average V value: 0.32423530022303265\n",
      "epoch 30:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9852941176470589 (average over 68 episode(s))\n",
      "== Mean score per episode is 0.9852926686872518 over 68 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2972, -0.3663,  0.0722, -0.6640, -0.8130], device='cuda:0') tensor([-0.2707, -0.3510,  0.0653, -0.6832, -0.8930], device='cuda:0') tensor([-0.3772, -0.4492,  0.0419, -0.6697, -0.8040], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0075], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0034147251426475123\n",
      "Episode average V value: 0.4822934791445732\n",
      "Average (on the epoch) training loss: 0.003966445703745673\n",
      "Episode average V value: 0.5259647179733623\n",
      "Average (on the epoch) training loss: 0.00403470197819512\n",
      "Episode average V value: 0.6029167970021566\n",
      "Average (on the epoch) training loss: 0.003944851449449305\n",
      "Episode average V value: 0.6023767828941345\n",
      "Average (on the epoch) training loss: 0.004045716051145324\n",
      "Episode average V value: 0.4902484118938446\n",
      "Average (on the epoch) training loss: 0.004171104124300958\n",
      "Episode average V value: 0.5556928440928459\n",
      "Average (on the epoch) training loss: 0.004118568321097304\n",
      "Episode average V value: 0.740653932094574\n",
      "Average (on the epoch) training loss: 0.004319777463024366\n",
      "Episode average V value: 0.5665697256724039\n",
      "Average (on the epoch) training loss: 0.004366451089453855\n",
      "Episode average V value: 0.7318893373012543\n",
      "Average (on the epoch) training loss: 0.004253039688423828\n",
      "Episode average V value: 0.43248624801635743\n",
      "Average (on the epoch) training loss: 0.004197107070857393\n",
      "Episode average V value: 0.8864278992017111\n",
      "Average (on the epoch) training loss: 0.004166859967101898\n",
      "Episode average V value: 0.6821813242776054\n",
      "Average (on the epoch) training loss: 0.004172418739788396\n",
      "Episode average V value: 0.8281123638153076\n",
      "Average (on the epoch) training loss: 0.004183540977735786\n",
      "Episode average V value: 1.001077651977539\n",
      "Average (on the epoch) training loss: 0.00418573732652779\n",
      "Episode average V value: 0.9472984671592712\n",
      "Average (on the epoch) training loss: 0.0040979261687468915\n",
      "Episode average V value: 0.5608577355742455\n",
      "Average (on the epoch) training loss: 0.0041543111642169065\n",
      "Episode average V value: 0.49176432689030963\n",
      "Average (on the epoch) training loss: 0.004122099398504481\n",
      "Episode average V value: 0.7759632269541422\n",
      "Average (on the epoch) training loss: 0.004130036732379904\n",
      "Episode average V value: 0.6789671083291372\n",
      "Average (on the epoch) training loss: 0.004154971159578329\n",
      "Episode average V value: 0.6542490601539612\n",
      "Average (on the epoch) training loss: 0.004128816037804687\n",
      "Episode average V value: 0.60935153439641\n",
      "Average (on the epoch) training loss: 0.0040970532695802165\n",
      "Episode average V value: 0.7317196130752563\n",
      "Average (on the epoch) training loss: 0.00420281358513256\n",
      "Episode average V value: 0.5012770209993634\n",
      "Average (on the epoch) training loss: 0.004248056738324982\n",
      "Episode average V value: 0.5963533951176537\n",
      "Average (on the epoch) training loss: 0.004226626472258995\n",
      "Episode average V value: 0.4494492778411278\n",
      "Average (on the epoch) training loss: 0.00421416237371613\n",
      "Episode average V value: 0.8986356556415558\n",
      "Average (on the epoch) training loss: 0.004251864914975735\n",
      "Episode average V value: 0.4840246468782425\n",
      "Average (on the epoch) training loss: 0.004262383752753593\n",
      "Episode average V value: 0.4606580663295019\n",
      "Average (on the epoch) training loss: 0.004275374589554118\n",
      "Episode average V value: 0.6297132883753095\n",
      "Average (on the epoch) training loss: 0.004291484448862013\n",
      "Episode average V value: 0.9356047213077545\n",
      "Average (on the epoch) training loss: 0.00431906522069995\n",
      "Episode average V value: 0.504420280456543\n",
      "Average (on the epoch) training loss: 0.004310484254503912\n",
      "Episode average V value: 0.47473665409617954\n",
      "Average (on the epoch) training loss: 0.004317156852642459\n",
      "Episode average V value: 0.5877898693084717\n",
      "Average (on the epoch) training loss: 0.00432840416645061\n",
      "Episode average V value: 0.8994841376940409\n",
      "Average (on the epoch) training loss: 0.004346414375861707\n",
      "Episode average V value: 0.9449669718742371\n",
      "Average (on the epoch) training loss: 0.004335354093462229\n",
      "Episode average V value: 0.8951956033706665\n",
      "Average (on the epoch) training loss: 0.004296820258001252\n",
      "Episode average V value: 0.5311370662280491\n",
      "Average (on the epoch) training loss: 0.00432832614666558\n",
      "Episode average V value: 0.5312880145178901\n",
      "Average (on the epoch) training loss: 0.004336738334885532\n",
      "Episode average V value: 0.7747200429439545\n",
      "Average (on the epoch) training loss: 0.004434712318370689\n",
      "Episode average V value: 0.38298183950510895\n",
      "Average (on the epoch) training loss: 0.0044092567268459995\n",
      "Episode average V value: 0.6685683301516941\n",
      "Average (on the epoch) training loss: 0.0043933873700652505\n",
      "Episode average V value: 0.996070921421051\n",
      "Average (on the epoch) training loss: 0.0043833818519487975\n",
      "Episode average V value: 0.4776202208466\n",
      "Average (on the epoch) training loss: 0.004407095747985064\n",
      "Episode average V value: 0.6916895747184754\n",
      "Average (on the epoch) training loss: 0.004405496212208655\n",
      "Episode average V value: 0.8970270355542501\n",
      "Average (on the epoch) training loss: 0.00437966938719062\n",
      "Episode average V value: 0.6377297043800354\n",
      "Average (on the epoch) training loss: 0.0043821336030821076\n",
      "Episode average V value: 0.4293040446937084\n",
      "Average (on the epoch) training loss: 0.0044202418736626154\n",
      "Episode average V value: 0.578061991267734\n",
      "Average (on the epoch) training loss: 0.004412580450380247\n",
      "Episode average V value: 0.6064640229398554\n",
      "Average (on the epoch) training loss: 0.004400961022698679\n",
      "Episode average V value: 0.6133107940355936\n",
      "Average (on the epoch) training loss: 0.004399094930773839\n",
      "Episode average V value: 0.8851926525433859\n",
      "Average (on the epoch) training loss: 0.004355722147030214\n",
      "Episode average V value: 0.3825457339937037\n",
      "Average (on the epoch) training loss: 0.004358672922554135\n",
      "Episode average V value: 0.5742679966820611\n",
      "Average (on the epoch) training loss: 0.00436021601912927\n",
      "Episode average V value: 0.9355061948299408\n",
      "Average (on the epoch) training loss: 0.004341661450500498\n",
      "Episode average V value: 0.8499341905117035\n",
      "Average (on the epoch) training loss: 0.004348674769573652\n",
      "Episode average V value: 0.3885423481464386\n",
      "Average (on the epoch) training loss: 0.004314133882487966\n",
      "Episode average V value: 0.6763789094984531\n",
      "Average (on the epoch) training loss: 0.004313909252024521\n",
      "Episode average V value: 0.8313438892364502\n",
      "Average (on the epoch) training loss: 0.0042868478055164165\n",
      "Episode average V value: 0.5978906489908695\n",
      "Average (on the epoch) training loss: 0.004271575365218722\n",
      "Episode average V value: 0.5681035935878753\n",
      "Average (on the epoch) training loss: 0.004263428634904149\n",
      "Episode average V value: 0.7431469738483429\n",
      "Average (on the epoch) training loss: 0.004257002971715871\n",
      "Episode average V value: 0.5443626443545023\n",
      "Average (on the epoch) training loss: 0.004258617205139895\n",
      "Episode average V value: 0.9028973281383514\n",
      "Average (on the epoch) training loss: 0.004261676791213557\n",
      "Episode average V value: 0.7055042882760366\n",
      "Average (on the epoch) training loss: 0.004251096502288264\n",
      "Episode average V value: 0.567271385874067\n",
      "Average (on the epoch) training loss: 0.004242994885199583\n",
      "Episode average V value: 0.8967397014300028\n",
      "Average (on the epoch) training loss: 0.0042254227406374415\n",
      "Episode average V value: 0.6012938618659973\n",
      "Average (on the epoch) training loss: 0.0042241770315967625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.004218395237802286\n",
      "Episode average V value: 0.5832088351249695\n",
      "Average (on the epoch) training loss: 0.004215550721695586\n",
      "Episode average V value: 0.653141301125288\n",
      "Average (on the epoch) training loss: 0.0042069836940021145\n",
      "Episode average V value: 0.9443319737911224\n",
      "Average (on the epoch) training loss: 0.004203813830161021\n",
      "Episode average V value: 0.8331085443496704\n",
      "LOSSES\n",
      "T = 0.016826456658542155; R = 0.03117630163859576;                 Gamma = 0.515070892393589; Q = 0.00420721521077212;\n",
      "Entropy Neighbor = 0.504391963005066;                 Entropy Random = 0.15573659650981425;                 Volume = 0.21220561660826207; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0732,  0.0018,  0.1827, -0.5825, -0.7527], device='cuda:0') tensor([ 0.1493,  0.0991,  0.2152, -0.5864, -0.7884], device='cuda:0') tensor([ 0.0732,  0.0018,  0.1827, -0.5825, -0.7527], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0053], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0042146435214593546\n",
      "Episode average V value: 0.652459849913915\n",
      "Average (on the epoch) training loss: 0.00421982126040753\n",
      "Episode average V value: 0.7461051642894745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004221861735081616\n",
      "Episode average V value: 0.5225146226584911\n",
      "Average (on the epoch) training loss: 0.004213585888825509\n",
      "Episode average V value: 0.5345101058483124\n",
      "Average (on the epoch) training loss: 0.004224385049718077\n",
      "Episode average V value: 0.4774106852710247\n",
      "Average (on the epoch) training loss: 0.004218899902703645\n",
      "Episode average V value: 0.7525234669446945\n",
      "Average (on the epoch) training loss: 0.004215500599630699\n",
      "Episode average V value: 0.8339539766311646\n",
      "Average (on the epoch) training loss: 0.004238306403329037\n",
      "Episode average V value: 0.6256998367607594\n",
      "Average (on the epoch) training loss: 0.004220448590726969\n",
      "Episode average V value: 0.4099595844745636\n",
      "Average (on the epoch) training loss: 0.004243765194826808\n",
      "Episode average V value: 0.5002746323744456\n",
      "Average (on the epoch) training loss: 0.004251669022565621\n",
      "Episode average V value: 0.5757591859860853\n",
      "Average (on the epoch) training loss: 0.004259080881986893\n",
      "Episode average V value: 0.6155755780637264\n",
      "Average (on the epoch) training loss: 0.004252828274564336\n",
      "Episode average V value: 0.5865771339999305\n",
      "Average (on the epoch) training loss: 0.004248019891467777\n",
      "Episode average V value: 0.7497511605421702\n",
      "Average (on the epoch) training loss: 0.004249326017289384\n",
      "Episode average V value: 0.4954471290111542\n",
      "Average (on the epoch) training loss: 0.004259521458837865\n",
      "Episode average V value: 0.5183108683143344\n",
      "Average (on the epoch) training loss: 0.004260301819053206\n",
      "Episode average V value: 0.8344313502311707\n",
      "Average (on the epoch) training loss: 0.004251564021513979\n",
      "Episode average V value: 0.48371733512197224\n",
      "Average (on the epoch) training loss: 0.00423938774118267\n",
      "Episode average V value: 0.4657400637865067\n",
      "Average (on the epoch) training loss: 0.00423765947677686\n",
      "Episode average V value: 0.4472297728061676\n",
      "Average (on the epoch) training loss: 0.004231938568853865\n",
      "Episode average V value: 0.4472877740859985\n",
      "Average (on the epoch) training loss: 0.004213558459751669\n",
      "Episode average V value: 0.5094013065099716\n",
      "Average (on the epoch) training loss: 0.004216479740191386\n",
      "Episode average V value: 0.8338568210601807\n",
      "Average (on the epoch) training loss: 0.0042108334441859465\n",
      "Episode average V value: 0.7984308203061422\n",
      "Average (on the epoch) training loss: 0.00421403210157019\n",
      "Episode average V value: 0.48050301273663837\n",
      "Average (on the epoch) training loss: 0.004210094333032921\n",
      "Episode average V value: 0.6513528492715623\n",
      "Average (on the epoch) training loss: 0.0042173616368220085\n",
      "Episode average V value: 0.32972843448321026\n",
      "Average (on the epoch) training loss: 0.004222541887091126\n",
      "Episode average V value: 0.8520391583442688\n",
      "Average (on the epoch) training loss: 0.004224742067958917\n",
      "Episode average V value: 0.9455350041389465\n",
      "Average (on the epoch) training loss: 0.0042380965567010865\n",
      "Episode average V value: 0.8162703037261962\n",
      "Average (on the epoch) training loss: 0.004250251147054814\n",
      "Episode average V value: 0.6806797782580057\n",
      "Average (on the epoch) training loss: 0.004237311346494235\n",
      "Episode average V value: 0.4708767587488348\n",
      "Average (on the epoch) training loss: 0.004246567194415191\n",
      "Episode average V value: 0.5065370798110962\n",
      "Average (on the epoch) training loss: 0.004243391258297865\n",
      "Episode average V value: 0.7324711084365845\n",
      "Average (on the epoch) training loss: 0.004229651001956442\n",
      "Episode average V value: 0.6229122132062912\n",
      "Average (on the epoch) training loss: 0.00423796866965794\n",
      "Episode average V value: 0.45902740210294724\n",
      "Average (on the epoch) training loss: 0.004247458412250551\n",
      "Episode average V value: 0.5689028203487396\n",
      "Average (on the epoch) training loss: 0.004247952040962197\n",
      "Episode average V value: 0.7444571495056153\n",
      "Average (on the epoch) training loss: 0.004253317834498567\n",
      "Episode average V value: 0.5082051157951355\n",
      "Average (on the epoch) training loss: 0.00426268036637628\n",
      "Episode average V value: 0.7038388748963674\n",
      "Average (on the epoch) training loss: 0.004257972111071668\n",
      "Episode average V value: 0.4840386211872101\n",
      "Average (on the epoch) training loss: 0.004259602320398914\n",
      "Episode average V value: 0.7443730235099792\n",
      "Average (on the epoch) training loss: 0.00426913707499999\n",
      "Episode average V value: 0.5812457054853439\n",
      "Average (on the epoch) training loss: 0.0042709189712728905\n",
      "Episode average V value: 0.8857332269350687\n",
      "Average (on the epoch) training loss: 0.004272893322147913\n",
      "Episode average V value: 0.4282691180706024\n",
      "Average (on the epoch) training loss: 0.004281104436701106\n",
      "Episode average V value: 0.7788009544213613\n",
      "Average (on the epoch) training loss: 0.00427921443331188\n",
      "Episode average V value: 0.7452239096164703\n",
      "Average (on the epoch) training loss: 0.004275322510072452\n",
      "Episode average V value: 0.5045606891314188\n",
      "Average (on the epoch) training loss: 0.0042773446264563\n",
      "Episode average V value: 0.7061414420604706\n",
      "Average (on the epoch) training loss: 0.004270403523057991\n",
      "Episode average V value: 0.736597648688725\n",
      "Average (on the epoch) training loss: 0.004275368898026084\n",
      "Episode average V value: 0.8980080485343933\n",
      "Average (on the epoch) training loss: 0.004270343318849322\n",
      "Episode average V value: 0.4451889663934708\n",
      "Average (on the epoch) training loss: 0.004264606709813678\n",
      "Episode average V value: 0.7057531327009201\n",
      "Average (on the epoch) training loss: 0.004245187072365573\n",
      "Episode average V value: 0.5185494806085315\n",
      "Average (on the epoch) training loss: 0.004244238828666994\n",
      "Episode average V value: 0.9432967603206635\n",
      "Average (on the epoch) training loss: 0.004240054815116735\n",
      "Episode average V value: 0.8345569372177124\n",
      "Average (on the epoch) training loss: 0.0042421425727157975\n",
      "Episode average V value: 0.9333193600177765\n",
      "Average (on the epoch) training loss: 0.004243275871342919\n",
      "Episode average V value: 0.8899953365325928\n",
      "Average (on the epoch) training loss: 0.004235380898533205\n",
      "Episode average V value: 0.6536306270531246\n",
      "Average (on the epoch) training loss: 0.004260022575739915\n",
      "Episode average V value: 0.4550051309845664\n",
      "Average (on the epoch) training loss: 0.0042670120632676625\n",
      "Episode average V value: 0.5695292864527021\n",
      "Average (on the epoch) training loss: 0.004263922711483582\n",
      "Episode average V value: 0.8970338106155396\n",
      "Average (on the epoch) training loss: 0.004276189148508673\n",
      "Episode average V value: 0.5404841184616089\n",
      "Average (on the epoch) training loss: 0.00428549722362106\n",
      "Episode average V value: 0.5444875061511993\n",
      "Average (on the epoch) training loss: 0.004280316701558771\n",
      "Episode average V value: 0.6975384099142892\n",
      "Average (on the epoch) training loss: 0.004280139468620646\n",
      "Episode average V value: 0.6170448005199433\n",
      "Average (on the epoch) training loss: 0.004278367894811105\n",
      "Episode average V value: 0.8986953496932983\n",
      "Average (on the epoch) training loss: 0.004275767856333814\n",
      "Episode average V value: 0.5493424385786057\n",
      "Average (on the epoch) training loss: 0.004280928300841218\n",
      "Episode average V value: 0.6729729533195495\n",
      "Average (on the epoch) training loss: 0.004278048464488319\n",
      "Episode average V value: 0.4884690290147608\n",
      "Average (on the epoch) training loss: 0.00428428109687785\n",
      "Episode average V value: 0.7444609224796295\n",
      "Average (on the epoch) training loss: 0.004274518446343006\n",
      "Episode average V value: 0.4757294627753171\n",
      "Average (on the epoch) training loss: 0.004277857197699126\n",
      "Episode average V value: 0.6565161943435669\n",
      "Average (on the epoch) training loss: 0.004277220847982273\n",
      "Episode average V value: 0.6038745989402136\n",
      "Average (on the epoch) training loss: 0.004295218623511439\n",
      "Episode average V value: 0.4236450232565403\n",
      "Average (on the epoch) training loss: 0.004298189466401512\n",
      "Episode average V value: 0.38062926701136995\n",
      "Average (on the epoch) training loss: 0.004292481211840036\n",
      "Episode average V value: 0.454751274802468\n",
      "Average (on the epoch) training loss: 0.004300796670917973\n",
      "Episode average V value: 0.5086559628446897\n",
      "LOSSES\n",
      "T = 0.01708509665634483; R = 0.0332095037214458;                 Gamma = 0.5129534237980843; Q = 0.004384350644075312;\n",
      "Entropy Neighbor = 0.5001059492826462;                 Entropy Random = 0.15251559709757567;                 Volume = 0.22209673011302947; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004295782927423716\n",
      "Episode average V value: 0.5632138947645823\n",
      "epoch 31:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0420, -1.0663, -0.1073, -0.9415, -1.1604], device='cuda:0') tensor([-0.8939, -0.9489, -0.0559, -0.9678, -1.1563], device='cuda:0') tensor([-0.6454, -0.6940, -0.0155, -0.7900, -0.9703], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1400], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004231526411604136\n",
      "Episode average V value: 0.441493883728981\n",
      "Average (on the epoch) training loss: 0.0042266047814683546\n",
      "Episode average V value: 0.4396641796285456\n",
      "Average (on the epoch) training loss: 0.004294875198975205\n",
      "Episode average V value: 0.8086584955453873\n",
      "Average (on the epoch) training loss: 0.004179320975182284\n",
      "Episode average V value: 0.5431123238343459\n",
      "Average (on the epoch) training loss: 0.004063457266117136\n",
      "Episode average V value: 0.7578242421150208\n",
      "Average (on the epoch) training loss: 0.004035254451051607\n",
      "Episode average V value: 0.5786344959185674\n",
      "Average (on the epoch) training loss: 0.004080569745636866\n",
      "Episode average V value: 0.7489622831344604\n",
      "Average (on the epoch) training loss: 0.004120454584846079\n",
      "Episode average V value: 0.5535866270462672\n",
      "Average (on the epoch) training loss: 0.004287933488713874\n",
      "Episode average V value: 0.514899492263794\n",
      "Average (on the epoch) training loss: 0.004318933518001492\n",
      "Episode average V value: 0.4885721940260667\n",
      "Average (on the epoch) training loss: 0.004301881318018993\n",
      "Episode average V value: 0.5078894893328348\n",
      "Average (on the epoch) training loss: 0.004225571909429212\n",
      "Episode average V value: 0.439622238278389\n",
      "Average (on the epoch) training loss: 0.004227950795715259\n",
      "Episode average V value: 0.4810810883839925\n",
      "Average (on the epoch) training loss: 0.00429869720210263\n",
      "Episode average V value: 0.5805023738316127\n",
      "Average (on the epoch) training loss: 0.004352870085687541\n",
      "Episode average V value: 0.5298156961798668\n",
      "Average (on the epoch) training loss: 0.004285573669975357\n",
      "Episode average V value: 0.7114261090755463\n",
      "Average (on the epoch) training loss: 0.0042380110050241155\n",
      "Episode average V value: 0.7407896263258797\n",
      "Average (on the epoch) training loss: 0.004247181614659526\n",
      "Episode average V value: 1.0007984638214111\n",
      "Average (on the epoch) training loss: 0.004227772197306254\n",
      "Episode average V value: 0.8548454642295837\n",
      "Average (on the epoch) training loss: 0.004257946334494527\n",
      "Episode average V value: 0.643537449836731\n",
      "Average (on the epoch) training loss: 0.004209508566590875\n",
      "Episode average V value: 0.5919860551754633\n",
      "Average (on the epoch) training loss: 0.00424489465658553\n",
      "Episode average V value: 0.5592921048402786\n",
      "Average (on the epoch) training loss: 0.00422096288694656\n",
      "Episode average V value: 0.5140618085861206\n",
      "Average (on the epoch) training loss: 0.004156823016189461\n",
      "Episode average V value: 0.4864310026168823\n",
      "Average (on the epoch) training loss: 0.004226679957640704\n",
      "Episode average V value: 0.5510309735933939\n",
      "Average (on the epoch) training loss: 0.004206183495265454\n",
      "Episode average V value: 0.7154177029927572\n",
      "Average (on the epoch) training loss: 0.004181360824271863\n",
      "Episode average V value: 0.6974831558763981\n",
      "Average (on the epoch) training loss: 0.004155996548712488\n",
      "Episode average V value: 0.7416699273245675\n",
      "Average (on the epoch) training loss: 0.0041052218223216405\n",
      "Episode average V value: 0.39779255125257706\n",
      "Average (on the epoch) training loss: 0.0041111817876388485\n",
      "Episode average V value: 0.44535580506691563\n",
      "Average (on the epoch) training loss: 0.004112167122413314\n",
      "Episode average V value: 0.8990501364072164\n",
      "Average (on the epoch) training loss: 0.004086644629815843\n",
      "Episode average V value: 0.5891451954841613\n",
      "Average (on the epoch) training loss: 0.004094112670778247\n",
      "Episode average V value: 0.8084428310394287\n",
      "Average (on the epoch) training loss: 0.004146125786147027\n",
      "Episode average V value: 0.35973088656152996\n",
      "Average (on the epoch) training loss: 0.0041366858372367836\n",
      "Episode average V value: 0.7172772685686747\n",
      "Average (on the epoch) training loss: 0.004069209972136513\n",
      "Episode average V value: 0.5001286821705955\n",
      "Average (on the epoch) training loss: 0.004109825885915261\n",
      "Episode average V value: 0.5618353022469414\n",
      "Average (on the epoch) training loss: 0.004097070297043758\n",
      "Episode average V value: 0.49227481087048847\n",
      "Average (on the epoch) training loss: 0.0040644352199226425\n",
      "Episode average V value: 0.680825874209404\n",
      "Average (on the epoch) training loss: 0.004055560760757631\n",
      "Episode average V value: 0.818471348285675\n",
      "Average (on the epoch) training loss: 0.0040870953293947075\n",
      "Episode average V value: 0.45209162072701886\n",
      "Average (on the epoch) training loss: 0.004089365620451745\n",
      "Episode average V value: 0.8425313830375671\n",
      "Average (on the epoch) training loss: 0.004103146423869653\n",
      "Episode average V value: 0.9472872018814087\n",
      "Average (on the epoch) training loss: 0.004105121794602755\n",
      "Episode average V value: 0.8530603647232056\n",
      "Average (on the epoch) training loss: 0.004130874196626797\n",
      "Episode average V value: 0.6165690223375956\n",
      "Average (on the epoch) training loss: 0.004160145813908788\n",
      "Episode average V value: 0.422526661838804\n",
      "Average (on the epoch) training loss: 0.0041300838012631015\n",
      "Episode average V value: 0.44326173112942624\n",
      "Average (on the epoch) training loss: 0.0041226916106753666\n",
      "Episode average V value: 0.8425798416137695\n",
      "Average (on the epoch) training loss: 0.004124972138654541\n",
      "Episode average V value: 0.7704917589823405\n",
      "Average (on the epoch) training loss: 0.0041339367317243855\n",
      "Episode average V value: 0.8284282833337784\n",
      "Average (on the epoch) training loss: 0.004099455041392626\n",
      "Episode average V value: 0.6572349837848118\n",
      "Average (on the epoch) training loss: 0.004085174837441906\n",
      "Episode average V value: 0.517377946111891\n",
      "Average (on the epoch) training loss: 0.004076372356428495\n",
      "Episode average V value: 0.602411150932312\n",
      "Average (on the epoch) training loss: 0.004079180528622186\n",
      "Episode average V value: 0.7520051598548889\n",
      "Average (on the epoch) training loss: 0.004079806290234141\n",
      "Episode average V value: 0.8535685241222382\n",
      "Average (on the epoch) training loss: 0.004054014126541889\n",
      "Episode average V value: 0.5523340068757534\n",
      "Average (on the epoch) training loss: 0.004058155360125879\n",
      "Episode average V value: 0.5023579349120458\n",
      "Average (on the epoch) training loss: 0.004042214876258271\n",
      "Episode average V value: 0.7750818530718485\n",
      "Average (on the epoch) training loss: 0.004047136704334683\n",
      "Episode average V value: 0.7501610815525055\n",
      "Average (on the epoch) training loss: 0.00405047215270678\n",
      "Episode average V value: 0.810118556022644\n",
      "Average (on the epoch) training loss: 0.00403388616107746\n",
      "Episode average V value: 0.7137277871370316\n",
      "Average (on the epoch) training loss: 0.004055731123968211\n",
      "Episode average V value: 0.8931429982185364\n",
      "Average (on the epoch) training loss: 0.004086069530394667\n",
      "Episode average V value: 0.46099218455227936\n",
      "Average (on the epoch) training loss: 0.004076388378843145\n",
      "Episode average V value: 0.6620959440867106\n",
      "Average (on the epoch) training loss: 0.0040734585312976945\n",
      "Episode average V value: 0.4873814880847931\n",
      "Average (on the epoch) training loss: 0.004083393035162018\n",
      "Episode average V value: 0.6225281059741974\n",
      "Average (on the epoch) training loss: 0.004091992485976874\n",
      "Episode average V value: 0.7940389394760132\n",
      "Average (on the epoch) training loss: 0.0040945763427666145\n",
      "Episode average V value: 0.9453689754009247\n",
      "Average (on the epoch) training loss: 0.004116911193405742\n",
      "Episode average V value: 0.5323179797692732\n",
      "Average (on the epoch) training loss: 0.004111824221325775\n",
      "Episode average V value: 0.9954323172569275\n",
      "Average (on the epoch) training loss: 0.004110494310988279\n",
      "Episode average V value: 0.5639810529020097\n",
      "LOSSES\n",
      "T = 0.016693324740976095; R = 0.032769155068323015;                 Gamma = 0.5128763881921768; Q = 0.004101881378563121;\n",
      "Entropy Neighbor = 0.4942081400156021;                 Entropy Random = 0.15252657207846643;                 Volume = 0.2282266713604331; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0984, -1.1839, -0.2217, -0.7554, -0.7912], device='cuda:0') tensor([-0.9391, -1.0590, -0.2024, -0.8481, -1.0785], device='cuda:0') tensor([-0.9002, -0.9555, -0.1143, -0.8114, -0.9491], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0640], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004122821894371256\n",
      "Episode average V value: 0.5595906853675843\n",
      "Average (on the epoch) training loss: 0.004112526602284561\n",
      "Episode average V value: 0.7500381708145142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004114107967535947\n",
      "Episode average V value: 0.3930607378482819\n",
      "Average (on the epoch) training loss: 0.004122828999902113\n",
      "Episode average V value: 0.9954858422279358\n",
      "Average (on the epoch) training loss: 0.004112891534268714\n",
      "Episode average V value: 0.8099669098854065\n",
      "Average (on the epoch) training loss: 0.004102235953208456\n",
      "Episode average V value: 0.7406310141086578\n",
      "Average (on the epoch) training loss: 0.004096629729429313\n",
      "Episode average V value: 0.888547420501709\n",
      "Average (on the epoch) training loss: 0.004082645676778943\n",
      "Episode average V value: 0.7497418045997619\n",
      "Average (on the epoch) training loss: 0.00408469466233353\n",
      "Episode average V value: 0.7440655589103699\n",
      "Average (on the epoch) training loss: 0.00409890874756337\n",
      "Episode average V value: 0.6426102850172255\n",
      "Average (on the epoch) training loss: 0.004090388497289384\n",
      "Episode average V value: 0.5260813940655101\n",
      "Average (on the epoch) training loss: 0.004088340915445697\n",
      "Episode average V value: 0.5014458298683167\n",
      "Average (on the epoch) training loss: 0.004100117459090362\n",
      "Episode average V value: 0.3899262547492981\n",
      "Average (on the epoch) training loss: 0.004102832026695563\n",
      "Episode average V value: 0.6724178067275456\n",
      "Average (on the epoch) training loss: 0.0041076468466543494\n",
      "Episode average V value: 0.8437471389770508\n",
      "Average (on the epoch) training loss: 0.00410437164611503\n",
      "Episode average V value: 0.9006552497545878\n",
      "Average (on the epoch) training loss: 0.00410562530320119\n",
      "Episode average V value: 0.7022253036499023\n",
      "Average (on the epoch) training loss: 0.004099903945708818\n",
      "Episode average V value: 0.6743046641349792\n",
      "Average (on the epoch) training loss: 0.004111422843175428\n",
      "Episode average V value: 0.44600796699523926\n",
      "Average (on the epoch) training loss: 0.004128058904402233\n",
      "Episode average V value: 0.5174288815922208\n",
      "Average (on the epoch) training loss: 0.0041347119778164815\n",
      "Episode average V value: 0.6650157504611545\n",
      "Average (on the epoch) training loss: 0.004126085266727573\n",
      "Episode average V value: 0.7182934284210205\n",
      "Average (on the epoch) training loss: 0.004127810201134707\n",
      "Episode average V value: 0.8511549234390259\n",
      "Average (on the epoch) training loss: 0.004124600845753312\n",
      "Episode average V value: 0.4459267631173134\n",
      "Average (on the epoch) training loss: 0.004128879743317763\n",
      "Episode average V value: 0.7382739271436419\n",
      "Average (on the epoch) training loss: 0.00413231298582451\n",
      "Episode average V value: 0.45021891593933105\n",
      "Average (on the epoch) training loss: 0.004127909995753456\n",
      "Episode average V value: 0.8970711827278137\n",
      "Average (on the epoch) training loss: 0.0041204447375254374\n",
      "Episode average V value: 0.8153274893760681\n",
      "Average (on the epoch) training loss: 0.004113456368935804\n",
      "Episode average V value: 0.8526748865842819\n",
      "Average (on the epoch) training loss: 0.004117554313268681\n",
      "Episode average V value: 0.9438092112541199\n",
      "Average (on the epoch) training loss: 0.004118786719895685\n",
      "Episode average V value: 0.6175505220890045\n",
      "Average (on the epoch) training loss: 0.004133770490046696\n",
      "Episode average V value: 0.46667737141251564\n",
      "Average (on the epoch) training loss: 0.004126562513785413\n",
      "Episode average V value: 0.41829289495944977\n",
      "Average (on the epoch) training loss: 0.004130977783955291\n",
      "Episode average V value: 0.6240557928880056\n",
      "Average (on the epoch) training loss: 0.004141308968571161\n",
      "Episode average V value: 0.6334902942180634\n",
      "Average (on the epoch) training loss: 0.004154169393586926\n",
      "Episode average V value: 0.754656712214152\n",
      "Average (on the epoch) training loss: 0.00416643060643935\n",
      "Episode average V value: 0.4890072405338287\n",
      "Average (on the epoch) training loss: 0.004171335758134487\n",
      "Episode average V value: 0.45049124414270575\n",
      "Average (on the epoch) training loss: 0.004170024665158115\n",
      "Episode average V value: 0.6917287349700928\n",
      "Average (on the epoch) training loss: 0.0041684988775653065\n",
      "Episode average V value: 1.0008647441864014\n",
      "Average (on the epoch) training loss: 0.004181934825026789\n",
      "Episode average V value: 0.603493723002347\n",
      "Average (on the epoch) training loss: 0.0041788094653058775\n",
      "Episode average V value: 0.8049778342247009\n",
      "Average (on the epoch) training loss: 0.004177518241185369\n",
      "Episode average V value: 0.529122531414032\n",
      "Average (on the epoch) training loss: 0.00420257405947716\n",
      "Episode average V value: 0.6489507726260594\n",
      "Average (on the epoch) training loss: 0.004203696800605132\n",
      "Episode average V value: 0.5956949830055237\n",
      "Average (on the epoch) training loss: 0.004210660334977446\n",
      "Episode average V value: 0.5281655232111613\n",
      "Average (on the epoch) training loss: 0.0041918911988691925\n",
      "Episode average V value: 0.6541042029857635\n",
      "Average (on the epoch) training loss: 0.00418809636354898\n",
      "Episode average V value: 0.741028219461441\n",
      "Average (on the epoch) training loss: 0.004192651709273993\n",
      "Episode average V value: 0.39958210123909843\n",
      "Average (on the epoch) training loss: 0.004189432982738061\n",
      "Episode average V value: 0.6424040964671544\n",
      "Average (on the epoch) training loss: 0.004192388023266338\n",
      "Episode average V value: 0.8998199303944906\n",
      "Average (on the epoch) training loss: 0.004164171189070821\n",
      "Episode average V value: 0.4359767572446303\n",
      "Average (on the epoch) training loss: 0.004189982669048028\n",
      "Episode average V value: 0.45956727599396424\n",
      "Average (on the epoch) training loss: 0.004187976845504088\n",
      "Episode average V value: 0.8871458570162455\n",
      "Average (on the epoch) training loss: 0.004189533677751858\n",
      "Episode average V value: 0.503176748752594\n",
      "Average (on the epoch) training loss: 0.004188537604158841\n",
      "Episode average V value: 0.43247293763690525\n",
      "Average (on the epoch) training loss: 0.004193025727895124\n",
      "Episode average V value: 0.4175787911965297\n",
      "Average (on the epoch) training loss: 0.0041957844147451785\n",
      "Episode average V value: 0.5201768428087234\n",
      "Average (on the epoch) training loss: 0.004191773815656011\n",
      "Episode average V value: 0.673946065562112\n",
      "Average (on the epoch) training loss: 0.004193426134882717\n",
      "Episode average V value: 0.6127574973636203\n",
      "Average (on the epoch) training loss: 0.004196708856073138\n",
      "Episode average V value: 0.8499913811683655\n",
      "Average (on the epoch) training loss: 0.004190123893483875\n",
      "Episode average V value: 0.5633029772175683\n",
      "Average (on the epoch) training loss: 0.0041847517755861175\n",
      "Episode average V value: 0.6213398426771164\n",
      "Average (on the epoch) training loss: 0.004177001896293284\n",
      "Episode average V value: 0.3600477603348819\n",
      "LOSSES\n",
      "T = 0.017243073155172168; R = 0.033777139573358;                 Gamma = 0.512732382118702; Q = 0.004248510019970127;\n",
      "Entropy Neighbor = 0.4954459112286568;                 Entropy Random = 0.15220922377705573;                 Volume = 0.238639253616333; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004175195699266623\n",
      "Episode average V value: 0.8256925940513611\n",
      "epoch 32:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9642857142857143 (average over 28 episode(s))\n",
      "== Mean score per episode is 0.9642822704204628 over 28 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2694,  0.2104,  0.2562, -0.5770, -0.7982], device='cuda:0') tensor([ 0.2829,  0.1863,  0.2401, -0.5688, -0.8029], device='cuda:0') tensor([ 0.2694,  0.2104,  0.2562, -0.5770, -0.7982], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0026], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004843607810991151\n",
      "Episode average V value: 0.7028727148260389\n",
      "Average (on the epoch) training loss: 0.005724799819290638\n",
      "Episode average V value: 0.6699988096952438\n",
      "Average (on the epoch) training loss: 0.005445839810328415\n",
      "Episode average V value: 0.9467023611068726\n",
      "Average (on the epoch) training loss: 0.004915542931197898\n",
      "Episode average V value: 0.6237922410170237\n",
      "Average (on the epoch) training loss: 0.0047620987276208\n",
      "Episode average V value: 0.9015227754910787\n",
      "Average (on the epoch) training loss: 0.005189348631704759\n",
      "Episode average V value: 0.7714573264122009\n",
      "Average (on the epoch) training loss: 0.004986092244507745\n",
      "Episode average V value: 0.4749218821525574\n",
      "Average (on the epoch) training loss: 0.0046838941308101865\n",
      "Episode average V value: 0.820703101158142\n",
      "Average (on the epoch) training loss: 0.004595875879293125\n",
      "Episode average V value: 0.5588268227875233\n",
      "Average (on the epoch) training loss: 0.004564474481811518\n",
      "Episode average V value: 0.6243983010450999\n",
      "Average (on the epoch) training loss: 0.0045802470250818576\n",
      "Episode average V value: 0.8542814552783966\n",
      "Average (on the epoch) training loss: 0.004464977385941893\n",
      "Episode average V value: 0.5933175550566779\n",
      "Average (on the epoch) training loss: 0.00445446151727221\n",
      "Episode average V value: 0.5486902706325054\n",
      "Average (on the epoch) training loss: 0.004461673506654712\n",
      "Episode average V value: 0.7692557811737061\n",
      "Average (on the epoch) training loss: 0.0044377826301941785\n",
      "Episode average V value: 0.6567326486110687\n",
      "Average (on the epoch) training loss: 0.004316643746569752\n",
      "Episode average V value: 0.6747915319034031\n",
      "Average (on the epoch) training loss: 0.00424791767092591\n",
      "Episode average V value: 0.5817423939704895\n",
      "Average (on the epoch) training loss: 0.004239546162231515\n",
      "Episode average V value: 0.5256061822175979\n",
      "Average (on the epoch) training loss: 0.004228355799809344\n",
      "Episode average V value: 0.9963245391845703\n",
      "Average (on the epoch) training loss: 0.004278158537868032\n",
      "Episode average V value: 0.3048754492226769\n",
      "Average (on the epoch) training loss: 0.004212298213032126\n",
      "Episode average V value: 0.7583350439866384\n",
      "Average (on the epoch) training loss: 0.004255525643877205\n",
      "Episode average V value: 0.4133934405716983\n",
      "Average (on the epoch) training loss: 0.004284842121929067\n",
      "Episode average V value: 0.6323134936392307\n",
      "Average (on the epoch) training loss: 0.004289981055848613\n",
      "Episode average V value: 0.8595078140497208\n",
      "Average (on the epoch) training loss: 0.004287473610713191\n",
      "Episode average V value: 1.0040289163589478\n",
      "Average (on the epoch) training loss: 0.004292922138291247\n",
      "Episode average V value: 0.9491644501686096\n",
      "Average (on the epoch) training loss: 0.004403553015516443\n",
      "Episode average V value: 0.5697639990936626\n",
      "Average (on the epoch) training loss: 0.0043878174670920755\n",
      "Episode average V value: 0.9956180453300476\n",
      "Average (on the epoch) training loss: 0.00436368684149197\n",
      "Episode average V value: 0.8293905556201935\n",
      "Average (on the epoch) training loss: 0.0043249793497249864\n",
      "Episode average V value: 0.5270138843493029\n",
      "Average (on the epoch) training loss: 0.004311137801885386\n",
      "Episode average V value: 0.5152688792773655\n",
      "Average (on the epoch) training loss: 0.004301333366146416\n",
      "Episode average V value: 0.6016871482133865\n",
      "Average (on the epoch) training loss: 0.0043115555319588545\n",
      "Episode average V value: 0.8074738383293152\n",
      "Average (on the epoch) training loss: 0.004320162012715757\n",
      "Episode average V value: 0.6478311187691159\n",
      "Average (on the epoch) training loss: 0.004330216602260328\n",
      "Episode average V value: 0.7567817618449529\n",
      "Average (on the epoch) training loss: 0.004316794969029082\n",
      "Episode average V value: 0.7595717906951904\n",
      "Average (on the epoch) training loss: 0.004324913841782738\n",
      "Episode average V value: 0.6548697799444199\n",
      "Average (on the epoch) training loss: 0.004293063583037974\n",
      "Episode average V value: 0.7635884433984756\n",
      "Average (on the epoch) training loss: 0.004283941647807053\n",
      "Episode average V value: 0.6902307520310084\n",
      "Average (on the epoch) training loss: 0.0042561710705361\n",
      "Episode average V value: 0.6509283951350621\n",
      "Average (on the epoch) training loss: 0.004260529015204465\n",
      "Episode average V value: 0.44268773089755664\n",
      "Average (on the epoch) training loss: 0.004213810238044074\n",
      "Episode average V value: 0.4505273699760437\n",
      "Average (on the epoch) training loss: 0.004208150465482115\n",
      "Episode average V value: 0.5032254606485367\n",
      "Average (on the epoch) training loss: 0.004208579019572333\n",
      "Episode average V value: 0.45533258517583214\n",
      "Average (on the epoch) training loss: 0.004200273545187277\n",
      "Episode average V value: 0.7987855315208435\n",
      "Average (on the epoch) training loss: 0.0041913960913762425\n",
      "Episode average V value: 0.5224502086639404\n",
      "Average (on the epoch) training loss: 0.004153874247724441\n",
      "Episode average V value: 0.5675189305435527\n",
      "Average (on the epoch) training loss: 0.004137703472784219\n",
      "Episode average V value: 0.4860338494181633\n",
      "Average (on the epoch) training loss: 0.004151215027506634\n",
      "Episode average V value: 0.42339715590843785\n",
      "Average (on the epoch) training loss: 0.004155273138488407\n",
      "Episode average V value: 0.4398607932604276\n",
      "Average (on the epoch) training loss: 0.004146203779655785\n",
      "Episode average V value: 0.5905916265078953\n",
      "Average (on the epoch) training loss: 0.004165202135331775\n",
      "Episode average V value: 0.7549070596694947\n",
      "Average (on the epoch) training loss: 0.004173749714705942\n",
      "Episode average V value: 0.578127404054006\n",
      "Average (on the epoch) training loss: 0.004164536545208741\n",
      "Episode average V value: 0.41991587389599194\n",
      "Average (on the epoch) training loss: 0.004143191076846878\n",
      "Episode average V value: 0.8980414271354675\n",
      "Average (on the epoch) training loss: 0.00415089169040411\n",
      "Episode average V value: 0.6626072724660238\n",
      "Average (on the epoch) training loss: 0.0041281887595187965\n",
      "Episode average V value: 0.5719973966479301\n",
      "Average (on the epoch) training loss: 0.004119736512365541\n",
      "Episode average V value: 0.4710694659839977\n",
      "Average (on the epoch) training loss: 0.004108047656850556\n",
      "Episode average V value: 0.5563732385635376\n",
      "Average (on the epoch) training loss: 0.004136190430352852\n",
      "Episode average V value: 0.6721161007881165\n",
      "Average (on the epoch) training loss: 0.004150917583084284\n",
      "Episode average V value: 0.5652841230233511\n",
      "Average (on the epoch) training loss: 0.004158677125558315\n",
      "Episode average V value: 0.8935380578041077\n",
      "Average (on the epoch) training loss: 0.004124600320186773\n",
      "Episode average V value: 0.6993692331016064\n",
      "Average (on the epoch) training loss: 0.004121699635875751\n",
      "Episode average V value: 0.8099913895130157\n",
      "Average (on the epoch) training loss: 0.004131615724075475\n",
      "Episode average V value: 0.6576230883598327\n",
      "Average (on the epoch) training loss: 0.004143849402517353\n",
      "Episode average V value: 0.44102191073553904\n",
      "Average (on the epoch) training loss: 0.004153356438352548\n",
      "Episode average V value: 0.6156152635812759\n",
      "Average (on the epoch) training loss: 0.004145416304677853\n",
      "Episode average V value: 0.6751414636770884\n",
      "LOSSES\n",
      "T = 0.017634274129755795; R = 0.03390534564945847;                 Gamma = 0.5109866950511932; Q = 0.004141691854805686;\n",
      "Entropy Neighbor = 0.48756331658363344;                 Entropy Random = 0.14938925209641457;                 Volume = 0.2458430680334568; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0086, -0.0502,  0.1668, -0.6225, -0.8221], device='cuda:0') tensor([ 0.0709,  0.0332,  0.1984, -0.6260, -0.8326], device='cuda:0') tensor([ 0.1088,  0.0639,  0.2184, -0.6458, -0.8927], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0075], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004133872687700668\n",
      "Episode average V value: 0.4596459236409929\n",
      "Average (on the epoch) training loss: 0.00416637361736204\n",
      "Episode average V value: 0.671415513753891\n",
      "Average (on the epoch) training loss: 0.004163448372196399\n",
      "Episode average V value: 0.830244317650795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004175258192775228\n",
      "Episode average V value: 0.3838039666414261\n",
      "Average (on the epoch) training loss: 0.004169326488795934\n",
      "Episode average V value: 0.5220807790756226\n",
      "Average (on the epoch) training loss: 0.004167265698822894\n",
      "Episode average V value: 0.9028398593266805\n",
      "Average (on the epoch) training loss: 0.004153422740984435\n",
      "Episode average V value: 0.43002431392669677\n",
      "Average (on the epoch) training loss: 0.004132955205929087\n",
      "Episode average V value: 0.4316115416586399\n",
      "Average (on the epoch) training loss: 0.004130498380186673\n",
      "Episode average V value: 0.723647395769755\n",
      "Average (on the epoch) training loss: 0.004136194343795275\n",
      "Episode average V value: 0.6667004142488752\n",
      "Average (on the epoch) training loss: 0.004133073659920085\n",
      "Episode average V value: 0.46665103094918386\n",
      "Average (on the epoch) training loss: 0.004135030579100342\n",
      "Episode average V value: 0.4035353345029494\n",
      "Average (on the epoch) training loss: 0.0041439223110907464\n",
      "Episode average V value: 0.9006814161936442\n",
      "Average (on the epoch) training loss: 0.004133894480745234\n",
      "Episode average V value: 0.9471144676208496\n",
      "Average (on the epoch) training loss: 0.004131531175786491\n",
      "Episode average V value: 0.9946720600128174\n",
      "Average (on the epoch) training loss: 0.00412654035578985\n",
      "Episode average V value: 0.7628845870494843\n",
      "Average (on the epoch) training loss: 0.0041388322852893\n",
      "Episode average V value: 0.9467857182025909\n",
      "Average (on the epoch) training loss: 0.0041235368089908445\n",
      "Episode average V value: 0.6164882108569145\n",
      "Average (on the epoch) training loss: 0.004125180110766938\n",
      "Episode average V value: 0.4490183889865875\n",
      "Average (on the epoch) training loss: 0.0041273881554062045\n",
      "Episode average V value: 0.5949431711977179\n",
      "Average (on the epoch) training loss: 0.004148258562257617\n",
      "Episode average V value: 0.4200511789984173\n",
      "Average (on the epoch) training loss: 0.004145600101657847\n",
      "Episode average V value: 0.9929381012916565\n",
      "Average (on the epoch) training loss: 0.004178114877353516\n",
      "Episode average V value: 0.3524582245770623\n",
      "Average (on the epoch) training loss: 0.004174560377676342\n",
      "Episode average V value: 0.6648512085278829\n",
      "Average (on the epoch) training loss: 0.00417412157883887\n",
      "Episode average V value: 0.770681631565094\n",
      "Average (on the epoch) training loss: 0.0041931833512534045\n",
      "Episode average V value: 0.5106521844863892\n",
      "Average (on the epoch) training loss: 0.004205865847567717\n",
      "Episode average V value: 0.5107118023766412\n",
      "Average (on the epoch) training loss: 0.004204072760898523\n",
      "Episode average V value: 0.9107502102851868\n",
      "Average (on the epoch) training loss: 0.004199180503864172\n",
      "Episode average V value: 0.8106258988380433\n",
      "Average (on the epoch) training loss: 0.004192638646848288\n",
      "Episode average V value: 0.7559498647848765\n",
      "Average (on the epoch) training loss: 0.004189858000432581\n",
      "Episode average V value: 0.7728723168373108\n",
      "Average (on the epoch) training loss: 0.0041827535968567845\n",
      "Episode average V value: 0.6671979469912392\n",
      "Average (on the epoch) training loss: 0.004175534661912234\n",
      "Episode average V value: 0.7525948524475098\n",
      "Average (on the epoch) training loss: 0.004171274703048829\n",
      "Episode average V value: 0.9923362135887146\n",
      "Average (on the epoch) training loss: 0.0041786013855216134\n",
      "Episode average V value: 0.6762039874281202\n",
      "Average (on the epoch) training loss: 0.004176209216496403\n",
      "Episode average V value: 0.711908791746412\n",
      "Average (on the epoch) training loss: 0.004173244123831441\n",
      "Episode average V value: 0.5192160552198236\n",
      "Average (on the epoch) training loss: 0.0041566417527683225\n",
      "Episode average V value: 0.5078719827261838\n",
      "Average (on the epoch) training loss: 0.004154592050340911\n",
      "Episode average V value: 0.48646196474631626\n",
      "Average (on the epoch) training loss: 0.004154256426649161\n",
      "Episode average V value: 0.5937842912971973\n",
      "Average (on the epoch) training loss: 0.004156394222245209\n",
      "Episode average V value: 0.671096122264862\n",
      "Average (on the epoch) training loss: 0.004157318458361905\n",
      "Episode average V value: 0.8522626161575317\n",
      "Average (on the epoch) training loss: 0.0041631919400242625\n",
      "Episode average V value: 0.5556145840220981\n",
      "Average (on the epoch) training loss: 0.004174878049525432\n",
      "Episode average V value: 0.5950784683227539\n",
      "Average (on the epoch) training loss: 0.004178475091136118\n",
      "Episode average V value: 0.6782713532447815\n",
      "Average (on the epoch) training loss: 0.0041785995771169175\n",
      "Episode average V value: 0.4266603643243963\n",
      "Average (on the epoch) training loss: 0.004176875432652558\n",
      "Episode average V value: 0.6933097958564758\n",
      "Average (on the epoch) training loss: 0.004176468478090429\n",
      "Episode average V value: 0.8524270802736282\n",
      "Average (on the epoch) training loss: 0.004169938177101529\n",
      "Episode average V value: 0.480397071908502\n",
      "Average (on the epoch) training loss: 0.004165463507837489\n",
      "Episode average V value: 0.656356792896986\n",
      "Average (on the epoch) training loss: 0.004147987296905571\n",
      "Episode average V value: 0.5955868437886238\n",
      "Average (on the epoch) training loss: 0.004151380795053605\n",
      "Episode average V value: 0.46632166504859923\n",
      "Average (on the epoch) training loss: 0.004148869331518256\n",
      "Episode average V value: 0.8083228319883347\n",
      "Average (on the epoch) training loss: 0.004151458104014731\n",
      "Episode average V value: 0.6643311778704325\n",
      "Average (on the epoch) training loss: 0.0041487134547122115\n",
      "Episode average V value: 0.5224385153163563\n",
      "Average (on the epoch) training loss: 0.004152883762990263\n",
      "Episode average V value: 0.4864190427156595\n",
      "Average (on the epoch) training loss: 0.004157666195225533\n",
      "Episode average V value: 0.6656332711378733\n",
      "Average (on the epoch) training loss: 0.004151267624733749\n",
      "Episode average V value: 0.4457603693008423\n",
      "Average (on the epoch) training loss: 0.00414254231025394\n",
      "Episode average V value: 0.6896926760673523\n",
      "Average (on the epoch) training loss: 0.004145290437836476\n",
      "Episode average V value: 0.5137638092041016\n",
      "Average (on the epoch) training loss: 0.004147596921243951\n",
      "Episode average V value: 0.4466869831085205\n",
      "Average (on the epoch) training loss: 0.004143263518866556\n",
      "Episode average V value: 0.6013982759581672\n",
      "Average (on the epoch) training loss: 0.0041455937886116165\n",
      "Episode average V value: 0.766112893819809\n",
      "Average (on the epoch) training loss: 0.004136674393766897\n",
      "Episode average V value: 0.6633017574037824\n",
      "Average (on the epoch) training loss: 0.004134918761473393\n",
      "Episode average V value: 0.5272009372711182\n",
      "Average (on the epoch) training loss: 0.0041393913884067825\n",
      "Episode average V value: 0.4528546892106533\n",
      "Average (on the epoch) training loss: 0.004128351366229904\n",
      "Episode average V value: 0.5960347776611646\n",
      "LOSSES\n",
      "T = 0.017267183737829327; R = 0.03490407453477383;                 Gamma = 0.5105266666412354; Q = 0.004108713666442782;\n",
      "Entropy Neighbor = 0.48732732915878296;                 Entropy Random = 0.1482434260994196;                 Volume = 0.25273179477453234; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004125202760624233\n",
      "Episode average V value: 0.48548588156700134\n",
      "epoch 33:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9090909090909091 (average over 11 episode(s))\n",
      "== Mean score per episode is 0.90908264470323 over 11 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0304, -0.0029,  0.2090, -0.6968, -0.9732], device='cuda:0') tensor([-0.1411, -0.1392,  0.2020, -0.7297, -0.9665], device='cuda:0') tensor([-0.2616, -0.2955,  0.1154, -0.7527, -1.0061], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0197], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0066710414830595255\n",
      "Episode average V value: 0.7563799023628235\n",
      "Average (on the epoch) training loss: 0.0044178734067827465\n",
      "Episode average V value: 0.8085411389668783\n",
      "Average (on the epoch) training loss: 0.004388914618175477\n",
      "Episode average V value: 0.6666044692198435\n",
      "Average (on the epoch) training loss: 0.003641241122610294\n",
      "Episode average V value: 0.7558285534381867\n",
      "Average (on the epoch) training loss: 0.003951009945012629\n",
      "Episode average V value: 0.6587144533793131\n",
      "Average (on the epoch) training loss: 0.003947445405647159\n",
      "Episode average V value: 0.591940987110138\n",
      "Average (on the epoch) training loss: 0.0038938569705351256\n",
      "Episode average V value: 0.6485518259661538\n",
      "Average (on the epoch) training loss: 0.003745432095363354\n",
      "Episode average V value: 0.6742802361647288\n",
      "Average (on the epoch) training loss: 0.003896375097717871\n",
      "Episode average V value: 0.48369865367809933\n",
      "Average (on the epoch) training loss: 0.003829070415425425\n",
      "Episode average V value: 0.5180327991644541\n",
      "Average (on the epoch) training loss: 0.0038427465278502615\n",
      "Episode average V value: 1.004177212715149\n",
      "Average (on the epoch) training loss: 0.003922373979298425\n",
      "Episode average V value: 0.5296309462615422\n",
      "Average (on the epoch) training loss: 0.003916673194284417\n",
      "Episode average V value: 1.004167914390564\n",
      "Average (on the epoch) training loss: 0.004066370725823082\n",
      "Episode average V value: 0.6686421831448873\n",
      "Average (on the epoch) training loss: 0.0041855373894673234\n",
      "Episode average V value: 0.903694212436676\n",
      "Average (on the epoch) training loss: 0.004325810875086926\n",
      "Episode average V value: 0.7537923753261566\n",
      "Average (on the epoch) training loss: 0.004282349531422369\n",
      "Episode average V value: 0.584300097823143\n",
      "Average (on the epoch) training loss: 0.004195307394652867\n",
      "Episode average V value: 0.618067377143436\n",
      "Average (on the epoch) training loss: 0.004121451820204154\n",
      "Episode average V value: 0.42861712723970413\n",
      "Average (on the epoch) training loss: 0.004126495574166903\n",
      "Episode average V value: 0.6792528480291367\n",
      "Average (on the epoch) training loss: 0.004100471865967847\n",
      "Episode average V value: 0.9391289055347443\n",
      "Average (on the epoch) training loss: 0.004093453435281153\n",
      "Episode average V value: 0.8571256995201111\n",
      "Average (on the epoch) training loss: 0.004115571773161186\n",
      "Episode average V value: 0.4157393184991983\n",
      "Average (on the epoch) training loss: 0.004149138033420481\n",
      "Episode average V value: 0.40824663639068604\n",
      "Average (on the epoch) training loss: 0.004139929121608132\n",
      "Episode average V value: 0.9958527088165283\n",
      "Average (on the epoch) training loss: 0.004123398787312539\n",
      "Episode average V value: 0.8578268736600876\n",
      "Average (on the epoch) training loss: 0.0041263379338488445\n",
      "Episode average V value: 0.9488556385040283\n",
      "Average (on the epoch) training loss: 0.004120144827067162\n",
      "Episode average V value: 0.9481422603130341\n",
      "Average (on the epoch) training loss: 0.004121781466249934\n",
      "Episode average V value: 0.6482909202575684\n",
      "Average (on the epoch) training loss: 0.004168070082827894\n",
      "Episode average V value: 0.7296168165547507\n",
      "Average (on the epoch) training loss: 0.004159194145876482\n",
      "Episode average V value: 0.7518669247627259\n",
      "Average (on the epoch) training loss: 0.0042575114650563115\n",
      "Episode average V value: 0.4393459322123692\n",
      "Average (on the epoch) training loss: 0.0042333833748070555\n",
      "Episode average V value: 0.5309487581253052\n",
      "Average (on the epoch) training loss: 0.0042315840354657025\n",
      "Episode average V value: 0.47645343975587323\n",
      "Average (on the epoch) training loss: 0.004217208993912465\n",
      "Episode average V value: 0.6080904901027679\n",
      "Average (on the epoch) training loss: 0.004173474802531686\n",
      "Episode average V value: 0.6523414850234985\n",
      "Average (on the epoch) training loss: 0.004174991443941816\n",
      "Episode average V value: 0.38277630342377555\n",
      "Average (on the epoch) training loss: 0.004171055840793997\n",
      "Episode average V value: 0.6987771466374397\n",
      "Average (on the epoch) training loss: 0.0041868981545053\n",
      "Episode average V value: 0.49719961086908976\n",
      "Average (on the epoch) training loss: 0.00418663574261487\n",
      "Episode average V value: 0.8564029335975647\n",
      "Average (on the epoch) training loss: 0.004184221470495686\n",
      "Episode average V value: 0.7308178941408793\n",
      "Average (on the epoch) training loss: 0.004260034172624242\n",
      "Episode average V value: 0.7212880452473959\n",
      "Average (on the epoch) training loss: 0.004231654668311353\n",
      "Episode average V value: 0.8322092592716217\n",
      "Average (on the epoch) training loss: 0.004209217250915375\n",
      "Episode average V value: 0.7740871787071228\n",
      "Average (on the epoch) training loss: 0.004209218404169815\n",
      "Episode average V value: 1.0023541450500488\n",
      "Average (on the epoch) training loss: 0.0042069410846027255\n",
      "Episode average V value: 0.9490134716033936\n",
      "Average (on the epoch) training loss: 0.004223300413286779\n",
      "Episode average V value: 0.6729223813329425\n",
      "Average (on the epoch) training loss: 0.004205386290807644\n",
      "Episode average V value: 0.6178052425384521\n",
      "Average (on the epoch) training loss: 0.004207051703341888\n",
      "Episode average V value: 0.6283670142292976\n",
      "Average (on the epoch) training loss: 0.004225030834837846\n",
      "Episode average V value: 0.77332444190979\n",
      "Average (on the epoch) training loss: 0.00418294663701715\n",
      "Episode average V value: 0.7298729760306222\n",
      "Average (on the epoch) training loss: 0.004181214119692252\n",
      "Episode average V value: 0.7513764262199402\n",
      "Average (on the epoch) training loss: 0.004180581787208905\n",
      "Episode average V value: 0.5313200950622559\n",
      "Average (on the epoch) training loss: 0.004165076287606693\n",
      "Episode average V value: 0.7770672559738159\n",
      "Average (on the epoch) training loss: 0.00415332538963201\n",
      "Episode average V value: 0.8127697855234146\n",
      "Average (on the epoch) training loss: 0.00416540659840041\n",
      "Episode average V value: 0.6966787676016489\n",
      "Average (on the epoch) training loss: 0.004176941416051218\n",
      "Episode average V value: 0.5222731381654739\n",
      "Average (on the epoch) training loss: 0.004174132094688848\n",
      "Episode average V value: 0.7558995187282562\n",
      "Average (on the epoch) training loss: 0.004166337274902577\n",
      "Episode average V value: 0.47843137979507444\n",
      "Average (on the epoch) training loss: 0.004159466304507929\n",
      "Episode average V value: 0.6707125703493754\n",
      "Average (on the epoch) training loss: 0.004172051087129653\n",
      "Episode average V value: 0.515381932258606\n",
      "Average (on the epoch) training loss: 0.004169074209877325\n",
      "Episode average V value: 0.8305533826351166\n",
      "Average (on the epoch) training loss: 0.004146018214425576\n",
      "Episode average V value: 0.7815204858779907\n",
      "Average (on the epoch) training loss: 0.00415274455307101\n",
      "Episode average V value: 0.5354087054729462\n",
      "Average (on the epoch) training loss: 0.004140293625561963\n",
      "Episode average V value: 0.5046113133430481\n",
      "Average (on the epoch) training loss: 0.004133767432105802\n",
      "Episode average V value: 0.5515781972143385\n",
      "Average (on the epoch) training loss: 0.004145602530567506\n",
      "Episode average V value: 0.47953165494478667\n",
      "Average (on the epoch) training loss: 0.004146190104126401\n",
      "Episode average V value: 0.4649945944547653\n",
      "Average (on the epoch) training loss: 0.004175887663674715\n",
      "Episode average V value: 0.8332541286945343\n",
      "Average (on the epoch) training loss: 0.004175996885768861\n",
      "Episode average V value: 0.5617587674747814\n",
      "Average (on the epoch) training loss: 0.004179938633430955\n",
      "Episode average V value: 0.7582583477099737\n",
      "Average (on the epoch) training loss: 0.004175362500350285\n",
      "Episode average V value: 0.9935846924781799\n",
      "Average (on the epoch) training loss: 0.0041686061142984805\n",
      "Episode average V value: 0.4062193036079407\n",
      "Average (on the epoch) training loss: 0.004165000782400712\n",
      "Episode average V value: 0.9459897875785828\n",
      "Average (on the epoch) training loss: 0.004174177442806509\n",
      "Episode average V value: 0.5546734631061554\n",
      "Average (on the epoch) training loss: 0.004170425748452544\n",
      "Episode average V value: 0.9372171461582184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.004146507483489167\n",
      "Episode average V value: 0.5905634090304375\n",
      "LOSSES\n",
      "T = 0.017347842006012797; R = 0.03495967228896916;                 Gamma = 0.5098261405229568; Q = 0.004150116550270468;\n",
      "Entropy Neighbor = 0.48170187187194824;                 Entropy Random = 0.14860568833351134;                 Volume = 0.25987633761763573; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9031, -0.9555, -0.1193, -0.8193, -0.9718], device='cuda:0') tensor([-0.8945, -0.9811, -0.1432, -0.8862, -1.1063], device='cuda:0') tensor([-0.9031, -0.9555, -0.1193, -0.8193, -0.9718], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0596], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004123669545001843\n",
      "Episode average V value: 0.46769649936602664\n",
      "Average (on the epoch) training loss: 0.0041123517123132685\n",
      "Episode average V value: 0.8919522166252136\n",
      "Average (on the epoch) training loss: 0.00410053981490469\n",
      "Episode average V value: 0.7428138852119446\n",
      "Average (on the epoch) training loss: 0.004096734353726843\n",
      "Episode average V value: 0.8038547039031982\n",
      "Average (on the epoch) training loss: 0.004076582261027311\n",
      "Episode average V value: 0.5974440932273865\n",
      "Average (on the epoch) training loss: 0.004063768480154504\n",
      "Episode average V value: 0.6631966663731469\n",
      "Average (on the epoch) training loss: 0.004102572177279693\n",
      "Episode average V value: 0.43256518617272377\n",
      "Average (on the epoch) training loss: 0.004108835440949811\n",
      "Episode average V value: 0.5224005315038893\n",
      "Average (on the epoch) training loss: 0.00409613896110023\n",
      "Episode average V value: 0.5116513562202454\n",
      "Average (on the epoch) training loss: 0.004091226162558543\n",
      "Episode average V value: 0.8622657060623169\n",
      "Average (on the epoch) training loss: 0.004073486546012433\n",
      "Episode average V value: 0.4414065107703209\n",
      "Average (on the epoch) training loss: 0.004062946082713187\n",
      "Episode average V value: 0.7335619727770487\n",
      "Average (on the epoch) training loss: 0.0040673338025655655\n",
      "Episode average V value: 0.5552256256341934\n",
      "Average (on the epoch) training loss: 0.00406596348872043\n",
      "Episode average V value: 0.7594798505306244\n",
      "Average (on the epoch) training loss: 0.004061568696527309\n",
      "Episode average V value: 0.8125831127166748\n",
      "Average (on the epoch) training loss: 0.004066961377138044\n",
      "Episode average V value: 0.5052856140666537\n",
      "Average (on the epoch) training loss: 0.004074143664582945\n",
      "Episode average V value: 0.37111708852979874\n",
      "Average (on the epoch) training loss: 0.004064728999100165\n",
      "Episode average V value: 0.5723914951086044\n",
      "Average (on the epoch) training loss: 0.00405831930754227\n",
      "Episode average V value: 0.7580309510231018\n",
      "Average (on the epoch) training loss: 0.004043931370232232\n",
      "Episode average V value: 0.8012731790542602\n",
      "Average (on the epoch) training loss: 0.004042848311378826\n",
      "Episode average V value: 0.7710841298103333\n",
      "Average (on the epoch) training loss: 0.004043752528899732\n",
      "Episode average V value: 0.9997555017471313\n",
      "Average (on the epoch) training loss: 0.0040398963948935045\n",
      "Episode average V value: 0.9998025298118591\n",
      "Average (on the epoch) training loss: 0.0040423629839158705\n",
      "Episode average V value: 0.6541931629180908\n",
      "Average (on the epoch) training loss: 0.004058235165732051\n",
      "Episode average V value: 0.5716582482511346\n",
      "Average (on the epoch) training loss: 0.004074386242554401\n",
      "Episode average V value: 0.3346693345478603\n",
      "Average (on the epoch) training loss: 0.004077521524127685\n",
      "Episode average V value: 0.5093578100204468\n",
      "Average (on the epoch) training loss: 0.004070802707663817\n",
      "Episode average V value: 0.678218686580658\n",
      "Average (on the epoch) training loss: 0.004071517702161067\n",
      "Episode average V value: 0.5780159632364908\n",
      "Average (on the epoch) training loss: 0.0040617731442167\n",
      "Episode average V value: 0.852553591132164\n",
      "Average (on the epoch) training loss: 0.004081256606275597\n",
      "Episode average V value: 0.4132319672240151\n",
      "Average (on the epoch) training loss: 0.004075364224186473\n",
      "Episode average V value: 0.6856737807393074\n",
      "Average (on the epoch) training loss: 0.004075796779828291\n",
      "Episode average V value: 0.9983593821525574\n",
      "Average (on the epoch) training loss: 0.004074320697737306\n",
      "Episode average V value: 0.6835129857063293\n",
      "Average (on the epoch) training loss: 0.004084808506343913\n",
      "Episode average V value: 0.6823030539921352\n",
      "Average (on the epoch) training loss: 0.004080034004649254\n",
      "Episode average V value: 0.9135891795158386\n",
      "Average (on the epoch) training loss: 0.004095621851485858\n",
      "Episode average V value: 0.7817382911841074\n",
      "Average (on the epoch) training loss: 0.004095585639132413\n",
      "Episode average V value: 0.5850934215954372\n",
      "Average (on the epoch) training loss: 0.004089574460449512\n",
      "Episode average V value: 0.42177778316868675\n",
      "Average (on the epoch) training loss: 0.0040985450669851565\n",
      "Episode average V value: 0.7503482103347778\n",
      "Average (on the epoch) training loss: 0.004090064465873439\n",
      "Episode average V value: 0.5684787531693777\n",
      "Average (on the epoch) training loss: 0.004085274339119745\n",
      "Episode average V value: 0.5503783263266087\n",
      "Average (on the epoch) training loss: 0.004101184828698617\n",
      "Episode average V value: 0.7567086517810822\n",
      "Average (on the epoch) training loss: 0.004099268855228296\n",
      "Episode average V value: 0.5330972671508789\n",
      "Average (on the epoch) training loss: 0.0040965799758291375\n",
      "Episode average V value: 0.5706571506129371\n",
      "Average (on the epoch) training loss: 0.004098365393273726\n",
      "Episode average V value: 0.45766473611195885\n",
      "Average (on the epoch) training loss: 0.00410362142151799\n",
      "Episode average V value: 0.5884000845253468\n",
      "Average (on the epoch) training loss: 0.0041011170491967765\n",
      "Episode average V value: 0.594227647781372\n",
      "Average (on the epoch) training loss: 0.004104685598135182\n",
      "Episode average V value: 0.45798297474781674\n",
      "Average (on the epoch) training loss: 0.004112461244486357\n",
      "Episode average V value: 0.5905397874968392\n",
      "Average (on the epoch) training loss: 0.004110747213171942\n",
      "Episode average V value: 0.41594891415701973\n",
      "Average (on the epoch) training loss: 0.004110057782267181\n",
      "Episode average V value: 0.8576610237360001\n",
      "Average (on the epoch) training loss: 0.004116549401052561\n",
      "Episode average V value: 0.5105535797774792\n",
      "Average (on the epoch) training loss: 0.004115994723321106\n",
      "Episode average V value: 0.5382347532681057\n",
      "Average (on the epoch) training loss: 0.004113664543005698\n",
      "Episode average V value: 0.6848624348640442\n",
      "Average (on the epoch) training loss: 0.004113924776266967\n",
      "Episode average V value: 0.5788076937198638\n",
      "Average (on the epoch) training loss: 0.004112932085436547\n",
      "Episode average V value: 0.6750403791666031\n",
      "Average (on the epoch) training loss: 0.004097694063108518\n",
      "Episode average V value: 0.49730220437049866\n",
      "Average (on the epoch) training loss: 0.00407781063698518\n",
      "Episode average V value: 0.3678055520241077\n",
      "Average (on the epoch) training loss: 0.004070705967330648\n",
      "Episode average V value: 0.8548951297998428\n",
      "Average (on the epoch) training loss: 0.0040705704439652005\n",
      "Episode average V value: 0.5321745872497559\n",
      "Average (on the epoch) training loss: 0.0040703667968473465\n",
      "Episode average V value: 0.7325689792633057\n",
      "Average (on the epoch) training loss: 0.004071673348276409\n",
      "Episode average V value: 0.5554464533925056\n",
      "Average (on the epoch) training loss: 0.004066853908644204\n",
      "Episode average V value: 0.42415461540222166\n",
      "Average (on the epoch) training loss: 0.0040685840418253445\n",
      "Episode average V value: 0.6827371716499329\n",
      "Average (on the epoch) training loss: 0.004066708502061187\n",
      "Episode average V value: 0.5332846641540527\n",
      "Average (on the epoch) training loss: 0.004065467597920028\n",
      "Episode average V value: 0.5516924947500229\n",
      "LOSSES\n",
      "T = 0.017433395584113897; R = 0.03558194627892226;                 Gamma = 0.5099121261835098; Q = 0.0039693639165489;\n",
      "Entropy Neighbor = 0.4820324713587761;                 Entropy Random = 0.14723468859493732;                 Volume = 0.26490065215528014; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.004059740233409684\n",
      "Episode average V value: 0.44081774124732387\n",
      "epoch 34:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.8571428571428571 (average over 7 episode(s))\n",
      "== Mean score per episode is 0.8571306124198226 over 7 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0814,  0.0223,  0.1836, -0.6031, -0.8086], device='cuda:0') tensor([ 0.1384,  0.1008,  0.2013, -0.6001, -0.8253], device='cuda:0') tensor([ 0.0814,  0.0223,  0.1836, -0.6031, -0.8086], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0054], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003746340356883593\n",
      "Episode average V value: 0.7585901518662771\n",
      "Average (on the epoch) training loss: 0.003923964890418574\n",
      "Episode average V value: 0.852965235710144\n",
      "Average (on the epoch) training loss: 0.004065840627946373\n",
      "Episode average V value: 0.6747641563415527\n",
      "Average (on the epoch) training loss: 0.0037560318056161384\n",
      "Episode average V value: 0.5786622497770522\n",
      "Average (on the epoch) training loss: 0.003879747745072977\n",
      "Episode average V value: 0.7535528659820556\n",
      "Average (on the epoch) training loss: 0.003888225963188184\n",
      "Episode average V value: 0.9035059611002604\n",
      "Average (on the epoch) training loss: 0.0037171584405401286\n",
      "Episode average V value: 0.5696325778961182\n",
      "Average (on the epoch) training loss: 0.003772326439502649\n",
      "Episode average V value: 0.996070146560669\n",
      "Average (on the epoch) training loss: 0.0038469889247789977\n",
      "Episode average V value: 0.9170293509960175\n",
      "Average (on the epoch) training loss: 0.004088185227980527\n",
      "Episode average V value: 0.5286584675312043\n",
      "Average (on the epoch) training loss: 0.00400730961331329\n",
      "Episode average V value: 0.7381832003593445\n",
      "Average (on the epoch) training loss: 0.004100823351532884\n",
      "Episode average V value: 0.47044154703617097\n",
      "Average (on the epoch) training loss: 0.004148895888834094\n",
      "Episode average V value: 0.6372327283024788\n",
      "Average (on the epoch) training loss: 0.004154134259127215\n",
      "Episode average V value: 0.8634486496448517\n",
      "Average (on the epoch) training loss: 0.004155316000956037\n",
      "Episode average V value: 0.7278558065493902\n",
      "Average (on the epoch) training loss: 0.004257885436403585\n",
      "Episode average V value: 0.7083063006401062\n",
      "Average (on the epoch) training loss: 0.004222141849822947\n",
      "Episode average V value: 0.9188085198402405\n",
      "Average (on the epoch) training loss: 0.004106397746759241\n",
      "Episode average V value: 0.8083338379859925\n",
      "Average (on the epoch) training loss: 0.004235194710830711\n",
      "Episode average V value: 0.4964971860249837\n",
      "Average (on the epoch) training loss: 0.004196596230149299\n",
      "Episode average V value: 0.8994156718254089\n",
      "Average (on the epoch) training loss: 0.0042593525413105945\n",
      "Episode average V value: 0.9500792026519775\n",
      "Average (on the epoch) training loss: 0.004268851757387893\n",
      "Episode average V value: 0.948346734046936\n",
      "Average (on the epoch) training loss: 0.004257717047629608\n",
      "Episode average V value: 0.8123308221499125\n",
      "Average (on the epoch) training loss: 0.004252255372514757\n",
      "Episode average V value: 0.7764078140258789\n",
      "Average (on the epoch) training loss: 0.004259922827232926\n",
      "Episode average V value: 0.7755085229873657\n",
      "Average (on the epoch) training loss: 0.004219102129822464\n",
      "Episode average V value: 0.8974350690841675\n",
      "Average (on the epoch) training loss: 0.004213350861045044\n",
      "Episode average V value: 0.6015155528272901\n",
      "Average (on the epoch) training loss: 0.004262896929943654\n",
      "Episode average V value: 0.7616799533367157\n",
      "Average (on the epoch) training loss: 0.004202318258814912\n",
      "Episode average V value: 0.677144855260849\n",
      "Average (on the epoch) training loss: 0.004289234606137431\n",
      "Episode average V value: 0.6437013626098633\n",
      "Average (on the epoch) training loss: 0.0043033533385813194\n",
      "Episode average V value: 0.6238519379070827\n",
      "Average (on the epoch) training loss: 0.004266067262175387\n",
      "Episode average V value: 0.6601057052612305\n",
      "Average (on the epoch) training loss: 0.004275633639766026\n",
      "Episode average V value: 0.5595571299393972\n",
      "Average (on the epoch) training loss: 0.0042758985122582\n",
      "Episode average V value: 0.6735430444989886\n",
      "Average (on the epoch) training loss: 0.004250393405621823\n",
      "Episode average V value: 0.5858269929885864\n",
      "Average (on the epoch) training loss: 0.004253396387593161\n",
      "Episode average V value: 0.4555475955659693\n",
      "Average (on the epoch) training loss: 0.004194423055545455\n",
      "Episode average V value: 0.5523795648054644\n",
      "Average (on the epoch) training loss: 0.004181685907999054\n",
      "Episode average V value: 0.5081075544540699\n",
      "Average (on the epoch) training loss: 0.004160211220825283\n",
      "Episode average V value: 0.9177773594856262\n",
      "Average (on the epoch) training loss: 0.004147959585877338\n",
      "Episode average V value: 0.6737548311551412\n",
      "Average (on the epoch) training loss: 0.004202080787320493\n",
      "Episode average V value: 0.6691061444580555\n",
      "Average (on the epoch) training loss: 0.004214727837951732\n",
      "Episode average V value: 0.7020721094948905\n",
      "Average (on the epoch) training loss: 0.004243082492587533\n",
      "Episode average V value: 0.6000649452209472\n",
      "Average (on the epoch) training loss: 0.004245416603049515\n",
      "Episode average V value: 0.6540917498724801\n",
      "Average (on the epoch) training loss: 0.004217050653022277\n",
      "Episode average V value: 0.8144963979721069\n",
      "Average (on the epoch) training loss: 0.004210296334990821\n",
      "Episode average V value: 1.0014127492904663\n",
      "Average (on the epoch) training loss: 0.004195925882578383\n",
      "Episode average V value: 0.7775593101978302\n",
      "Average (on the epoch) training loss: 0.004215743640418131\n",
      "Episode average V value: 0.6062891645865007\n",
      "Average (on the epoch) training loss: 0.00423053473917979\n",
      "Episode average V value: 0.5534779466688633\n",
      "Average (on the epoch) training loss: 0.004190801540210557\n",
      "Episode average V value: 0.6552958451211452\n",
      "Average (on the epoch) training loss: 0.004173593717824993\n",
      "Episode average V value: 0.6166424112660545\n",
      "Average (on the epoch) training loss: 0.00417156271500783\n",
      "Episode average V value: 0.7539264798164368\n",
      "Average (on the epoch) training loss: 0.0041747059438577185\n",
      "Episode average V value: 0.4643327171603839\n",
      "Average (on the epoch) training loss: 0.004155365095316876\n",
      "Episode average V value: 0.6549589965078566\n",
      "Average (on the epoch) training loss: 0.004171122692564508\n",
      "Episode average V value: 0.48450739681720734\n",
      "Average (on the epoch) training loss: 0.004143833687270129\n",
      "Episode average V value: 0.47604375226157053\n",
      "Average (on the epoch) training loss: 0.004145851531084479\n",
      "Episode average V value: 0.9941251277923584\n",
      "Average (on the epoch) training loss: 0.004178127595036981\n",
      "Episode average V value: 0.5831383988261223\n",
      "Average (on the epoch) training loss: 0.004153093132335925\n",
      "Episode average V value: 0.5536723045202402\n",
      "Average (on the epoch) training loss: 0.004146699593681386\n",
      "Episode average V value: 0.6351832515663571\n",
      "Average (on the epoch) training loss: 0.004145663250826793\n",
      "Episode average V value: 0.7246638884147009\n",
      "Average (on the epoch) training loss: 0.004166250714163498\n",
      "Episode average V value: 0.5254761315882206\n",
      "Average (on the epoch) training loss: 0.004169160792025011\n",
      "Episode average V value: 0.7619959712028503\n",
      "Average (on the epoch) training loss: 0.004164295922991948\n",
      "Episode average V value: 0.9181427657604218\n",
      "Average (on the epoch) training loss: 0.004151012833013242\n",
      "Episode average V value: 0.5514647391709414\n",
      "Average (on the epoch) training loss: 0.00414605568789025\n",
      "Episode average V value: 0.8984121481577555\n",
      "Average (on the epoch) training loss: 0.0041123419233420125\n",
      "Episode average V value: 0.5490603089332581\n",
      "Average (on the epoch) training loss: 0.004099921367840849\n",
      "Episode average V value: 0.9382046759128571\n",
      "Average (on the epoch) training loss: 0.004096084252333917\n",
      "Episode average V value: 0.7778340578079224\n",
      "Average (on the epoch) training loss: 0.004089362169478965\n",
      "Episode average V value: 0.4369671121239662\n",
      "Average (on the epoch) training loss: 0.004091767041905562\n",
      "Episode average V value: 0.5572256909476386\n",
      "Average (on the epoch) training loss: 0.004096673639643908\n",
      "Episode average V value: 0.558054056432512\n",
      "Average (on the epoch) training loss: 0.004108162650100572\n",
      "Episode average V value: 0.6904546618461609\n",
      "LOSSES\n",
      "T = 0.017581068337894978; R = 0.036528195394203065;                 Gamma = 0.5081647310853005; Q = 0.004100724234478549;\n",
      "Entropy Neighbor = 0.47843985038995746;                 Entropy Random = 0.14775483970344067;                 Volume = 0.27110273389518263; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0319, -1.0275, -0.0850, -1.0179, -1.3282], device='cuda:0') tensor([-1.0973, -1.0280, -0.0344, -1.0508, -1.3890], device='cuda:0') tensor([-0.6487, -0.5942,  0.1046, -1.0928, -1.5738], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1798], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004098424575508635\n",
      "Episode average V value: 0.7191317528486252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.00412180950183938\n",
      "Episode average V value: 0.5725865304470062\n",
      "Average (on the epoch) training loss: 0.0041212271469731505\n",
      "Episode average V value: 0.782422681649526\n",
      "Average (on the epoch) training loss: 0.004105033890783305\n",
      "Episode average V value: 0.575224943459034\n",
      "Average (on the epoch) training loss: 0.004118122380668186\n",
      "Episode average V value: 0.45618391036987305\n",
      "Average (on the epoch) training loss: 0.004116642390431186\n",
      "Episode average V value: 0.8030680894851685\n",
      "Average (on the epoch) training loss: 0.004107151865027845\n",
      "Episode average V value: 0.5750210545957088\n",
      "Average (on the epoch) training loss: 0.004113494950324755\n",
      "Episode average V value: 0.8109964728355408\n",
      "Average (on the epoch) training loss: 0.004116019359722545\n",
      "Episode average V value: 0.9993783235549927\n",
      "Average (on the epoch) training loss: 0.004113825465697976\n",
      "Episode average V value: 0.8462095558643341\n",
      "Average (on the epoch) training loss: 0.004107254206827109\n",
      "Episode average V value: 0.7113511860370636\n",
      "Average (on the epoch) training loss: 0.004102885069917126\n",
      "Episode average V value: 0.555885873734951\n",
      "Average (on the epoch) training loss: 0.004089624891444996\n",
      "Episode average V value: 0.8191362261772156\n",
      "Average (on the epoch) training loss: 0.004084480655321584\n",
      "Episode average V value: 0.8109195033709208\n",
      "Average (on the epoch) training loss: 0.004082294668932406\n",
      "Episode average V value: 0.6764591974871499\n",
      "Average (on the epoch) training loss: 0.00408482543338323\n",
      "Episode average V value: 0.4002102216084798\n",
      "Average (on the epoch) training loss: 0.0040800756743426024\n",
      "Episode average V value: 0.7302680909633636\n",
      "Average (on the epoch) training loss: 0.004066868603809131\n",
      "Episode average V value: 0.6658833358022902\n",
      "Average (on the epoch) training loss: 0.0040668772464443935\n",
      "Episode average V value: 0.9360761046409607\n",
      "Average (on the epoch) training loss: 0.00405700156104697\n",
      "Episode average V value: 0.7089060885565621\n",
      "Average (on the epoch) training loss: 0.004055325946374127\n",
      "Episode average V value: 0.830908790230751\n",
      "Average (on the epoch) training loss: 0.004055901893891341\n",
      "Episode average V value: 0.6880300045013428\n",
      "Average (on the epoch) training loss: 0.004034930864273948\n",
      "Episode average V value: 0.41266816041686316\n",
      "Average (on the epoch) training loss: 0.004031252817821951\n",
      "Episode average V value: 0.5390429496765137\n",
      "Average (on the epoch) training loss: 0.00404470294228762\n",
      "Episode average V value: 0.4378174382906694\n",
      "Average (on the epoch) training loss: 0.0040225666140130305\n",
      "Episode average V value: 0.48970477655529976\n",
      "Average (on the epoch) training loss: 0.004024809087273883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0040118668035110765\n",
      "Episode average V value: 0.49182942509651184\n",
      "Average (on the epoch) training loss: 0.004018273919920081\n",
      "Episode average V value: 0.7188967963059744\n",
      "Average (on the epoch) training loss: 0.004020116983389525\n",
      "Episode average V value: 0.7529540300369263\n",
      "Average (on the epoch) training loss: 0.004017731947963312\n",
      "Episode average V value: 0.9933084845542908\n",
      "Average (on the epoch) training loss: 0.004015687130697759\n",
      "Episode average V value: 0.7796564698219299\n",
      "Average (on the epoch) training loss: 0.004026842785570001\n",
      "Episode average V value: 0.47379811356465024\n",
      "Average (on the epoch) training loss: 0.004020198606052785\n",
      "Episode average V value: 0.7527557134628295\n",
      "Average (on the epoch) training loss: 0.004021629562674146\n",
      "Episode average V value: 0.6730622351169586\n",
      "Average (on the epoch) training loss: 0.004019034846376467\n",
      "Episode average V value: 0.6295162567070552\n",
      "Average (on the epoch) training loss: 0.003996567157808712\n",
      "Episode average V value: 0.46786439648041356\n",
      "Average (on the epoch) training loss: 0.004003885902096265\n",
      "Episode average V value: 0.4332612587345971\n",
      "Average (on the epoch) training loss: 0.004001978022193733\n",
      "Episode average V value: 0.5550589627689786\n",
      "Average (on the epoch) training loss: 0.004003642555390898\n",
      "Episode average V value: 0.5540746365274701\n",
      "Average (on the epoch) training loss: 0.003999360647924056\n",
      "Episode average V value: 0.4985627730687459\n",
      "Average (on the epoch) training loss: 0.003992617221331885\n",
      "Episode average V value: 0.5483409294060299\n",
      "Average (on the epoch) training loss: 0.0039906702466020036\n",
      "Episode average V value: 0.8568977564573288\n",
      "Average (on the epoch) training loss: 0.004001282362368043\n",
      "Episode average V value: 0.5751407742500305\n",
      "Average (on the epoch) training loss: 0.004009212724463253\n",
      "Episode average V value: 0.8514959067106247\n",
      "Average (on the epoch) training loss: 0.004017663392841179\n",
      "Episode average V value: 0.638879656791687\n",
      "Average (on the epoch) training loss: 0.004019922228104252\n",
      "Episode average V value: 0.4729582518339157\n",
      "Average (on the epoch) training loss: 0.0040168007704077064\n",
      "Episode average V value: 0.7391485373179117\n",
      "Average (on the epoch) training loss: 0.0040113823781543516\n",
      "Episode average V value: 0.8975219329198202\n",
      "Average (on the epoch) training loss: 0.004015608254050976\n",
      "Episode average V value: 0.4025833091952584\n",
      "Average (on the epoch) training loss: 0.003999083910763555\n",
      "Episode average V value: 0.4461505860090256\n",
      "Average (on the epoch) training loss: 0.003988868852122311\n",
      "Episode average V value: 0.6254863739013672\n",
      "Average (on the epoch) training loss: 0.0039853768154671865\n",
      "Episode average V value: 0.5517756640911102\n",
      "Average (on the epoch) training loss: 0.003983165123781666\n",
      "Episode average V value: 0.7634537220001221\n",
      "Average (on the epoch) training loss: 0.003981558984279248\n",
      "Episode average V value: 0.6503373861312867\n",
      "Average (on the epoch) training loss: 0.003980975108259015\n",
      "Episode average V value: 0.7207727909088135\n",
      "Average (on the epoch) training loss: 0.0039794299633796795\n",
      "Episode average V value: 0.8345367610454559\n",
      "Average (on the epoch) training loss: 0.003978665354790994\n",
      "Episode average V value: 0.590661707520485\n",
      "Average (on the epoch) training loss: 0.003967742555675509\n",
      "Episode average V value: 0.4598738511403402\n",
      "Average (on the epoch) training loss: 0.003958242881879513\n",
      "Episode average V value: 0.6656670967737833\n",
      "Average (on the epoch) training loss: 0.003972004797567504\n",
      "Episode average V value: 0.6519190311431885\n",
      "Average (on the epoch) training loss: 0.003971650175976106\n",
      "Episode average V value: 0.6893161237239838\n",
      "Average (on the epoch) training loss: 0.003970022111464681\n",
      "Episode average V value: 0.900515615940094\n",
      "Average (on the epoch) training loss: 0.003973894071291682\n",
      "Episode average V value: 0.7251550555229187\n",
      "Average (on the epoch) training loss: 0.003961552831975753\n",
      "Episode average V value: 0.5603044629096985\n",
      "Average (on the epoch) training loss: 0.003956710701413942\n",
      "Episode average V value: 0.47081032892068225\n",
      "Average (on the epoch) training loss: 0.003954405000206465\n",
      "Episode average V value: 0.6159678548574448\n",
      "Average (on the epoch) training loss: 0.003959739651283761\n",
      "Episode average V value: 0.48036497831344604\n",
      "Average (on the epoch) training loss: 0.00395379154778302\n",
      "Episode average V value: 0.6810785134633383\n",
      "Average (on the epoch) training loss: 0.003957476575673754\n",
      "Episode average V value: 0.5401952266693115\n",
      "Average (on the epoch) training loss: 0.003955437717409254\n",
      "Episode average V value: 0.5699930042028427\n",
      "LOSSES\n",
      "T = 0.017596163047477603; R = 0.03654650217108429;                 Gamma = 0.508293986916542; Q = 0.003807346085784957;\n",
      "Entropy Neighbor = 0.475980541408062;                 Entropy Random = 0.1484351412653923;                 Volume = 0.27885103748738765; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.003954035160131752\n",
      "Episode average V value: 0.6578989028930664\n",
      "epoch 35:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9090909090909091 (average over 11 episode(s))\n",
      "== Mean score per episode is 0.90908264470323 over 11 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1683,  0.1340,  0.2407, -0.6570, -0.9405], device='cuda:0') tensor([ 0.1616,  0.1500,  0.2215, -0.6227, -0.8659], device='cuda:0') tensor([ 0.1683,  0.1340,  0.2407, -0.6570, -0.9405], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0145], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0029486188432201743\n",
      "Episode average V value: 0.5552122533321381\n",
      "Average (on the epoch) training loss: 0.0033014155303438503\n",
      "Episode average V value: 0.5429260730743408\n",
      "Average (on the epoch) training loss: 0.0037754994458130873\n",
      "Episode average V value: 0.5166224473052554\n",
      "Average (on the epoch) training loss: 0.0038248744496176467\n",
      "Episode average V value: 0.8610723912715912\n",
      "Average (on the epoch) training loss: 0.003751166792015635\n",
      "Episode average V value: 0.7831660807132721\n",
      "Average (on the epoch) training loss: 0.00421891983003459\n",
      "Episode average V value: 0.7834836483001709\n",
      "Average (on the epoch) training loss: 0.004310961766168475\n",
      "Episode average V value: 0.8558171540498734\n",
      "Average (on the epoch) training loss: 0.004428884950287353\n",
      "Episode average V value: 0.49016623695691425\n",
      "Average (on the epoch) training loss: 0.004316918705890496\n",
      "Episode average V value: 0.5923445463180542\n",
      "Average (on the epoch) training loss: 0.004285172424073715\n",
      "Episode average V value: 0.5692064265410105\n",
      "Average (on the epoch) training loss: 0.004309078001312282\n",
      "Episode average V value: 0.7429162661234537\n",
      "Average (on the epoch) training loss: 0.004476062526142724\n",
      "Episode average V value: 0.6360629469156265\n",
      "Average (on the epoch) training loss: 0.004294555318100672\n",
      "Episode average V value: 0.48946304275439334\n",
      "Average (on the epoch) training loss: 0.004247398897654043\n",
      "Episode average V value: 0.6277660619128834\n",
      "Average (on the epoch) training loss: 0.004239198698831553\n",
      "Episode average V value: 0.8582088947296143\n",
      "Average (on the epoch) training loss: 0.0042414028884459895\n",
      "Episode average V value: 0.44638516345331747\n",
      "Average (on the epoch) training loss: 0.004200106198374407\n",
      "Episode average V value: 0.6100573539733887\n",
      "Average (on the epoch) training loss: 0.004135458140853815\n",
      "Episode average V value: 0.5932467579841614\n",
      "Average (on the epoch) training loss: 0.004083333514516421\n",
      "Episode average V value: 0.6193157169553969\n",
      "Average (on the epoch) training loss: 0.004046115849321499\n",
      "Episode average V value: 0.5098354657491048\n",
      "Average (on the epoch) training loss: 0.004030993116511988\n",
      "Episode average V value: 1.0020936727523804\n",
      "Average (on the epoch) training loss: 0.0040152109801662545\n",
      "Episode average V value: 0.6837747196356455\n",
      "Average (on the epoch) training loss: 0.003943430916086643\n",
      "Episode average V value: 0.44123318791389465\n",
      "Average (on the epoch) training loss: 0.003932612406900331\n",
      "Episode average V value: 0.853732630610466\n",
      "Average (on the epoch) training loss: 0.003908602945176104\n",
      "Episode average V value: 0.6368482046657138\n",
      "Average (on the epoch) training loss: 0.0038965066397477956\n",
      "Episode average V value: 0.9477194249629974\n",
      "Average (on the epoch) training loss: 0.0038636452951811224\n",
      "Episode average V value: 0.5821600589487288\n",
      "Average (on the epoch) training loss: 0.0038523562698367427\n",
      "Episode average V value: 0.5686573684215546\n",
      "Average (on the epoch) training loss: 0.00384432648573554\n",
      "Episode average V value: 0.8103467226028442\n",
      "Average (on the epoch) training loss: 0.0038288384260892197\n",
      "Episode average V value: 0.8533705621957779\n",
      "Average (on the epoch) training loss: 0.0038001848059879403\n",
      "Episode average V value: 0.6716033592820168\n",
      "Average (on the epoch) training loss: 0.0037700327017819116\n",
      "Episode average V value: 0.6721521355211735\n",
      "Average (on the epoch) training loss: 0.003765494828588668\n",
      "Episode average V value: 0.9033453663190206\n",
      "Average (on the epoch) training loss: 0.0037912923300555392\n",
      "Episode average V value: 0.8163544684648514\n",
      "Average (on the epoch) training loss: 0.0037917126068695837\n",
      "Episode average V value: 0.6933179895083109\n",
      "Average (on the epoch) training loss: 0.003803210645099588\n",
      "Episode average V value: 0.8058903098106385\n",
      "Average (on the epoch) training loss: 0.003778510130514052\n",
      "Episode average V value: 0.8351401388645172\n",
      "Average (on the epoch) training loss: 0.003782438350096027\n",
      "Episode average V value: 0.6337083995342254\n",
      "Average (on the epoch) training loss: 0.0037924980338414713\n",
      "Episode average V value: 0.47926082936200226\n",
      "Average (on the epoch) training loss: 0.003789800153591465\n",
      "Episode average V value: 0.6668799950016869\n",
      "Average (on the epoch) training loss: 0.003782206290671189\n",
      "Episode average V value: 0.7629663944244385\n",
      "Average (on the epoch) training loss: 0.0037873336606515716\n",
      "Episode average V value: 0.5116999712255266\n",
      "Average (on the epoch) training loss: 0.0037855277916519084\n",
      "Episode average V value: 0.5726924687623978\n",
      "Average (on the epoch) training loss: 0.003776708788651929\n",
      "Episode average V value: 0.8928006887435913\n",
      "Average (on the epoch) training loss: 0.0037692308710770613\n",
      "Episode average V value: 0.5511785030364991\n",
      "Average (on the epoch) training loss: 0.0037880373478401453\n",
      "Episode average V value: 0.5835909707979723\n",
      "Average (on the epoch) training loss: 0.003778183638843685\n",
      "Episode average V value: 0.5798761627890847\n",
      "Average (on the epoch) training loss: 0.003795948139413955\n",
      "Episode average V value: 0.5871361754834652\n",
      "Average (on the epoch) training loss: 0.0037933362366680008\n",
      "Episode average V value: 0.813527500629425\n",
      "Average (on the epoch) training loss: 0.0038346605563464647\n",
      "Episode average V value: 0.6388989806175231\n",
      "Average (on the epoch) training loss: 0.003825304503529097\n",
      "Episode average V value: 0.6489814420541128\n",
      "Average (on the epoch) training loss: 0.0038583602370886967\n",
      "Episode average V value: 0.5085259526968002\n",
      "Average (on the epoch) training loss: 0.0038583036484285903\n",
      "Episode average V value: 0.4004883576523174\n",
      "Average (on the epoch) training loss: 0.00387257974493741\n",
      "Episode average V value: 0.4268319010734558\n",
      "Average (on the epoch) training loss: 0.003851140477497399\n",
      "Episode average V value: 0.6090488488023932\n",
      "Average (on the epoch) training loss: 0.0038282659934499854\n",
      "Episode average V value: 0.6421264484524727\n",
      "Average (on the epoch) training loss: 0.0038263296174663912\n",
      "Episode average V value: 0.4607510136233436\n",
      "Average (on the epoch) training loss: 0.0038284631407115174\n",
      "Episode average V value: 0.9923474788665771\n",
      "Average (on the epoch) training loss: 0.003870840761021531\n",
      "Episode average V value: 0.4441061317920685\n",
      "Average (on the epoch) training loss: 0.003879396337464858\n",
      "Episode average V value: 0.5454735577106475\n",
      "Average (on the epoch) training loss: 0.0038771390428543775\n",
      "Episode average V value: 0.8525359630584717\n",
      "Average (on the epoch) training loss: 0.0038944734776930386\n",
      "Episode average V value: 0.5034506916999817\n",
      "LOSSES\n",
      "T = 0.01793588870950043; R = 0.03803033437114209;                 Gamma = 0.5056789135932922; Q = 0.0038935822575585917;\n",
      "Entropy Neighbor = 0.46933690601587297;                 Entropy Random = 0.14189798491448163;                 Volume = 0.29232125195860864; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0690,  0.0255,  0.1939, -0.6471, -0.8973], device='cuda:0') tensor([-0.0750, -0.0970,  0.1765, -0.6824, -0.9213], device='cuda:0') tensor([-0.0438, -0.0967,  0.1456, -0.6415, -0.8568], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0067], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003920454198747288\n",
      "Episode average V value: 0.7270654638608297\n",
      "Average (on the epoch) training loss: 0.003925713622034071\n",
      "Episode average V value: 0.6557564267090389\n",
      "Average (on the epoch) training loss: 0.003929244101907129\n",
      "Episode average V value: 0.9183399081230164\n",
      "Average (on the epoch) training loss: 0.003936089540925772\n",
      "Episode average V value: 0.7196804046630859\n",
      "Average (on the epoch) training loss: 0.003940398058737182\n",
      "Episode average V value: 0.762620598077774\n",
      "Average (on the epoch) training loss: 0.003938060360165306\n",
      "Episode average V value: 0.9467246234416962\n",
      "Average (on the epoch) training loss: 0.003929737297519089\n",
      "Episode average V value: 0.834091454744339\n",
      "Average (on the epoch) training loss: 0.0039378717520071535\n",
      "Episode average V value: 0.7781109094619751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.0039303541187973925\n",
      "Episode average V value: 0.3987228512763977\n",
      "Average (on the epoch) training loss: 0.003918257866920785\n",
      "Episode average V value: 0.777425209681193\n",
      "Average (on the epoch) training loss: 0.0039044039173258857\n",
      "Episode average V value: 0.446973132816228\n",
      "Average (on the epoch) training loss: 0.0039044177017652512\n",
      "Episode average V value: 0.9473225772380829\n",
      "Average (on the epoch) training loss: 0.003916275715862967\n",
      "Episode average V value: 0.8535018265247345\n",
      "Average (on the epoch) training loss: 0.00391860704041944\n",
      "Episode average V value: 0.423504114151001\n",
      "Average (on the epoch) training loss: 0.003925610017739015\n",
      "Episode average V value: 0.5185339798529943\n",
      "Average (on the epoch) training loss: 0.003922417306348322\n",
      "Episode average V value: 0.9383177161216736\n",
      "Average (on the epoch) training loss: 0.003910220644169236\n",
      "Episode average V value: 0.6483702957630157\n",
      "Average (on the epoch) training loss: 0.003928396893669011\n",
      "Episode average V value: 0.5672435324925643\n",
      "Average (on the epoch) training loss: 0.0039390224849827765\n",
      "Episode average V value: 0.626662814617157\n",
      "Average (on the epoch) training loss: 0.003946166360369262\n",
      "Episode average V value: 0.5663190126419068\n",
      "Average (on the epoch) training loss: 0.003950165946895071\n",
      "Episode average V value: 0.6956194043159485\n",
      "Average (on the epoch) training loss: 0.0039748622356455595\n",
      "Episode average V value: 0.6454845496586391\n",
      "Average (on the epoch) training loss: 0.003966375561177896\n",
      "Episode average V value: 0.4703534170985222\n",
      "Average (on the epoch) training loss: 0.0039946778445455215\n",
      "Episode average V value: 0.64125828232084\n",
      "Average (on the epoch) training loss: 0.003977681813643274\n",
      "Episode average V value: 0.4228297173976898\n",
      "Average (on the epoch) training loss: 0.0039742202319515245\n",
      "Episode average V value: 0.9450471103191376\n",
      "Average (on the epoch) training loss: 0.003979757467403618\n",
      "Episode average V value: 0.875789999961853\n",
      "Average (on the epoch) training loss: 0.003977462757153145\n",
      "Episode average V value: 0.8918975591659546\n",
      "Average (on the epoch) training loss: 0.0039914118138297825\n",
      "Episode average V value: 0.5156294107437134\n",
      "Average (on the epoch) training loss: 0.003986954075497004\n",
      "Episode average V value: 0.5442916750907898\n",
      "Average (on the epoch) training loss: 0.003985155839223904\n",
      "Episode average V value: 0.7779287576675415\n",
      "Average (on the epoch) training loss: 0.003984340107294295\n",
      "Episode average V value: 0.9189617931842804\n",
      "Average (on the epoch) training loss: 0.003979019858368485\n",
      "Episode average V value: 0.8121922612190247\n",
      "Average (on the epoch) training loss: 0.003978954450453593\n",
      "Episode average V value: 0.5572745651006699\n",
      "Average (on the epoch) training loss: 0.003974514702492619\n",
      "Episode average V value: 0.7856625020503998\n",
      "Average (on the epoch) training loss: 0.003976702245059781\n",
      "Episode average V value: 0.832136332988739\n",
      "Average (on the epoch) training loss: 0.003976959029275591\n",
      "Episode average V value: 0.6957447230815887\n",
      "Average (on the epoch) training loss: 0.003987280346740995\n",
      "Episode average V value: 0.8913134336471558\n",
      "Average (on the epoch) training loss: 0.003983473083855392\n",
      "Episode average V value: 0.8143198490142822\n",
      "Average (on the epoch) training loss: 0.003990920918614106\n",
      "Episode average V value: 0.6418745279312134\n",
      "Average (on the epoch) training loss: 0.0039888560713339585\n",
      "Episode average V value: 0.603109632219587\n",
      "Average (on the epoch) training loss: 0.003989126686468665\n",
      "Episode average V value: 0.5441586971282959\n",
      "Average (on the epoch) training loss: 0.003970193523279197\n",
      "Episode average V value: 0.6564081013202667\n",
      "Average (on the epoch) training loss: 0.0039875304013636545\n",
      "Episode average V value: 0.944974958896637\n",
      "Average (on the epoch) training loss: 0.003979640872057163\n",
      "Episode average V value: 0.6023006439208984\n",
      "Average (on the epoch) training loss: 0.003989624960998602\n",
      "Episode average V value: 0.5153545171022416\n",
      "Average (on the epoch) training loss: 0.003991234811501826\n",
      "Episode average V value: 0.5955374240875244\n",
      "Average (on the epoch) training loss: 0.003985285879813072\n",
      "Episode average V value: 0.8549546748399734\n",
      "Average (on the epoch) training loss: 0.003987613198371988\n",
      "Episode average V value: 0.4388471982545323\n",
      "Average (on the epoch) training loss: 0.003985762855645456\n",
      "Episode average V value: 0.5390343268712362\n",
      "Average (on the epoch) training loss: 0.003985007344233042\n",
      "Episode average V value: 0.7800334930419922\n",
      "Average (on the epoch) training loss: 0.003996947491814265\n",
      "Episode average V value: 0.6691879510879517\n",
      "Average (on the epoch) training loss: 0.003995861389168142\n",
      "Episode average V value: 0.9985308051109314\n",
      "Average (on the epoch) training loss: 0.00399612496412045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.003995537434163383\n",
      "Episode average V value: 0.6959130465984344\n",
      "Average (on the epoch) training loss: 0.003991112615777173\n",
      "Episode average V value: 0.652832201548985\n",
      "Average (on the epoch) training loss: 0.003985210108991619\n",
      "Episode average V value: 0.8320406079292297\n",
      "Average (on the epoch) training loss: 0.003962391956462574\n",
      "Episode average V value: 0.5896230773492293\n",
      "Average (on the epoch) training loss: 0.003957488459693397\n",
      "Episode average V value: 0.35996847261082043\n",
      "Average (on the epoch) training loss: 0.003953362880899452\n",
      "Episode average V value: 0.5633040964603424\n",
      "Average (on the epoch) training loss: 0.003973453330711408\n",
      "Episode average V value: 0.6353530526161194\n",
      "Average (on the epoch) training loss: 0.0039706783225199604\n",
      "Episode average V value: 0.6930826380848885\n",
      "Average (on the epoch) training loss: 0.00397027169536045\n",
      "Episode average V value: 0.8916172782580057\n",
      "Average (on the epoch) training loss: 0.0039693633882173646\n",
      "Episode average V value: 0.6131386955579122\n",
      "Average (on the epoch) training loss: 0.003967495188742388\n",
      "Episode average V value: 1.000321388244629\n",
      "Average (on the epoch) training loss: 0.0039471755029306475\n",
      "Episode average V value: 0.4631178820574725\n",
      "Average (on the epoch) training loss: 0.003948196212983465\n",
      "Episode average V value: 0.547164315978686\n",
      "Average (on the epoch) training loss: 0.003948781690954492\n",
      "Episode average V value: 0.5503404655239799\n",
      "Average (on the epoch) training loss: 0.003952908183409703\n",
      "Episode average V value: 0.9455208480358124\n",
      "Average (on the epoch) training loss: 0.003961337710258758\n",
      "Episode average V value: 0.5626045655120503\n",
      "Average (on the epoch) training loss: 0.003966721931105857\n",
      "Episode average V value: 0.4774301317003038\n",
      "Average (on the epoch) training loss: 0.003972021508593407\n",
      "Episode average V value: 0.8916343251864115\n",
      "Average (on the epoch) training loss: 0.0039772515412323396\n",
      "Episode average V value: 0.43814765214920043\n",
      "Average (on the epoch) training loss: 0.003972715209497981\n",
      "Episode average V value: 0.8344298203786215\n",
      "Average (on the epoch) training loss: 0.003967412632083588\n",
      "Episode average V value: 0.7611175576845804\n",
      "LOSSES\n",
      "T = 0.017765238150022924; R = 0.03725827209278941;                 Gamma = 0.5068923754692077; Q = 0.004035409706062637;\n",
      "Entropy Neighbor = 0.46837780910730364;                 Entropy Random = 0.14607184557616712;                 Volume = 0.29005216431617736; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.003964495981810615\n",
      "Episode average V value: 0.6368724576064518\n",
      "epoch 36:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9333333333333333 (average over 15 episode(s))\n",
      "== Mean score per episode is 0.9333271111525924 over 15 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0283, -1.0240, -0.0879, -1.0174, -1.3345], device='cuda:0') tensor([-1.0736, -1.1396, -0.1278, -1.0562, -1.2900], device='cuda:0') tensor([-1.2081, -1.1903, -0.1265, -1.0950, -1.4389], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1950], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.00253083067946136\n",
      "Episode average V value: 0.9922915101051331\n",
      "Average (on the epoch) training loss: 0.0023748934036120772\n",
      "Episode average V value: 1.0006482601165771\n",
      "Average (on the epoch) training loss: 0.0024402543203905225\n",
      "Episode average V value: 0.6340741515159607\n",
      "Average (on the epoch) training loss: 0.003892710360770042\n",
      "Episode average V value: 0.6173713547842843\n",
      "Average (on the epoch) training loss: 0.004279083483852446\n",
      "Episode average V value: 0.5684134612480799\n",
      "Average (on the epoch) training loss: 0.0043110276716921865\n",
      "Episode average V value: 0.5899272859096527\n",
      "Average (on the epoch) training loss: 0.004198749449003387\n",
      "Episode average V value: 0.6388798020780087\n",
      "Average (on the epoch) training loss: 0.004114083004520929\n",
      "Episode average V value: 0.5282040387392044\n",
      "Average (on the epoch) training loss: 0.0041733927142698895\n",
      "Episode average V value: 0.6515306979417801\n",
      "Average (on the epoch) training loss: 0.003951891354952396\n",
      "Episode average V value: 0.4447339673837026\n",
      "Average (on the epoch) training loss: 0.003920031889145703\n",
      "Episode average V value: 0.4710797667503357\n",
      "Average (on the epoch) training loss: 0.003937256927662469\n",
      "Episode average V value: 0.9941636323928833\n",
      "Average (on the epoch) training loss: 0.003807392197220748\n",
      "Episode average V value: 0.41532179713249207\n",
      "Average (on the epoch) training loss: 0.003835257630877701\n",
      "Episode average V value: 0.7371660619974136\n",
      "Average (on the epoch) training loss: 0.003901302086071886\n",
      "Episode average V value: 0.5173069807616147\n",
      "Average (on the epoch) training loss: 0.00392353770439513\n",
      "Episode average V value: 0.5124093733335796\n",
      "Average (on the epoch) training loss: 0.003912304750419215\n",
      "Episode average V value: 0.4001837418629573\n",
      "Average (on the epoch) training loss: 0.00386355424959523\n",
      "Episode average V value: 0.5866170406341553\n",
      "Average (on the epoch) training loss: 0.0038553510916479413\n",
      "Episode average V value: 0.8346395045518875\n",
      "Average (on the epoch) training loss: 0.0038176265522492053\n",
      "Episode average V value: 0.8134172757466634\n",
      "Average (on the epoch) training loss: 0.0038229930345906036\n",
      "Episode average V value: 0.6961268901824951\n",
      "Average (on the epoch) training loss: 0.003807646187555673\n",
      "Episode average V value: 0.5918605625629425\n",
      "Average (on the epoch) training loss: 0.0038536599332963726\n",
      "Episode average V value: 0.4298555213544104\n",
      "Average (on the epoch) training loss: 0.003866021282710224\n",
      "Episode average V value: 0.9935749769210815\n",
      "Average (on the epoch) training loss: 0.0038500455443660707\n",
      "Episode average V value: 0.5832108457883199\n",
      "Average (on the epoch) training loss: 0.003901829820924287\n",
      "Episode average V value: 0.448750130004353\n",
      "Average (on the epoch) training loss: 0.0038795515146643634\n",
      "Episode average V value: 0.677208662033081\n",
      "Average (on the epoch) training loss: 0.003896799077973606\n",
      "Episode average V value: 0.8612671047449112\n",
      "Average (on the epoch) training loss: 0.0038988490931224076\n",
      "Episode average V value: 0.8112990617752075\n",
      "Average (on the epoch) training loss: 0.0039003728340958332\n",
      "Episode average V value: 0.7086118459701538\n",
      "Average (on the epoch) training loss: 0.0038661019809760095\n",
      "Episode average V value: 0.6579628842217582\n",
      "Average (on the epoch) training loss: 0.0038790111517088394\n",
      "Episode average V value: 0.46287720040841535\n",
      "Average (on the epoch) training loss: 0.0038759556455129377\n",
      "Episode average V value: 0.7710207998752594\n",
      "Average (on the epoch) training loss: 0.0039221610967637745\n",
      "Episode average V value: 0.5403930761597373\n",
      "Average (on the epoch) training loss: 0.003915165572336314\n",
      "Episode average V value: 0.5248939096927643\n",
      "Average (on the epoch) training loss: 0.0038913618531152016\n",
      "Episode average V value: 0.4444063539090364\n",
      "Average (on the epoch) training loss: 0.0038998503904377367\n",
      "Episode average V value: 0.7413782477378845\n",
      "Average (on the epoch) training loss: 0.0038879801612133756\n",
      "Episode average V value: 0.8522945493459702\n",
      "Average (on the epoch) training loss: 0.003885326842694678\n",
      "Episode average V value: 0.5985604763031006\n",
      "Average (on the epoch) training loss: 0.0038729558721909397\n",
      "Episode average V value: 0.7291410565376282\n",
      "Average (on the epoch) training loss: 0.0038592013196595124\n",
      "Episode average V value: 0.9917399883270264\n",
      "Average (on the epoch) training loss: 0.0038415182312621318\n",
      "Episode average V value: 0.72951240837574\n",
      "Average (on the epoch) training loss: 0.003855325229573621\n",
      "Episode average V value: 0.5676651217720725\n",
      "Average (on the epoch) training loss: 0.003857858456871731\n",
      "Episode average V value: 0.8808127045631409\n",
      "Average (on the epoch) training loss: 0.0038396010446455834\n",
      "Episode average V value: 0.6562770456075668\n",
      "Average (on the epoch) training loss: 0.0038440691997834314\n",
      "Episode average V value: 0.814709742863973\n",
      "Average (on the epoch) training loss: 0.003836819698024332\n",
      "Episode average V value: 0.9035550951957703\n",
      "Average (on the epoch) training loss: 0.0038502869728552105\n",
      "Episode average V value: 0.8359024524688721\n",
      "Average (on the epoch) training loss: 0.003850604423337187\n",
      "Episode average V value: 0.4921475603030278\n",
      "Average (on the epoch) training loss: 0.00385668584086222\n",
      "Episode average V value: 0.6905304789543152\n",
      "Average (on the epoch) training loss: 0.0038665815288778486\n",
      "Episode average V value: 0.5829202930132548\n",
      "Average (on the epoch) training loss: 0.003865082488408771\n",
      "Episode average V value: 0.6940009891986847\n",
      "Average (on the epoch) training loss: 0.003864655623776623\n",
      "Episode average V value: 0.9923708438873291\n",
      "Average (on the epoch) training loss: 0.0038988894327445416\n",
      "Episode average V value: 0.42450172901153566\n",
      "Average (on the epoch) training loss: 0.003918942588564\n",
      "Episode average V value: 0.4281393711765607\n",
      "Average (on the epoch) training loss: 0.003917397801981755\n",
      "Episode average V value: 0.7576786279678345\n",
      "Average (on the epoch) training loss: 0.003932153476331302\n",
      "Episode average V value: 0.7050870309273402\n",
      "Average (on the epoch) training loss: 0.003927318531074481\n",
      "Episode average V value: 0.8344681262969971\n",
      "Average (on the epoch) training loss: 0.0039372027133663424\n",
      "Episode average V value: 0.9226960837841034\n",
      "Average (on the epoch) training loss: 0.003923067030249329\n",
      "Episode average V value: 0.4509604200720787\n",
      "Average (on the epoch) training loss: 0.0039001076694295833\n",
      "Episode average V value: 0.6130527630448341\n",
      "LOSSES\n",
      "T = 0.017807473649270832; R = 0.038906357379630205;                 Gamma = 0.5055002185106278; Q = 0.003928138474002481;\n",
      "Entropy Neighbor = 0.46457499378919603;                 Entropy Random = 0.14559742476046086;                 Volume = 0.30039726847410203; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.5329, -1.5627, -0.2949, -1.0170, -1.2041], device='cuda:0') tensor([-1.3126, -1.3195, -0.1839, -1.0915, -1.4614], device='cuda:0') tensor([-0.1021, -0.3010, -0.0695, -0.2124, -0.0054], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.3158], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003932855028785512\n",
      "Episode average V value: 0.5129602645572863\n",
      "Average (on the epoch) training loss: 0.003950892195640371\n",
      "Episode average V value: 0.7400415341059366\n",
      "Average (on the epoch) training loss: 0.003950742347437273\n",
      "Episode average V value: 0.9214842915534973\n",
      "Average (on the epoch) training loss: 0.003938812481370662\n",
      "Episode average V value: 0.8353447715441386\n",
      "Average (on the epoch) training loss: 0.003960645194120633\n",
      "Episode average V value: 0.6678066849708557\n",
      "Average (on the epoch) training loss: 0.003963302495360246\n",
      "Episode average V value: 0.8812589049339294\n",
      "Average (on the epoch) training loss: 0.003966602450324373\n",
      "Episode average V value: 0.4797653555870056\n",
      "Average (on the epoch) training loss: 0.003952025799716504\n",
      "Episode average V value: 0.46850623325868085\n",
      "Average (on the epoch) training loss: 0.003960540009220728\n",
      "Episode average V value: 0.9463043808937073\n",
      "Average (on the epoch) training loss: 0.0039593700982756014\n",
      "Episode average V value: 0.9479698240756989\n",
      "Average (on the epoch) training loss: 0.003952682912984694\n",
      "Episode average V value: 0.7659265697002411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.003935052325860376\n",
      "Episode average V value: 0.46694435817854746\n",
      "Average (on the epoch) training loss: 0.003937414714968519\n",
      "Episode average V value: 0.8917794823646545\n",
      "Average (on the epoch) training loss: 0.003933369969518168\n",
      "Episode average V value: 0.7428674186979022\n",
      "Average (on the epoch) training loss: 0.003918364228083606\n",
      "Episode average V value: 0.31464087150313635\n",
      "Average (on the epoch) training loss: 0.003909342519113882\n",
      "Episode average V value: 0.572948519140482\n",
      "Average (on the epoch) training loss: 0.003910385255417055\n",
      "Episode average V value: 0.6391324036651187\n",
      "Average (on the epoch) training loss: 0.003908730591486225\n",
      "Episode average V value: 0.9452321529388428\n",
      "Average (on the epoch) training loss: 0.003896978971306083\n",
      "Episode average V value: 0.6093526631593704\n",
      "Average (on the epoch) training loss: 0.0039001486957763415\n",
      "Episode average V value: 0.8963657021522522\n",
      "Average (on the epoch) training loss: 0.0039046731575196744\n",
      "Episode average V value: 0.48980614272030915\n",
      "Average (on the epoch) training loss: 0.00392403932822701\n",
      "Episode average V value: 0.4024559131690434\n",
      "Average (on the epoch) training loss: 0.003916721154939853\n",
      "Episode average V value: 0.5962290101581149\n",
      "Average (on the epoch) training loss: 0.003912449861458941\n",
      "Episode average V value: 0.5410162111123403\n",
      "Average (on the epoch) training loss: 0.003905558344347915\n",
      "Episode average V value: 0.5078739987479316\n",
      "Average (on the epoch) training loss: 0.00389825770464117\n",
      "Episode average V value: 0.9007122119267782\n",
      "Average (on the epoch) training loss: 0.0038934658159085556\n",
      "Episode average V value: 0.8110698461532593\n",
      "Average (on the epoch) training loss: 0.0038884977764249403\n",
      "Episode average V value: 0.8967130780220032\n",
      "Average (on the epoch) training loss: 0.0038894976636212196\n",
      "Episode average V value: 0.43865711015203723\n",
      "Average (on the epoch) training loss: 0.0038939374795673573\n",
      "Episode average V value: 0.9373812675476074\n",
      "Average (on the epoch) training loss: 0.003868245412364951\n",
      "Episode average V value: 0.5042948067188263\n",
      "Average (on the epoch) training loss: 0.0038786942138177016\n",
      "Episode average V value: 0.5455855362945132\n",
      "Average (on the epoch) training loss: 0.0038730035564863425\n",
      "Episode average V value: 0.6787695203508649\n",
      "Average (on the epoch) training loss: 0.0038760704051578956\n",
      "Episode average V value: 0.9032089312871298\n",
      "Average (on the epoch) training loss: 0.003872685862498622\n",
      "Episode average V value: 0.5304952984054884\n",
      "Average (on the epoch) training loss: 0.0038724077023535725\n",
      "Episode average V value: 0.8534367382526398\n",
      "Average (on the epoch) training loss: 0.0038724801511950263\n",
      "Episode average V value: 0.8930988907814026\n",
      "Average (on the epoch) training loss: 0.0038804389385367526\n",
      "Episode average V value: 0.7837215065956116\n",
      "Average (on the epoch) training loss: 0.003879723065205602\n",
      "Episode average V value: 0.4646145800749461\n",
      "Average (on the epoch) training loss: 0.0038913881318220042\n",
      "Episode average V value: 0.5399549044668674\n",
      "Average (on the epoch) training loss: 0.00389241349830514\n",
      "Episode average V value: 0.7040178179740906\n",
      "Average (on the epoch) training loss: 0.003886849457760238\n",
      "Episode average V value: 0.45587558012742263\n",
      "Average (on the epoch) training loss: 0.0038915499375469786\n",
      "Episode average V value: 0.5037867687642574\n",
      "Average (on the epoch) training loss: 0.003889246096139682\n",
      "Episode average V value: 0.7207283278306326\n",
      "Average (on the epoch) training loss: 0.0038838826572410675\n",
      "Episode average V value: 0.7436381237847465\n",
      "Average (on the epoch) training loss: 0.0038744638737322986\n",
      "Episode average V value: 0.6465819776058197\n",
      "Average (on the epoch) training loss: 0.0038970328792403202\n",
      "Episode average V value: 0.4716877314177426\n",
      "Average (on the epoch) training loss: 0.0038923816592486642\n",
      "Episode average V value: 0.9452799260616302\n",
      "Average (on the epoch) training loss: 0.0038865681389219186\n",
      "Episode average V value: 0.5938320532441139\n",
      "Average (on the epoch) training loss: 0.0038949555277838174\n",
      "Episode average V value: 0.43293806314468386\n",
      "Average (on the epoch) training loss: 0.0039029880445769346\n",
      "Episode average V value: 0.4358575915296872\n",
      "Average (on the epoch) training loss: 0.003902404606012667\n",
      "Episode average V value: 0.7255265216032664\n",
      "Average (on the epoch) training loss: 0.003901464193227466\n",
      "Episode average V value: 0.5887045093945095\n",
      "Average (on the epoch) training loss: 0.003907617781980789\n",
      "Episode average V value: 0.561746450761954\n",
      "Average (on the epoch) training loss: 0.0039047637232604436\n",
      "Episode average V value: 0.5181011497974396\n",
      "Average (on the epoch) training loss: 0.003918859452996043\n",
      "Episode average V value: 0.7853567838668823\n",
      "Average (on the epoch) training loss: 0.003918494877373092\n",
      "Episode average V value: 0.8580929040908813\n",
      "Average (on the epoch) training loss: 0.003906327730020214\n",
      "Episode average V value: 0.47730403343836464\n",
      "Average (on the epoch) training loss: 0.003910436710171409\n",
      "Episode average V value: 0.4536314606666565\n",
      "Average (on the epoch) training loss: 0.003919920580219209\n",
      "Episode average V value: 0.5135037183761597\n",
      "Average (on the epoch) training loss: 0.003919673752445705\n",
      "Episode average V value: 0.5305904924869538\n",
      "Average (on the epoch) training loss: 0.003909660456853909\n",
      "Episode average V value: 0.44332271355849046\n",
      "LOSSES\n",
      "T = 0.017874775625765324; R = 0.03874464302137494;                 Gamma = 0.5051324815750122; Q = 0.0038971198057988657;\n",
      "Entropy Neighbor = 0.45839402401447293;                 Entropy Random = 0.14112606330215932;                 Volume = 0.3054482098817825; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0039126291399006734\n",
      "Episode average V value: 0.5678211599588394\n",
      "epoch 37:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.75 (average over 4 episode(s))\n",
      "== Mean score per episode is 0.9999666677777407 over 3 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7127, -0.6315,  0.1089, -1.1816, -1.7447], device='cuda:0') tensor([-0.9249, -0.8766,  0.0696, -1.1376, -1.4498], device='cuda:0') tensor([-0.1021, -0.3010, -0.0698, -0.2123, -0.0054], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.3695], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003115624561905861\n",
      "Episode average V value: 0.8590902090072632\n",
      "Average (on the epoch) training loss: 0.004512903979048133\n",
      "Episode average V value: 0.7768828670183817\n",
      "Average (on the epoch) training loss: 0.0050091787707060575\n",
      "Episode average V value: 0.9009522596995035\n",
      "Average (on the epoch) training loss: 0.004941687857928245\n",
      "Episode average V value: 0.606831505894661\n",
      "Average (on the epoch) training loss: 0.004702180461026728\n",
      "Episode average V value: 0.5812992236830972\n",
      "Average (on the epoch) training loss: 0.004358029254944995\n",
      "Episode average V value: 0.5161929488182068\n",
      "Average (on the epoch) training loss: 0.004524502718898778\n",
      "Episode average V value: 0.6466001905500889\n",
      "Average (on the epoch) training loss: 0.004286197068346343\n",
      "Episode average V value: 0.6357484191656113\n",
      "Average (on the epoch) training loss: 0.0042608743644363825\n",
      "Episode average V value: 0.538086211681366\n",
      "Average (on the epoch) training loss: 0.0042541577396067705\n",
      "Episode average V value: 0.48750447162560057\n",
      "Average (on the epoch) training loss: 0.004218515535902189\n",
      "Episode average V value: 0.5185541152954102\n",
      "Average (on the epoch) training loss: 0.004132833937183023\n",
      "Episode average V value: 0.48056038841605186\n",
      "Average (on the epoch) training loss: 0.004114302735281538\n",
      "Episode average V value: 0.8361280759175619\n",
      "Average (on the epoch) training loss: 0.00407826575627994\n",
      "Episode average V value: 0.6810001986367362\n",
      "Average (on the epoch) training loss: 0.003975501199981765\n",
      "Episode average V value: 0.5552916526794434\n",
      "Average (on the epoch) training loss: 0.003971122835094157\n",
      "Episode average V value: 0.9223107397556305\n",
      "Average (on the epoch) training loss: 0.003974943074397743\n",
      "Episode average V value: 0.5141925439238548\n",
      "Average (on the epoch) training loss: 0.00393634472616521\n",
      "Episode average V value: 0.5247782245278358\n",
      "Average (on the epoch) training loss: 0.0038679406912902974\n",
      "Episode average V value: 0.43731016119321187\n",
      "Average (on the epoch) training loss: 0.003946567271716623\n",
      "Episode average V value: 0.8036621958017349\n",
      "Average (on the epoch) training loss: 0.0039289605088175875\n",
      "Episode average V value: 0.4327969153722127\n",
      "Average (on the epoch) training loss: 0.003957677847971497\n",
      "Episode average V value: 0.5955226302146912\n",
      "Average (on the epoch) training loss: 0.003960349152803646\n",
      "Episode average V value: 0.537904965877533\n",
      "Average (on the epoch) training loss: 0.003954845487667052\n",
      "Episode average V value: 0.6473461128771305\n",
      "Average (on the epoch) training loss: 0.003944512760922821\n",
      "Episode average V value: 0.6829604804515839\n",
      "Average (on the epoch) training loss: 0.003991514748450732\n",
      "Episode average V value: 0.6151969347681318\n",
      "Average (on the epoch) training loss: 0.003976967587672015\n",
      "Episode average V value: 0.7258888383706411\n",
      "Average (on the epoch) training loss: 0.003980583327101569\n",
      "Episode average V value: 0.4254114627838135\n",
      "Average (on the epoch) training loss: 0.003966487614544914\n",
      "Episode average V value: 0.9481257796287537\n",
      "Average (on the epoch) training loss: 0.003948215739542825\n",
      "Episode average V value: 0.8969653050104777\n",
      "Average (on the epoch) training loss: 0.00392876974034199\n",
      "Episode average V value: 0.5143893286585808\n",
      "Average (on the epoch) training loss: 0.0039001792364258647\n",
      "Episode average V value: 0.9222545921802521\n",
      "Average (on the epoch) training loss: 0.0039159305018365105\n",
      "Episode average V value: 0.8035562187433243\n",
      "Average (on the epoch) training loss: 0.003899995746029294\n",
      "Episode average V value: 0.4632741596017565\n",
      "Average (on the epoch) training loss: 0.00389629220396719\n",
      "Episode average V value: 0.5962599575519562\n",
      "Average (on the epoch) training loss: 0.003904133339888636\n",
      "Episode average V value: 0.6481211185455322\n",
      "Average (on the epoch) training loss: 0.003977169766945375\n",
      "Episode average V value: 0.7438040852546692\n",
      "Average (on the epoch) training loss: 0.0039429347304230505\n",
      "Episode average V value: 0.5272865187038075\n",
      "Average (on the epoch) training loss: 0.00394669527643239\n",
      "Episode average V value: 0.6385947689414024\n",
      "Average (on the epoch) training loss: 0.00396650594262875\n",
      "Episode average V value: 0.579354441165924\n",
      "Average (on the epoch) training loss: 0.003938486397571838\n",
      "Episode average V value: 0.6566912167602115\n",
      "Average (on the epoch) training loss: 0.003943406129064322\n",
      "Episode average V value: 0.8034016489982605\n",
      "Average (on the epoch) training loss: 0.003919208512606674\n",
      "Episode average V value: 0.8159362196922302\n",
      "Average (on the epoch) training loss: 0.003906832677732288\n",
      "Episode average V value: 0.5590618153413137\n",
      "Average (on the epoch) training loss: 0.003918242454705195\n",
      "Episode average V value: 0.9441544711589813\n",
      "Average (on the epoch) training loss: 0.003923603801432854\n",
      "Episode average V value: 0.6715331524610519\n",
      "Average (on the epoch) training loss: 0.0039330392625735065\n",
      "Episode average V value: 0.5496823787689209\n",
      "Average (on the epoch) training loss: 0.003926590171183555\n",
      "Episode average V value: 0.47793394097915065\n",
      "Average (on the epoch) training loss: 0.003936222434029374\n",
      "Episode average V value: 0.5507609844207764\n",
      "Average (on the epoch) training loss: 0.003910584834367191\n",
      "Episode average V value: 0.432203544811769\n",
      "Average (on the epoch) training loss: 0.0039003924458739362\n",
      "Episode average V value: 0.6942460338274637\n",
      "Average (on the epoch) training loss: 0.0038946601701837606\n",
      "Episode average V value: 0.6270893812179565\n",
      "Average (on the epoch) training loss: 0.003876297494096258\n",
      "Episode average V value: 0.48348870873451233\n",
      "Average (on the epoch) training loss: 0.00386721123329316\n",
      "Episode average V value: 0.7437738946505955\n",
      "Average (on the epoch) training loss: 0.0038494334871938918\n",
      "Episode average V value: 0.49324623346328733\n",
      "Average (on the epoch) training loss: 0.003839507229183513\n",
      "Episode average V value: 0.8363402883211771\n",
      "Average (on the epoch) training loss: 0.0038552108897011352\n",
      "Episode average V value: 0.4399427600204945\n",
      "Average (on the epoch) training loss: 0.0038794059737879056\n",
      "Episode average V value: 0.4174049437046051\n",
      "Average (on the epoch) training loss: 0.0038886093193651362\n",
      "Episode average V value: 0.4844768001483037\n",
      "Average (on the epoch) training loss: 0.003888247803034675\n",
      "Episode average V value: 0.4872924043582036\n",
      "Average (on the epoch) training loss: 0.003909679374523848\n",
      "Episode average V value: 0.8117367267608643\n",
      "Average (on the epoch) training loss: 0.0039081291840889565\n",
      "Episode average V value: 0.7269733101129532\n",
      "LOSSES\n",
      "T = 0.017729412380605936; R = 0.03845843591634184;                 Gamma = 0.505740035355091; Q = 0.0039279806818813085;\n",
      "Entropy Neighbor = 0.4613359806537628;                 Entropy Random = 0.14101295292377472;                 Volume = 0.3089826746881008; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1719,  0.1248,  0.2152, -0.6105, -0.8611], device='cuda:0') tensor([ 0.0388, -0.0025,  0.1854, -0.6410, -0.8901], device='cuda:0') tensor([ 0.0615,  0.0165,  0.1833, -0.6396, -0.8890], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0161], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003929506574231799\n",
      "Episode average V value: 0.6307246051728725\n",
      "Average (on the epoch) training loss: 0.003955262629819648\n",
      "Episode average V value: 0.440295251707236\n",
      "Average (on the epoch) training loss: 0.00396875542091121\n",
      "Episode average V value: 0.6130658523602919\n",
      "Average (on the epoch) training loss: 0.003954209309547389\n",
      "Episode average V value: 0.541940975934267\n",
      "Average (on the epoch) training loss: 0.003952691589990906\n",
      "Episode average V value: 0.8019764622052511\n",
      "Average (on the epoch) training loss: 0.003940828077140716\n",
      "Episode average V value: 0.4105565696954727\n",
      "Average (on the epoch) training loss: 0.0039610519937317195\n",
      "Episode average V value: 0.5451724864542484\n",
      "Average (on the epoch) training loss: 0.003968946718936954\n",
      "Episode average V value: 0.8546968698501587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.003962513698536661\n",
      "Episode average V value: 0.5053491493066152\n",
      "Average (on the epoch) training loss: 0.003962836942971787\n",
      "Episode average V value: 0.7764760951201121\n",
      "Average (on the epoch) training loss: 0.003952193673002789\n",
      "Episode average V value: 0.4703874954810509\n",
      "Average (on the epoch) training loss: 0.003953404357229784\n",
      "Episode average V value: 0.7049300670623779\n",
      "Average (on the epoch) training loss: 0.0039200961475234115\n",
      "Episode average V value: 0.46309487625609996\n",
      "Average (on the epoch) training loss: 0.003923181077833612\n",
      "Episode average V value: 0.5850746116854928\n",
      "Average (on the epoch) training loss: 0.003928137423743442\n",
      "Episode average V value: 0.7326568961143494\n",
      "Average (on the epoch) training loss: 0.003912263195334727\n",
      "Episode average V value: 0.6499700744946798\n",
      "Average (on the epoch) training loss: 0.0039057617861282517\n",
      "Episode average V value: 0.8117362499237061\n",
      "Average (on the epoch) training loss: 0.0039170964845214725\n",
      "Episode average V value: 0.5716855302453041\n",
      "Average (on the epoch) training loss: 0.0039051262446907226\n",
      "Episode average V value: 0.6426453420094081\n",
      "Average (on the epoch) training loss: 0.0039206038573167965\n",
      "Episode average V value: 0.4698021709918976\n",
      "Average (on the epoch) training loss: 0.003912566186108292\n",
      "Episode average V value: 0.745193076133728\n",
      "Average (on the epoch) training loss: 0.003916208405908626\n",
      "Episode average V value: 0.7971557974815369\n",
      "Average (on the epoch) training loss: 0.003917781403370692\n",
      "Episode average V value: 0.5021830526265231\n",
      "Average (on the epoch) training loss: 0.0039048604456265717\n",
      "Episode average V value: 0.5510251919428507\n",
      "Average (on the epoch) training loss: 0.0039026045040194907\n",
      "Episode average V value: 0.8966725865999857\n",
      "Average (on the epoch) training loss: 0.003895744397414595\n",
      "Episode average V value: 0.6622820837157113\n",
      "Average (on the epoch) training loss: 0.0038866187740505573\n",
      "Episode average V value: 0.5335649143565785\n",
      "Average (on the epoch) training loss: 0.003883772582670797\n",
      "Episode average V value: 0.6511095762252808\n",
      "Average (on the epoch) training loss: 0.003886471290017126\n",
      "Episode average V value: 0.6915113925933838\n",
      "Average (on the epoch) training loss: 0.0038874833799175494\n",
      "Episode average V value: 0.5487545639276504\n",
      "Average (on the epoch) training loss: 0.003887967771972617\n",
      "Episode average V value: 0.8966655333836874\n",
      "Average (on the epoch) training loss: 0.003896686589596404\n",
      "Episode average V value: 0.7152496150561741\n",
      "Average (on the epoch) training loss: 0.0038876289621213593\n",
      "Episode average V value: 0.5349809655121395\n",
      "Average (on the epoch) training loss: 0.0038851659986936272\n",
      "Episode average V value: 0.5851572453975677\n",
      "Average (on the epoch) training loss: 0.003884304890172124\n",
      "Episode average V value: 0.7769918143749237\n",
      "Average (on the epoch) training loss: 0.003891440647462458\n",
      "Episode average V value: 0.4896356850862503\n",
      "Average (on the epoch) training loss: 0.0038903639403511238\n",
      "Episode average V value: 0.573025768995285\n",
      "Average (on the epoch) training loss: 0.0038943164976877557\n",
      "Episode average V value: 0.7330881357192993\n",
      "Average (on the epoch) training loss: 0.003908778255751094\n",
      "Episode average V value: 0.6146415770053864\n",
      "Average (on the epoch) training loss: 0.0039024754789319226\n",
      "Episode average V value: 0.4496433466672897\n",
      "Average (on the epoch) training loss: 0.0039018950337429614\n",
      "Episode average V value: 0.5211060146490732\n",
      "Average (on the epoch) training loss: 0.003905781035974486\n",
      "Episode average V value: 0.5046204200812748\n",
      "Average (on the epoch) training loss: 0.0038855153958650464\n",
      "Episode average V value: 0.5232992087091718\n",
      "Average (on the epoch) training loss: 0.0038812618164061944\n",
      "Episode average V value: 0.6967160105705261\n",
      "Average (on the epoch) training loss: 0.0038764719244764735\n",
      "Episode average V value: 0.5499530368381076\n",
      "Average (on the epoch) training loss: 0.0038761264944757764\n",
      "Episode average V value: 0.6080275535583496\n",
      "Average (on the epoch) training loss: 0.00388372594339164\n",
      "Episode average V value: 0.7977399230003357\n",
      "Average (on the epoch) training loss: 0.003883630857206072\n",
      "Episode average V value: 0.6735885143280029\n",
      "Average (on the epoch) training loss: 0.0038804060149840104\n",
      "Episode average V value: 0.556947865656444\n",
      "Average (on the epoch) training loss: 0.0038782095077972167\n",
      "Episode average V value: 0.8359989523887634\n",
      "Average (on the epoch) training loss: 0.003888764612750746\n",
      "Episode average V value: 0.693948487440745\n",
      "Average (on the epoch) training loss: 0.0038872089866503223\n",
      "Episode average V value: 0.818881893157959\n",
      "Average (on the epoch) training loss: 0.0038905360269663653\n",
      "Episode average V value: 0.7158714277403695\n",
      "Average (on the epoch) training loss: 0.003907623861165603\n",
      "Episode average V value: 0.8384228547414144\n",
      "Average (on the epoch) training loss: 0.003902891944620778\n",
      "Episode average V value: 0.6558782590760125\n",
      "Average (on the epoch) training loss: 0.0038941422224314393\n",
      "Episode average V value: 0.5780864983797074\n",
      "Average (on the epoch) training loss: 0.003893614608023199\n",
      "Episode average V value: 0.5296059787273407\n",
      "Average (on the epoch) training loss: 0.003892175130920752\n",
      "Episode average V value: 0.797437995672226\n",
      "Average (on the epoch) training loss: 0.0038969117359584676\n",
      "Episode average V value: 0.6801682412624359\n",
      "Average (on the epoch) training loss: 0.003887928688691616\n",
      "Episode average V value: 0.8159030228853226\n",
      "Average (on the epoch) training loss: 0.0038914845588406913\n",
      "Episode average V value: 0.5542570576071739\n",
      "Average (on the epoch) training loss: 0.003894725102411366\n",
      "Episode average V value: 0.606041973287409\n",
      "Average (on the epoch) training loss: 0.003891337406565179\n",
      "Episode average V value: 0.8138602375984192\n",
      "LOSSES\n",
      "T = 0.018181695660576223; R = 0.039144906990230086;                 Gamma = 0.5051455006599427; Q = 0.0038512261426076294;\n",
      "Entropy Neighbor = 0.4542984927296638;                 Entropy Random = 0.1418870994001627;                 Volume = 0.312857486397028; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0038896034122444688\n",
      "Episode average V value: 0\n",
      "epoch 38:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9 (average over 10 episode(s))\n",
      "== Mean score per episode is 0.8999910000899991 over 10 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0320, -1.0487, -0.1241, -0.9522, -1.2147], device='cuda:0') tensor([-1.0542, -1.0181, -0.0761, -1.0086, -1.3431], device='cuda:0') tensor([-1.2052, -1.1874, -0.1335, -1.0915, -1.4427], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1804], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.004317506177661319\n",
      "Episode average V value: 0.5306325932343801\n",
      "Average (on the epoch) training loss: 0.00423989007686032\n",
      "Episode average V value: 0.887434720993042\n",
      "Average (on the epoch) training loss: 0.004329234295848595\n",
      "Episode average V value: 0.6753567755222321\n",
      "Average (on the epoch) training loss: 0.004146062961808639\n",
      "Episode average V value: 0.6092708706855774\n",
      "Average (on the epoch) training loss: 0.0041521048965828065\n",
      "Episode average V value: 0.3949433729052544\n",
      "Average (on the epoch) training loss: 0.004053775117393922\n",
      "Episode average V value: 0.4613465666770935\n",
      "Average (on the epoch) training loss: 0.0040657994807055545\n",
      "Episode average V value: 0.9243703186511993\n",
      "Average (on the epoch) training loss: 0.00402407232277955\n",
      "Episode average V value: 0.7275823801755905\n",
      "Average (on the epoch) training loss: 0.004224918449196864\n",
      "Episode average V value: 0.6678836146990458\n",
      "Average (on the epoch) training loss: 0.004055352952987464\n",
      "Episode average V value: 0.45978921226092745\n",
      "Average (on the epoch) training loss: 0.0040362916985506436\n",
      "Episode average V value: 0.8168681710958481\n",
      "Average (on the epoch) training loss: 0.004023952877546832\n",
      "Episode average V value: 0.3852253664623607\n",
      "Average (on the epoch) training loss: 0.0038767302626460465\n",
      "Episode average V value: 0.5493916322787603\n",
      "Average (on the epoch) training loss: 0.0038759214687161146\n",
      "Episode average V value: 0.8172685623168945\n",
      "Average (on the epoch) training loss: 0.003948258895737429\n",
      "Episode average V value: 0.6957525610923767\n",
      "Average (on the epoch) training loss: 0.003903414465689151\n",
      "Episode average V value: 0.5166249672571818\n",
      "Average (on the epoch) training loss: 0.0038923441951807876\n",
      "Episode average V value: 0.88789963722229\n",
      "Average (on the epoch) training loss: 0.0038749715704198954\n",
      "Episode average V value: 0.6417484496320996\n",
      "Average (on the epoch) training loss: 0.0038849262978303536\n",
      "Episode average V value: 0.537373386323452\n",
      "Average (on the epoch) training loss: 0.003849375603702403\n",
      "Episode average V value: 0.5190349022547404\n",
      "Average (on the epoch) training loss: 0.003861226786379388\n",
      "Episode average V value: 0.6598131623533037\n",
      "Average (on the epoch) training loss: 0.003779997230906572\n",
      "Episode average V value: 0.5465811192989349\n",
      "Average (on the epoch) training loss: 0.0038486842822749168\n",
      "Episode average V value: 0.5105563215911388\n",
      "Average (on the epoch) training loss: 0.003866844861213253\n",
      "Episode average V value: 0.47150280326604843\n",
      "Average (on the epoch) training loss: 0.0038442535252005863\n",
      "Episode average V value: 0.4828851797751018\n",
      "Average (on the epoch) training loss: 0.003873382524833618\n",
      "Episode average V value: 0.3916743208061565\n",
      "Average (on the epoch) training loss: 0.0038712496424300803\n",
      "Episode average V value: 0.7066785395145416\n",
      "Average (on the epoch) training loss: 0.00386524068297851\n",
      "Episode average V value: 0.8441872298717499\n",
      "Average (on the epoch) training loss: 0.0038895783574171678\n",
      "Episode average V value: 0.594189926981926\n",
      "Average (on the epoch) training loss: 0.003874851936504607\n",
      "Episode average V value: 0.6023979038000107\n",
      "Average (on the epoch) training loss: 0.003855388760384099\n",
      "Episode average V value: 0.6162857599556446\n",
      "Average (on the epoch) training loss: 0.0037987669024176036\n",
      "Episode average V value: 0.39633171473230633\n",
      "Average (on the epoch) training loss: 0.0037657647624432127\n",
      "Episode average V value: 0.5002618208527565\n",
      "Average (on the epoch) training loss: 0.003761947783682222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0037459379789652305\n",
      "Episode average V value: 0.5282477608748845\n",
      "Average (on the epoch) training loss: 0.0037395012544989463\n",
      "Episode average V value: 0.48550014363394844\n",
      "Average (on the epoch) training loss: 0.003733596258849326\n",
      "Episode average V value: 0.9913108944892883\n",
      "Average (on the epoch) training loss: 0.003716465162675365\n",
      "Episode average V value: 0.8169709742069244\n",
      "Average (on the epoch) training loss: 0.003705089625524398\n",
      "Episode average V value: 0.6123445153236389\n",
      "Average (on the epoch) training loss: 0.0037370078887134857\n",
      "Episode average V value: 0.46999049683411914\n",
      "Average (on the epoch) training loss: 0.0037304563089497612\n",
      "Episode average V value: 0.7079054117202759\n",
      "Average (on the epoch) training loss: 0.0037465461573867676\n",
      "Episode average V value: 0.517512860623273\n",
      "Average (on the epoch) training loss: 0.0037390157277563166\n",
      "Episode average V value: 0.7194228768348694\n",
      "Average (on the epoch) training loss: 0.003744334252763447\n",
      "Episode average V value: 0.588501513004303\n",
      "Average (on the epoch) training loss: 0.0037336043071014525\n",
      "Episode average V value: 0.8924554189046224\n",
      "Average (on the epoch) training loss: 0.003726023660085441\n",
      "Episode average V value: 0.6554590344429017\n",
      "Average (on the epoch) training loss: 0.003730375356816997\n",
      "Episode average V value: 0.6990514993667603\n",
      "Average (on the epoch) training loss: 0.003722135026314665\n",
      "Episode average V value: 0.6438044011592865\n",
      "Average (on the epoch) training loss: 0.0037165614701843972\n",
      "Episode average V value: 0.8003870248794556\n",
      "Average (on the epoch) training loss: 0.003750126762285857\n",
      "Episode average V value: 0.6641625336238316\n",
      "Average (on the epoch) training loss: 0.0037515600988902434\n",
      "Episode average V value: 0.8189064025878906\n",
      "Average (on the epoch) training loss: 0.003758627949149975\n",
      "Episode average V value: 0.5338747389614582\n",
      "Average (on the epoch) training loss: 0.003756212282391535\n",
      "Episode average V value: 0.6992275714874268\n",
      "Average (on the epoch) training loss: 0.0037869099033521975\n",
      "Episode average V value: 0.39838290214538574\n",
      "Average (on the epoch) training loss: 0.0037783684214754997\n",
      "Episode average V value: 0.9248871803283691\n",
      "Average (on the epoch) training loss: 0.00377715869108215\n",
      "Episode average V value: 0.889691948890686\n",
      "Average (on the epoch) training loss: 0.003772122156505687\n",
      "Episode average V value: 0.9912036061286926\n",
      "Average (on the epoch) training loss: 0.0037761007461460305\n",
      "Episode average V value: 0.5751222848892212\n",
      "Average (on the epoch) training loss: 0.0037697887419860555\n",
      "Episode average V value: 0.9242611825466156\n",
      "Average (on the epoch) training loss: 0.003782554106361905\n",
      "Episode average V value: 0.691705326239268\n",
      "Average (on the epoch) training loss: 0.003796793104919691\n",
      "Episode average V value: 0.7045168951153755\n",
      "Average (on the epoch) training loss: 0.003803263111937364\n",
      "Episode average V value: 0.46621699452400206\n",
      "Average (on the epoch) training loss: 0.0037965800974412447\n",
      "Episode average V value: 0.8579098284244537\n",
      "Average (on the epoch) training loss: 0.003789490926607707\n",
      "Episode average V value: 0.8104547739028931\n",
      "LOSSES\n",
      "T = 0.01796715760510415; R = 0.03899595951847732;                 Gamma = 0.5046767171621322; Q = 0.0037886753532802688;\n",
      "Entropy Neighbor = 0.45362808227539064;                 Entropy Random = 0.14244603751599788;                 Volume = 0.3157005206048489; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0442, -0.0097,  0.1633, -0.6147, -0.8385], device='cuda:0') tensor([ 0.0617, -0.0146,  0.1542, -0.6186, -0.8694], device='cuda:0') tensor([ 0.0442, -0.0097,  0.1633, -0.6147, -0.8385], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0158], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003788847865725114\n",
      "Episode average V value: 0.6138175807215951\n",
      "Average (on the epoch) training loss: 0.0037845471429903354\n",
      "Episode average V value: 0.6427459972245353\n",
      "Average (on the epoch) training loss: 0.003778913800094931\n",
      "Episode average V value: 0.3983343115874699\n",
      "Average (on the epoch) training loss: 0.0037727257530648438\n",
      "Episode average V value: 0.6191867291927338\n",
      "Average (on the epoch) training loss: 0.0037834977376581098\n",
      "Episode average V value: 0.8156435489654541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.0037952190762272574\n",
      "Episode average V value: 0.7675698161125183\n",
      "Average (on the epoch) training loss: 0.0037994682449931814\n",
      "Episode average V value: 0.7338707745075226\n",
      "Average (on the epoch) training loss: 0.0038010916213535393\n",
      "Episode average V value: 0.5803655207157135\n",
      "Average (on the epoch) training loss: 0.0037954004384698247\n",
      "Episode average V value: 0.5168651017275724\n",
      "Average (on the epoch) training loss: 0.0037916575263110684\n",
      "Episode average V value: 0.7078717947006226\n",
      "Average (on the epoch) training loss: 0.0037951691569392816\n",
      "Episode average V value: 0.41093432903289795\n",
      "Average (on the epoch) training loss: 0.0037928026412359247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.003827540027212881\n",
      "Episode average V value: 0.46996409942706424\n",
      "Average (on the epoch) training loss: 0.003817404797843176\n",
      "Episode average V value: 0.8562887758016586\n",
      "Average (on the epoch) training loss: 0.003810131077041293\n",
      "Episode average V value: 0.4544222219423814\n",
      "Average (on the epoch) training loss: 0.0038209595231170988\n",
      "Episode average V value: 0.8454749882221222\n",
      "Average (on the epoch) training loss: 0.003807241374097047\n",
      "Episode average V value: 0.5299153923988342\n",
      "Average (on the epoch) training loss: 0.00380371894410199\n",
      "Episode average V value: 0.5545699000358582\n",
      "Average (on the epoch) training loss: 0.003800607254584648\n",
      "Episode average V value: 0.66661696434021\n",
      "Average (on the epoch) training loss: 0.0038144374839089432\n",
      "Episode average V value: 0.7854450225830079\n",
      "Average (on the epoch) training loss: 0.00381158879164269\n",
      "Episode average V value: 0.7665319204330444\n",
      "Average (on the epoch) training loss: 0.003809588279533441\n",
      "Episode average V value: 0.7774390876293182\n",
      "Average (on the epoch) training loss: 0.0038067167760469423\n",
      "Episode average V value: 0.5621025941588662\n",
      "Average (on the epoch) training loss: 0.0037992302707671034\n",
      "Episode average V value: 0.6525192499160767\n",
      "Average (on the epoch) training loss: 0.003792792021719736\n",
      "Episode average V value: 0.8545892536640167\n",
      "Average (on the epoch) training loss: 0.003816316175606274\n",
      "Episode average V value: 0.7036020196974277\n",
      "Average (on the epoch) training loss: 0.00381368495251781\n",
      "Episode average V value: 0.506384402513504\n",
      "Average (on the epoch) training loss: 0.003818432832221416\n",
      "Episode average V value: 0.5547410249710083\n",
      "Average (on the epoch) training loss: 0.00383525588874082\n",
      "Episode average V value: 0.5129536475454058\n",
      "Average (on the epoch) training loss: 0.003831376451410182\n",
      "Episode average V value: 0.6755814552307129\n",
      "Average (on the epoch) training loss: 0.0038282271680897075\n",
      "Episode average V value: 0.4773648331562678\n",
      "Average (on the epoch) training loss: 0.003822501499197935\n",
      "Episode average V value: 0.5838128477334976\n",
      "Average (on the epoch) training loss: 0.003816576194062938\n",
      "Episode average V value: 0.658334367805057\n",
      "Average (on the epoch) training loss: 0.0038198460910694094\n",
      "Episode average V value: 0.6276680997439793\n",
      "Average (on the epoch) training loss: 0.0038145986647976637\n",
      "Episode average V value: 0.7682317018508911\n",
      "Average (on the epoch) training loss: 0.0038245887550221263\n",
      "Episode average V value: 0.5379541993141175\n",
      "Average (on the epoch) training loss: 0.0038225697669759646\n",
      "Episode average V value: 0.9005335172017416\n",
      "Average (on the epoch) training loss: 0.003816872889965718\n",
      "Episode average V value: 0.4627521187067032\n",
      "Average (on the epoch) training loss: 0.0038133897442431015\n",
      "Episode average V value: 0.6998293002446493\n",
      "Average (on the epoch) training loss: 0.0038154468920836297\n",
      "Episode average V value: 0.3482941143652972\n",
      "Average (on the epoch) training loss: 0.003799764022512571\n",
      "Episode average V value: 0.46711293033191137\n",
      "Average (on the epoch) training loss: 0.003794165740896768\n",
      "Episode average V value: 0.36238111555576324\n",
      "Average (on the epoch) training loss: 0.0037929892779197316\n",
      "Episode average V value: 0.498455890587398\n",
      "Average (on the epoch) training loss: 0.0037906587663923703\n",
      "Episode average V value: 0.455774509244495\n",
      "Average (on the epoch) training loss: 0.0037966949785860145\n",
      "Episode average V value: 0.572422306984663\n",
      "Average (on the epoch) training loss: 0.0038041550725976046\n",
      "Episode average V value: 0.7150225281715393\n",
      "Average (on the epoch) training loss: 0.003806270011442875\n",
      "Episode average V value: 0.54942239182336\n",
      "Average (on the epoch) training loss: 0.003799250700432283\n",
      "Episode average V value: 0.8110039949417114\n",
      "Average (on the epoch) training loss: 0.0038069431480524185\n",
      "Episode average V value: 0.5859929621219635\n",
      "Average (on the epoch) training loss: 0.003797540536163271\n",
      "Episode average V value: 0.5158182301304557\n",
      "Average (on the epoch) training loss: 0.0037932365780917526\n",
      "Episode average V value: 0.6050413370132446\n",
      "Average (on the epoch) training loss: 0.0037864138250314067\n",
      "Episode average V value: 0.5529625415802002\n",
      "Average (on the epoch) training loss: 0.003782489300615512\n",
      "Episode average V value: 0.45895370841026306\n",
      "Average (on the epoch) training loss: 0.003774046054505693\n",
      "Episode average V value: 0.5622029423713684\n",
      "Average (on the epoch) training loss: 0.003774632086554984\n",
      "Episode average V value: 0.5451383471488953\n",
      "Average (on the epoch) training loss: 0.003775708382511869\n",
      "Episode average V value: 0.9450165033340454\n",
      "Average (on the epoch) training loss: 0.003779402950460771\n",
      "Episode average V value: 0.7339617411295573\n",
      "Average (on the epoch) training loss: 0.003779716269172622\n",
      "Episode average V value: 0.8014632165431976\n",
      "Average (on the epoch) training loss: 0.0037806565580389157\n",
      "Episode average V value: 0.9365555047988892\n",
      "Average (on the epoch) training loss: 0.0037699812120384497\n",
      "Episode average V value: 0.6430543462435404\n",
      "Average (on the epoch) training loss: 0.003768296417728534\n",
      "Episode average V value: 0.8159228265285492\n",
      "Average (on the epoch) training loss: 0.003782600895083772\n",
      "Episode average V value: 0.4411232390187003\n",
      "Average (on the epoch) training loss: 0.003784701040491655\n",
      "Episode average V value: 0.45953163504600525\n",
      "Average (on the epoch) training loss: 0.003787525174048209\n",
      "Episode average V value: 0.7814998149871826\n",
      "Average (on the epoch) training loss: 0.0037868472953515326\n",
      "Episode average V value: 0.63322314620018\n",
      "Average (on the epoch) training loss: 0.0037913915885768525\n",
      "Episode average V value: 0.9357423782348633\n",
      "LOSSES\n",
      "T = 0.018023380629718304; R = 0.03971259973663837;                 Gamma = 0.5036911255121231; Q = 0.003789150866679847;\n",
      "Entropy Neighbor = 0.450834512591362;                 Entropy Random = 0.13968938659131527;                 Volume = 0.32415506133437155; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.003788913109980058\n",
      "Episode average V value: 0.39486202597618103\n",
      "epoch 39:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9230769230769231 (average over 13 episode(s))\n",
      "== Mean score per episode is 0.9230698225398266 over 13 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7577, -0.7983, -0.0720, -0.8220, -1.0344], device='cuda:0') tensor([-0.8493, -0.8418, -0.0700, -0.8813, -1.1556], device='cuda:0') tensor([-1.0307, -1.0467, -0.1259, -0.9526, -1.2191], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1048], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.003799597323606057\n",
      "Episode average V value: 0.3929490736552647\n",
      "Average (on the epoch) training loss: 0.003959237762058201\n",
      "Episode average V value: 0.8067002296447754\n",
      "Average (on the epoch) training loss: 0.004160507145570591\n",
      "Episode average V value: 0.6687437534332276\n",
      "Average (on the epoch) training loss: 0.0039777247090208925\n",
      "Episode average V value: 0.6476525142788887\n",
      "Average (on the epoch) training loss: 0.0038308733139095492\n",
      "Episode average V value: 0.6231423914432526\n",
      "Average (on the epoch) training loss: 0.0038851880944212494\n",
      "Episode average V value: 0.6076477084841047\n",
      "Average (on the epoch) training loss: 0.003912676854556656\n",
      "Episode average V value: 0.8520306795835495\n",
      "Average (on the epoch) training loss: 0.003887109666844301\n",
      "Episode average V value: 0.7016807993253072\n",
      "Average (on the epoch) training loss: 0.003994952073614848\n",
      "Episode average V value: 0.4560121756333571\n",
      "Average (on the epoch) training loss: 0.003968828344193188\n",
      "Episode average V value: 0.6045482382178307\n",
      "Average (on the epoch) training loss: 0.003920799352982569\n",
      "Episode average V value: 0.9464676976203918\n",
      "Average (on the epoch) training loss: 0.0039060404028176616\n",
      "Episode average V value: 0.5690217256546021\n",
      "Average (on the epoch) training loss: 0.0038695860722024614\n",
      "Episode average V value: 0.670063602924347\n",
      "Average (on the epoch) training loss: 0.0038551338347148334\n",
      "Episode average V value: 0.9462147951126099\n",
      "Average (on the epoch) training loss: 0.0038373480765442327\n",
      "Episode average V value: 0.8376361727714539\n",
      "Average (on the epoch) training loss: 0.003839602582047519\n",
      "Episode average V value: 0.5569637417793274\n",
      "Average (on the epoch) training loss: 0.003839879599921127\n",
      "Episode average V value: 0.7769612669944763\n",
      "Average (on the epoch) training loss: 0.003855032675988589\n",
      "Episode average V value: 0.7807393670082092\n",
      "Average (on the epoch) training loss: 0.0038056175738316158\n",
      "Episode average V value: 0.5584982964727614\n",
      "Average (on the epoch) training loss: 0.003780688119838266\n",
      "Episode average V value: 0.9377480447292328\n",
      "Average (on the epoch) training loss: 0.0037038618704500776\n",
      "Episode average V value: 0.5584122439225515\n",
      "Average (on the epoch) training loss: 0.0036925495613688306\n",
      "Episode average V value: 1.0002379417419434\n",
      "Average (on the epoch) training loss: 0.0037469816359910458\n",
      "Episode average V value: 0.649384155869484\n",
      "Average (on the epoch) training loss: 0.003841813793789677\n",
      "Episode average V value: 0.5775352228771556\n",
      "Average (on the epoch) training loss: 0.00379296518027435\n",
      "Episode average V value: 0.5760416984558105\n",
      "Average (on the epoch) training loss: 0.0037735892582536484\n",
      "Episode average V value: 0.6884699889591762\n",
      "Average (on the epoch) training loss: 0.0037830816695421207\n",
      "Episode average V value: 0.6267632395029068\n",
      "Average (on the epoch) training loss: 0.003771960536233973\n",
      "Episode average V value: 0.9259366989135742\n",
      "Average (on the epoch) training loss: 0.0036836277948168574\n",
      "Episode average V value: 0.4813080502278877\n",
      "Average (on the epoch) training loss: 0.0036806402591361303\n",
      "Episode average V value: 0.5645751282572746\n",
      "Average (on the epoch) training loss: 0.003661772251675407\n",
      "Episode average V value: 0.5453683465719223\n",
      "Average (on the epoch) training loss: 0.003670656928889467\n",
      "Episode average V value: 0.42582871871335165\n",
      "Average (on the epoch) training loss: 0.00367826098081423\n",
      "Episode average V value: 0.7607763310273489\n",
      "Average (on the epoch) training loss: 0.0036707195971234486\n",
      "Episode average V value: 0.4673757824030789\n",
      "Average (on the epoch) training loss: 0.0037368264458659964\n",
      "Episode average V value: 0.4642678424715996\n",
      "Average (on the epoch) training loss: 0.0037448134037047164\n",
      "Episode average V value: 0.8999650080998739\n",
      "Average (on the epoch) training loss: 0.003732507852220033\n",
      "Episode average V value: 0.734190434217453\n",
      "Average (on the epoch) training loss: 0.0037601315052140176\n",
      "Episode average V value: 0.6172549605369568\n",
      "Average (on the epoch) training loss: 0.003803113772049489\n",
      "Episode average V value: 0.7206989824771881\n",
      "Average (on the epoch) training loss: 0.0038175363923783597\n",
      "Episode average V value: 0.8998893698056539\n",
      "Average (on the epoch) training loss: 0.0038104585660194436\n",
      "Episode average V value: 0.5446339309215545\n",
      "Average (on the epoch) training loss: 0.003813382589273275\n",
      "Episode average V value: 0.8919306000073751\n",
      "Average (on the epoch) training loss: 0.0038038216890704767\n",
      "Episode average V value: 0.7692517042160034\n",
      "Average (on the epoch) training loss: 0.00382248068687969\n",
      "Episode average V value: 0.926173597574234\n",
      "Average (on the epoch) training loss: 0.0038211488004515006\n",
      "Episode average V value: 0.9002930124600729\n",
      "Average (on the epoch) training loss: 0.0038140536602203953\n",
      "Episode average V value: 0.8172295242547989\n",
      "Average (on the epoch) training loss: 0.0037955586218336706\n",
      "Episode average V value: 0.6708894703123305\n",
      "Average (on the epoch) training loss: 0.0037675418461243504\n",
      "Episode average V value: 0.47827909588813783\n",
      "Average (on the epoch) training loss: 0.0037726171702044974\n",
      "Episode average V value: 0.7697784900665283\n",
      "Average (on the epoch) training loss: 0.003775750333535677\n",
      "Episode average V value: 0.7809830904006958\n",
      "Average (on the epoch) training loss: 0.0037673806702211246\n",
      "Episode average V value: 0.7168430288632711\n",
      "Average (on the epoch) training loss: 0.0037456679896805864\n",
      "Episode average V value: 0.747793436050415\n",
      "Average (on the epoch) training loss: 0.0037577223258138024\n",
      "Episode average V value: 0.858990877866745\n",
      "Average (on the epoch) training loss: 0.0037393014349843294\n",
      "Episode average V value: 0.5494352668523789\n",
      "Average (on the epoch) training loss: 0.0037551561104608136\n",
      "Episode average V value: 0.43637815316518147\n",
      "Average (on the epoch) training loss: 0.0037500446600439007\n",
      "Episode average V value: 0.38301160080092295\n",
      "LOSSES\n",
      "T = 0.01830387002788484; R = 0.03882260968908668;                 Gamma = 0.5049182023406029; Q = 0.0037676520997192713;\n",
      "Entropy Neighbor = 0.4483211485743523;                 Entropy Random = 0.14144803884625434;                 Volume = 0.3246212954223156; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5103, -0.4668,  0.1117, -1.0188, -1.4915], device='cuda:0') tensor([-0.6702, -0.6860,  0.0650, -1.0098, -1.2809], device='cuda:0') tensor([-0.6571, -0.6009,  0.0819, -1.0875, -1.5879], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2580], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.00377415974662563\n",
      "Episode average V value: 0.6163252964615822\n",
      "Average (on the epoch) training loss: 0.003786044441239003\n",
      "Episode average V value: 0.605747127532959\n",
      "Average (on the epoch) training loss: 0.0037814044347848266\n",
      "Episode average V value: 0.705681823194027\n",
      "Average (on the epoch) training loss: 0.003786800118076531\n",
      "Episode average V value: 0.6973417152961096\n",
      "Average (on the epoch) training loss: 0.0037809572073067574\n",
      "Episode average V value: 0.896255612373352\n",
      "Average (on the epoch) training loss: 0.0037905531862224705\n",
      "Episode average V value: 0.5165516833464304\n",
      "Average (on the epoch) training loss: 0.0037889732284010083\n",
      "Episode average V value: 0.9265606701374054\n",
      "Average (on the epoch) training loss: 0.003780847726884801\n",
      "Episode average V value: 0.9008616209030151\n",
      "Average (on the epoch) training loss: 0.0037691733454869813\n",
      "Episode average V value: 0.4468373417854309\n",
      "Average (on the epoch) training loss: 0.003762235853126296\n",
      "Episode average V value: 0.6188798248767853\n",
      "Average (on the epoch) training loss: 0.0037553735283473275\n",
      "Episode average V value: 0.7165487706661224\n",
      "Average (on the epoch) training loss: 0.003747933340644103\n",
      "Episode average V value: 0.5438155744756971\n",
      "Average (on the epoch) training loss: 0.00374259915932419\n",
      "Episode average V value: 0.891620914141337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.003735035794795069\n",
      "Episode average V value: 0.5759899355471134\n",
      "Average (on the epoch) training loss: 0.003738236576736339\n",
      "Episode average V value: 0.7815439502398173\n",
      "Average (on the epoch) training loss: 0.003741799958457412\n",
      "Episode average V value: 0.7818316320578257\n",
      "Average (on the epoch) training loss: 0.0037797768401762236\n",
      "Episode average V value: 0.6875970789364406\n",
      "Average (on the epoch) training loss: 0.003795229774113026\n",
      "Episode average V value: 0.5215417792399725\n",
      "Average (on the epoch) training loss: 0.003794400758414866\n",
      "Episode average V value: 0.9454050660133362\n",
      "Average (on the epoch) training loss: 0.0037958699333826033\n",
      "Episode average V value: 0.7689292192459106\n",
      "Average (on the epoch) training loss: 0.00378553739375627\n",
      "Episode average V value: 0.49016585675152863\n",
      "Average (on the epoch) training loss: 0.003781317546508944\n",
      "Episode average V value: 0.5740812599658967\n",
      "Average (on the epoch) training loss: 0.0037802956022599254\n",
      "Episode average V value: 0.8041554391384125\n",
      "Average (on the epoch) training loss: 0.0037691872002008236\n",
      "Episode average V value: 0.900175134340922\n",
      "Average (on the epoch) training loss: 0.003775262982247675\n",
      "Episode average V value: 0.49868130454650295\n",
      "Average (on the epoch) training loss: 0.003790390059690584\n",
      "Episode average V value: 0.8938222527503967\n",
      "Average (on the epoch) training loss: 0.0037848807280390384\n",
      "Episode average V value: 0.5366409085690975\n",
      "Average (on the epoch) training loss: 0.003779577922188459\n",
      "Episode average V value: 0.6331433862447738\n",
      "Average (on the epoch) training loss: 0.0037913016545602436\n",
      "Episode average V value: 0.4568340044755202\n",
      "Average (on the epoch) training loss: 0.0037880859981513876\n",
      "Episode average V value: 0.6064009845256806\n",
      "Average (on the epoch) training loss: 0.003785029612249757\n",
      "Episode average V value: 0.5572937726974487\n",
      "Average (on the epoch) training loss: 0.0037807668423353474\n",
      "Episode average V value: 0.6520589739084244\n",
      "Average (on the epoch) training loss: 0.0037748175746754797\n",
      "Episode average V value: 0.5097169015142653\n",
      "Average (on the epoch) training loss: 0.0037719905375628126\n",
      "Episode average V value: 0.8047177493572235\n",
      "Average (on the epoch) training loss: 0.0037678304678748892\n",
      "Episode average V value: 0.9458806216716766\n",
      "Average (on the epoch) training loss: 0.003764781312028113\n",
      "Episode average V value: 0.5275516932209333\n",
      "Average (on the epoch) training loss: 0.0037672401871689945\n",
      "Episode average V value: 0.7122301459312439\n",
      "Average (on the epoch) training loss: 0.003765859657864623\n",
      "Episode average V value: 0.5257043154800639\n",
      "Average (on the epoch) training loss: 0.0037800323036627317\n",
      "Episode average V value: 0.5539997882313199\n",
      "Average (on the epoch) training loss: 0.0037734146991706997\n",
      "Episode average V value: 0.8927815556526184\n",
      "Average (on the epoch) training loss: 0.0037787495331434275\n",
      "Episode average V value: 0.6010284291373359\n",
      "Average (on the epoch) training loss: 0.003775982192108781\n",
      "Episode average V value: 0.7702430486679077\n",
      "Average (on the epoch) training loss: 0.0037754417641106277\n",
      "Episode average V value: 0.9460383057594299\n",
      "Average (on the epoch) training loss: 0.0037721415225843973\n",
      "Episode average V value: 0.9273602962493896\n",
      "Average (on the epoch) training loss: 0.0037713611126621344\n",
      "Episode average V value: 0.6162846521897749\n",
      "Average (on the epoch) training loss: 0.003764888033825778\n",
      "Episode average V value: 0.6513751149177551\n",
      "Average (on the epoch) training loss: 0.003760992497740318\n",
      "Episode average V value: 0.7119473417599996\n",
      "Average (on the epoch) training loss: 0.0037496281542780986\n",
      "Episode average V value: 0.6398832410573959\n",
      "Average (on the epoch) training loss: 0.003772333385781679\n",
      "Episode average V value: 0.43857397304640877\n",
      "Average (on the epoch) training loss: 0.0037673372151046038\n",
      "Episode average V value: 0.559978666404883\n",
      "Average (on the epoch) training loss: 0.003758088635433558\n",
      "Episode average V value: 0.5929424576461315\n",
      "Average (on the epoch) training loss: 0.0037606533143560513\n",
      "Episode average V value: 0.8991852601369222\n",
      "Average (on the epoch) training loss: 0.003758997775219903\n",
      "Episode average V value: 0.9364126324653625\n",
      "Average (on the epoch) training loss: 0.0037545259128946656\n",
      "Episode average V value: 0.608307808637619\n",
      "Average (on the epoch) training loss: 0.003747884636736828\n",
      "Episode average V value: 0.5079077134529749\n",
      "Average (on the epoch) training loss: 0.0037443030108872733\n",
      "Episode average V value: 0.6545990034937859\n",
      "Average (on the epoch) training loss: 0.003738372975154623\n",
      "Episode average V value: 0.5330666953867133\n",
      "Average (on the epoch) training loss: 0.003728153296531784\n",
      "Episode average V value: 0.45235063364872563\n",
      "Average (on the epoch) training loss: 0.0037352953593337746\n",
      "Episode average V value: 0.8087489604949951\n",
      "Average (on the epoch) training loss: 0.0037292066750500602\n",
      "Episode average V value: 0.5904981096585592\n",
      "Average (on the epoch) training loss: 0.0037316070962796983\n",
      "Episode average V value: 0.7881910920143127\n",
      "Average (on the epoch) training loss: 0.0037486853454404842\n",
      "Episode average V value: 0.7585113525390625\n",
      "Average (on the epoch) training loss: 0.003751834391035069\n",
      "Episode average V value: 0.5509209707379341\n",
      "Average (on the epoch) training loss: 0.003751204346901769\n",
      "Episode average V value: 0.6411131223042806\n",
      "Average (on the epoch) training loss: 0.003751026406403511\n",
      "Episode average V value: 0.3852378539741039\n",
      "Average (on the epoch) training loss: 0.0037503760039875565\n",
      "Episode average V value: 0.6263672212759653\n",
      "Average (on the epoch) training loss: 0.003746906157782499\n",
      "Episode average V value: 0.7711016237735748\n",
      "Average (on the epoch) training loss: 0.0037478935064036807\n",
      "Episode average V value: 0.7834498484929403\n",
      "Average (on the epoch) training loss: 0.0037470373584014573\n",
      "Episode average V value: 0.7040810585021973\n",
      "Average (on the epoch) training loss: 0.0037426786656714825\n",
      "Episode average V value: 0.6894625276327133\n",
      "Average (on the epoch) training loss: 0.003738222594815071\n",
      "Episode average V value: 0.6590695778528849\n",
      "Average (on the epoch) training loss: 0.0037316608083570123\n",
      "Episode average V value: 0.6692946434020997\n",
      "LOSSES\n",
      "T = 0.01820203399285674; R = 0.04034964791033417;                 Gamma = 0.5033740853667259; Q = 0.0036980949111748485;\n",
      "Entropy Neighbor = 0.4468942548632622;                 Entropy Random = 0.14111122496426107;                 Volume = 0.32938110783696173; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.00373287350544706\n",
      "Episode average V value: 0.4328801433245341\n",
      "epoch 40:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.9090909090909091 (average over 11 episode(s))\n",
      "== Mean score per episode is 0.90908264470323 over 11 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/simple_maze_env.py:218: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(all_possib_abs_states[length_block[i][0]:length_block[i][1],0], all_possib_abs_states[length_block[i][0]:length_block[i][1],1] ,all_possib_abs_states[length_block[i][0]:length_block[i][1],2], marker='x', depthshade=True, edgecolors='k', alpha=0.5, s=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best neural net obtained after 28 epochs, with validation score 0.9926470588235294\n"
     ]
    }
   ],
   "source": [
    "if set_network is not None:\n",
    "    agent.setNetwork(\n",
    "        f'{set_network[0]}/fname', nEpoch=set_network[1],\n",
    "        encoder_only=set_network[2]\n",
    "        )\n",
    "agent.run(parameters['epochs'], parameters['steps_per_epoch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.setNetwork(f'{fname}/fname', nEpoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent._in_episode = True\n",
    "agent._mode = 0 # Testing mode with plan_depth=0\n",
    "initState = env.reset(agent._mode)\n",
    "inputDims = env.inputDimensions()\n",
    "\n",
    "for i in range(len(inputDims)):\n",
    "    if inputDims[i][0] > 1:\n",
    "        agent._state[i][1:] = initState[i][1:]\n",
    "agent._Vs_on_last_episode = []\n",
    "is_terminal = False\n",
    "reward = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGfCAYAAAAZGgYhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaNklEQVR4nO3df2xV9f3H8VdLuRdme28p4C0dLYMoFDFgrFBu1P2AzoYYgqNLmCEZc2RGV4hQl80mEzTZUqKJKK6g2RhkyVgnS8BgMhkpcolby6DQCDgrKK5dyr3oYu8tnb1t6Of7h/HGK0W/t73wbm+fj+Qk9Jxzb9+fNukz597TkuWccwIA4AbLth4AADA2ESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJnOv1xPX19Xr22WcVDoe1YMECvfjii1q0aNFXPm5gYECdnZ3Ky8tTVlbW9RoPAHCdOOfU3d2toqIiZWd/yXWOuw4aGhqcx+Nxv//9793Zs2fdT37yE5efn+8ikchXPrajo8NJYmNjY2Mb5VtHR8eX/rzPci79f4y0vLxcCxcu1G9+8xtJn17VFBcXa/369XriiSe+9LHRaFT5+fn698lvyJfLK4QAMNrELg9oxp0fqKurS36//5rnpf0luL6+PrW0tKi2tjaxLzs7WxUVFWpqarrq/Hg8rng8nvi4u7tbkuTLzZYvjwABwGj1VW+jpP0n/EcffaQrV64oEAgk7Q8EAgqHw1edX1dXJ7/fn9iKi4vTPRIAYAQyv8Sora1VNBpNbB0dHdYjAQBugLS/BDdlyhSNGzdOkUgkaX8kElFhYeFV53u9Xnm93nSPAQAY4dJ+BeTxeFRWVqbGxsbEvoGBATU2NioYDKb70wEARqnr8ntANTU1WrNmje666y4tWrRIzz//vHp6evTQQw9dj08HABiFrkuAVq1apQ8//FCbNm1SOBzWHXfcoddff/2qGxMAAGPXdfk9oOGIxWLy+/36+N1Z3IYNAKNQrHtAk2a/r2g0Kp/Pd83z+AkPADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJnKsBxgtKovusB4BAAZ1sLPVeoQh4QoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEykH6OjRo1q+fLmKioqUlZWl/fv3Jx13zmnTpk2aNm2aJk6cqIqKCp07dy5d8wIAMkTKAerp6dGCBQtUX18/6PFnnnlG27Zt00svvaRjx47ppptuUmVlpXp7e4c9LAAgc+Sk+oBly5Zp2bJlgx5zzun555/XL3/5S61YsUKS9Ic//EGBQED79+/XD37wg6seE4/HFY/HEx/HYrFURwIAjEJpfQ/owoULCofDqqioSOzz+/0qLy9XU1PToI+pq6uT3+9PbMXFxekcCQAwQqU1QOFwWJIUCASS9gcCgcSxL6qtrVU0Gk1sHR0d6RwJADBCpfwSXLp5vV55vV7rMQAAN1har4AKCwslSZFIJGl/JBJJHAMAQEpzgGbOnKnCwkI1NjYm9sViMR07dkzBYDCdnwoAMMql/BLc5cuXdf78+cTHFy5cUGtrqwoKClRSUqINGzboV7/6lW699VbNnDlTTz75pIqKivTAAw+kc24AwCiXcoBOnDih73znO4mPa2pqJElr1qzR7t279fOf/1w9PT16+OGH1dXVpXvuuUevv/66JkyYkL6pAQCjXpZzzlkP8XmxWEx+v18fvztLvryR85eCKovusB4BAAZ1sLPVeoQkse4BTZr9vqLRqHw+3zXPGzk/4QEAYwoBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYSClAdXV1WrhwofLy8nTzzTfrgQceUFtbW9I5vb29qq6u1uTJk5Wbm6uqqipFIpG0Dg0AGP1SClAoFFJ1dbWam5t16NAh9ff367777lNPT0/inI0bN+rAgQPau3evQqGQOjs7tXLlyrQPDgAY3bKcc26oD/7www918803KxQK6Zvf/Kai0aimTp2qPXv26Pvf/74k6Z133tHcuXPV1NSkxYsXf+VzxmIx+f1+ffzuLPnyRs4rhJVFd1iPAACDOtjZaj1Cklj3gCbNfl/RaFQ+n++a5w3rJ3w0GpUkFRQUSJJaWlrU39+vioqKxDmlpaUqKSlRU1PToM8Rj8cVi8WSNgBA5htygAYGBrRhwwbdfffduv322yVJ4XBYHo9H+fn5SecGAgGFw+FBn6eurk5+vz+xFRcXD3UkAMAoMuQAVVdX68yZM2poaBjWALW1tYpGo4mto6NjWM8HABgdcobyoHXr1um1117T0aNHNX369MT+wsJC9fX1qaurK+kqKBKJqLCwcNDn8nq98nq9QxkDADCKpXQF5JzTunXrtG/fPh0+fFgzZ85MOl5WVqbx48ersbExsa+trU3t7e0KBoPpmRgAkBFSugKqrq7Wnj179OqrryovLy/xvo7f79fEiRPl9/u1du1a1dTUqKCgQD6fT+vXr1cwGPx/3QEHABg7UgrQjh07JEnf/va3k/bv2rVLP/rRjyRJW7duVXZ2tqqqqhSPx1VZWant27enZVgAQOZIKUD/n18ZmjBhgurr61VfXz/koQAAmW/k/KYnAGBMIUAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgIieVk3fs2KEdO3bogw8+kCTNmzdPmzZt0rJlyyRJvb29evzxx9XQ0KB4PK7Kykpt375dgUAg7YMDGLsWtl5J6fzjd4y7Ic+F1KR0BTR9+nRt2bJFLS0tOnHihJYsWaIVK1bo7NmzkqSNGzfqwIED2rt3r0KhkDo7O7Vy5crrMjgAYHRL6Qpo+fLlSR//+te/1o4dO9Tc3Kzp06dr586d2rNnj5YsWSJJ2rVrl+bOnavm5mYtXrw4fVMDAEa9Ib8HdOXKFTU0NKinp0fBYFAtLS3q7+9XRUVF4pzS0lKVlJSoqanpms8Tj8cVi8WSNgBA5ks5QKdPn1Zubq68Xq8eeeQR7du3T7fddpvC4bA8Ho/y8/OTzg8EAgqHw9d8vrq6Ovn9/sRWXFyc8iIAAKNPygGaM2eOWltbdezYMT366KNas2aN3n777SEPUFtbq2g0mtg6OjqG/FwAgNEjpfeAJMnj8eiWW26RJJWVlen48eN64YUXtGrVKvX19amrqyvpKigSiaiwsPCaz+f1euX1elOfHMCYda070VK9o20onwPpM+zfAxoYGFA8HldZWZnGjx+vxsbGxLG2tja1t7crGAwO99MAADJMSldAtbW1WrZsmUpKStTd3a09e/boyJEjOnjwoPx+v9auXauamhoVFBTI5/Np/fr1CgaD3AEHALhKSgG6dOmSfvjDH+rixYvy+/2aP3++Dh48qO9+97uSpK1btyo7O1tVVVVJv4gKAMAXpRSgnTt3funxCRMmqL6+XvX19cMaCgCQ+fhbcAAAEynfBQcAo006745D+nAFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4I+RAhh1bsQfF73W5+C/6k4froAAACYIEADABAECAJggQAAAEwQIAGCCu+AAjDop34nWOP3ax5b+Z3jDYMi4AgIAmCBAAAATBAgAYIIAAQBMECAAgAnuggOQ+bjTbUTiCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmBhWgLZs2aKsrCxt2LAhsa+3t1fV1dWaPHmycnNzVVVVpUgkMtw5AQAZZsgBOn78uF5++WXNnz8/af/GjRt14MAB7d27V6FQSJ2dnVq5cuWwBwUAZJYhBejy5ctavXq1fvvb32rSpEmJ/dFoVDt37tRzzz2nJUuWqKysTLt27dI//vEPNTc3p21oAMDoN6QAVVdX6/7771dFRUXS/paWFvX39yftLy0tVUlJiZqamgZ9rng8rlgslrQBADJfTqoPaGho0MmTJ3X8+PGrjoXDYXk8HuXn5yftDwQCCofDgz5fXV2dnn766VTHAACMcildAXV0dOixxx7TH//4R02YMCEtA9TW1ioajSa2jo6OtDwvAGBkSylALS0tunTpku68807l5OQoJydHoVBI27ZtU05OjgKBgPr6+tTV1ZX0uEgkosLCwkGf0+v1yufzJW0AgMyX0ktwS5cu1enTp5P2PfTQQyotLdUvfvELFRcXa/z48WpsbFRVVZUkqa2tTe3t7QoGg+mbGgAw6qUUoLy8PN1+++1J+2666SZNnjw5sX/t2rWqqalRQUGBfD6f1q9fr2AwqMWLF6dvagDAqJfyTQhfZevWrcrOzlZVVZXi8bgqKyu1ffv2dH8aAMAol+Wcc9ZDfF4sFpPf79fH786SL2/k/KWgyqI7rEcAgEEd7Gy1HiFJrHtAk2a/r2g0+qXv64+cn/AAgDGFAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJlAL01FNPKSsrK2krLS1NHO/t7VV1dbUmT56s3NxcVVVVKRKJpH1oAMDol/IV0Lx583Tx4sXE9uabbyaObdy4UQcOHNDevXsVCoXU2dmplStXpnVgAEBmyEn5ATk5KiwsvGp/NBrVzp07tWfPHi1ZskSStGvXLs2dO1fNzc1avHjx8KcFAGSMlK+Azp07p6KiIs2aNUurV69We3u7JKmlpUX9/f2qqKhInFtaWqqSkhI1NTVd8/ni8bhisVjSBgDIfCkFqLy8XLt379brr7+uHTt26MKFC7r33nvV3d2tcDgsj8ej/Pz8pMcEAgGFw+FrPmddXZ38fn9iKy4uHtJCAACjS0ovwS1btizx7/nz56u8vFwzZszQK6+8ookTJw5pgNraWtXU1CQ+jsViRAgAxoBh3Yadn5+v2bNn6/z58yosLFRfX5+6urqSzolEIoO+Z/QZr9crn8+XtAEAMt+wAnT58mW99957mjZtmsrKyjR+/Hg1NjYmjre1tam9vV3BYHDYgwIAMktKL8H97Gc/0/LlyzVjxgx1dnZq8+bNGjdunB588EH5/X6tXbtWNTU1KigokM/n0/r16xUMBrkDDgBwlZQC9J///EcPPvig/vvf/2rq1Km655571NzcrKlTp0qStm7dquzsbFVVVSkej6uyslLbt2+/LoMDAEa3LOecsx7i82KxmPx+vz5+d5Z8eSPnLwVVFt1hPQIADOpgZ6v1CEli3QOaNPt9RaPRL31ff+T8hAcAjCkECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACZS+v+AxrKR9ufOAWC04woIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAiRzrAb7IOSdJil0eMJ4EADAUn/38/uzn+bWMuAB1d3dLkmbc+YHtIACAYenu7pbf77/m8Sz3VYm6wQYGBtTZ2am8vDx1d3eruLhYHR0d8vl81qPdMLFYjHWPkXWPxTVLY3PdY2nNzjl1d3erqKhI2dnXfqdnxF0BZWdna/r06ZKkrKwsSZLP58v4b9hgWPfYMRbXLI3NdY+VNX/Zlc9nuAkBAGCCAAEATIzoAHm9Xm3evFler9d6lBuKdY+ddY/FNUtjc91jcc1fZcTdhAAAGBtG9BUQACBzESAAgAkCBAAwQYAAACYIEADAxIgOUH19vb7xjW9owoQJKi8v1z//+U/rkdLq6NGjWr58uYqKipSVlaX9+/cnHXfOadOmTZo2bZomTpyoiooKnTt3zmbYNKmrq9PChQuVl5enm2++WQ888IDa2tqSzunt7VV1dbUmT56s3NxcVVVVKRKJGE2cHjt27ND8+fMTvwUfDAb117/+NXE8E9f8RVu2bFFWVpY2bNiQ2JeJ637qqaeUlZWVtJWWliaOZ+Kah2rEBujPf/6zampqtHnzZp08eVILFixQZWWlLl26ZD1a2vT09GjBggWqr68f9Pgzzzyjbdu26aWXXtKxY8d00003qbKyUr29vTd40vQJhUKqrq5Wc3OzDh06pP7+ft13333q6elJnLNx40YdOHBAe/fuVSgUUmdnp1auXGk49fBNnz5dW7ZsUUtLi06cOKElS5ZoxYoVOnv2rKTMXPPnHT9+XC+//LLmz5+ftD9T1z1v3jxdvHgxsb355puJY5m65iFxI9SiRYtcdXV14uMrV664oqIiV1dXZzjV9SPJ7du3L/HxwMCAKywsdM8++2xiX1dXl/N6ve5Pf/qTwYTXx6VLl5wkFwqFnHOfrnH8+PFu7969iXP+9a9/OUmuqanJaszrYtKkSe53v/tdxq+5u7vb3Xrrre7QoUPuW9/6lnvsscecc5n7vd68ebNbsGDBoMcydc1DNSKvgPr6+tTS0qKKiorEvuzsbFVUVKipqclwshvnwoULCofDSV8Dv9+v8vLyjPoaRKNRSVJBQYEkqaWlRf39/UnrLi0tVUlJScas+8qVK2poaFBPT4+CwWDGr7m6ulr3339/0vqkzP5enzt3TkVFRZo1a5ZWr16t9vZ2SZm95qEYcX8NW5I++ugjXblyRYFAIGl/IBDQO++8YzTVjRUOhyVp0K/BZ8dGu4GBAW3YsEF33323br/9dkmfrtvj8Sg/Pz/p3ExY9+nTpxUMBtXb26vc3Fzt27dPt912m1pbWzN2zQ0NDTp58qSOHz9+1bFM/V6Xl5dr9+7dmjNnji5evKinn35a9957r86cOZOxax6qERkgjA3V1dU6c+ZM0uvjmWzOnDlqbW1VNBrVX/7yF61Zs0ahUMh6rOumo6NDjz32mA4dOqQJEyZYj3PDLFu2LPHv+fPnq7y8XDNmzNArr7yiiRMnGk428ozIl+CmTJmicePGXXVnSCQSUWFhodFUN9Zn68zUr8G6dev02muv6Y033kj8/0/Sp+vu6+tTV1dX0vmZsG6Px6NbbrlFZWVlqqur04IFC/TCCy9k7JpbWlp06dIl3XnnncrJyVFOTo5CoZC2bdumnJwcBQKBjFz3F+Xn52v27Nk6f/58xn6vh2pEBsjj8aisrEyNjY2JfQMDA2psbFQwGDSc7MaZOXOmCgsLk74GsVhMx44dG9VfA+ec1q1bp3379unw4cOaOXNm0vGysjKNHz8+ad1tbW1qb28f1esezMDAgOLxeMaueenSpTp9+rRaW1sT21133aXVq1cn/p2J6/6iy5cv67333tO0adMy9ns9ZNZ3QVxLQ0OD83q9bvfu3e7tt992Dz/8sMvPz3fhcNh6tLTp7u52p06dcqdOnXKS3HPPPedOnTrl/v3vfzvnnNuyZYvLz893r776qnvrrbfcihUr3MyZM90nn3xiPPnQPfroo87v97sjR464ixcvJrb//e9/iXMeeeQRV1JS4g4fPuxOnDjhgsGgCwaDhlMP3xNPPOFCoZC7cOGCe+utt9wTTzzhsrKy3N/+9jfnXGaueTCfvwvOucxc9+OPP+6OHDniLly44P7+97+7iooKN2XKFHfp0iXnXGaueahGbICcc+7FF190JSUlzuPxuEWLFrnm5mbrkdLqjTfecJKu2tasWeOc+/RW7CeffNIFAgHn9Xrd0qVLXVtbm+3QwzTYeiW5Xbt2Jc755JNP3E9/+lM3adIk97Wvfc1973vfcxcvXrQbOg1+/OMfuxkzZjiPx+OmTp3qli5dmoiPc5m55sF8MUCZuO5Vq1a5adOmOY/H477+9a+7VatWufPnzyeOZ+Kah4r/DwgAYGJEvgcEAMh8BAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATPwf/3MJkEPTs9IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for i in range(100):\n",
    "    obs = env.observe()\n",
    "    width = height = int(np.sqrt(obs[0].size))\n",
    "    _obs = obs[0].reshape((width, height))\n",
    "    plt.figure()\n",
    "    plt.imshow(np.flip(_obs.squeeze()))\n",
    "    plt.show()\n",
    "    if is_terminal: break\n",
    "    for i in range(len(obs)):\n",
    "        agent._state[i][0:-1] = agent._state[i][1:]\n",
    "        agent._state[i][-1] = obs[i]\n",
    "    V, action, reward, _ = agent._step()\n",
    "    print(action)\n",
    "    agent._Vs_on_last_episode.append(V)\n",
    "    is_terminal = env.inTerminalState()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "obs = env.observe()\n",
    "_obs = obs[0].reshape((env.WIDTH, env.HEIGHT))\n",
    "_obs = np.flip(_obs.squeeze())\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "im = ax.imshow(np.zeros(_obs.shape))\n",
    "\n",
    "def init():\n",
    "    plt.cla()\n",
    "    im = ax.imshow(_obs)\n",
    "    return [im]\n",
    "\n",
    "def animate(i, *args, **kwargs):\n",
    "    plt.cla()\n",
    "    obs = env.observe()\n",
    "    _obs = obs[0].reshape((env.WIDTH, env.HEIGHT))\n",
    "    _obs = np.flip(_obs.squeeze())\n",
    "    im = ax.imshow(_obs)\n",
    "    for i in range(len(obs)):\n",
    "        agent._state[i][0:-1] = agent._state[i][1:]\n",
    "        agent._state[i][-1] = obs[i]\n",
    "        V, action, reward, _ = agent._step()\n",
    "        agent._Vs_on_last_episode.append(V)\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, init_func=init, \n",
    "     frames=100, blit=False, repeat=True)\n",
    "ani.save(f'figs/{fname}/behavior.gif', writer=\"ffmpeg\", fps = 15)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-auxrl]",
   "language": "python",
   "name": "conda-env-.conda-auxrl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
