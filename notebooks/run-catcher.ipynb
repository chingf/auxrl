{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "from joblib import hash, dump\n",
    "import os\n",
    "\n",
    "from deer.default_parser import process_args\n",
    "from deer.agent import NeuralAgent\n",
    "from deer.learning_algos.CRAR_torch import CRAR\n",
    "import deer.controllers as bc\n",
    "from deer.environments.Catcher import MyEnv as Env\n",
    "\n",
    "from deer.policies import EpsilonGreedyPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Defaults:\n",
    "    # ----------------------\n",
    "    # Experiment Parameters\n",
    "    # ----------------------\n",
    "    steps_per_epoch = 2000\n",
    "    epochs = 50\n",
    "    steps_per_test = 500\n",
    "    period_btw_summary_perfs = 1\n",
    "    \n",
    "    # ----------------------\n",
    "    # Environment Parameters\n",
    "    # ----------------------\n",
    "    frame_skip = 2\n",
    "\n",
    "    # ----------------------\n",
    "    # DQN Agent parameters:\n",
    "    # ----------------------\n",
    "    update_rule = 'rmsprop'\n",
    "    learning_rate = 0.0005\n",
    "    learning_rate_decay = 0.9\n",
    "    discount = 0.9\n",
    "    discount_inc = 1\n",
    "    discount_max = 0.99\n",
    "    rms_decay = 0.9\n",
    "    rms_epsilon = 0.0001\n",
    "    momentum = 0\n",
    "    clip_norm = 1.0\n",
    "    epsilon_start = 1.0\n",
    "    epsilon_min = 1.0\n",
    "    epsilon_decay = 10000\n",
    "    update_frequency = 1\n",
    "    replay_memory_size = 1000000\n",
    "    batch_size = 32\n",
    "    freeze_interval = 1000\n",
    "    deterministic = False\n",
    "\n",
    "HIGHER_DIM_OBS = True\n",
    "HIGH_INT_DIM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ec531",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = Defaults()\n",
    "if parameters.deterministic:\n",
    "    rng = np.random.RandomState(123456)\n",
    "else:\n",
    "    rng = np.random.RandomState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa1cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Instantiate environment ---\n",
    "env = catcher_env(rng, higher_dim_obs=HIGHER_DIM_OBS, reverse=False)\n",
    "\n",
    "# --- Instantiate learning algorithm ---\n",
    "learning_algo = CRAR(\n",
    "    env,\n",
    "    parameters.rms_decay,\n",
    "    parameters.rms_epsilon,\n",
    "    parameters.momentum,\n",
    "    parameters.clip_norm,\n",
    "    parameters.freeze_interval,\n",
    "    parameters.batch_size,\n",
    "    parameters.update_rule,\n",
    "    rng,\n",
    "    double_Q=True,\n",
    "    high_int_dim=HIGH_INT_DIM,\n",
    "    internal_dim=3)\n",
    "\n",
    "test_policy = EpsilonGreedyPolicy(learning_algo, env.nActions(), rng, 0.)\n",
    "\n",
    "# --- Instantiate agent ---\n",
    "agent = NeuralAgent(\n",
    "    env,\n",
    "    learning_algo,\n",
    "    parameters.replay_memory_size,\n",
    "    max(env.inputDimensions()[i][0] for i in range(len(env.inputDimensions()))),\n",
    "    parameters.batch_size,\n",
    "    rng,\n",
    "    test_policy=test_policy)\n",
    "\n",
    "# --- Bind controllers to the agent ---\n",
    "# Before every training epoch (periodicity=1), we want to print a summary of the agent's epsilon, discount and \n",
    "# learning rate as well as the training epoch number.\n",
    "agent.attach(bc.VerboseController(\n",
    "    evaluate_on='epoch', \n",
    "    periodicity=1))\n",
    "\n",
    "# As for the discount factor and the learning rate, one can update periodically the parameter of the epsilon-greedy\n",
    "# policy implemented by the agent. This controllers has a bit more capabilities, as it allows one to choose more\n",
    "# precisely when to update epsilon: after every X action, episode or epoch. This parameter can also be reset every\n",
    "# episode or epoch (or never, hence the resetEvery='none').\n",
    "agent.attach(bc.EpsilonController(\n",
    "    initial_e=parameters.epsilon_start, \n",
    "    e_decays=parameters.epsilon_decay, \n",
    "    e_min=parameters.epsilon_min,\n",
    "    evaluate_on='action',\n",
    "    periodicity=1,\n",
    "    reset_every='none'))\n",
    "\n",
    "# During training epochs, we want to train the agent after every [parameters.update_frequency] action it takes.\n",
    "# Plus, we also want to display after each training episode (!= than after every training) the average bellman\n",
    "# residual and the average of the V values obtained during the last episode, hence the two last arguments.\n",
    "agent.attach(bc.TrainerController(\n",
    "    evaluate_on='action', \n",
    "    periodicity=parameters.update_frequency, \n",
    "    show_episode_avg_V_value=True, \n",
    "    show_avg_Bellman_residual=True))\n",
    "\n",
    "# We wish to discover, among all versions of our neural network (i.e., after every training epoch), which one \n",
    "# has the highest validation score.\n",
    "# To achieve this goal, one can use the FindBestController along with an InterleavedTestEpochControllers. It is \n",
    "# important that the validationID is the same than the id argument of the InterleavedTestEpochController.\n",
    "# The FindBestController will dump on disk the validation scores for each and every network, as well as the \n",
    "# structure of the neural network having the best validation score. These dumps can then used to plot the evolution \n",
    "# of the validation and test scores (see below) or simply recover the resulting neural network for your \n",
    "# application.\n",
    "agent.attach(bc.FindBestController(\n",
    "    validationID=catcher_env.VALIDATION_MODE,\n",
    "    testID=None,\n",
    "    unique_fname=f\"{fname}\"))\n",
    "\n",
    "# Every epoch end, one has the possibility to modify the learning rate using a LearningRateController. Here we \n",
    "# wish to update the learning rate after every training epoch (periodicity=1), according to the parameters given.\n",
    "agent.attach(bc.LearningRateController(\n",
    "    initial_learning_rate=parameters.learning_rate, \n",
    "    learning_rate_decay=parameters.learning_rate_decay,\n",
    "    periodicity=1))\n",
    "\n",
    "# Same for the discount factor.\n",
    "agent.attach(bc.DiscountFactorController(\n",
    "    initial_discount_factor=parameters.discount, \n",
    "    discount_factor_growth=parameters.discount_inc, \n",
    "    discount_factor_max=parameters.discount_max,\n",
    "    periodicity=1))\n",
    "\n",
    "# All previous controllers control the agent during the epochs it goes through. However, we want to interleave a \n",
    "# \"validation epoch\" between each training epoch (\"one of two epochs\", hence the periodicity=2). We do not want \n",
    "# these validation epoch to interfere with the training of the agent, which is well established by the \n",
    "# TrainerController, EpsilonController and alike. Therefore, we will disable these controllers for the whole \n",
    "# duration of the validation epochs interleaved this way, using the controllersToDisable argument of the \n",
    "# InterleavedTestEpochController. For each validation epoch, we want also to display the sum of all rewards \n",
    "# obtained, hence the showScore=True. Finally, we want to call the summarizePerformance method of ALE_env every \n",
    "# [parameters.period_btw_summary_perfs] *validation* epochs.\n",
    "agent.attach(bc.InterleavedTestEpochController(\n",
    "    id=catcher_env.VALIDATION_MODE, \n",
    "    epoch_length=parameters.steps_per_test,\n",
    "    periodicity=1,\n",
    "    show_score=True,\n",
    "    summarize_every=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8479fc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2070,  0.0249, -0.2277], device='cuda:0') tensor([-0.0761,  0.4696, -0.0573], device='cuda:0') tensor([-0.2061,  0.0247, -0.2287], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1810], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.00018334352256488273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04661249943881236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.061794693946379854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0709240395091261\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07522782950977878\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08166642835731353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08633279713936029\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08807645158906742\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0867097328234138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08985261148646724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0930305857594258\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09423022193633297\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09586466783359968\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09830830703995526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09743638120111522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09723080058334121\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09818318037052247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09608069204204246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0968170258240073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09792840022650552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09714964281564102\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09694948864046124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09758343695612823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09812126648040184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0989949732296651\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09974807538983169\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09857178748604217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0984399251885816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09903411645810907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.099816326963986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09983057780134083\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10061456594846312\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10017739418978752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10042383633074335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10088688043921736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10063007087411918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10008975644491905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10100101216204377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10177894673025288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10169213004573495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10223979200092043\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10254089281177667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10255795377868618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10251010901902767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10277913288902399\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10292715113255811\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10261252923340965\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.102598413316004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10218639462345788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10229198366310074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10200026714407542\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10186280964359051\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10189826404681554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10225819495310565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.1018773301471168\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.03991964321956038 0.10164755189651624 0.1583195943199098 0.1017766331926532 0.3373990264385939 0.0013802028596401215 0.16814262517541648\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6357, -0.7447, -0.1681], device='cuda:0') tensor([ 0.5497, -0.5895, -0.2655], device='cuda:0') tensor([ 0.3695, -0.4780, -0.1181], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0332], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.10162187670298128\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10170728012313557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10135228888721433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.1012621611188556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10131251672788943\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.1011218390720339\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10074287425978995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.1004417929344702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10055928139652441\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10049795157867611\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10055658081221201\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10035468701748022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.10005133237553952\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0999185870978819\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09964923991845279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09972617296465383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09985755519913984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09993927023525338\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09989097279773675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09975832394585289\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09934284163378397\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09921396017196948\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09897937287717218\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09887347142727494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09870394708978501\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09846822475905653\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09826679795205724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09820153116833957\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09832849900803078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0978066302373074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09788155336741305\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.09770314454311729\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09756330583252709\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09713613181424932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09686407556044645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09658352961962892\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09612682332054924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09568489081626134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0955170477927053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09537791331024836\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.095497638684743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09530870066018937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09504387653124023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09459673573381153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09433203216094038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0939833414581153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09351263176124652\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09333676149202612\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09291767122336449\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0927947121666701\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0924755626539169\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0920584417773372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09168861692200551\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09149190420040557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09122594828024258\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09099336571187894\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.02910547384619713 0.08015956581942738 0.037033042053692046 0.08019013306498528 0.12782181234657763 0.0008125796169042587 0.05566976113989949\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.7023,  0.2363, -0.9229], device='cuda:0') tensor([ 0.2877,  0.4981, -0.7323], device='cuda:0') tensor([ 0.4432,  0.5329, -0.8988], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0818], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.09073382860427795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0906328901883453\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09042404355202252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09007391916821157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0902109164882387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.09003081440630727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08981041319207389\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08952484936055562\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08921308816595243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08899082842333386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08900824072446399\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08876437422052248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08826231934800845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08822525082087224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08802363992270776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08774963722741182\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08733860343821657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0869042380836802\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08653500383209065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08615315166068736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0860642787651486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08575382496125118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08536628100134494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0852143828690589\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08509257471812516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08505096696856124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08484784211495817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0846387439898619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08430996776099765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08410632726070133\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08396304093336973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08369575941663548\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08348511272180466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08326100444193284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08303637257545153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08261517284689457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08241119442410308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08232880474146706\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08216831301077952\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08202230211051705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0818992341474993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08170472943797237\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08147659430322637\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08134256560488322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0810875030441758\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08083464496034849\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0807212401226218\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0808118401286936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08079098736347554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.08060487486110068\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0803054189636618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.080004812520439\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07978912052472971\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07967234878192953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07957489544913379\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.015684403953142464 0.06679049474559724 0.02309639270417392 0.05599449105863459 0.07659157904982566 0.0006089594215154647 0.04502208450064063\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9224, -0.5206,  0.2560], device='cuda:0') tensor([ 1.0220, -0.1873, -0.1671], device='cuda:0') tensor([ 0.9515, -0.1964,  0.0270], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0023], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.07928995996191192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07918440545638167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07920047846307475\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.0789817424119519\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07883258895653279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07867400546291459\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07839266677873022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07819991123519147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07792777760086825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07774606324355726\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07753883060499576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.077305851789932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07717396148855271\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0770724955228181\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07695230511035976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07665812328827017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07647779546102593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07647287443380342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07627274127910429\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07608500257555241\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07616701571105777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07614115327810313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07591038877291233\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07569178873004381\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07560003294152456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07553802348198202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07548733603517688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07533040751557872\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07505086265307327\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0749662659237325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07478457315018124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07460809993757346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07436875123943176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07427763320209978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07433064706337626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07412087537305431\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07403169994103465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0739984015596935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0738072117104988\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07355968613749209\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.073557514517153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07348227178651247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07323128727770202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07317970559603158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07303434022159293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07300566232682366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07290479975902449\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07283793633262067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07279901646285866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07284069954102933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07262152973381376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07258575783120377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07255366153953804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07239696114141167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07230394027667819\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0722066837143542\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.07216697897608045\n",
      "Episode average V value: 0\n",
      "epoch 1:\n",
      "Learning rate: 0.0005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cf2794/.conda/envs/auxrl/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/share/ctn/users/cf2794/Code/deer/deer/learning_algos/CRAR_torch.py:390: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  state = torch.as_tensor(state, device=self.device).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 0.3392857142857143 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.33928510841944926 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.015860880648717286 0.057782385820522905 0.023236250063870104 0.05070142632909119 0.06642225942015648 0.0005712060183286667 0.044059299996122715\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1625, -1.0060,  0.6988], device='cuda:0') tensor([ 0.6134, -0.9160,  0.6410], device='cuda:0') tensor([ 0.5711, -0.9310,  0.6296], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0834], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.062452656113439135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0501529433661037\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04387112525809142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04633630914354904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04837293154042628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.05070671648718417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04937805212472403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04878389223530474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.049767165490782556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04893828366055257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04879406717314263\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04912676539754978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.05014755180439888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.05256205510407213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.05225222969634665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0539010397025979\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.05273378468605574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.052636964179081036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.052211678433041385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.050855240961795466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.05069283671829869\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.05047399040212798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.05015027654303265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.049643929098103265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04910900034734772\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04957355727525189\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04928412208613391\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.05047832738833561\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.050797340386079706\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.050927381809904346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.05097590432849489\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.050102789814344656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0500984293634467\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04938629596171523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04831524762724127\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04776376772120043\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.047337839056880354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0474118387751412\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.048842555946773954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04862748299751224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.048650249577604415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04859308803838397\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.048015336519304556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04761374213572855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0478520931865744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04739674597422948\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04748300615594619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0475524211807944\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.047375781706042265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04683686882930083\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.047413291993970964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04737512763036399\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04701054609425569\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04737950247950055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.046778251093370145\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.01489278276450932 0.04500525701977313 0.022153203038033097 0.046795488372445106 0.05789320497214794 0.0004895391166210174 0.04250254631321877\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9334,  0.3366,  0.4697], device='cuda:0') tensor([-1.2460,  0.0915,  1.5855], device='cuda:0') tensor([ 0.7046, -0.7622, -0.3960], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.8238], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04696138295537186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.047023327737051784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04674057684788816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04635997142698861\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04671880362676112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04656094703942076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04646141972646491\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04640734239565159\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.046263980545013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04593811557572494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04567667069650484\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04546211587703767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04532365178996758\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045122205186785225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045167706306609844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04515500800794862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045107732786377315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044885491787156874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044703295011794916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044798823630920165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045434598961425675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04516076778624782\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0449823614327964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044765933534672744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04477974158427161\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04475078845028708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04457542615082004\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.044428816183633514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044451612592662476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044556406216111545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04456707553785217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04459822053145641\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044406653563856535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04466606135894027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04453599185389639\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04448190105707136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04455476747583913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04452765589355176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04464312270063528\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0449074118202062\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04471959713717095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04452953708783765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044625754647121645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04464965112774929\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04449658798907573\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044218375138545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04428862343939967\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04403155259818176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04405786624251921\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043908359599176536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04390651997241272\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04370704850158727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043456231623336124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0431800090558789\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04327497230983819\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04326396805371295\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.01433496604859829 0.038738722610287366 0.027518718138337134 0.03960194808524102 0.0469082356877625 0.0005501871034502983 0.04099032864626497\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.6958, 0.0851, 0.1658], device='cuda:0') tensor([ 0.5680,  0.3509, -0.2507], device='cuda:0') tensor([ 0.5550,  0.3198, -0.2737], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0036], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.043197133151041935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04316788625875039\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0432072217552605\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043141334656859945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04310505487331657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042922481099817576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043054447870213966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04295507088359219\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0429165058389858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0428706821241511\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043009032904575896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04284854094365775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04323189208904902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04342691559468707\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04331665934060209\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0431692746691145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04295971577852874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0431068436367779\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04312862471128121\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04302872968734928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04297640375081161\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04299260578262203\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043079744565731555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042891526165506476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04282745268968926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042926533964960344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042751720522330915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042879113263423016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04295482540591842\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04307459675030999\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043013681962587674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042934424737026945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042855072007327695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04272528323612508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04259554091578738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04239385296028876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04243658236476142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04238634368374883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042326522915348136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04217390593732731\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04209457098370913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04208264475672782\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042100691806201115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042061838117598366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04203037527622655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04197207769337496\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04196024826697026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042028730119995715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04210619607199785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04198150512514272\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041882874376896834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04213074235840438\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042120105480153096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042078822577585426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04193901852844844\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.012915401350706816 0.0333314892356284 0.0265653220647946 0.03903867391543463 0.03910895997285843 0.0006016474440693855 0.04069264827249572\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6229, -0.5263,  0.9738], device='cuda:0') tensor([ 0.9189, -0.0905,  0.6570], device='cuda:0') tensor([ 0.8916, -0.1486,  0.7213], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0250], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.041813860791602125\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.04186623006250349\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04194024700336501\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041880755634899285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042049894220261674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04196725867388443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04197310457259115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041872002241334916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04187676792092148\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04184419289437085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04189520452156364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04190058306210701\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04197097254378234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04199335203350832\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041908380224445506\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04191964097270999\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04190205143675271\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04186196923750826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04180099957611401\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04195982119329429\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04218284256185781\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04222790038240105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042160052474481936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042085698901741\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04200489956946798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04193128888046313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041915511204547444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04210536080620061\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04204817896488619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04207621428779223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041974531716309396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0419647877020176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04190359057716626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0417676416286526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04186892487876315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041761041496577084\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041744249009720465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04173980646932595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04167499235164889\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04168809284699705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04159390293169213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0414806202236358\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041564094366264126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04154178585583669\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04144771486187767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041363870165778416\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041406461606715524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04142424691386757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04141208895010445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0413433633731063\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04129092514367571\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04119420451053706\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04109631647603451\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04102974461398624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04103636272617299\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041044401905585164\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04101915781397838\n",
      "Episode average V value: 0\n",
      "epoch 2:\n",
      "Learning rate: 0.00045000000000000004\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.125 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.12499977678611288 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.012100292985327542 0.031683799042832105 0.024619219380430876 0.038543680463917554 0.0356292384415865 0.00038590507209301 0.03762214131141081\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1988, -0.7786,  0.9842], device='cuda:0') tensor([ 0.7462, -0.3386,  0.9172], device='cuda:0') tensor([ 0.7748, -0.3497,  0.9377], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0223], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03945576513393058\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0388002286458181\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04697359394696024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04903249809932378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04665277743091186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.046919388713798034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04623072396313387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04494967041278465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04521925002336502\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04504178777957956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04437172585496246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0429867458253823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04380861723906974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043710152633369914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045033783910589084\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04526670233462937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045144695024693905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04438313769383563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043496702432806726\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042564344610501494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04230515991717025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04178732917455937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04180341190321074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04204380976174165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04241142192648517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041493676397869855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04127364806685244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041253766412698914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041339826493584676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041169109568862175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040895212051962705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04099956055627748\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040937881513031495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040255686308537285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04021438513808544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04078752042030065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04056149714573233\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04025757669917803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03995224189124683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03984532342163018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039603590514753165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040270886328514846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040907483272379606\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04096293410361566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04046610682558866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04067696913725872\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04089743291065273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04172213698297532\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04173310388242847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04235791867598891\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041971812345298544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04159369566338535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04151228227139113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041240764424442446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04110004162942671\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.011065873194951564 0.029217376296408474 0.023411679533077403 0.040864104249514636 0.03323252722248435 0.00038112850487232206 0.03888389962632209\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7953, -0.5750, -0.4097], device='cuda:0') tensor([-0.4761, -0.7316,  0.2876], device='cuda:0') tensor([-0.4571, -0.7450,  0.3114], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0702], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.041177722094174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040890527605923294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040706691754111214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040372561096878486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04008419474379884\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03999060917754262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03973309058148587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03946759215083032\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039279917716258855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039463471955993874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03931252117251494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03901040299477405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03916433674178323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03882399444159378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03851250031748639\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03838069274612004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038791116044991705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039140998659077095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03933975186902336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03917658655697273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039314767359061524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03904231437710403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03902840013436686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03895651675602251\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038818829825160925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038684312064157206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03883963029706714\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03883426258286868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03875448690110167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038827911518161104\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038844764500661474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03876596748190165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038541031982267576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038536504813564125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038514815092972124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03831805655663385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038416879021299435\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03856332095149624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03835530098539779\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03848481835301813\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03845945316883175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038447808198666014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03848035852416881\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038451371582378616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038322662793798375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038345085565442354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03819233528985125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03805932420682154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03842934747373299\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038447557616284087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038591537392132995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038722482747214564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038883006837723944\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0389278999986184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03886927953965943\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038704733230388935\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.01011579441651702 0.027718287490773947 0.021863903906662017 0.03651731473370455 0.03170369634404779 0.00038329805433750153 0.03806625624466688\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5600,  0.5734, -0.5425], device='cuda:0') tensor([ 0.1281,  0.5688, -0.9122], device='cuda:0') tensor([ 0.2208,  0.7293, -0.8175], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0627], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03862486614063585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03879461397845921\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038677655560618945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03890558822510161\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03911327380119195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039165911090370986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03905237042101752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039146391144539744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03920897379252387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03916686735767187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03908027080067931\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039159847351608004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03928552902736334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03946643386957132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039553521849100874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03956758783046932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039509399491382484\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0393750767379359\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03944921867979659\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03955796317079289\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03952284858227701\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03970849747995557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03956209067176104\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03960361099397618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03958879814403713\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039721573475542095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03984161929012578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040018010274715556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04012809490391408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04012060456792182\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04038226508733296\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04031686522325294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04046010662954987\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04055082405804945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04046798212079138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04042986271231001\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04037863060308679\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040690896058150225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04062870775168348\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04063829824434987\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04072557612959151\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04076432896879101\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04067915689035871\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04070083756445436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04079906617221953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040838015672351353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04070558819489858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04056031935352697\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040517305607580864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04048482613569592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04038252886466168\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040506980212639584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04056136237688017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04041295614781843\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04037147813557349\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.010142251612618565 0.030489136712159963 0.018441806637390982 0.044440293106250466 0.029703906793147324 0.00045797306299209594 0.038333502067718656\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0186,  0.5073, -0.8550], device='cuda:0') tensor([-0.5497,  0.2866, -0.5292], device='cuda:0') tensor([-0.5965,  0.3917, -0.7733], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0970], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.040633950205795535\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.040641496762945616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040605209116244725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040597536291826664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0404979442209193\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04041714336774529\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04037592969450492\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04033568708663497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04049682168785246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04063433194890174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040672393395782935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04076997258375747\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04067058818353239\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04061606485895341\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04053174652437353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04051319538265687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04054651453190002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04056820109946899\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040544580087952274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04047627254060148\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040375208086278834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04033100761889577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04037656731990334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04050134066853139\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040450899075424714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04053361637603235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04058218804834422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04066105412282231\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04063363438664519\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04081710425524681\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04082575039361597\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04076057691217215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040845873817192555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04090387640372178\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04077775495863304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04081729332086803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04079631398569336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04075319809979386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04068976093423086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04065168615484092\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0405599743001472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040577212919525374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04045683561269974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04044587225720986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040393354139892014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040307587115335684\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040283547101426245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040256128516055444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040263401778734914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040318118200583265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040292276981948594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04031123737105625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04044152619991686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040345491705676355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0403851107216022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040407413176460856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040439159063331315\n",
      "Episode average V value: 0\n",
      "epoch 3:\n",
      "Learning rate: 0.00040500000000000003\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is -0.05357142857142857 (average over 56 episode(s))\n",
      "== Mean score per episode is -0.05357133290833409 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.010463572794571519 0.028385277815628798 0.016187154627637937 0.03993015939835459 0.028718786112964155 0.0003630547374486923 0.03568429351435043\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0400, -0.5882,  0.6967], device='cuda:0') tensor([ 0.4642, -0.2587,  0.7580], device='cuda:0') tensor([ 0.3761, -0.3537,  0.6904], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0063], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03398380366464456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04510932746860716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04576039828222107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04874141258187592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04962113329933749\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04405417124292365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042878775118244075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043681279853141554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04222649017946772\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042400489597477845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04230106299780686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040318361850006985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0406953716953086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04133632085064337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04298937350373577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043548705399088145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042889609707677676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04387084007792083\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043648313376943616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04453264682864149\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043406899873088434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043923174992975114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043398081795154995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04302986740798655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04279928189391891\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04336904871882473\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04300749611393108\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04217920964398968\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04215039478051137\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04149127084830845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0415627544572223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04215903141691039\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04231666759133138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04208641591500126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04329835649224974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04340372093159844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04323345412117046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04316350722369569\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04307121882464556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04321165043446753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04309997216074003\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04351309188961904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04373879374296089\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0434314184140113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043921100716164084\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0439404742139873\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044086724270936586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04440469685208949\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04444208353242569\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04414115545857284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044055835722310546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044205455416932896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04380598622598769\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04362616050363721\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04323542848172964\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.011420770525466651 0.02698909621592611 0.011066433083848096 0.04298642212804407 0.029343166518956423 0.0003477946445345879 0.03551439776271582\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4855,  0.4979, -0.5122], device='cuda:0') tensor([ 0.0416,  0.4849, -0.8854], device='cuda:0') tensor([ 0.0713,  0.6813, -0.8272], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0643], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04280292665463917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04255315246419948\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04256904845828925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042746384303645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04258683331707423\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04286915038157601\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0428510478916361\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04300441007036223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043083819601937044\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043035169432146685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04337356251551572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04325179594752702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04303818762308486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04315978789105172\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043207371793687346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04325432165092986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04338568797978906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043798177354207865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04387163059567815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04367547346003078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043670996052093194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043513227655306394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04341301345531736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04346412011132734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04324383545705738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04316910151558301\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04317133641816918\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.04284773909311038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04290250205513701\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04267391781474835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04254292670122374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04254720462985708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04245229210584622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04235851922515459\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04234434005022509\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042339301634561705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04238897054242465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04259082447045361\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04228121049957566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04243489136233142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042569643600102236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042553474735105914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04264186038435046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04266162392684372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04281040027944578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042843563640971714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042893847360322354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043013733607227586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04294349384319005\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04313893201095717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043075874307245576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04295500531223983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042959422875318384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04284679810217488\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04289722276823313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042788433388819\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.010857239183038473 0.028370152367046104 0.008202993677812628 0.0425399917634204 0.02719913121499121 0.0003068566173315048 0.03604902731021866\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3291, -0.4258,  0.6713], device='cuda:0') tensor([ 0.6485, -0.0202,  0.4121], device='cuda:0') tensor([ 0.5212, -0.1096,  0.3467], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0357], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0426456020315296\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04262999563744418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042474311924871735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042318735366174275\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04232543716885121\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04226609136367965\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042573682292980156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042809544140725186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04284084352354209\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042741239598128665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04254864594510643\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04272711702539184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04283898727514357\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04291623497133454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04295499661134152\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042986990982945276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04311498870366551\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04311628437470276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04332892834009905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04313954722493306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043004161139686754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042938002373917386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0428818126759688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04286116364185886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04275411427564298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042706272910392126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042880170978980676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042967761133825014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0428687057568736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04270781042242175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04256918520706011\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042606176225223925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04258099848686223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04283583821207856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04298064905563242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04299352462005746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042821789197427955\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04275984343246881\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04274340423030986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04264285081053171\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04268027181404899\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04273533547119918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042697022771153705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042697039952227935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04269813905480686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04292533712584185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042978514066429704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04298326735964642\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042864240283314654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04284716422751217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042943333790143146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042988873501584424\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04297720454081131\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043006233410182275\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043061288969604976\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.010267353197094053 0.02846633115154691 0.0065681989931035785 0.04351385278860107 0.02753013637661934 0.0003465784266591072 0.035420912672299895\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0793, -0.7847,  0.9847], device='cuda:0') tensor([ 0.6994, -0.2716,  0.8959], device='cuda:0') tensor([ 0.6674, -0.3341,  0.9664], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0045], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04294897333693431\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.04307028275659485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04306352640459905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042982227423264845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043013084425528605\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04295428380209505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0429360890273823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04303068633677169\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04300956178855683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04296162202904316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04292483495478796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04287692061965511\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042727303870853606\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04263423805076192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04260187762665938\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04272433036471511\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042855545777616015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04285262065086455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042856797363816035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04284117107108244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04295051096514115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042964205798917576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04280612608395968\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042806342295888394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042752789685349867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042792564880747466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04268712286526958\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04253388922645541\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04256168855592991\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04263724444767718\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042551497725514593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04260856630311972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0425932121820361\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04250064473883766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04239908108284883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04237437635794389\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04239020569935099\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042365402996759206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042294862010291596\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04221876433341208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04234118937623202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042343202524402566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042376662882026093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04238133381327821\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042289500163251115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04228937565432022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04233910409642804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042326042490628345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042240537454804904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04223399570294648\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042207060376643804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04221781922675665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042273873688307234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04218881847795494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042085521364099474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04199499113054515\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04198138025682419\n",
      "Episode average V value: 0\n",
      "epoch 4:\n",
      "Learning rate: 0.0003645\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is -0.05357142857142857 (average over 56 episode(s))\n",
      "== Mean score per episode is -0.05357133290833409 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.010603470149915665 0.023767790428129956 0.0050875501825939865 0.03885830559534952 0.028276318125426768 0.0002734684944152832 0.03618639567075297\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8261, -0.1920, -0.8684], device='cuda:0') tensor([-0.7993, -0.5134, -0.0555], device='cuda:0') tensor([-0.6966, -0.5502, -0.1961], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1235], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04828129905379481\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04228535387665033\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04222291449291839\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044656739466720156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04800234623253345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04275308018205343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04576659683019869\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04389286994571901\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04425421210557774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04513024495811098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04285534427529483\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043592093033819564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043868979319739036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043444662931419555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04253543986835413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04305290749309481\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04248215415168042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04255533813970325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04241263392866094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04146460203402158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040954745776222025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0422030505794806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04208687531586359\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04180208313132257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041321544607894285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04060013544284062\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04039139778702041\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04049701261193684\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041274558297818766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041308628227906645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040641494061944734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04037276701759159\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04109645779213244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04046903137692853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04122627945690756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04103743004322305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04100474630980319\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04159589128075875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041902594227858546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041339121578494085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04093869735971396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040869616618177916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04101250529378287\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04070982399968092\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040478303579521584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04124643086008098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040871247670659465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040877744947297116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04130735046171125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04090841237196906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04064873205183362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0406521839954349\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040347298033695585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04010047396470567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04023485395991516\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00970893916953355 0.02511001278972253 0.004646367255947552 0.04022318538511172 0.027428570859134197 0.00028327679634094236 0.0353902247659862\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7251, -0.9900,  0.5770], device='cuda:0') tensor([-0.0753, -0.8841,  0.9212], device='cuda:0') tensor([-0.1430, -0.8926,  0.8912], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0276], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04000771096362437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991923370983154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040059380749351135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040105784915671766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03977351184908508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03984307184966386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03977579710125509\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04000907052658183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03975074361571589\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03942918727437082\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039285779543776024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03906634657884674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03901295882559935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039048277910561834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03936043284234724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03937113270599319\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039351538084892924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03932068798842711\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039355555222392105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03950156501770295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039335455814558926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039419721020116844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03956388351089584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039598873551507936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0397058934823791\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03948267352376363\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03945118880314566\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03950946583472432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03942098720374926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03929416675613645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039158083721983324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03943875322289679\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03922977694075065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039273041106304724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039505177745480596\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03928233446241772\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03932858097528958\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039319322014443374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03942417890195631\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039341288169421125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03955851880622235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039578681958376306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03948486559652637\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03935634345155916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039261266738435045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03931186621577343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039354213420352405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039350100851968384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039498526063443236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039641876365723354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039745796722481005\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03985651135265727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03975606905397051\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03984198822767097\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03993565515836118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04017314219775538\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.009893343177158386 0.023924102963646873 0.004446437815437093 0.040092931509017944 0.027417896185070276 0.0002747843265533447 0.03477354140067473\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9674,  0.7087, -0.1879], device='cuda:0') tensor([ 0.7008,  0.9471, -0.7426], device='cuda:0') tensor([ 0.7595,  0.9580, -0.6722], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0237], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04013392261006788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040135967635642096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040067008469339103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040090687539437474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039902487057180885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03982552553611964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03987810623120839\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03985237875230694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039738281360284115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039907391498008996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03994290592536527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039975007168331134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04011669088890242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04017476204555068\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04006862816892768\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040042426904226706\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040025728547940766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04005092129846882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04007801753608112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03993321374904734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04002604243460798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04008628694346811\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039996768690407844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0400278121719727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04010125725671612\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040051171144837666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040029392552587556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03998511848631773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039907160984160056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039935605509839274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040194102853364624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040147515729492315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04014568531923111\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0400923660717248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04022694043630856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040147735660533874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040255510870523904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04024659431179031\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04021127130629288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04021195202827388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040247380204515106\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04022559802167621\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04022257420278731\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04032294514912805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0402596554015113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04034827212306756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040276530124417356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040328753438526356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040214184017127584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04023456944729888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04013327563747467\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040196004295569285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04011729686015581\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040060262672245654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04000119432863696\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.009629969919100404 0.023796711222967133 0.0047835067358100785 0.039450060034170745 0.028365214340388776 0.00027428578585386276 0.035203106854110953\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5747, -0.6504,  0.2262], device='cuda:0') tensor([-0.0325, -0.5906,  0.6419], device='cuda:0') tensor([-0.0396, -0.6291,  0.6416], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0963], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.039874897813250966\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.039831487924660056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03996144746550231\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040027277198547095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04004916857248456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04003094697809713\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04003350931942324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039966421796985466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04001297508721195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0400004425717252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040059470023628974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04005811226943138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03997275520802298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039902606964496504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0399254262191515\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03999172542622297\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040031351472670125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03995615995198304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03989740254807736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03990430372314841\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0398348017679544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039883746775048814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03984305630016444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991453266901383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03989204299612347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03982449560391143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0398102563805342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0397425628110408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03987603129267141\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03974324164045193\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03974207396893744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03966832190190727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039709762974560574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0396359046204533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03960138908265629\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03971376332348854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03976749042971707\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03974758298897178\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03961451548987086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03963662281319973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03965767779349041\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039667229861882716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039871341116867014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03983080177937472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03983010696968149\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03981670722891567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03985426578273337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03983788813311057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0398159887171194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03984678047266022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03982560718548901\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039765370191952115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03978399774789686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03974552088795757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03979908811785805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03986944315604981\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039948476455756464\n",
      "Episode average V value: 0\n",
      "epoch 5:\n",
      "Learning rate: 0.00032805000000000003\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is -0.125 (average over 56 episode(s))\n",
      "== Mean score per episode is -0.12499977678611288 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.009348036866169423 0.025171366152819247 0.0036102069864282385 0.040066558383405206 0.028411861572414637 0.0003008919656276703 0.034876529372297224\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4944,  0.5261, -0.7677], device='cuda:0') tensor([-0.8779,  0.1891,  0.2394], device='cuda:0') tensor([-0.9086,  0.2213,  0.3392], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0493], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.034582520110739604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027318569572849408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03130214119812957\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029989323837475643\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03019574766771661\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03295423544046504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031756172311447915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03448182257771906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03452627656889366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034029365690528515\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03730933355741353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03717440847712741\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03865377300689554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039794201768624284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039619860313487826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04082351386669972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04067826851003262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04072495834919176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04123010226982858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041759692255355835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0409027195336031\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04068686520666674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040911989431639297\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0404934903867629\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04145553964397146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041663985549169794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04205531402828302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04256870394798055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04238746815960555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042988156476403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04324941287788572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04325672211335688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0427847015350016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041998368381291284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04171871940368816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041999731736723334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04181247034568798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041518043269871664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041618839474766384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04221453934248227\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04183549747353061\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04144672408303315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040972408859627156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04076903110141913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04061150308870883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04113861746300948\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04089686541320496\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04106021079577557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041327236359094244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04195999937701143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04222649864574452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042177340630183205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04207271487604382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0418640657250459\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04158351761665233\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.009414672126062215 0.024089932641712948 0.004217025079065934 0.04136108602723107 0.028461829088628293 0.0002643681913614273 0.0359469728465192\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5270, -0.5858,  0.9847], device='cuda:0') tensor([ 0.8891, -0.0037,  0.6297], device='cuda:0') tensor([ 0.9302, -0.0114,  0.6769], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0289], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04151044870747091\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04150246580759495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04139053678787688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04162128908926246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04145495406722788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04185548748860037\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04178448391395644\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04165628182494806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04153402465251727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041327674875959244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04132863389749883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04127204638772998\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04091020739748404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0410682784124231\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040892035192218686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041192249510457656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04115889206806048\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0411610552956757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04109435380323211\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04093466447424834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0409288482712609\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04071880089727863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04058687874955786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040889715717885376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04072125772783895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04095943340493829\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0408309994881902\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.04099370881203198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040917555874560974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04090203577865621\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04079375738574033\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04068399983782935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04059855524401152\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040823912531132815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040659046627834074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04070537770849281\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04074255362600718\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040723470686695656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04049551308465501\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040385375407725924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04038736333960616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04042557747778563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04027095711431012\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040311425766990205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04034932463688569\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04052843617857306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04041248322352929\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04048853813336023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040527001483978815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04063217250541562\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040628543392065876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04057046872112022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040449433929359714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04033084799678926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040273321278844816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04027309611503098\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.009458441296126694 0.023079723227536306 0.004008168453350663 0.03911554594105109 0.028638855051249267 0.00024351099133491515 0.0340644098892808\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3917, -0.4552,  0.6446], device='cuda:0') tensor([ 0.6279, -0.0534,  0.3030], device='cuda:0') tensor([ 0.4752, -0.1105,  0.2240], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0520], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.040297658987886585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040502001835910593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04062204370429452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040483925263464886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04058535140805246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040555471370875805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04052451935424881\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04043772649828668\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04035697874087082\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040400481450177314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04039043239495956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04032908220772902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040292115650877466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040282310540477435\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04031638092668546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040653801880848585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040733182069541525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04082815287976456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040838999576611905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04085788069698925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040872873401313216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040924645564304904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04084760202851709\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04097079786629159\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04120314234351812\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04126090181134913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04136603334303735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04135488754593961\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04137080902758513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04148590986354906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04147701106232435\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04151281339341446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04155563583409264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04150055452496156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04147558663284216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04158670025527793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041503802151978575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041454862989693614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04143407903301219\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04127658000167917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04127902418650055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041330627199551856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04140970168143382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04145536161625364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041408033260778444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04135830755169541\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0414422333912476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04144427197276609\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04144686625546051\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04157527668300047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041576653773882345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04150665780985201\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04149426310512472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041744006598236585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04187783988509352\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.009004810920683667 0.02575180861586705 0.004091347927227616 0.045124837779439986 0.028441093400120736 0.00027301590889692304 0.03289014951651916\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5009, -0.0472,  0.2862], device='cuda:0') tensor([ 0.4596,  0.3222, -0.2541], device='cuda:0') tensor([ 0.3916,  0.3317, -0.2583], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0205], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04190295445283532\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.04185829556143039\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04183853448801512\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041872096686849214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04176118866497526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04177979274065708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041733204661680096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04191227327071197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041960694199753186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0419598557866376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04191227484440661\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04182787012563467\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04183664247925462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04184981655720391\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04180760024386436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042021491167946325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04204913005504235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04207506756509704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04202347937412001\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04193768035559253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041895321760142906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04194276697821387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04191739247566519\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04186500989537882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04184703253520573\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0418511725748195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0418416725465718\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04181833090692682\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04194418451486107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042022124052949486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04204019136517795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041952534839531826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041921819074548436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041928842950922744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04183312436084908\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0418929288643274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04194627037107716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04195257269803735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04195313920244211\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041933918524630964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04187620180944942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04184834015743238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041854021730246035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041781392046151854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04177925653822853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04180219891689527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04180505530154221\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041915359517229626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04183957131461599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04189018462461212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04187533436130868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041853430616018095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04176226399334753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04171986487950433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041668076024968095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041687573979000886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041670791387208736\n",
      "Episode average V value: 0\n",
      "epoch 6:\n",
      "Learning rate: 0.000295245\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.08928571428571429 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.08928555484722348 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008941926483530552 0.023124025281053038 0.003919918485800735 0.04105226310575381 0.02879995656386018 0.0002771766260266304 0.03657334454613738\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2995, -0.7773,  0.5561], device='cuda:0') tensor([ 0.3553, -0.5304,  0.7461], device='cuda:0') tensor([ 0.3738, -0.4456,  0.6988], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0092], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04617918313791355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04235703099725975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03961345637907033\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04344882920850068\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04516017636698153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.048213709223394595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04705319722877845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04807395599911817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0471391677454022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.048863559418047466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04741419134003044\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04642945188270123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044339479500443764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043193303647318056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04241218245415776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04284904899153238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04367031713984176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04358533443308171\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045024515118733135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.046319212997332215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04551739472324255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04485435260111711\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04564248478256058\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04551068490103784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045591505664504234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04511336655690311\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044989759696517216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04664223573155819\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045819753656071036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.046303896528358264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04634302270208155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045589522164340854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04571360858590013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04539215416659668\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04531735837429998\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045809604769377156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04630318877647992\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04660130951864024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04666587037095359\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.046414937996046825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0463174463610662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.046696635707227326\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04648005123459553\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.046383269342847845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0460831079080149\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0461438265606617\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045637026605312984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04573362758728089\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04593894291719815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04614995658190714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04578720479757243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04591283129536125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04591074720243738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04612386406211512\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045661690351412154\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008783341989386826 0.02460923760663718 0.004314166615717113 0.0456076915320009 0.02795458652637899 0.0002755164355039597 0.03424953319970518\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9656,  0.2417, -0.7113], device='cuda:0') tensor([-1.0114, -0.1865,  0.4590], device='cuda:0') tensor([-0.0810, -1.1250, -0.0151], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0371], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.045802030324315034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.046055148602563156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04582737043671224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045787259892485124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04577486589550972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04602971243823052\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0460544127794016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04615224024849226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04566908112853222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04567429383293304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04553237479565797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04560823146343404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045357358272893514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04535667184851284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045295943367841936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04534194658471035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04558995720300892\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04559297333691195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04536628790756313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04536108973194604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04528518528772834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045046617614957374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044839485598186776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04459115200769025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0444663700046173\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0443726470010465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044132890904746286\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.04391246470978042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044006266830139175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043895030598113546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043763729809838746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04394053484968565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04399413004461111\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04410605286753803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04422241026006731\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044159243465543375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04426715786429347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04413860654313754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044127104600261785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044202609163060874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04426737077085784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04426083486966729\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044048532079102774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04387803683757749\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04375693483795557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043723660457686685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04361790234287937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04363338753054603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04368004513383071\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04378636659827655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043801276262193545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043689852255480686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043656339678231154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043655933698337375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04360263210373244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04354938883446269\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00854165958124213 0.02240534834517166 0.0038617708571255208 0.04145616311021149 0.02791420616954565 0.0002522989511489868 0.03352585929189809\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9720, 0.0838, 0.5735], device='cuda:0') tensor([ 0.9993,  0.6071, -0.0568], device='cuda:0') tensor([ 0.9767,  0.6269, -0.0570], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0637], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04337794933420059\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04339924233534255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043482712586183414\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043285605748710425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04324379250125324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043315524805393794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04334872608553625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043345081101212546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043301625825740674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04314721970843738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04300302473144548\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04297886871671356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04309120749108373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043155804983857605\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04299348543605043\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04288105105277239\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04284016940194609\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04286698838711927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042886139260222896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04295571787485045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04286452898518919\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042811584305298286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042855829177702316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042889780310890926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04291721015409232\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04300391809736882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04288191137454456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04284190255285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04280017268666554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042838500875765365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042867380015826045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04290454534896256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0428411277380404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04288908107263318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04286560579699208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04280172670485335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04270645058133525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04273019007828689\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042757207775764444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04268152653249947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042763369648760916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04267511959339863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042752913901552794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04268802857413674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04269936728454394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04265808589098697\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04270048765039907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04266784559436804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042544707181837615\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042565117363244025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042526705042984135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042517516289373586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04244563240131368\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04262260883193626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042719030855634964\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008341018392704427 0.022666047373088076 0.0034880064907483756 0.040958466092124585 0.026853082578629256 0.00023258277028799057 0.034925280911382285\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6630,  0.1038, -0.9078], device='cuda:0') tensor([-0.8228, -0.4457, -0.0584], device='cuda:0') tensor([-0.5288, -0.3899, -0.0357], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0830], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04266542153332583\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.042559084822959635\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04254786610645582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04252030412024313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042501312339087785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04249577357801332\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04232660381350123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04232342396598157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04233083630261558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04232134671856513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04230829183323857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04237856633438567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042288070436350855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04231134664632357\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04225328094851937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042118563184142796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04213282777662047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0421084465169638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042129775739551796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042115939168950484\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042216903016948436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04209498391251672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042164066349123897\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04218883027679325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04226006696598281\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04229231508563518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04224902766335286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04237752772623914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04232426550162378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04225729877494018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04225781882505862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04217919948974396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04228893964081308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04224881867684113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04219497246047376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04218746938963489\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042161894258856976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04211534814889317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04200994262893288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041951873143928925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04199672046655382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042040004717204996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041988396851132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04200644364183838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0421761755279563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042234199382125574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04217009288166544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04205415515180267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04206316656871032\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04200739992210937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04202250411118349\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042073359078666904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04202103222420752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04195815459484084\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0420101162952466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04196622773543004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04193865889322478\n",
      "Episode average V value: 0\n",
      "epoch 7:\n",
      "Learning rate: 0.0002657205\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.19642857142857142 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.19642822066389165 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00804913956602104 0.02179458901938051 0.0035159639935009182 0.03983879310498014 0.027423230789601804 0.0003139286562800407 0.034905339764431116\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3538,  0.6463, -0.9735], device='cuda:0') tensor([-0.8852,  0.2536, -0.2690], device='cuda:0') tensor([-1.0009,  0.0855, -0.5564], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0874], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04577486548158857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03761287364694807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0430149618467247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042982981954183846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04072998402019342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04194196146326484\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04519335966971186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04630297476736208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0452700251782382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04525116490614083\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04518085133961656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.045440385954592516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0448171302723961\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04467873488892875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04308297180881103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04419554381295004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04260993876123156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04260950445852898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042709046544518035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04229304302069876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04267387311393149\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04186355479230935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04126530170332694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040902126567541726\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04145175375044346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04211509109546359\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04259024535156326\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04272042313176724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04329648639621406\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04347455193530078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043566014177055766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043471640302515074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04348031584148355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04360116048247304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04349433752811617\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043513784627717586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044016693223704086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04374751401792842\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0433715267725119\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04327787805814296\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04308429794249738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04308192556842216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043351460688624735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0432151985858012\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04304261282316329\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04287590010424599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042877642120769686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04269338143058121\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04250324286030534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042441464588046075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04255106601222928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04257335442985989\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042434766525461236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04227127834345854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042433319787372546\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00843448639055714 0.022790855288505555 0.003472166601102799 0.04232890245039016 0.02707612410187721 0.0002045673206448555 0.03568749222671613\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0231, -0.5555,  0.5106], device='cuda:0') tensor([ 0.4162, -0.3503,  0.5503], device='cuda:0') tensor([ 0.5786, -0.3139,  0.6572], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0402], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04235992839075773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042181825382384464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04234161124015191\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042405330648789576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042767092065575225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04252083898727224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04237511792340346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042470714159480685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04255834570115743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0422430154397829\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04208655747575591\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0424687214092248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04230890428005212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042620683326603376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042797639592742874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042744993772182806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04282465088971672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04265823850232422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04240281549114566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04245633022238811\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042402531017960536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04267401672116229\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04291890738193646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04302038668927313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043022082787744394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04324180070235457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04308569944005581\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.042994022300501804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042997091200150966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043131746516983004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04317927037549833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043129718466096895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043162804952707384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043259764373588486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043452909481596705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04349916136166324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04344756513466195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043511599910099466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043435552441757216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0434672899263753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043502599036771616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04370012535886436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043858013000991826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04405925987945822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04395908180805337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04409035012956885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04420192596377817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04401394924949634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04419176257190565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04415135804696807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043997111290242266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044039381005746135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04405664256702028\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0440070912041146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044113689160322524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044040710362069704\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00859390909736976 0.025097576656378805 0.0032954616522183643 0.04570494704460725 0.027146767750382425 0.00024168048799037934 0.03450091245723888\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0808, -0.9677,  0.8882], device='cuda:0') tensor([ 0.6147, -0.6707,  1.0059], device='cuda:0') tensor([ 0.6115, -0.6402,  0.9792], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0392], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.044030757959320446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04414488587481764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.044053981556524444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04403013242206172\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04378531931233111\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04376580371965406\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04369465634687199\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04373204281330143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043620158358761624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043536115161727354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04349476961060198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04346059802133008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043469721065228305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04348260147145225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043630877187979825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043639337047747126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043508185912287445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043357371652023954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04335560495149281\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04329000492509142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04318887090035291\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04320263937010633\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0432328815816378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04311066293119311\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04308552334250219\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04313600524547695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043245238847558154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043177012850133645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04312661846024206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04319726174658383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04321311361499638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04333886460194157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04342097312339185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04337477622735689\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04340944871468728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043523497207411256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04346160168179895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043449704449708554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04342019676731002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04333657652706407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04329995083815298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04328692920107635\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04331180144791474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043394314783281485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04329493104999598\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04337945107290863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04326571239883528\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043231607507686516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043414067656623145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043450005844671194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04341040730054154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04347000134637136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043444106999379624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043325020501904364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04320046677047803\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008241964219603687 0.02364966486254707 0.0033707311819307505 0.04163850719761104 0.027421161353588103 0.0002249012216925621 0.03373331847554073\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6275, -0.6077,  0.9864], device='cuda:0') tensor([ 0.8657, -0.0176,  0.6489], device='cuda:0') tensor([ 0.9401, -0.0128,  0.6497], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0240], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.043214509851520436\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.04323937195872459\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04335673435476047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04330511280910715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04321799156088999\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04318310713707722\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04314060530364489\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0431847644362915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0432583492466559\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04318683075226462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043189782563191226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043185669015924424\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04314921512228016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04308096294414919\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043088940098999495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043029172645491734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04297740661689552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04299490399737978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043017625800465364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04300195503584359\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04299021979217847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04299668053148015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04303170246869295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043025771056966346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04300909884826081\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04291837984311752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0428925448358134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042868363336960806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0428587997707663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04283349556716944\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04293484508440222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042953114959622465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042899786385342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042820620773774055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04285304001730703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04285231901448511\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04288899686853246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04285857165998258\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042882704415022926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042942817585880366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04297375851083333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04290996830110462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042923018075367324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042820835157381325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0427753804732171\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04277409103589691\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0426687562233833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04273190752671778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04270863876526439\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04269763533794417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04264979803657156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04264401364169643\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0426019322210266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0425941062432648\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042541995109374973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04250303506235908\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04253038291912526\n",
      "Episode average V value: 0\n",
      "epoch 8:\n",
      "Learning rate: 0.00023914845\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.125 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.12499977678611288 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008246828832197935 0.022191151496255772 0.0032857069921446965 0.04035816899919882 0.027268884740769862 0.00021307702362537384 0.035256334943231195\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6216,  0.6851, -0.4112], device='cuda:0') tensor([ 0.2318,  0.7624, -0.7854], device='cuda:0') tensor([ 0.2354,  0.8603, -0.8018], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0423], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03554419531590409\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04109780148913463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03492435395579647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03853393692730202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036317440143062006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036511986533662784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0400745210104755\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038877978649300836\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03717219835595676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03934898575405694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04014643316740415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040778390427240754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0399992020549969\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040162448381399\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039502490534343654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03935073651923125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03948894154213466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04011566211601696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04012607077370828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039727923192549496\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03998752861165456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04003682517507725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03993371753404502\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040436618248888945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04022400673375361\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040415474789766356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04073638373836415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04029231682504779\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0405408615894059\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040388849701008034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04017886653539181\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04097365892489001\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040643375231304305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04137658329872305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04156185722880302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04138043867122313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041202418759951856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04158165722020646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042263620899873455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04201529954055635\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04221281595338833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0424431976819135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04237519554704793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0425434627286817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042742118425092394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042856160982664905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04271021901836826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04254911049577425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04250891304198999\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04248225810885843\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04238252646861951\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04233805256105689\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042525826497940615\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04266555447643048\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042698061857090304\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008106283908011392 0.023523495377507062 0.0031322276239516213 0.042798110665287825 0.027138358429074288 0.00023381975293159486 0.033670705624390396\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0225, -0.4948,  0.5113], device='cuda:0') tensor([ 0.3983, -0.2743,  0.5852], device='cuda:0') tensor([ 0.6083, -0.1795,  0.6359], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0187], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04269879529694288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042918250185744314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04301497725889415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04277916315709734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04277882629238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04266931424774094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04241138873713619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042321371452101034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04221444773955025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04198369447372726\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04185609337176049\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042163733777915983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042135932432941094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04240967401591296\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04212043164039238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.042297395574750964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04230834136862181\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04213323247834439\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04195956808728846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041861427773687024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041750733571451114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041778021412437936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04173620344316083\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04172385112728279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04170658247668244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041677005091728066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04164374800528927\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.04161880060330961\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04165451026801266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04149429824878918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0415550745979736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04148657969258592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041373610067019014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041460464152445864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04140504703333854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04141144063613708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04139354158331222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041296656852423376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0412862368589091\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04140674438659777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04119303894738011\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041096559213634413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04127916680277239\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04122436636856074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04126981313133405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04132866261504402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04131077249049491\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04136373217196526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04125561919680231\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04115136360069589\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04097755154227717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0409910589976861\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04104666387922908\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04104998653467885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04107870540929714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041075078963495056\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007953948048874736 0.02174901420925744 0.0030969233635114507 0.039359809149522335 0.0279188785366714 0.00021933228522539138 0.035439785746624694\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4541,  0.6253, -0.6543], device='cuda:0') tensor([-0.7577,  0.3315,  0.4433], device='cuda:0') tensor([-0.7783,  0.3664,  0.4080], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0415], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04098072470930804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040796741812545785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04076039428063841\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04067501059917796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04076398290217394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04080081435543081\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040741763834923984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04070985101356434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04080381581551154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040805270696525814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04077410239188547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04081908824736658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04099778946877981\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04098367820473181\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04095250525761468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04093318706751522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04102459699061001\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04108300295631938\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041204775480601266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04125529629169656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041333486719577504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04132625198578376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041313141283222395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04142877244210415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04151070768582738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041515749805536656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041484924322354115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0413856725621638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0414139963287328\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041318256749240924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04136632319907067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041326557057413976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04124932476307875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04152361010968457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04145902298005295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04146038038826471\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04147026544386471\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04154651255765617\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041477985077848036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041432479073000884\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04140831418308206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04132402318576452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04131904580263478\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04135334239037554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04131343996515789\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04120660870173196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04127671049826591\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041233586668083085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04116071593339762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04116008847147185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04123748282599167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04119539029144599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041252719964024416\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04131792810077619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0412149755440034\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007745157655328512 0.0240006553651765 0.0031890889101196082 0.0414858656860888 0.027809531483799218 0.0002500506564974785 0.033447780968621374\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7743, -0.7314,  0.2005], device='cuda:0') tensor([-0.3150, -0.8645,  0.5435], device='cuda:0') tensor([-0.3306, -0.8167,  0.5297], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0763], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04119473614272025\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.041238689099108335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041478131305644345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04141882491644983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041434610994136936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04158982115999846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04152235300289126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041645406958281915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04164781363473998\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041552968517844235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04162608980091858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04160726138945209\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041548918404869045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04150285130930076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041557170813154264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04172435107667077\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0416736148725279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041664583882955825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04162497089605208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041577702890269304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041546410718845316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041538501215050656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041470427455370704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04143724781896767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04140231975745962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04136558423542064\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04131040474020318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04134104739237718\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04136727229795522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04138593414091968\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041351541845013426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041295281374893925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04125528453497215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04121714420254446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04117936014278595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04124328347406585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041258198363052966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04123472887464679\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041223769201859224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04126146888438745\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041237872141906794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04128292860298091\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041236724556462837\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04123815764333048\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04139967063631178\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0414472885612414\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04141719578622015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041453198111506794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04147548694933647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04143531662086217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04137113719894391\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04146590506445301\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04143161593947251\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04144610805352303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04142433080247235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04147691673667238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0414554305956699\n",
      "Episode average V value: 0\n",
      "epoch 9:\n",
      "Learning rate: 0.000215233605\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.16071428571428573 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.16071399872500228 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007851777489297091 0.02444878710084595 0.0027891475460492077 0.04216990155912936 0.027593113210052252 0.00023726383596658706 0.03515806172788143\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3559, -0.7486,  0.9940], device='cuda:0') tensor([ 0.8397, -0.1488,  0.8173], device='cuda:0') tensor([ 0.8992, -0.1960,  0.9028], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0167], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04254191710303227\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03860188244531552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04372271302121657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04393538651573989\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04132521878927946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04085987705426911\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04048298248311594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039342562228234276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037461778309978086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03666950786072347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03693524530778328\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03827412983540584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03829033629427481\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039346127693230905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038917434867471457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03971626498645896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039361741652505264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0392446874577644\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03934268967373765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03954499540074418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039818666045056295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04005687135140026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03984391491563208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039981510656178686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04092212866784798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04082840467946461\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040050634665897596\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039971069288661794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040379587914152394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04056944152064346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04023560375228898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04005516456284871\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040072203971295045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0397429729878805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039872568733398873\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040050996335246315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039859697975039306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03987531364508714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03968110195549465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04042154229763481\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04010103185355744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04041900288648706\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04050006953282258\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04101342093340601\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04107406387266554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04073253355848328\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040538587814403906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04070815388695337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040795314392864775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04071547854588264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04069284730020724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04053557886738075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040543354574231666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040349051562318036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04041665873462052\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007952024745289237 0.02299033122533001 0.0028568682182813065 0.040483567762188616 0.02776808387041092 0.0002220802828669548 0.035375901638530195\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0622, -0.6527,  0.5836], device='cuda:0') tensor([ 0.5546, -0.2779,  0.6664], device='cuda:0') tensor([ 0.5925, -0.2400,  0.6812], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0132], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04039700270264542\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04038105952892939\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04039724821214104\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04031598224460714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04046932530882596\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040342071316695226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04037118537308094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04027279957347078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04037931681604176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040580916401540115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04029855151387929\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040342149428195424\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04031519873335568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04013550359059887\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04014702212390682\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04019361955051038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04011241775465968\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040038291420192204\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03996059479745659\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03970667130969189\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03969116406297388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039598988776308894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03966970260963481\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03961818687664934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03947966545302835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039370494470541945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039316755751031766\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.0392745683316286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03936311558243774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039462371852273255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03930401293565675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039220170018002674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03925906595858661\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039357940273384996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039503962276388464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039616223132426555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039460009286756026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03950334336662058\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03963022637037873\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03957608647600949\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03979986917693168\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03970466224201459\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0397534863537604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039816709212314935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03968043210812741\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03961856237830896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03956197113131451\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03959631955024044\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03954609362289119\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039407046053499456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03952332542022101\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039386526095416874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03952080695966542\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039412266210245614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03940229707802034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039373839397106446\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008017901384737342 0.0214845984922722 0.002696329857688397 0.03832300627138466 0.027608892153948544 0.00016883978992700578 0.03510494444286451\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0172, -0.5657,  0.5725], device='cuda:0') tensor([ 0.4707, -0.3054,  0.6041], device='cuda:0') tensor([ 0.5633, -0.3194,  0.7055], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0325], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03939493989668018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03936647821855141\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039406187987575926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03943010660311306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03948701940159317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039502549342942006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03960531028364689\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039542831955729774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03956833851946242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03967377311388446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039822278553212846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03977920158952138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039913181225956156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03986912642626299\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039775043863530486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03978850376243888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0397139454528062\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03968147264671585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03966709803590854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03972327371939157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039680519299221034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03965370396522489\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039713480654612776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03967299203315573\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03979443830896011\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03978962196106664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03977594856996143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039670277313574205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039794328484299875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0396962981051681\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03956624739023628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03967763778768775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039682297268882394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039783817989273544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03987810211298672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03981631665503943\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03994871265822658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040000431990357896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03995748021329443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039956164834136866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03999743290444324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039961686511385375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03992386166514321\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039892584764428675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0399679606236475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039901563083398386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040030211722740246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04012236930397395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040042099632490946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04004234058738752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0400260929078942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03998518976634946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03997250021275052\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991061722207501\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03997483285339711\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008182015103055164 0.022689922603778542 0.0024307847938034683 0.04111396043840796 0.028490713063627483 0.0002278388887643814 0.03340637517464347\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1585,  0.9280, -0.9720], device='cuda:0') tensor([-0.5242,  0.7244, -0.9098], device='cuda:0') tensor([-0.4887,  0.8520, -0.9182], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0421], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04000684755302207\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.040083176578042744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04012704721176207\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04009133023879448\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04024092403414179\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04025407964742721\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04021843538787659\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04032024496953368\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040387551025561394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04027320135906903\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04030753020021763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040233933043604564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04025718450175123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04020591158747535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040153667073184594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04012176264799513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040140461045728444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040160415233236595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04014268655039079\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04010415451685712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04023562282250792\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040211488475723645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04014783947816724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0401982205337164\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04020545965167865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04013626764073571\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04017723047602911\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040129029913992115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04009392919560146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04004911487671819\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039956259877393124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039985246002552856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04011575390269126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04005241610937648\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04004878931894544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04004739217431468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039991923049194245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039913849204612294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03995495932000036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03997264467852899\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0399355355868145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039969005179193474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03993533158195559\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991574001370402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991409178392637\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03988679570308935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03985840067618182\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03987431169056207\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03995888754460739\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03994755534557702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991563550563299\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039913311661444184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03987113666734391\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039938373433313135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991321249887939\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991056403547928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039936291115824134\n",
      "Episode average V value: 0\n",
      "epoch 10:\n",
      "Learning rate: 0.0001937102445\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.05357142857142857 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.05357133290833409 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00808073007548228 0.022521905849687756 0.0027267337245866657 0.039858277664519846 0.028536099322140216 0.00023931759595870972 0.03427653739298694\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.6909, 0.2472, 0.2848], device='cuda:0') tensor([ 0.6251,  0.6478, -0.3059], device='cuda:0') tensor([ 0.6236,  0.6718, -0.3459], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0242], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.040204676489035286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04082844044185347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03661577603607266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03533903129088382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03819185282207198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038855007073531546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03768431055285628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03647134912252012\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0376577540933166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03834694235896071\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03739901596322806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03700168538597171\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036897197182680294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03848944500916534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038548589728910614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038839285679083936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038932807983988835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03903035041991115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039255648685281565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0387808222297786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038254702239538786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038355368050756025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03864017426562698\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03799919294909126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03733478661212656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03852487505119071\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03882310326774547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03893360497415184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03931056769828801\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039151873518885286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03994294027146954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039849934179478116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0402451524815149\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040237640896568595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04013831822852057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04030681594510643\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991435517839439\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03989853171702496\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03995589679903072\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0399694210345236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03978664732505353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039633900448236434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04008002414726664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03993777670742323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03971307422436866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03961375718014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03973643537764889\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03967472996791238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03937590014413337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03955682647000584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03928081165037416\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039142091811284356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03926871156327786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039133212695841066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03929424606677559\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008024225902510807 0.02168192489631474 0.002544065106427297 0.039078713110648096 0.029344439871609212 0.00020129694789648055 0.03330686342110857\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7326,  0.3894,  0.4369], device='cuda:0') tensor([-0.4780,  0.4363,  1.6659], device='cuda:0') tensor([-0.0251, -1.1506,  0.1840], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-1.0643], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03892250254376984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038908054314183385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03888042200039144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039244795006764754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039162189008978505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03903585411896607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038946567247638404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039085442677462175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03905237773384821\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0389089029497252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03899319019867891\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039038126439529516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03913725671598846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039363280023431674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039434464257358325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03948061395631826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03952975439505629\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03930300087249828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03963372826802771\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03955819798495482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0395734491642314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03967049973714468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03965527259352009\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03964994484938566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039593423882292374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03960806787887841\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03976912816057643\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.0398411030545731\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03996321127661282\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03989319090968838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03981346145479216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03979036460795926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0397797567649942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040032475532152306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039899674374150276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039680070973823575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03972021007352477\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039793041193125635\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039760830209438575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039763381016816486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03977829576804113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0396075529304524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03977023584761841\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03970681521341238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039574802812292344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039575642662797006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03971463360738472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03966899314581818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0395367231969244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039433687644956444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039484784631370964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039723456153009755\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039591424913076614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03961942834346712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039465301154143734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03935413779150154\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007958415458211675 0.02306518859253265 0.0022854191265068947 0.039817378425970676 0.0292904537320137 0.00021795353293418884 0.03392796729621477\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9220,  0.2844,  0.3438], device='cuda:0') tensor([-0.7528,  0.0590,  1.4714], device='cuda:0') tensor([-0.0186, -1.1562,  0.2092], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.9760], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03934708143360839\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03940102930850145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039472814340264215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03950384318927564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03963765541539381\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039639747507449204\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03954257258861247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03953573895126136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039476797202843486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03947302023131876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03952354806320969\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03949207958261387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03948958990194144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03962425342616108\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03960716672819863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03962422526349441\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0395843766172119\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03966275235304319\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03965759785073754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03976129509146824\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03975853088558009\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03965814233661856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03955948159174305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03952647966980444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03947742504152938\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039600052981843624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03960117956566446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039550915585278415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039606290377144304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03957053045085371\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03963187572740147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03969795922672763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03979103242041382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039709408323626634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03965835904282953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039715840430537455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03971062837009159\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039587869194991146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039553035179635994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039544928503360506\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039509101526754534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03945215662722202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03950874278527479\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039600122257679914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03970371011380595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03969456421696467\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03978334424418624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03975310669183617\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03979606073666623\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03976582291550816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039731774390042746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03985984109744592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039824395325996464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03981554078013457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03982503679418909\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.0076276185477618125 0.02414331403700635 0.0022394486820558088 0.04070195979252458 0.02912735014408827 0.00025646988302469254 0.03431655646162107\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3924,  0.8060, -0.7279], device='cuda:0') tensor([-0.7798,  0.5659,  0.2070], device='cuda:0') tensor([-0.7469,  0.5416,  0.2926], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0044], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03982774049560437\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03989198918007166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03989649775488832\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03984318524446898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039784161508013144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03984533351435728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039839746347074045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03992668695130539\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03987227816016428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03980606250909411\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03974344808232958\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039804154693366456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039804648485411626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03986847098905271\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040003419326626315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03996919085907321\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039922726730763476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039980717268232525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03993610787252943\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039943027628303075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03998224568164249\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0399833526043992\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04000518750508854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039997314413933206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039966418633780344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0399291329888877\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991099834875362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03987755844388733\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039823781840630575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03986369689151459\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03981819981210106\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03979351737731953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03980205975429247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039761697167220215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03984668687183663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03990497902533648\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991397558678335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03990744237741354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03994062704041721\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0399690333089742\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03992791589293519\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03992492345293076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039904744826269115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03987624181345815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03994963160338858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039941471075420454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04002127487282378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040084715027880476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040061084308134494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039994629460229796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04003525727141898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04002785860161154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04003885421780978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04009827825410122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040143160637357594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04012197328710908\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04009163121134043\n",
      "Episode average V value: 0\n",
      "epoch 11:\n",
      "Learning rate: 0.00017433922005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.08928571428571429 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.08928555484722348 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007651435802225023 0.024257710001431405 0.002311991428141482 0.040776867779903116 0.028826549109071495 0.00023487385362386704 0.0325155405048281\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6574,  0.5977, -0.8391], device='cuda:0') tensor([-0.8443,  0.2303,  0.2906], device='cuda:0') tensor([-0.9145,  0.3238,  0.2931], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0772], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.042936751825941935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03546365671273735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03191353791151886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03397864447389212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03398989192727539\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03380859763947902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0339402909582806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03560388149020986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035717198745933945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03459660155802137\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03411176059903069\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0348049920198887\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03409718961303688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03422042714535362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033315051888564116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03382688730036736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03345995549161255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03321420166204557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0337349960297259\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03463493502284917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03479480979934571\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03456683402805768\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035435715100867446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03559309042369326\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03612008289330536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03631016495836596\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036610687320185784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03681029824333058\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03678303138063899\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03705573476919973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03736010891815988\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03757270207279362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03762518910546897\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037557295000095386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03760557748998205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038165704097115886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038376919156102626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038542652341989225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03862080577644188\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038528902753670186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03892920671288318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038789616067396115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0387906880606476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039182500135285236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038954632402754125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03873383183851118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03843947100820764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038553400614074675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038688158681890725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038354655376945934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03821856260384902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03842486495562057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03851795510000371\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03862700886054754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038644893278339594\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007924234561156481 0.022409665249753744 0.002029810960870236 0.038725236083380875 0.029584336433559656 0.00023180956393480302 0.031472723917569966\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9785, 0.2859, 0.5065], device='cuda:0') tensor([ 0.9495,  0.7080, -0.1183], device='cuda:0') tensor([ 0.9229,  0.6786, -0.0989], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0248], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.038763876471276736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038736467720799105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03888348785721451\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03871781833859234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038655784730454563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038800687791240185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03893547925487241\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03912914078600534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039102880959237356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038875181610799496\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038793759767800216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0386740016692301\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038567899996445214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03858162939545493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038523009743925835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038525266438017194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03861042942756925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03852429858208995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03873024348172362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03886975496386488\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038911361043744486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03888928589933857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03892495349696983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03886642915349972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03872325025667023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038808777760356586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038841962317751874\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03891014806375187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03884308440573809\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038937486849993076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03888490443474081\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03910326313448649\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03897176442533788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038892954500152566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038813832888586655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03877613966959336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03863778471573288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038734134706126674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03873558196263392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03897382335530387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038911479690189786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03892234778074379\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03879126053052171\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038768174715745694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038570856632561316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03860789841774552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03853477309823182\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038385710567979396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038413837366502605\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03845702941879315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03849358583480292\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03836956220076478\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038309660104942724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03833806369582782\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03824252114922862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038192107709491996\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00798635261785239 0.02218041369272396 0.002014152921852656 0.03757209994550794 0.030001512471586465 0.00018066557496786118 0.0339622093946673\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8618,  0.5543, -0.0500], device='cuda:0') tensor([ 0.6767,  0.7759, -0.6093], device='cuda:0') tensor([ 0.5620,  0.8557, -0.7090], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0690], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.038129610063079446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03828673112236381\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038480737525243565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03841134292356994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03840204308896015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03844501529948508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03843946954131954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03854755782430955\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03854165871291318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03858968423580267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038559589755105594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03862595835670344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038626592010042655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03864599050705632\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03867246705432615\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03867854981227718\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03861875647392784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03879385843710985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03867341267207685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038565064471158136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03851046280030738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03846923194852103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0383597240218766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03832079749286114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03834176450523432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03832112427646806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03827686509231462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03829255788330194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03827314829926879\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03822944368697392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03818915272022252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038157111945219785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03815088737403893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03813902802187307\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03811886667166206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03810071576638703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03813357671824852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038109344061836324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03815470821707061\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03820946259935324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03823921405124799\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038240338921189825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03823929769759742\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03825921775659673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03825301358123387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03822522164537965\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03822997391666646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038231073927516956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038281476522226715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03824229222086687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03825525233083863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03827758693061997\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038236350026473825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03825665703294203\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03824609461292834\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007860225017182528 0.023567396841943263 0.0018823809761670419 0.038348918584175405 0.030182108648121358 0.00014814098924398423 0.032899209972354584\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7615,  0.1936,  0.4849], device='cuda:0') tensor([-0.4561,  0.1163,  1.4424], device='cuda:0') tensor([ 0.0051, -1.1665,  0.2188], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.7272], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0381952200741126\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.038152322914419334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03807579724664294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038112826128277225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03815123131873886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038140781375083796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038254694563056135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038234513401949485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0382308509724126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03815426321193397\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03811793814618456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0380306900414951\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0380831150260588\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038061342064153264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038006282699659714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038016699676393956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03807735956841136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038088136244619236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03802225622026859\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03796865965635822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03793063572958218\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03784323151550315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037777828995734106\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03776412058692447\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03775791572883656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037809138003299096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03776919981786444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03772039667869633\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03773566310153345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037764188027338816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037906005803665835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0379160706089197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03804116545188891\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03801238930551335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03802297283566339\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03799965362498953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037981131033269465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03802770081895337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037969066241003956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03796263445297331\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03791724785190562\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03781709865404245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03784544526211668\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03787557757976982\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037938275718262096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03792321603536309\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03787621927006004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03789957243923063\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03789686315045608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03792458894583991\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037914523093294045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03790810281101322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03789270958777674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03784211691083255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037888055367141495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037916100743386125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037909032774623486\n",
      "Episode average V value: 0\n",
      "epoch 12:\n",
      "Learning rate: 0.00015690529804500002\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.30357142857142855 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.30357088648055985 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00800124555407092 0.023069487649947405 0.0016001185425557195 0.03698315130081028 0.03056632412597537 0.00014489857852458953 0.03349438085127622\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2989,  0.2254, -0.1301], device='cuda:0') tensor([ 0.0077,  0.3837, -0.5118], device='cuda:0') tensor([ 0.0668,  0.4603, -0.5166], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0113], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.035345469497972064\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038939985550112195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03843719701938055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03750755906932884\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03634733396271864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03718052100804117\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03647695852827931\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036248303497106664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03610640949351184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03620689069438312\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03619507402934209\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037129140821182065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03780105912214161\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038185850428860815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03768369283665109\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03756327446576001\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037247381075681034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03857065038180646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038543876543728234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038451059172964756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038301943017849845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03875491461443781\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03879878654680102\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039040155363855536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039110151007771495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03900944978460415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038912668011683985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0390721356037945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039287519662630284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03965003015473485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03964334296055912\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03991892465920602\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03949993361189008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038956548766007806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03846662784852679\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038992137688407556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03896436593061811\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0387935846450341\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03858958767127362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03838850649384161\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03819941598316276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038024146518812925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03779680639486134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03777875349094922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03753228942277255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037322846320030335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03705689525694078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036932698953293125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037005010614268766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036925128938423264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036769520286430074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03680515462039118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036875313317766355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037117247475472126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03702071536181852\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008462625928223133 0.021492080902215095 0.0017175098427687772 0.03719266046024859 0.03062295062839985 0.0001327335461974144 0.03284556990908459\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2640, -0.9849,  0.8324], device='cuda:0') tensor([ 0.5210, -0.6193,  0.9980], device='cuda:0') tensor([ 0.4804, -0.6294,  0.9964], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0081], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.037166446464003196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03678081840454631\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03687896329634805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03706906394149035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03694499740808237\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03689124172499135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03682322188207085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03681428895974154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03671083269728115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03658679501416209\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03658000460468383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036619371699808695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03670310000417255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03660782696169332\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0367647453129942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036634248364366975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036645654724037025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03655843734117494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036680498319837426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03657429442085602\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03667091678185334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03650790181355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03661643414150531\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03671967724414147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03687719098395771\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03674976528329655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036616658694729166\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03641439100211284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0363134793350818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036225568130612375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03643954602053307\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03639617593159678\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0364117709669341\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036444047637418674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036268766398576124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03626326561117402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03623042459057527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0362739520622562\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03612475447636318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03606663668931228\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0359460674441868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03612856500763937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03595420344713695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03594116778369035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03599675997988217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036100679658132025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03613428192412022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03614812631395112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03611644348736582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03601897878513213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035998297399847105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03588870812549816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035853922279425146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03590066851402474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03593598939666543\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03595003479526745\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007872485520783812 0.02118998839519918 0.0014001090326346457 0.03465921141952276 0.03039472744986415 0.00014595820754766464 0.033581570288864895\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6617,  0.4076,  0.5237], device='cuda:0') tensor([-0.4000,  0.4401,  1.6345], device='cuda:0') tensor([ 0.0180, -1.1760,  0.2457], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.9081], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03593871720959359\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035880112842882866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03595193886501283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0360836727409691\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036127053199414436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03618400143008371\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03630455450870433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036318592337176665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03646253459198676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036594536357719185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03668198738126712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03670515261746963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03677630664214932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036722136587318446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03670502813595365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03672732840099047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03662985060913747\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03663307213858989\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03668960087383405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036746376824420675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036636329175252155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036543424410859095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03655015051852955\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036493249213775246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036545076740759554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03661349370006082\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03660495023598562\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03664037332215684\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03657076538259548\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036638656820459005\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03670815631735586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03668498159433254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03664905413191904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03662216862613671\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036745339493115564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03674432002388093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03667453178568175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036684318224772375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03664240599023523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036657110878387696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03659252545044741\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03659537765579589\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036639429114807345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03661758528828728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036663741612955505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036603601554491716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03657977363656625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03655459578874684\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036466828778955254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03655396873777986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036522863822412995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036540186663692145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036523603718111995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03657455588455754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03654550457868221\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008055276688188314 0.022848230456002056 0.0013316179839894175 0.037966086951084436 0.032055382560938595 0.0002302316203713417 0.03197740584961139\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6481,  0.5674, -0.8075], device='cuda:0') tensor([-0.8341,  0.2244,  0.3343], device='cuda:0') tensor([-0.9114,  0.3323,  0.3534], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0864], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03662436719424899\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03665357124012348\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036643845666895505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03670005220219834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0366985475807254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03672784442071218\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03671826661146302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03671229060645314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03685374845321926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03692238557950894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036959776498449816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036993820253368954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0369839371219023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036987640032326276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036952227455528966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03703627591214674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037007779933333526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03699097318314961\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03699633567188461\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03701120911565528\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03713517674270949\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037118079960093024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037165043160247054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03710647531164189\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03707955668774098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03707608263061114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03706659723762755\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03706760405838054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03704823362282836\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037078222617572446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03702903175526926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037031565127814844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03706061225649675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037014835935551674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0370646167617042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037038042895215166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036982966829335995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03701885688206899\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03709876494492255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037096804842511606\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037075558569586234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03707777334374185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0371108780088223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03707768279226329\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037079837781599304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03712497631491082\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037083055676837014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03705581699798768\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037071441316577664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03705629855135663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03702448610706599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0370418273392404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03700948305137905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0369801970742022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03698030481622552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036928628897853755\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036923453503055495\n",
      "Episode average V value: 0\n",
      "epoch 13:\n",
      "Learning rate: 0.00014121476824050002\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.26785714285714285 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.26785666454167045 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00824536505388096 0.023977584233041853 0.0012421465933148284 0.037836768329143525 0.03231557294726372 0.00021093744039535524 0.0338991198358126\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9653, -0.4566, -0.3937], device='cuda:0') tensor([-0.7782, -0.8968,  0.1997], device='cuda:0') tensor([-0.8455, -0.8727,  0.2638], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0083], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.042334536297453776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.043569543605877295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0414040322519011\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0372271006150792\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037096705411871274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03947828209924477\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0391233427863982\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03902968355557985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038957832415622694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041292235244893366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.041228902403904935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.04083785935546513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.040088092828662984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039811201223600955\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03917144131329325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03884189432978423\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039927015476707926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03989539844455359\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.039658413328535376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0392285890204625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0387567455717732\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.038344594546490245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03809600729261332\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0377502001658151\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03779638227903181\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03754210780557786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0376557294172024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037548591914985864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037735395411821616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03755990293359867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03792662463254399\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037658716888270445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037525339563211\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.037474319500106025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03736195553330675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0369500444776574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036639713706006785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036278502371608776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036112396756287905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03602416722181564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03626490486684813\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03599579900715047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0361719354854786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03630490396806801\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03620381651584197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036093901270316635\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0360995780128378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03597985514702655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03587763077450616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03572281298227608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03568946635898422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035451363959214374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03562985810859273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035931909962752716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035781481965548464\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007772950808517635 0.02326827131723985 0.0013433958925888874 0.035933592535555364 0.032488163951784374 0.0001943040117621422 0.0326706980089657\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3207, -0.5584,  0.6014], device='cuda:0') tensor([ 0.5967, -0.0381,  0.3267], device='cuda:0') tensor([ 0.4582, -0.0673,  0.3164], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0850], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03602951433553937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03590396723980502\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035899023846562565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0358140451865176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035719207334504635\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035853006787096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035719721731612974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035647495299893084\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03562217534312771\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035851399508169575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03587550938330114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035768600776915134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03566985537778903\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03547064201672368\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03559532523938706\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03584616460381236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035778060021528536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035736665976640616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035646214332381215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03554646666886078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03547154721049647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03531329823566485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03535174011873702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035272244524483146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03516389029423913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03528893244898634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03523299630622816\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.035148680261853665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035098899410244216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03529830596354954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03525745150998947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03514057175954507\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03518833379517545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03504418469930577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035138624432255273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03511010060400699\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035093172321181546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03516265994779045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03523545663629881\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03517787508415984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03521118859633269\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03507261270687052\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03497757706653893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0349824053316882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03489902700711456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0348631521211517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03492830623517499\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03495710334080516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03500629886566924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034959581816598535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03487236306863979\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03488124463985735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034918461376302896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03504525375752791\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03489430166047179\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03481666839544524\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008030026578577236 0.021558251990936698 0.0009556496708974009 0.03365834197308868 0.033299811545759436 0.00017363410443067552 0.034509423864539715\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2603,  0.1628, -0.9813], device='cuda:0') tensor([-0.8223, -0.4146, -0.5956], device='cuda:0') tensor([-0.9906,  0.1324, -0.5036], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1622], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.034698946036986034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03486425546020812\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03488832252457753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035027906470054736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0351413566609345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03514575257195126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03524349542753859\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03531592447583735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03532865523852201\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0353268421934088\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035322293800764966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0352706584861534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03533947343836241\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03542974220506019\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03538202151132179\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03544204349060032\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03540803019495797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0354647798945808\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03541283874581449\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03534420206629378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03537463232277507\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0352591225840836\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03521959752479188\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035147099794413696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03513226345268206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035120371087482206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03524380994041341\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035154776756750716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03515202849105533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035120103699415685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035042220417261474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03503376536365098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034992876588754974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0349247678318614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03502700590001224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03508340551405976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035126677518165124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035103393964105514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03506021212544982\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035002529913404676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03498267784016207\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034981146754768655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03495392390301056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03491074256432046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034861654679004386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0348502654600058\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03491680900652732\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03487794492998994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03491613371976807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03486411805053192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03482031640762767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03475977752571031\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034742754867343295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03473479924347214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03478164165318162\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007852159053552896 0.021981766807846723 0.0009907216461433562 0.034943349670618774 0.03302278449758887 0.00018904168903827667 0.03181674937345087\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3618, -0.9895,  0.8125], device='cuda:0') tensor([ 0.4250, -0.6616,  0.9865], device='cuda:0') tensor([ 0.4536, -0.7052,  1.0001], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0189], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.034820196880876564\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03479128095805497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03474147064319857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03467547675028589\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0346797131909066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03467042187501939\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034655696431601955\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03464999377262442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03473131462547278\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03474316573460737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0347803218593635\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034865303287403504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03486651324908105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03488037422713306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0348407781624022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03484561015659618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034835012759119904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03474910681249556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034832898462219195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03483981419362466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034814341717293966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03477504011546317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03475879257170375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03483926057570467\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03485823887654425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03482260814457226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03485021133605277\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03484764290500949\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03482568672807765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0347839004136812\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034764936746681685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03473083087186696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03475692536913811\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034789991615495335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03482981112328985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03481628316120584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03478351571088933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034803048040756394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034877205656987785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034833826911570394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034793285505273254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03470546741145026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03475004777976731\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034747441516814644\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03477157520722714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034808500822920516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034818632222360306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034813598249743956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03479971740880947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034733804224256364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03474668246997674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034797434395304465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03479422086647573\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03475118554855763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03477493618451557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034774865889856524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03478082124888897\n",
      "Episode average V value: 0\n",
      "epoch 14:\n",
      "Learning rate: 0.00012709329141645002\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.26785714285714285 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.26785666454167045 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007760879297507927 0.022658427195623516 0.0008555132929759566 0.03461392776761204 0.032820629492402074 0.0001760922074317932 0.03279511830676347\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3434, -0.9983,  0.8185], device='cuda:0') tensor([ 0.3881, -0.7638,  0.9684], device='cuda:0') tensor([ 0.3328, -0.7848,  0.9963], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0678], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.026971218797067802\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024169680817673605\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026361723775389017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028944031516503956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030378831488390764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030893561137081298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031235650640040163\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032067177034655794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031265626506259046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03147709203573565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0316721019993602\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03141490598122969\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03234473033609171\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03268830711391592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033145542680803275\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03386353792868451\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03333746793138143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034370235095582444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034345906007250675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0345755247787262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03390900356813319\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03400084806483879\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03402482016587963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03401449139454161\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03368830199042956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03382272620359038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0337910186269401\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033589788945391774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0336912934279419\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03405769618090104\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033955653965820336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03463997128225552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03472728913442956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03482848472795845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03474276607767457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03509450744101663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03530678079203443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035070376418944865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03521696265065177\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035281188822247914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03503204600981419\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03481080965508544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034754518200511\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03483869465575977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03472289668258142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034542794914124306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03439282922373631\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03429584935656749\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034107501663968746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033990292461175055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034273408833193166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03420339001672995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03406647893949656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03394956998201279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03414327141857057\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008164974498795345 0.022062528737355022 0.0008669896192295709 0.03400686615053564 0.03323810156807303 0.0001522251144051552 0.03083891994925216\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6810, -0.7317,  0.3127], device='cuda:0') tensor([-0.1665, -0.8130,  0.6103], device='cuda:0') tensor([-0.1745, -0.7682,  0.6176], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0879], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.034012371231617024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03393901484522816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033782881348290376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0336389247943663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033542323972236505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03367575795181055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033770391483053455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0339103007099445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034174386527512174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03437284837023188\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03434795388710444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034152567426011485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03425999661661027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03443188404502428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034442608656420834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034424135526306986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03434578350667531\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03422564144290224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03405945124342344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033902914622729576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03400415993685023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03405868649162879\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03408369456253352\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03413107994689741\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034243877941561446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03431612511698172\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03434292398844934\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03424630503430763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034279829697442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03427766855940028\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03431091903112059\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0343679575752681\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03423422317178167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034257086146781024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03437152574080284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034433889400068404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03456194269423629\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034604783508739696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03455191214533686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03445673595885174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03441114140689563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03436178690940568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03433621273262008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034290717111421724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034201130386338464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03424810293326267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03418245365130989\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034207775189713074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03419607047849279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034136635564247925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03411519048009185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034239602226837466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03418366718125135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034364958797846366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03433426353572445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034334236992759865\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007895840464159847 0.023040094485040755 0.0009304557139548705 0.03469367366749793 0.03325137344747782 0.00018552060425281524 0.031901296539232134\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3216,  0.8435, -0.5212], device='cuda:0') tensor([-0.6881,  0.7227,  0.3940], device='cuda:0') tensor([-0.6940,  0.6709,  0.4219], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0135], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03435845557592868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03430658657627589\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03433897165076891\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03438141796252002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03434477915444993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03440308567500918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03449624272505358\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03464075944444685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034621476991688487\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034553147478694486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03463130414346827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03460044259173491\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034478106094510914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034439169925947984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034465310870089964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03451094121043998\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03443925584482107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034431522552479096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03440679208152633\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034442665710637664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03447101021503798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034574479264975116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03468417874336626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03469073608739938\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0347024451129388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034708398592560905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03464799847539316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0346514671005392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03466067852430223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03458060716793317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03469509751745828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034684581973350434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03474064583546643\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034753708707318566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03473052829879661\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03480454825796891\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034873795398446664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034851025285770165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03472383417327095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03467586797760077\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03463798201723264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03461488786869741\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03455118883184788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03462359999076173\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03457218985022855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034677734008613875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03468480814934699\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03468017044570232\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03461338419874664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03462698996765057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03457912296121902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03450665969037195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03441657430680373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03453011189113914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0345271450908134\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007914548150729388 0.02279708283720538 0.000956305658648489 0.03475093433726579 0.03401712922006846 0.00016781383007764817 0.03250191360944882\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6974,  0.7076,  0.3727], device='cuda:0') tensor([-0.6301,  0.7173,  1.7044], device='cuda:0') tensor([ 0.0149, -1.1960,  0.2593], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-1.1264], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03447008624280037\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03444701186461355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03447772450114427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03452874938287815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034572380479628524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03459098062914789\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03450795017121815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03447047133732582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03450135863814799\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034533950953798444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0344821813186585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03448266979596448\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03451700443355685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034447994498524495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034443757035686626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034499147769589074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034483258568064855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03447448700280626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03445921718833728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03444058576119194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034396638009427154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034417953122854145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03439287111400761\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034342210905147136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03437748054636251\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03436037058445099\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0343412523780921\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034326403912525935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0343279020290323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03435288854772246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034371537748656984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034347951892234475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03430546804121683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03433697600512662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03430397609699746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0342901104262531\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03426609942220563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03427942059320359\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03424886683819861\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034289715737014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034327252645753384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03426008392448744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03420442782252322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03422856978239324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03423465710263768\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03422737628806273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03421480429709059\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034196340560918886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034240511454189396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034241734584458096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03417617275417271\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03421845383634534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03418107381428841\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034266029334758794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03423935978740356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03423232500892584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03423404062795453\n",
      "Episode average V value: 0\n",
      "epoch 15:\n",
      "Learning rate: 0.00011438396227480502\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.3392857142857143 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.33928510841944926 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007922683991258964 0.022789436696097256 0.001064121838848223 0.03347073719650507 0.034403461288660765 0.00017049486190080643 0.03039313012454659\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5312, -0.6734,  1.0010], device='cuda:0') tensor([ 9.1344e-01, -7.1114e-04,  8.2902e-01], device='cuda:0') tensor([ 0.9725, -0.0476,  0.8039], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0057], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.040429150892628565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03787394431937072\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.035830730054941445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036345845786854625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03417075457465318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03416587840938182\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03305518329291353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030904879942277655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03127886252017853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03190092706224985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03199733679907189\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032020887135769484\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031809057069257796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03218192464509417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031479429646774575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03197601869598859\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03187555972535431\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0319751106651017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03136276951528084\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03151649765463339\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03162263730964648\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031949910974939065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031890177077969206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03209385697954093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03199440273559756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03177072720315594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03187664715504205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031989177012638675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03198263877324788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03274984416655368\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032986726101127364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032633868211026616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032716525654286545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032740747557612124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032604423438804965\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032625639122726834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03248895494569395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03219035959377754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03242250720697039\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03255775581088124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03258605311097209\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03222960316103011\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03237091902600125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032420375902967695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03244243503697677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03238658306800765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03266378796723259\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03259224428243383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03258934103020059\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032807367249495456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03270989330789817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03280051340524139\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03298167970062739\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032988795544952154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03273746146622932\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007835611742921174 0.021908414972946048 0.0010421894782339223 0.03280075714737177 0.03520271010324359 0.00018371576070785523 0.030698943404015154\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4954, -0.0546, -0.4582], device='cuda:0') tensor([-0.5092, -0.3872,  0.2891], device='cuda:0') tensor([-0.4407, -0.4744,  0.2176], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0698], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.032991473171268666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03304637623061272\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03301824039112334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032831511069124256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03283196740818244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032996179607233715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03306336519325079\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03289902928848693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03274076532074509\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03256137454006662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03259515852952746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03262230783089328\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032807498569204625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03277073678787012\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03269574045617547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03279017864512236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03277347206905553\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03265227670915981\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032618301529744945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03257308568874443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032554465789233517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0328732479335458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032926150352861255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03281445973834387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032797458921171106\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03280141275307095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03285625422068021\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03291427979988845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03299603422810496\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03311584695163213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03317163071537376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0332210843087356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033274655450826904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03323961999883571\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033198454153413576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0332285425357375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03327604612517778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03342599972799919\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033443647691645345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03339843219363986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03348311266152585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03352749150167438\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033557257345241925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03347190417815522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03331033192419757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03321190315019032\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03319739924149267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03313106721761398\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033028991737215914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032997471883045464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033008978576682495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03299486173871955\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03304995739652388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03309589883105622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033077627264264255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03328177879925247\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007725331834284589 0.02381355007691309 0.001113188726696535 0.03379845859855413 0.03484546116739511 0.00019111960381269454 0.031485091465525326\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4473,  0.5191, -0.0708], device='cuda:0') tensor([ 0.0966,  0.5619, -0.3894], device='cuda:0') tensor([ 0.1112,  0.4089, -0.3341], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.1000], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03318302254820804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03322108648534253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0331884717412627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03318382490354316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033270193612688286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03318958979184896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03320672794415312\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03324002659263091\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033304463664104264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03330149739224693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03327576675705055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03332160369769856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03330609578252052\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033214049893948765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03312787574073678\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03311001513990935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03310963967588679\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03316014475998542\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03315478093349017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03306230393327627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03303064490348628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03294936181477885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033050741391815554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032965538367138475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0330121278613684\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03299744633711506\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03305094549132454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03302306370834986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03304577612332881\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03301522978842024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03292369914455383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03292779761302142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03291112301802194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0329228637240456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03300330042484666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03307305080837268\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03301925598657704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03294322684637808\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03294449689487616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03297213465318007\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032915854142374246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032978011590760734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03297754967905054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03295865743003759\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032941961790331535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03289460592889355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032911704199548426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03292220649859399\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03289036395015298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032937095437540816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0328656346824618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03283757816532902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03280276879807051\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032782301032031426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03277018533737824\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008127214940264822 0.020813913892023264 0.0006478578186652158 0.031606338910758494 0.035425382312387226 0.00015219400078058244 0.030676796330604703\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0976, -0.9179,  0.9170], device='cuda:0') tensor([ 0.7847, -0.4994,  0.9789], device='cuda:0') tensor([ 0.8203, -0.4066,  0.9949], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0334], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0327192838672432\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03273557116666799\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032747531945300994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03267302245839067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03268715246962389\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032628846209789855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032627240824049566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03263428588344277\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032619983867875166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03260632931616985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03264181987994584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03264175175739157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032630736992216344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03265090763603372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03265162973743026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03265753072391973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03270343514911392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03267081772260692\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032635772022958455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03264046820568248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032652325201082355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032596068270174215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032574392915941525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03251363374156692\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032518173414355644\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03250927342661372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03249686433186794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0325024467159515\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03251696473061826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03252181051327486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0325018082551282\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032487838397217514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03244324849509243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03249014586766458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032461072760878666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032429089854631214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03244421046727287\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03242658882532248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0323965252623174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03233422462397959\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032279631290039905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03238733498686547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03240729385730946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03242630335667402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03244135321118918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032424567987877816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03239413737693494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03236715721901166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0323429360568225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03233344077073716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032256899134141974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03226014607095622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03227891429575025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03222236340040002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032199159490839846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03221538973362973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032229547420633026\n",
      "Episode average V value: 0\n",
      "epoch 16:\n",
      "Learning rate: 0.00010294556604732453\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.26785714285714285 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.26785666454167045 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007812750316690653 0.02131611292017624 0.0008168869745713892 0.030772739857900886 0.035738267716020344 0.00013663721829652785 0.030370427457150073\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9397, 0.4071, 0.5093], device='cuda:0') tensor([ 0.9315,  0.8416, -0.1626], device='cuda:0') tensor([ 0.9247,  0.8342, -0.2197], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0127], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03382078082197242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033772457391023636\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032473209210568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03292630773244633\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031079386588599947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02977002822552566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029282677741277786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02968446160149243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03195953821004541\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0316180494096544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03195155329174466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032541711892311774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03227598415130479\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03201714146231848\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031870211129663165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03204374098115497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03272078581933492\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032621382344744085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03218863888681806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03170061476735605\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03216082737756469\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03172839121102835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03147440354659217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031085833592374844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03069667030953699\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030716599860730078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03058039620058772\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031003712218195673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031395069426960416\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031695693224254584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031795904748008245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03185830805968079\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03172620230978386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03183611618123608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03230507771765429\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03263514184818408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03301256141057601\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03270404744751708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03253962595461526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032703911632092464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03262772866673667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03265312869131329\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032632194091241025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03256026895086497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03259698471951264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032551586097061345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03274695531313195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03261290013216677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03262418251201646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032450564494356515\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03218691355055746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03208469494711608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03198697106850253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03193240307382626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031977390735927556\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008052761656697839 0.021905405150726438 0.0008916088789410423 0.03206540207844227 0.03610383277758956 0.00013758891820907592 0.03162248325673863\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6376,  0.4004,  0.5679], device='cuda:0') tensor([-0.3616,  0.5224,  1.5105], device='cuda:0') tensor([-0.0021, -1.2179,  0.2903], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.7492], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.032081632678108735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03247013669116078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03252148420649841\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032227712123007596\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03216611460385913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032152468928107095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032048196340727496\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03219502122507708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032260990561755735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032272061411864485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032301005760759664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0323136803558155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03216535819533092\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03207645510756763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03187866337996508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03169666134704237\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03152964318553446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03151915721025437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031663386021844216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03150426459050289\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03144404256637399\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03135399430691874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0315210067055472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03159763188063365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031580381057251035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031543741610146475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03175185478373171\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03168980418137179\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031644282443079326\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03166932271233474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03162806473121297\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031629131684058356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03159853338082838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03165364331890191\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031581107841482686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03151025450180065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031438157643452466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03147052782292844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03155332679825067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031615523282133524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03155261940372401\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03167020064540728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03170322532165804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03170737013059818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031693998684382274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031673051556726\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03167611897379274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0317026098352227\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031660136577681214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03157082984135264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031600931985401384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03157213733068291\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03161068954179255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03164542267985725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031612811077649544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031646079669060474\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007868724229279906 0.021984276509378106 0.0009055090083857067 0.031218668672256172 0.03674658162891865 0.0001501808688044548 0.03070216772146523\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9037, 0.3891, 0.5212], device='cuda:0') tensor([ 0.8937,  0.8221, -0.1421], device='cuda:0') tensor([ 0.8843,  0.8225, -0.1613], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0250], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03173012448112584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0316799821518911\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03166143155201079\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03173700792058078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031691113611776026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03166461382361955\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031732137006288304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03174161355347693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03180382145327274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03182779302216786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031728823166272735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031696828269814466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03175433867153675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03177943094737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03182315766545279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031857694614896986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03183628461637353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03185419992340807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03182013272188413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03183815663520869\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03185811846968577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031853151250142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031988624917346345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03212328394529996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03211829170517721\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032123402514119555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03204083009570501\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03195832445130622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031943436517631485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03196605444879185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032015387389330845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031983590746340405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032039763434663596\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031986839000592404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03193807810732083\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03193783974915585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031938674828938175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03190694310501673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031906366695960364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03188456394425247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031881741792704275\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031996540695472135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03195518964376102\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03195104024015821\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0319723501782254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03196531190765627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03199408081774083\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03200296431800688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03196339690799101\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03195688542392519\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03195509249191164\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03205683880790956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032008608436555196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03198143936794013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03201758649781187\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007887385497335345 0.023249747321009637 0.0010019064622028963 0.03271642659977078 0.03747167420387268 0.0001841302216053009 0.03145608199620619\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.6448, 0.5038, 0.3848], device='cuda:0') tensor([ 0.5172,  0.7665, -0.1092], device='cuda:0') tensor([ 0.4723,  0.6957, -0.1187], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.1907], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.032021404416266275\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.03201395767758152\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03198967940240785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03197244852872602\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031910563108666794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03192428875057561\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031980173383566075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031946981329908586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0319379484730344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03191676093418283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031945506448121434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03196600140520045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03194145212663323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031925346434438305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03189415346654995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03191226384555864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03190229307073007\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0318701376132937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03181727653084038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03182193781265916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031779745876439364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03177550694592579\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03184081973789423\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03186633755120705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031862220693316796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031781792082862616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0317379515156982\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03175620538985862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03168753066134673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03168355547949722\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03170963455027298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03169383242304043\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03164226061595361\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0316115240400864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031544720656725006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031540757210615805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03154431195541213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03148728977251709\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03142178321413716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03142694970683276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03146553719321279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03145711502342875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03147771955972289\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03142548326757692\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03143217655515721\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03139892817168366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031374986558942726\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03142162465885947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03139430304522354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031378174217421666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031433800793802716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031451994610169974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03148740940580342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031449814155377974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031445836659114434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0314335671614285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03142949986178428\n",
      "Episode average V value: 0\n",
      "epoch 17:\n",
      "Learning rate: 9.265100944259208e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.375 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.3749993303583386 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007789214394986629 0.02124295541131869 0.00072197189812141 0.02969062560237944 0.03793823310732841 0.000146383136510849 0.031010066841263326\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9789, -0.0353,  0.8768], device='cuda:0') tensor([1.0270, 0.5435, 0.2335], device='cuda:0') tensor([0.9985, 0.5043, 0.1102], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0743], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.028986403511630163\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027890608775325947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02742316851530362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029710179906234972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03156158206984401\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03066503973160353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029439308333195864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02913670348546778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02913652489789658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029763915048291286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03015341635116122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031063797573248546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03214074123618949\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03143265481210417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031739884249314114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03221827978915018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03187435878793788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032463209295392405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03253752996938096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03227678084125121\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03217263079233586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03260919214179269\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03229538372893264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03221787109591619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0319443436132537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03199578901259308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031637212771293804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031665466293426495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03136335315461131\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031455451050014405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03132504901738577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031092983867792\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030858982482968957\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030983920875644565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030840211633651974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030959613273426154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03096005816415355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030876353059007586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031036081750402254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03121143483246366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031457872753382375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03148055984269059\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03137658187007719\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03135004242872725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031398631452962206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031410197506924184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03160073256547217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03181192888533352\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032026193066671184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03185096802603867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03179181103791417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03177037820992116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03171015119051221\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03152960481375088\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03140162266226429\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007841531991027295 0.02247171954764053 0.0010464628511545017 0.03131848315894604 0.03921863782033324 0.00017535629868507385 0.031344753792509436\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2342,  0.9990, -0.5752], device='cuda:0') tensor([-0.3111,  0.9340, -0.4952], device='cuda:0') tensor([-0.3501,  0.9184, -0.5006], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0199], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.031388900357313336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031200025809772648\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03125795407998608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03145961708997827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031367599265649915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03139339173501035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03141329768297386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03135034695064002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031202065915244423\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031179700629451336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03127861674247868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031248482355035558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031332792030963924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03132617091175151\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03115159583588441\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031214587160142748\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03115346178665389\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031120933056490063\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03110562791410196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030994416945786387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03090102066236891\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030804555637366844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030840759078024797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03082332975963332\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030780577860099988\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030705275005100112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030751043018256503\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.030788697883327165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030669151045253903\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03061936280501434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030585548777893688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030568580390554812\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03060489547123775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0305245802522673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030458161806296787\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030413115608604838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030414335187839498\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03037101853629986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03033130632022101\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030381101304501817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0304744188637145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03044729423255821\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03036614383366001\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030280465365718847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030296803046431807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030282365675601695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030176507458212525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03014123704417045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03017331612829724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0300958890053961\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030051011281708877\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030212439430310843\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03022421701665615\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03018166369281018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030185070347906365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030113062712254824\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007763355462811887 0.02106085244845599 0.0008275849756464595 0.02889764691144228 0.03933627406880259 0.0001289372742176056 0.03098172781523317\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3930, -0.4668,  0.6108], device='cuda:0') tensor([ 0.5106, -0.0609,  0.3358], device='cuda:0') tensor([ 0.4380, -0.1496,  0.3140], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0369], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03007641063988327\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030049993931302102\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030071775035907244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030011037575161974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030112627349522723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030047198929111955\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03012129314429707\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03012543438866832\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03014797600141416\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030206307354045364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030233679469064124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03025684549364698\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03031880076720937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030343113300700983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03036132757757286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030384350711461856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030405114498636168\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030348574842946424\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03032321375436508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030276131834376656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03028935903090645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030233858851132386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030188942992994888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030089374454577027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03008876410632522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030144908358188102\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030112764051996904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030170396670883746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030164259639642543\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030124642385699743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030131351693893357\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03016114604558793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03018949148431995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03013543624830543\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030102771902499405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03011834131622756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03011553204693907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0301010629334428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03010067828827434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030157964463490304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030208173602457263\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030243040172392658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03022752906307363\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03024814707764481\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03017864083245057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030149345943982393\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030143762656399762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03017847657113861\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03015778997376199\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030139645563182726\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030100747399014232\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030053553653623204\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030074283610310074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030051102392494627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030010901865738893\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007857463074382395 0.021909221943933518 0.0008897984291106695 0.029842171135824172 0.04015693425014615 0.00014764655381441116 0.03115533386543393\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9670, -0.0033,  0.8725], device='cuda:0') tensor([0.9867, 0.4783, 0.2794], device='cuda:0') tensor([0.9325, 0.5570, 0.3653], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0322], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.03000710122965782\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.029988079316878358\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030099397597290738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03007950588035111\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030040925529484695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030015924406864798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02995577857108259\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02998265737502944\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030057645483119858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030016578837254348\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030065740142818553\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02999456105047439\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029963131984325805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0299291030786943\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02986720692240013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029847390297999304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029818584968753805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029860631913561957\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029825754393054335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029820099289822776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029772909276659997\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029727252845208756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029680955108076657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029677392476870085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029674840180166476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029664095851600264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029698625739763566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02964418223151726\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029571380367651157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02959402824412554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029636919169223962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029711831480867777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02968388307480311\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029658710730598413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02957887920312122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02956343775528521\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0295694213520866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02952251861174743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029494180571323206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029468924963636827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029491824520475888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02951591831304105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029470826720606965\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029474188149512484\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029488886230448166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029436588391199888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029378621428102124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029400703391453845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02941675342159774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029416229288546952\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029450169239547037\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02944025291174092\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029447078447905194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0294815249290703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029490212733703284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02946092951117555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029475541367079132\n",
      "Episode average V value: 0\n",
      "epoch 18:\n",
      "Learning rate: 8.338590849833288e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.26785714285714285 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.26785666454167045 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007712485017254949 0.02095035823667422 0.0008115412215702236 0.027785030333325265 0.04046663646399975 0.00012594097107648848 0.032193174713058395\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9687,  0.5130,  0.2267], device='cuda:0') tensor([-0.9114,  0.2940,  1.4250], device='cuda:0') tensor([-0.0123, -1.2346,  0.2615], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-1.0108], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.02713575152059396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026485209974149864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02713209701081117\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03242325668947564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.033847444587283664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0341798280434752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03487513245393833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03507708689560079\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.034994580736958686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03506626473325822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03421798650401108\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03326101346734773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03264773137166969\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03240336035008705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03235498973754821\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032692737036591604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03294499931869164\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032080212579235254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.032523851716422546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03204450745963388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0318837274043333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03174410472539338\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03146340235491882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031089865072216425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031237391494214534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03086117506186422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.031021410434548993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03077664835348962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030614330169255934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030536953759966075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030380235941526498\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030619483321465343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030480074533182966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0305098862070712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030799616769784027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030651167417405013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030585907953413757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030461064256640556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03034166289636722\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030450585677236734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03023253017809333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03039953312171357\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030373601834903393\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030248261771795123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030229372149448337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030305286450986412\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030204987333950984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030129713312446797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030165515789369338\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029997144091046517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02980041690170765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029587477665498026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02948182924265975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029475537620277867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029348093117916522\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007510639000684023 0.021143295207526534 0.0006941761755297194 0.029454535362310706 0.04090370006486774 0.00015541835129261018 0.030591470814310014\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3642, -0.9300, -0.6134], device='cuda:0') tensor([-0.2419, -1.5912, -0.5739], device='cuda:0') tensor([-0.0096, -1.2374,  0.2667], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.6822], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.029390557790138123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029228103508697152\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02932883169987307\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029455826933479916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029404148683641797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029477946836847426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029423094354569912\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029484362962345283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029475938438230917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02941131826617524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02942862630718284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029474088988555705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02960164018821434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029628790750043786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029618546102077713\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029659401020545262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029627834511403408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029601173157856164\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02946501111964116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02950651389029291\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029668534998319042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029796752813950847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029732979964093437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0296759820410932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02961289222714388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02959148321602243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029527104818098105\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.029578639701796743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0296029002459907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029634389202140905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02965604762476929\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02972379611212746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02974153279369189\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0298635968333866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029923869437181654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029849131261277147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02971021806459046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029629775206697493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02955577342911903\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029459294275386117\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029465373344094218\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029493951124010046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02943747119065754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02940803451524205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02945572566965388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02942727171028047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029509442086353865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02948356860346425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029407236648476724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02948360309527113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02950361932518519\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029438005019992837\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02939308206157935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029484310475530275\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029414001863092336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02941054578178802\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.0075980050484649835 0.022318525311071424 0.0005734629897488048 0.029475107472389937 0.040390657793730494 0.00013256824761629103 0.03078325772099197\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0008,  0.0231, -0.2350], device='cuda:0') tensor([-0.3452, -0.0900, -0.1805], device='cuda:0') tensor([-0.3185,  0.0556, -0.1389], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0455], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.02951084377404879\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029547687559026856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029527098422899085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029485807494498827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02948069423695819\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02952223228191619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029540927554068563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029537229983520413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029482814799390595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029444242934923006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029480404907138595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029469326257540795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029482496468814283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029562149157540667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029593625049660312\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02960118861976532\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02960928386285862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029613672631722935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029749641243097747\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029752467890871187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029727423557328055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029759751719950933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02972158835274144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029719697661820508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029759932318519727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02976528033674585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02981283012912541\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029786537258441357\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029684649166163233\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029643864144106566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0296932195002834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029721194012749075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029729359113484805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029784640872501322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029793072560634834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02977589399920592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02971983524165242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029641762226514413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029635343482648884\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029587891978034207\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029593522130778573\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029583605333686567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029542483243564465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02956890937568466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029555221652728836\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02960746984082549\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02960436505562876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029599125164474414\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029583270189404074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02970774408386155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029713977432320474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029744453539649034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029701821753997507\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029723034864322907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02971980728612966\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007753903753124177 0.022838533897884192 0.0007753796662582317 0.030142356301657857 0.04100207402184606 0.0001372816562652588 0.030097494279267268\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8340, -0.1004,  0.9945], device='cuda:0') tensor([0.8898, 0.4667, 0.5140], device='cuda:0') tensor([0.8635, 0.4560, 0.5063], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0571], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.02964958205449823\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.029603583512152667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02964338635931491\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029664702135826053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02970866201829124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029805991228896093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029804449795829652\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029793183153345323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029793831039634015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02976166583877527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029726640743420362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02976019549289353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02972037489638704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029688609215534397\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029609228661278134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029596722181897805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029538224376036894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029555762435224106\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02953546476402172\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029540626316586133\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029480448535538932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029439462972452632\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029418291700899882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029398340762903295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029376106051193934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02935764077496801\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029390064949597616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029375578565651046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029417998932482425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029363936207430382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02933697312838123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0293469596829257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029338020731246237\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02941470695219727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029410381175139007\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0293953117832021\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02938249754246893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029359548063776282\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029349223014754736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02937560814619667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029393202115562147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029362198224332996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02940413471017229\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029400715481972806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02934785766660453\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02931348624638237\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029310052669580384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029263844007339914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029296868467024822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029276671070833555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029238414072040114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02922391205827661\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02919175214087378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0291873341739046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029186230731819925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02916087749744164\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029145740452455358\n",
      "Episode average V value: 0\n",
      "epoch 19:\n",
      "Learning rate: 7.50473176484996e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.48214285714285715 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4821419961750068 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.0074989641895517704 0.021105594826396554 0.0005071264550933847 0.027522612187080086 0.04096897416934371 0.00010427308082580567 0.02976769925188273\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4196, -0.3830, -0.2162], device='cuda:0') tensor([-0.3112, -0.8265,  0.1800], device='cuda:0') tensor([ 0.0155, -0.9348, -0.2880], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1741], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.04850079471038447\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03734589756156007\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03356847187711133\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03514460836433702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03419463644838995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03206297289580107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03123113102028294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030949755429497197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03128052533914646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030232941535198028\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029787471818954053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.030191735209276278\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029667347080559812\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029323004186153412\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02892211011990353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028858622096271977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028812449656767783\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028256978874129278\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028697800610149114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028442530799657105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028211505324752244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027804268364126635\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0277095636834305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027267610233846225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027263100873678923\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02706499541234066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027698127202183745\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02780939835042412\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028183482171632208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028125943841964558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027930577003520557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027916325607091293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027808898042335554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027928156210596557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027835299572833472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027894011679979295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02793814312504442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027918549070722963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028149577936269026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027821067618464843\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027646552479818343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027951906089025435\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02817694299784549\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028132876982169246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027993877242422766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02803769892257085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027986774726354694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02794130699584019\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027762644959068824\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02776109990870787\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027652162729817277\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02769171780683737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02776024471656019\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027692592231395804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027874109882748486\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007774848558939993 0.02070514490827918 0.0008130708244716516 0.027851337602362036 0.04168085061013699 0.00012653402984142304 0.032091680262237784\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5916, -0.0566,  0.9449], device='cuda:0') tensor([0.6996, 0.6537, 0.5865], device='cuda:0') tensor([0.6928, 0.6345, 0.4182], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.1789], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.027847262718419117\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027719088009473293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02767772178818611\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027607719284147306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027474975423818385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027523122705817766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027471487437905645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027429795911867415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027386702085398913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027282057802041626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027373065271254892\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02741520832312814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027417307466213757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027421346912835386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027337841886938326\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02738929781494356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027277328763128383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027311327071262232\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027401173132815742\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02735959760223826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027295863403590144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02733473528195361\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027238563893819255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027236257435468387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02719531450097242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02705777456871501\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02706946084732669\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.027110684937342422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027172404417777976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027124269282311396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027248825974165624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027326816590657485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027310898734463587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02723502242395866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027155917050477898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027139504510631855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027111330750096894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027075346288902145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02711039878996023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02720403936392034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02714155248152868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027140944650479917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027216498255877505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027258327404323518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02722459283243451\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027157101530184184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027168668226251674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027157204000614863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02720614127579949\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027292010301438272\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027346840118540282\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02733649987135535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027448008558425455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027441852763067327\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027550250103678366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027546898832915723\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007751974541693926 0.02077977293357253 0.0008210067149921088 0.0272178312279284 0.041416948541998864 0.00011441024392843246 0.030278265321627258\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4766, -0.9950,  0.7350], device='cuda:0') tensor([ 0.2617, -0.6766,  0.9274], device='cuda:0') tensor([ 0.2861, -0.7115,  0.9733], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0346], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.027506617625014825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0275539202091807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027474703946192596\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027476275690655777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027509751679711186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027444750629542332\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027475716935544365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027426207225063656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02741009762113983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02734749293582526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027334256934846847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02732561124310355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027428767312982362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02738831060172783\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02744939357635271\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027386935270120073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027382044436510315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02745847417439537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027485278654350048\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027461293169658275\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02745799848892936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02748844513059621\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02752981295424574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027483858111402627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027518001276987537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02754700919560369\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027521626260461535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02751716690065025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027558001451608208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027541573597536582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027573632077840107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027549862600399853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027566442748295995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027585300471333937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027566461866406818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027555896496528356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027553406992910413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027597992312188117\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027631265849771876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027589168603449093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027620426706945228\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0275309746554047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02759393549209775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02762994801518791\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02759918982250632\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027641288760155754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02761372170147765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027660084730189927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027645456179096882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02769740952822856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027711443831078677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0276854281671137\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027688326109024042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02766435226042965\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0276425672848391\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007785387480165809 0.02155461377557367 0.0007708470639918232 0.027945364121347665 0.041548555940389635 0.00015947220474481582 0.03010333496518433\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9577,  0.6326, -0.6665], device='cuda:0') tensor([ 0.6165,  0.5892, -1.0131], device='cuda:0') tensor([ 0.6625,  0.5097, -0.9432], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0545], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.027668664610497926\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.027641010985010005\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027711427884444566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02765927457439354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027652090162406735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027629646358323268\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027618253549145787\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027538280642090667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027540158958189072\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02754862884481701\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027522616663962902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027537731079677684\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02755719210581379\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027527451419478488\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02754907201583388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027526706813349046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027523816135413968\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027570694747689105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027592791152374074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02754039664890755\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02755555370767212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02756008950869022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027607437409077284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027574474149661368\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027570421760062046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02758852975131487\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02757131549243954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027606595247047276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0276167036580755\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027613426315547505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027637487007131683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0275988185803869\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02761883805685332\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027655057448428125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027611383793730394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027661233110972183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027611149112797446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02758142482748048\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027555581108290893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027550042424292705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027524926572972112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02753563792644761\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02749281394845474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027516832147729854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02747141948978114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027420896865706694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027446582200453578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027391323998429244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027359974621831217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027351331710959152\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027312928569182198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027274759547788723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027272327360567148\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027252568953407157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02724480160847756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027245285413885215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02725151974824257\n",
      "Episode average V value: 0\n",
      "epoch 20:\n",
      "Learning rate: 6.754258588364964e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.48214285714285715 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4821419961750068 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.0078056097603403036 0.01990360063267872 0.0005874850427208003 0.02599232766311616 0.0416227497048676 0.0001231318339705467 0.028537324650678784\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1685,  0.4140, -0.9977], device='cuda:0') tensor([-0.4201,  0.2102, -1.0008], device='cuda:0') tensor([-0.5042,  0.5301, -0.9874], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0350], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.032817894799841776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.036538535729050636\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.03006297684516068\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027223360854097538\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02698815218690369\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025065197893935773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024807806208079295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02578747553181731\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027519738589080026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02685910744799508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026821812492503663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028211034843008274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027974842458517633\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028504880167366492\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02870061650734257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028394507774565782\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02855372470894865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029216627228177257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02945624568025794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02929862125052346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02929664861962751\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028997462111139537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028704443276108462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02907983324042073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02909548477994071\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029411183304002143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029338918748951743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029389085547466363\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029300271190874194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02904426027779226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028965306525055225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028927226246903755\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029002651498536973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028781272329426573\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028546594138005896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0286100925202194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02839012829273626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028428705116428914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028166567624156546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028323711906301063\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028335778187798855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028376961845126024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028122218109147494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02816880533396445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028110847371503895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028104779168801462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028109151447284306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028005464496177242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027851675440665004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028007260635495187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02797083368764334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028034941265439123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028032680961695856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027815274840581074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02791922331571278\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008061906285118312 0.020809887938667088 0.0007008925624832045 0.027923305394127965 0.041357802294194695 0.00013973868638277054 0.03061866946145892\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0453, -0.6116,  0.8032], device='cuda:0') tensor([ 0.5634, -0.1164,  0.8859], device='cuda:0') tensor([ 0.5825, -0.0951,  0.9797], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0135], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.02784997293363429\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02787200103515712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028010823462386814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027905332242014157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02792872444174632\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027960839681327343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028070609095276044\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028009063393416335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027881594625392206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02774426020984339\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027813902417956678\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027723949405659688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027798210797234883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02780583462619407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027675719522235413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02779540726667232\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02780326411996129\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02779957370143639\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02776591275474644\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027770353726766728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027813129675743436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02783008101618006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027718421297301763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027643899865574223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027594581900888846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027628879048778525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027616950052318373\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.02753737864397476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027392375154208844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027399685149221056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027432568044611073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027392677861083854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02735784523144383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02730978527553984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027336173886893154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027335784066541254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02735264360587504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02725447658638569\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0271695389959468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0272627008942702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027329202447651402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02747505471453856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027558387346384106\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027518059399321792\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027561035084331203\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027578340370486704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02756288653890925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027548596693429905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02751066564466868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027503913788804932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027464532239686704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027472115934150425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02751169116868649\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02750581265194579\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027477817986198146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027438650540709198\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007816799138206989 0.02111117207771167 0.0009106978168274509 0.02700061546638608 0.04145139733329415 0.00012148687243461608 0.031078176682349294\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7245,  0.7072,  0.5640], device='cuda:0') tensor([-0.6958,  1.0997,  1.7765], device='cuda:0') tensor([ 0.0040, -1.2552,  0.2425], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.9701], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.027412836433440033\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027432404170060053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02736273387875444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02735082093122357\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02738923598098715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02730074540578388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027296142141806513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027268528128277604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02723766932376074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0272210692782451\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027298494853259136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027343704319342823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02728219150221743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027255982564555276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027197249529380647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027123736042434825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027220439709102113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0273865859532002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027376551271026207\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027330055068214634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027344083661991186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02731950232197368\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027282634842677497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027283729641955086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027352486651092526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027369340876417972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027361763679480927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027347310242220032\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027275391232724936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02727769359937444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027374388671921733\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027352415842945572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027334540591569458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02738605880488952\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027380155495834314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02731565773016854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02729532272448657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027371810991553162\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027386628613565805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027391631130850035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027410101630910143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027398285127976017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02742341746445772\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027415889468858534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02744689894550907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02753153444984262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02747623956305107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027502350788693654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027536513197507398\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027536718000955442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027503361709260054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027489214188063132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027466621134760803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027477124953949793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027510361485071032\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007827817189972847 0.022388235822785645 0.0008834924622351536 0.027841884539462625 0.04153246002644301 0.0001242488771677017 0.03034446045290679\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4911,  0.9185, -0.8361], device='cuda:0') tensor([-0.0029,  0.8386, -0.9476], device='cuda:0') tensor([ 0.0158,  0.7246, -0.9992], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0426], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.027576136799666754\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.02757282199359021\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027554965738138523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02753161607474527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027523272063539564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02754623657459446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027563728473173763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027571268975294622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027611148607222333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027623135625323602\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02761127471243314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02759293271240298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027580533031267847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027584907350728265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0276173604409307\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027630509501345848\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027617203833678942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027600511432465634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027594817752247907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027585794212599258\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027586178804027826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02754391067970685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027554689132077932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02752604108298339\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02749083439644519\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027513874554305977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02753880426634015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02752528742050703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027540964222754594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027584239873505046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02758933995018865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02753813909006114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02751447338510007\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02750513355894428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027494392987657823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027501381008257747\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02749328151703101\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027451854527619522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027472722287817296\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027442081340115432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027432163794371498\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027428022526606567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027393385054467367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027360156737760735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027326514482941516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027335413240591373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027318570429112336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027287701891419918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027270966630130622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027270030187166953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02723906874891296\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027200527331591503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027195139616096552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027178450694514647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027170979615456347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027195684774009674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027183531106449662\n",
      "Episode average V value: 0\n",
      "epoch 21:\n",
      "Learning rate: 6.078832729528468e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.48214285714285715 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4821419961750068 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007754527796059847 0.020718806322664023 0.0006249187669309322 0.025971983700059355 0.04214115571975708 0.00010504913330078125 0.028148213751614092\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9015, 0.6786, 0.3459], device='cuda:0') tensor([ 0.8516,  1.0019, -0.2502], device='cuda:0') tensor([ 0.8614,  1.0007, -0.3431], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0019], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.021159143911467657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028783610608014796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027803239412605762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02756053098063502\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02599752572261625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026039404984287643\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026764433165746077\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0257446276049854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025886309344643428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025064408427311315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024616326177210518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025694046014298994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026091581648295253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026095642242580652\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026026818880604374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026294422775713935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026358527417471207\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026675881909919374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0269447916203685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027451994999622305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02747912377749801\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02786355930371116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028374295591732154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.029080758681865753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028922890602714486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028919122830574583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02891807295305371\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02858848819169142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02851115288284261\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02818572993942157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02810821400982024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02779738829283613\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027714644569702924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027440924987233446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027456540133922347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02735595470495568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027243576430668076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027131532001641322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027194151146724778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02720964199009662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027223541937657407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027214726099310808\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02714187058304901\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027194756387751737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026994189846524855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027028255320968475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02694434107745828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027306857134034444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02734563378152562\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02741259459302657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027535847691547183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027684113282399874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027590360803884967\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0276736080399312\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02758021696818748\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007950094131287187 0.02305853616213426 0.0009830210029467708 0.027847444421611727 0.04176893689110875 9.688346832990646e-05 0.0291277954922989\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2458, -0.7062,  0.9598], device='cuda:0') tensor([ 0.8003, -0.0341,  1.0004], device='cuda:0') tensor([0.8194, 0.0214, 0.9653], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0147], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.027779476474120563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027764471209667928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027674873991087937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02774730373679076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027646882759614123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027676510999491522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02760892594400059\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027616224215551554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027564652899551827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027407230782266867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027295775808745162\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027234859631750517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027174340550379913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027111974472836885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027229370491667872\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02712045775519477\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02714938537022214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027208912420218393\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027176031237328285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027156078974129978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027261254637725434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027130002642391737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027091603062813437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027113387659820826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027001319692418393\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02712977697129971\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02712725505843597\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.02715081911798382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027084720876590206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027043776842917686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027040527740647434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0269064344650094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026954427284466082\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026904129849330577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02683195857975034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026813083792262243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02670825288545538\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02670020912968628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02668007968068475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026680605759441155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026641141792491975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02666025611978421\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026664626467846283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02659676916161437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026566432530267373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02648346236936658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02653939419168338\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026547902362157934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026643085232776646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026682582129995344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026634524368429148\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026662032210354153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026790594182421794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02673424524753511\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02662181202933719\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02657900976848689\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.0077376597942784425 0.020726488380227236 0.000804368369630538 0.025281511668115854 0.04234947492927313 0.00012171921133995056 0.030014274298679082\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.4920, 0.6274, 0.0845], device='cuda:0') tensor([ 0.2630,  0.7927, -0.2858], device='cuda:0') tensor([ 0.1995,  0.8290, -0.2833], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0052], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.026559410892548926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026575364105150674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026582656230788395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026605202842971697\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02659339602310496\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02656978087549267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026576224366806293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026586391124352605\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026532035596082332\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02647847813597724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026528665156380183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026467587313401937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026402291984507633\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026374888443284564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026400442219567624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026357986260293505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026370221298647165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026329011295366196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026376599669615683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02644381056712708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026431650100887348\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026407525868838967\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026423325541291762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026420258668561777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026347025805092083\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026329379941926724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02629443067508403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026357210909040998\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026400060517462118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02644495755306337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026487476221928503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026514589934513586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02651345119186401\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02654849624197031\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026621290480454356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026570635887872333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02663665363011328\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026615162252946453\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026578626247743764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026571665922038648\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026570012812007066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02655081673523245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026507309082933146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026481519711594428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02649023654297567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02652046221498893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026490696840467648\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02646011468198783\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02649596097471658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02645487387827228\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02641671822682299\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026439380175900667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026406985231193142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026444289635753994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02638817642886476\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007935817804187536 0.021898771435488015 0.0007706466094823554 0.026121623075567185 0.04276296314969659 9.569620341062546e-05 0.02728761627105996\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2223,  0.6587, -0.2353], device='cuda:0') tensor([-0.6847,  0.5131,  0.5231], device='cuda:0') tensor([-0.6120,  0.6088,  0.5846], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.1851], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.026421530917039016\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.02647219012890543\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026454074547689145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026527417288009638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026494316690159045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026479225180975764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026483270887574975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026471801392976693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026431688524427868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026442511095383175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02644721512628365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026484375979435093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02650187724668239\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02649136043418153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026506189924668796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026496895795326422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026458850014235532\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02646742869592564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026447081304918806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026456013910768367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026435489388624347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026430121878377795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02640789357243409\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0263554872383979\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02639534729606038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02644681142151563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02642692214443156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026411592458424938\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026395795859417686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02634562514648433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026310651710711827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026320408701512015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026337738260148392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02633089723220716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026331866175479952\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026347763844580277\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02636980576890296\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026334653566905942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026278908844522345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026240236083188265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02620435446066861\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026186950630647663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02617109665852129\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02615916921643826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02613184158996791\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02609853695324413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02605880821977796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026071619621051527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026054453595182846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026019388090947514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026024111411860906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02599553331551422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025953480100872506\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025935288377792923\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025921117574072037\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02588618800414165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025880319225834683\n",
      "Episode average V value: 0\n",
      "epoch 22:\n",
      "Learning rate: 5.4709494565756215e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.44642857142857145 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4464277742361174 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007851274451240897 0.020782500147353857 0.0005794896907464135 0.024276261110790075 0.043238739464432 9.32309478521347e-05 0.029522929618833585\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9685,  0.5556,  0.5875], device='cuda:0') tensor([-0.8657,  0.8142,  1.6806], device='cuda:0') tensor([-0.0045, -1.2656,  0.2179], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-1.1003], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.022864932090871863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0242654239344928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022634177296249954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022974468224371474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02306730683065123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0238679272674576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025181259841672958\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02432928473636922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024791842292028445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024975811917748718\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025086032160830617\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025057802899499184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025135192120622877\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02532400334593914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024860836610335994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02477496094393751\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024806159508895444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024873281004091287\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02459584379416199\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024216661511713432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02397579977919579\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023977381485335604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024487754498756883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024771505063485907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024603736663444176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025079529626995452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025043498113398812\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02559023288573833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025740379612122118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025952590337988954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025759543350640696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025901209790996898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025817995262253868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025653517660471838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025524587800637596\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02566242446680266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02547176562210506\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02557527958633302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02567635853496245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025648604297182628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025750144210651638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02556277705336768\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025580113152046845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02540806122712151\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025489207305428054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025483813542863668\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02542694306318113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025395668033053407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02537750528255254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02526332881819043\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025361034492627273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025544511505529985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025519062916258158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025579596112708373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02554320353224422\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007975242787506432 0.021354591212701054 0.0006458003490988631 0.02555916552990675 0.042764752279967067 9.1267392039299e-05 0.02917320422688499\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2089,  0.9656, -0.4036], device='cuda:0') tensor([-0.2939,  0.9342, -0.3501], device='cuda:0') tensor([-0.3183,  0.8421, -0.3054], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0089], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.025574461272400286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02549393696176727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025399461509909665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025570144490979038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02548551821253366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025437692287149\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025408332218586276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025527490169052987\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025507680353055347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025594706994951026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02555905425096376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02560793094809598\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02556317534945978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02557700924836279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025603815075749208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02560388960792495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025556066877605324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025572487958983335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025691704509231646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02563443317388495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02562081088224829\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02553442693590946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02540207899008424\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02549277206440096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025413516909530802\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025401911732136427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025348879022745865\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.02537030797424306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025433425049336933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025364103537125916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025363581169646918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02547981234869205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025396210986960942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025507010381724617\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025450290571093374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02537357178829401\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0254322498196574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025453528521188592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02538127775180724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02531449901245055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02536993889036778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025333698205799206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025306924182368344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02533964572660416\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02534241465644704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025308261151098705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02525034492068431\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025288216804858488\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025221455626340948\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02518045102793073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025176716443205904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025166407944141333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025165476867883108\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02514451216036695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025197635056695554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02526731932306433\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007861400345806032 0.02142574778199196 0.0007844571390014607 0.025049348339438438 0.043733601674437524 0.00010872214287519455 0.02815701205446385\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3763, -0.9867, -0.6323], device='cuda:0') tensor([-0.1800, -1.3693, -0.4818], device='cuda:0') tensor([-3.7099e-04, -1.2676e+00,  1.9611e-01], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.4908], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.025239531775855178\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025201101343247274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025178233724356163\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02528555676035115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02524730003299727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025340236850783356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025391600741048934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02538149921792228\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025350869311606166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025375459740011926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025371833594146104\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025416389752142367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02540490622915942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02539160983512799\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025346002746800475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025286998493842982\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025255348712865573\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025328345727544475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02528541166510465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025318677313594214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025306607384911993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02527500980641808\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025233727896811557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025179863369299307\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025205437311586115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02519228974537016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02520121323040742\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025263748876154898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025204115743113178\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02522795847004281\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025241959469133466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02525492830935753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025185694891447775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02521315881861124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02522911972336505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025204519872171403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02522889756130519\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025237046274523917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025255060767823898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025240033114571576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025331122020520923\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02534043256426061\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025295978627056098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02524587757030909\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025271651847155345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02526485481611219\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025248515594858054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02517888145156824\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0251507153181592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025128775366547913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02510882826235825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02507381398553294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025038435317570884\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02503730106396406\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025051587221363542\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007848694547545165 0.020858179716393352 0.0007144677265314385 0.024468790389597418 0.0438381952829659 9.091424942016602e-05 0.02846966204699129\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.9995, 0.2841, 0.5177], device='cuda:0') tensor([ 0.9883,  0.6071, -0.0939], device='cuda:0') tensor([0.9852, 0.7369, 0.0152], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1393], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.02500798272902142\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.024983251672767832\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024941648421827448\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024925311322451807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024905366812789688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02488525074519198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024860567382764723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024908942462445866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024942750308721784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024951568756468895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02492360785084368\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02496584357993768\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024945966114910362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02495590222735004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024929074104303613\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0248961372386837\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024945829206434122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024897459950376805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024881691949067263\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02489673671882328\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02487006139113118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0248065702669459\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024807570864069223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024781899997822897\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0248537110798646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02481994938743473\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02482917486482488\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02485028819425324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024892606922661476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024910029867566835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02488915641459616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024887670722071972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024895809443656092\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02485748327130245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02487854923638003\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024885271721733663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024830556016611105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02488583477831817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02487620324234612\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02489780324024973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024889274664529136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024919342758327037\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024941024509868064\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02489381384069997\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024948930748154248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024936302664369518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024905402409850418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024876057201037076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024860206743322063\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024830702658974538\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024800705448788707\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024781170794569433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02476800975136039\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02473965046875593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02474709534867774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02476436198592089\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024754730633227154\n",
      "Episode average V value: 0\n",
      "epoch 23:\n",
      "Learning rate: 4.923854510918059e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.44642857142857145 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4464277742361174 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007922324264422059 0.021172006917651743 0.000711908863435383 0.023990303899161517 0.044399392187595366 0.00010223972797393799 0.028547005439177157\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6467, -0.2346, -0.4542], device='cuda:0') tensor([-0.6586, -0.6136,  0.3809], device='cuda:0') tensor([-0.5850, -0.7627,  0.3908], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0363], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.023330495589309268\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024108294035411544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02662941709988647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026996067414681118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02635945017553038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02532467246055603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026913267368125538\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02768412899846832\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.028009004821931874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.027296623711784682\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02717941649483912\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02669543130495758\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02611973412080198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026320494667050384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.026288280401516845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025520248422657862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02493808234073952\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02510198683443445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025068003466429067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.025016069319099186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02489373095767208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02489242045622733\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024857945578253788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02450661735902368\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02441808957192633\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024225470785083424\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024208042609654826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0242978890559503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024112191069086165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02400996683303405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02387955164917374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02410294028878626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02443893199868074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02434722430322295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024183099985950522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023941886732009827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023809552410835617\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023916659405596598\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024078112947316762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023894542155580387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023948124317114107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02409196202520025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024032009284202134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02408971841625794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024114880531474397\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024027967438605673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024123789595074545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02405416185501963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024081845130019583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023996735842277607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02379086586669055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023908945276107416\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023827915913591347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023807279137059004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023892079508214287\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.0079235447072424 0.020868923803325744 0.0006168392047984526 0.02384366627782583 0.04565261670202017 9.077952802181244e-05 0.027540891188196838\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.7294, 0.6702, 0.4663], device='cuda:0') tensor([ 0.6623,  1.0420, -0.0676], device='cuda:0') tensor([ 0.6186,  0.9606, -0.1215], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0417], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.023901403066702187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023841454017522506\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023828083870511402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023834616144007097\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02381270061660972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023747540053611245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023661681839789006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02358370818973008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023537844898075692\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023626955710033065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023564625572983916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023693123460897116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023734342835667038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02376842882031284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02373956042223625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023705401344163598\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023708393373296676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023546729759912784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023504892046711554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02362513418274897\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02384302655795905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02396085597225297\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023958517646448862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023913675642136156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023955727845249283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02404284901822443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02409012934134965\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.024139399943845858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024168826090837165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024129576202530683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024136720918893854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02412206379192409\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024140354773297793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024122750008136927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024053496748415962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024048010022089485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02396701546419628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023993789705168567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023937707625430772\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023868686257594685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023941799710478842\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02390934423173331\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023834749571070953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023827123210590863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02389327839999977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023886445515796263\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023813349943027744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02390094737129481\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023960604588600654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02393662176444811\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02392774870261878\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024025999957856144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024011576480669095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02399892842342031\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023980636777111677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023916243544282827\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008112074572592973 0.02173844392108731 0.0004833155260857893 0.024001233047805725 0.044732890509068965 9.664887189865112e-05 0.027712119952542708\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5420,  0.6126, -0.9588], device='cuda:0') tensor([ 0.0813,  0.4872, -1.1085], device='cuda:0') tensor([ 0.1190,  0.3740, -0.9948], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0561], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.023945810537072017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023987611839520282\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023949076757869787\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024008197926326795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024067672146609147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024187414880827818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02410945892833847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02405826315365516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02405117211854775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024025810622893225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024000870866721365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02402658349108338\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024028809013856595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023977740950468514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023998315574607864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024051708488277798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024089046290302778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024110159372652557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024136056183861235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024188139003111432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024207780330899716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024243524621350498\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02424394853403838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024258580086407838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02427893994662156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024323341210840295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02433860109783049\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024338841338535484\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02432395336144264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024390012533693824\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024368965668175282\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024406928900504818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02433111960352916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024346271598304825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024335997748292156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024324971601755577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02426284702785604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024228843684620062\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024203047289478558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024217470187208642\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0241891527888828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024200963129653995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02418888398361477\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024185718413055158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024165770089375836\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0241636939614389\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024213475868781784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024216153323103673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024239469714747327\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024247205712086297\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02422743499954838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02425642599825936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02427975982736776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024287226319827316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024284029388525977\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00782503178762272 0.022460259507410228 0.0007568879889586242 0.024938795564696192 0.044844780042767526 0.0001142323836684227 0.02733833068748936\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8261, -0.9720,  0.1767], device='cuda:0') tensor([-0.2539, -0.8546,  0.5467], device='cuda:0') tensor([-0.2684, -0.8468,  0.4222], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0031], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.02427665204775141\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.024256092693013626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024218991831714075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024281216704353594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02425057938851324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0242519802865103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024206131325248695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024238779732308053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024205195734661723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024188977581827496\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02420471169958353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024190603063317405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02414679410477174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02418305450607735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024181577087448027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024161792462305036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024167938891042795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02415651420118953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024167303061084795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024146291944715712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024115036490173547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02408805868233913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024090263685939733\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02414729008614494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02413012304707902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02413148570539542\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02412028577329916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02414661771799187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02412797304326695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024114338434016218\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024077714149810234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024162792426656293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024162625460269264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024165190930167835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024167470867715205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02418061932323478\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024161777083395477\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02416364592347854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024125642400123885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024201351211395238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024188920832526536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024177537340487745\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02417939024294614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024139459385344432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02413774139344449\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02415788140337313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024132111061210892\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024132927655322652\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024139860289734465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024133995897807334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024119963444563377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02410978923345727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024081362262538306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024106507082799017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024098574395524222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024072283600178268\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024090372644364835\n",
      "Episode average V value: 0\n",
      "epoch 24:\n",
      "Learning rate: 4.431469059826253e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.44642857142857145 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4464277742361174 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008024945446290076 0.021127170080319047 0.0007442153732699808 0.023527615898288785 0.04485565524920821 0.00011086306720972062 0.027277528257109225\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.8883, 0.7016, 0.3055], device='cuda:0') tensor([ 0.8196,  1.0051, -0.2414], device='cuda:0') tensor([ 0.8130,  0.9941, -0.2708], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0099], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.020905502864884004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022508102831327252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.024060461670160294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022386735667371087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02407667123609119\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02261005264396469\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02227102608848659\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02248522239581992\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02238071640309544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023224284877586696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023335103843963208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02317166571608848\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0227120102614037\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022297817496730696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022752276559670766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02245109489498039\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02194609441885761\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02171391298143584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0213833490266786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021418218992443547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021688415693542944\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0219264386710946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021846949860705556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02214200258323992\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02203896676086717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022015669781109717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02186975663780798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022009521257132292\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022376194032501445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022387285978981743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022295389264341322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022103535559532855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02214368613223586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022041346861073882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02198921162487259\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02200780689779577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021969755038943467\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02173612607174624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02159457403683552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021568359236698597\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021551427096986594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02159701795662167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02176854789175228\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02173615281700599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021692611963522655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02176997367999008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021838707496009187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022097375074668822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02200232422435466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021956768194213508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02222547766271662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022369163436218142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022379011833411594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022505204982810306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022496436438476198\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008066252773627639 0.01980886666616425 0.0008212088402869995 0.022548174446448684 0.045707277227193116 8.867797255516053e-05 0.028458697699476034\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4215, -0.3122,  0.8221], device='cuda:0') tensor([0.5693, 0.2569, 0.5960], device='cuda:0') tensor([0.5449, 0.1139, 0.5053], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0153], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.022545886325782964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02273326741121201\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022787097267007235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02281534678448279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02288985098367212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0228115059045196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022766997098028124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022877104447356293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02293298796414294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02287156674055717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02290448310913562\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023065922085263736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023002162738551015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023011688399466053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023015097210863752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023068352803552933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02303960020395203\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023080414205738534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02319701998242857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023198519075220383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02313030021856076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02317360012280025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023338323299165423\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02325419503501217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02325537960859947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023308376313426082\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023285687529433993\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.023246285072347047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023346930921506432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023417101982445305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023374025814009\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023385508777514233\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023441851030296713\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023443284826457834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023383942428677355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023341948847071484\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02336717110097966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02332143160584633\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023275338608141873\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023247047127578517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023282106504969608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023261398969395226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023188013006360725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02324997113106143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02325534130808794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023185587031674563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023145189813656777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023088602036209587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02301432409385442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02299934680322333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023005731066540507\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02296687654332719\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023017685941359174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023005730365227364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023056124818671232\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023018986267318298\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008058418503962456 0.020429915559478103 0.0009171191798086511 0.02348806148953736 0.04576168024912477 8.887666463851929e-05 0.02875080447923392\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4857,  0.7770, -0.9159], device='cuda:0') tensor([-0.0156,  0.7235, -0.9808], device='cuda:0') tensor([-0.0347,  0.8157, -0.9774], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0217], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.023025726615857806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023026070273650723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023041358908373305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023051198443244908\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02309375869153046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02309130385680812\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023078807235016662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02312088266352451\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02307281320379978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023117597451770493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023086971214858778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02308889960343491\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023058892201004703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023084183706177607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023068538177068585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023148693615278965\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02319675484775669\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023240217706389104\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023208427702227974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02320898023447412\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02320290569871388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02317734676395343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02319572300064821\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02323895103026013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02329102505699981\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02339949982772549\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023381191518400676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023347599276651938\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023331913571908242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023325949516499647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023289292704981514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023241772054800967\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02322002262183189\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023365328223640777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02335300557265736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02336555702797646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023336115537921677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02325142424457792\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023201247624432045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023181487141743114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0231506953826746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023106329428801718\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0230733538022961\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023059013526966814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023028074352115797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02300895506487098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023044685531556922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02303578112838018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02309866678131382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023127906954171763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023111641263609702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02308720982415778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023141359976306054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023129219741494667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023101138666339487\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007960838815197348 0.021171721146907657 0.0005739914559526369 0.02324038017820567 0.04626004469767213 7.865184545516968e-05 0.028008417588425802\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9189,  0.4756, -0.8202], device='cuda:0') tensor([ 0.5509,  0.4345, -1.0711], device='cuda:0') tensor([ 0.5229,  0.5988, -0.9627], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0017], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.023100342004512223\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.023114382747927847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023148366920270374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02319761736385427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023237453010828853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023226269813511974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023195925654093365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023198826261409494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023167948469460485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023204391670232225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023200146714488497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023243183440141632\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023232570769291888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023229301814852214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023191897608762856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02319234817218313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023182362232370836\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023166388541781727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023141619967794545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023216967630893294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023209868585253694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02320118713490973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023216280514874805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0231778969348283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023175535143589804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02324189386665778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023210806961111816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023219740077723053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02326734057173897\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023287685761965236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023253846841875318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023255245751721155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023250572639764485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02325895031939985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02323723703312892\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023284203703571583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02330837072294815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02335566890954541\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023336735778919808\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023311152754094303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02331511270713763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02338515768950988\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023355333826958674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02333164525701216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02332988946947253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023298056860624243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023286008772070543\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023268172672397513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02323745824083763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023250794784815544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0232607126595997\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02326452216607206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023251743348129187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0232363768131237\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02321463276956618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023247209974462998\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02323591623757966\n",
      "Episode average V value: 0\n",
      "epoch 25:\n",
      "Learning rate: 3.988322153843628e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.48214285714285715 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4821419961750068 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008226553916931152 0.021970498587703332 0.0005168477444385644 0.023673770532011987 0.046061200857162476 0.00010197731107473374 0.028397173604927956\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8316, -0.9947,  0.1338], device='cuda:0') tensor([-0.2614, -0.8797,  0.5065], device='cuda:0') tensor([-0.2757, -0.8603,  0.3187], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0096], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.021815483458340168\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02049742690804932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022037552911098355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020982832440899477\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020476221479475497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019813811009818758\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02050115116354492\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021647836754305497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021317676215628047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0214719261870616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021172165790704463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021743446342750557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022198623933821406\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02179323082479338\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02186840699157781\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021859506911520537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021749090375926566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02184160730663549\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022176157282828762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022141766907750732\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02188176558003145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021976859969641976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021641480279771457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021527513652539777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021636077829947073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021531676286513098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02153989775182963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02163387195480662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021863584697489193\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021886847873597785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02176429129516085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02173603377337309\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021646933484295704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021373632106796103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021460355085039896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021713026199938246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021922078533182003\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021862496133098566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021723432876328882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021594362962059677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021862760095334634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021861034704165325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02197551782043213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022040465977184023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02212070579767043\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022118606342560642\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022224389284135813\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022072472568618617\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022141648473349016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02208905460933844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021994244558878714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022128985886278953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022000327132314257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021918429642409823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021856852381894686\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007985712591558695 0.019943111838307232 0.0006993616444960936 0.021935196546837687 0.04652708719670773 7.833494991064072e-05 0.02783367298869416\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0554,  0.0641, -0.2319], device='cuda:0') tensor([-0.3706, -0.1740, -0.2304], device='cuda:0') tensor([-0.2983, -0.3572, -0.2340], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0444], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.02193169562249548\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02181411283108865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021873427185647446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021887100945365407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021816645879988317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02183990485844065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0218425691394823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021750959598934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02176151947706886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021677816356731276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021680185434907073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021675050448607746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021616912445394335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021547857677974947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021624594781961708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02167957603890618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021626787157413077\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021662434223540344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02175702292307115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02164427810727998\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021688045705777554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021695443756292437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021659801186107504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0216467323399944\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021623492173643576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021709346780949497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021717916678783655\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.021663154638091844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02173694445463341\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021702238103508756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021675178074237026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02180122185943322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02178028359893954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02181293700674035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021797122588427163\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02179056788557033\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021904542228962848\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021952482540129263\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021865530082643313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02179306017953837\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021698025138768437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021745667705911916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02171613055634019\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021739867996679478\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021737296116641824\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02174820735890775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021742524803374654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021849035176909663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02177055638520302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02173186080609128\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02165887447999521\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021698118093677894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02167987607567046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02169558548802371\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021700520850623947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02170195306760368\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007949113462120294 0.019810693304985763 0.000839623696214403 0.021535135283134877 0.046832100067287684 9.888977557420731e-05 0.027832384646870195\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3222,  0.0544, -0.9903], device='cuda:0') tensor([-0.7958, -0.3504, -0.5084], device='cuda:0') tensor([-1.0024,  0.1060, -0.5293], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0596], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.021708321335840053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021740120000891833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021696645372999254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021708046497804098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021697120780706892\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02165669697254599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0216906490712032\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021704718832754426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021708284926824962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021763266447787852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02184851215736693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021851081060802576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02187182353500704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021928744080579942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021933933689194933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02194146312771598\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021968336189375905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021970257764276274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021910458354231638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02190834613109325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021945450456126246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021914650303674996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021898325125317693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021932940407744284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021937070029035964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021904914600235338\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021879008261414902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021879836725224432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021892289543480034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021887301780368584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02193845766275853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021894215834460915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021902909463222632\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02196596945917869\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021979216856547436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021961630559621418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022006388757498125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02196652627092391\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021970048789624816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021968280467546713\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021975408016148498\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02198013891624902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021947854734059493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021944539780364668\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02198654797625996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021989354743804816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021959160605862046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02204839610589042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022098179836757482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022075541103432267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022199499876262678\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022194700409552234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022177151392963602\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02221383427078475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022200889028284643\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008151210847310722 0.021485738669987767 0.0007066593483323232 0.023070177721790968 0.046156662978231906 8.881908655166626e-05 0.027719249612186105\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0903,  0.3491, -0.9917], device='cuda:0') tensor([-0.3940,  0.1082, -1.0228], device='cuda:0') tensor([-0.3328,  0.0744, -0.9914], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0071], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.02217485976770411\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.022212022662325394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022191337701043434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022197049598702612\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022272768695164008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022232705854464237\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022233720863741622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02226219991296958\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022266749673715187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02228638441613499\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022311078612233717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02228631083702392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02225889014149539\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022255506569715103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022239893946700607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022239054960024717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022256052459386003\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02222974622843715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022255490557220696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022240115433381683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022237056093506263\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022268068984956712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0222421274249437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022252275886787482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02226140082246554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0222507835203066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022227609902191383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022214590321121074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022196256886488436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022169506893484788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022136963244939398\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0221399710880536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022145808946355837\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02217095256679588\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022168874892989465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022133095760095138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022124179536971194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02212185173169639\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022081965586640002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022099622451432026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022075920811665838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022042022900592186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022032965720046444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022052137118335518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022022817069797012\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02207444668164188\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022062083987672666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022059819539104658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022036967071697347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022026350821244794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02201298362464838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02200967754927064\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022005455551776736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022014846920266257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022018551360464586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02203631989489607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022034318636055105\n",
      "Episode average V value: 0\n",
      "epoch 26:\n",
      "Learning rate: 3.589489938459265e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.48214285714285715 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4821419961750068 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008107544388156385 0.02023361509409733 0.0006904037130370852 0.02158341727545485 0.047316059842705725 8.880425244569778e-05 0.027309414835646747\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.8755, 0.6569, 0.3425], device='cuda:0') tensor([ 0.7720,  0.8867, -0.1408], device='cuda:0') tensor([ 0.7488,  0.9327, -0.2037], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0606], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01549616621600257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02063066020814909\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019743132491216616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019707260666311614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020757005001521774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02039426748847796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020911350144102933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020329623903510056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02044165164899127\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02095151669345796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021101604041765736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021360718718453967\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020945435875437707\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021092219610831568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02150343303327207\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02134959441739031\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021126162601647035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02113105477420268\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02168409983839905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022279206632326045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022295290279009984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022601670881902628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022316042117882465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022293617974759802\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02243507694866922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022419937733067278\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02265517321633704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022850681284797333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022948833478621825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02273574987495387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022739587658782586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022619853423546173\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022515046143722454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02256435053910013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022524205763779934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022505620859540356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022495870244921418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02251796168002861\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02256243714022628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022446239239070565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022530551922828122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02265411950081153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022504601372497334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02239184084023829\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02230715188830171\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022151063302090924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022076807883138774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022266200896680216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02235441168985602\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0223676602780405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022429142209187895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022446545857824702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022454459354890592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022507397806724158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022615596014216092\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008036704181227834 0.02210903357202187 0.0005872684873102117 0.02260354412905872 0.04685039626061916 8.255736529827118e-05 0.027588194085285067\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.5267, 0.7309, 0.0895], device='cuda:0') tensor([ 0.2354,  0.7923, -0.1769], device='cuda:0') tensor([ 0.1708,  0.6632, -0.2196], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0800], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.02253719593494362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022563747913698296\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022517619116617173\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02268289358893553\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02259915473577739\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022647047311047223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02261749384540891\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02253710629740431\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022533638912945107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022497856829506464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02247182619663877\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022547686769847895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022495589394037143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02253346883762334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022527358082256147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022542293689247216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02244790935282377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022386764286757878\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022387225481516518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02228721895703563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02233121887513856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022216521769299738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022247231739209672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022189149056704067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022184928784716045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022205187755142464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02217429410918618\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.02220123001764537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022134835165358645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02205810528126807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022073068085682483\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0221209902272323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022083462193617693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02210554987606075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022053322726055796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021982597762557322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021890417584960443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02187421198115376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021912132901740624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021896074409460464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021920451894402504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021845567987470078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021829915246155424\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0217609484397778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021724766060813434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021694910641333418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021724399374513877\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021688836670411347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021759138629138947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021759690574454094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021797530940271117\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021833784084743894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021887607029792488\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02188415322253418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021925466951697763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021916922578053014\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008253917879890651 0.020873284310568126 0.0005818469219957479 0.021259753761813046 0.04697814025729895 6.796689331531524e-05 0.027589444171171637\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5882,  0.5832, -0.9447], device='cuda:0') tensor([-1.0134,  0.3566,  0.1588], device='cuda:0') tensor([-0.9983,  0.6656,  0.4125], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0754], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0218775611262702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02184450823581075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021876344892521323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021871970089575376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021821715461778888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021809120792081863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021807420263487826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02178147919241245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02173870625966056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0217658253604695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02179777171193047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021790692689151327\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02183933753819008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02187757616614302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021902493328082737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02187708769220132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021825043268310966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021813387501644712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02184335623597169\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021836233938680023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021937534131144208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021929870116070796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021851610523613035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021865030966791106\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021824695704066577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02179602491015996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021823575979266645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021803678080013735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021818044404351405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021832326099414517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021789731409368636\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02180213800203793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02175184706891427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021748400205867616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021715083227902537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02170208461430608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021667599805292335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02166792384913437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02166557775258466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02169875671019376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021709975152690377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021714001074947347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021706013968496612\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021682330883879174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02169769294719156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02163746701362322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021627056483787113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021594310782662354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021582253720326763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0215631809716773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0215370228893503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021560736536984756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021564696717320822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021601907081074186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021581451334383394\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008158452047035098 0.019701772093307226 0.0007337776058484451 0.020858671687543393 0.04675574591010809 5.938141047954559e-05 0.02828289177152328\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0048,  0.9182, -0.7235], device='cuda:0') tensor([-0.5299,  0.8685, -0.4779], device='cuda:0') tensor([-0.4966,  0.7626, -0.4999], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0250], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.02156175430913667\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.021516617838411578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02151906717002862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021485822232975776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02146887809402461\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021460760300269097\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02144957477808257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021450732657709665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021442992403098042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02145460167531667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021457959409354153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021448577199882354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021448204835239754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021431080466653738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021452505629168946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021451133415921704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02145559221967539\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021457918056912252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021438517166978425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021470661831712583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021447150116101286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021469228775196445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021482886699713256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021451542071987226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021474629305487304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021446188679773413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02148727054005863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02148696983084808\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02149136679703396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021456498298698997\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021461981612646893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0214916908631141\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021485366331780508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021482206449016102\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021477181568943612\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021523422696315186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021491291750779098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021476052218057977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021504614966590875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02155302766712529\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021552107503844634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021535929430745795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021548968910624345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021524081899779578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02157310444960717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021570382919699437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021601843654703256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02157159353488416\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021583590741950334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021555940015768486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02156372340891989\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02159691275625274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02158851324420428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021558146489868788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021562735550807927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02155034344114766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021542897809529678\n",
      "Episode average V value: 0\n",
      "epoch 27:\n",
      "Learning rate: 3.230540944613339e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5892857142857143 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.589284661991675 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007986842578276991 0.020758103551808745 0.0006681560018259916 0.021461224655620753 0.04663291782513261 8.077464997768402e-05 0.027797000272665174\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2741, -0.9946,  0.8996], device='cuda:0') tensor([ 0.8456, -0.3778,  0.8680], device='cuda:0') tensor([ 0.8046, -0.4016,  0.9384], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0068], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.021251573744747374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022065267173780337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0190220569708833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018902633080465928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02129116306702296\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02043301270653804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019998551952460454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019998628413304687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019746893390231293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02014503433989982\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020271490934784666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02008802651134492\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021137970053933114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021149201059920922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021048009347308567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020683634418269828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021047226037659676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021382863498235375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021608163839565556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02133704228585379\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021102160001025785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02075020267364729\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02038475022772732\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020494455318570276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020579342152923345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020364411615042224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02048490837086069\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020373772340087547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020499154595279945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02084514161537367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020870736691646786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02096254623999509\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020981170698021998\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020954854442476252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021042412575629967\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020902282710727534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021073196916743083\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021159548383227915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021176781821093837\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02120424314117473\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021276714147742445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02138776303190127\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02146060740363421\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02133423454396314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02153910131044226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02145370289656347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021445405497777122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021396094547256966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021301203791702552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021392746642231942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021467650660226417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02145206125982456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02154651588898941\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02156794624721225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02157278929583051\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008452510985545813 0.020517323047155513 0.0006208006453744019 0.021608801428228616 0.0471136644333601 7.107803225517273e-05 0.02750703250337392\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8597,  0.9776, -0.5270], device='cuda:0') tensor([ 0.4865,  1.0169, -0.7352], device='cuda:0') tensor([ 0.4602,  0.9789, -0.7159], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0338], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.021613984302218472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021511231141517095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02147249203671298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02148339950625141\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021351444330583842\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021282220765683656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021309201341075657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021225283350269894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021310520892762322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0212619526240115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021285302723014748\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021184549771965933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021144891909500158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02114147133525347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02132054159181222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021343389368602927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0213753355488779\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021374699266987485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021434707864951174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02138821595106964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021438500295224334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021462211959214522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021497227653510805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021554654401906473\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02150155325847057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021414274342782254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02140456772924257\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.021358789127429764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021320490318685572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021214759575653504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021166141437924918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021275045148585834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02133199361075337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021299139277942098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021334420836726087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021371458944783834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021412374838682764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021363949166163534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021328804637998976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02132243600548708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021429063477424078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021339806017571503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021378625040692267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021380585099870442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02132871405325002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021275900813010167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021284453444535924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02128374768107599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0212402580326829\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021210355122903826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0211365527255691\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021163657920286138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021165724370893046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021131244737742267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021102041958106887\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02116711280337564\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007992068834602833 0.020327882178593427 0.00046285182834253645 0.020694565752521158 0.04702725294232368 6.795353442430496e-05 0.027796844257507475\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9994,  0.1260, -0.5524], device='cuda:0') tensor([-1.1184, -0.4193,  0.6361], device='cuda:0') tensor([-0.0089, -1.2880,  0.1480], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.4081], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.021122189219264936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021084204972735374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021037049512569492\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021035891203524698\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02098460565677976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020981846286597727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02098766380961346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021055586073011938\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021035659576645466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021084857443082458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021149667732685614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021110374599530312\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021133326140055465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021164932870202595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021196922416284653\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021191413238911855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021195839671741448\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021237682339371945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021222946788064946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02120206422552441\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021214966274569005\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021216564469814375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021196221494522088\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02121959734945692\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02118118332502633\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021185767482996398\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02117052452073353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021145751189476224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021104678427726623\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021059459476409536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02109673373140278\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021086542705390905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021049810937436207\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021071708412534088\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021059755330531088\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02103149263013664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020982090307905845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0209655017046137\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02098591570397494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02098224741099039\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021018102130926166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021025336927483394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02100977127192996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020978082060533504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02098102505787135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02093106531620458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020903021550073213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020863551585619408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020865593056078068\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02088590483216529\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02086340823588926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02081350834809127\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02081943369315316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020875187995859266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020852390152166587\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008129828724544496 0.01996393794915639 0.0006095585730799939 0.02026693694386631 0.04700513838231563 6.288247555494308e-05 0.02613922116602771\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3347, -0.4494,  0.6722], device='cuda:0') tensor([0.5779, 0.2224, 0.5036], device='cuda:0') tensor([0.5815, 0.2578, 0.5167], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0389], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.020859725185603657\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.020855851132957334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020842331445076058\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02086548636320467\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020873667369097414\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020877522006703092\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020918572231213215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02091369101162738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020903174626744455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020896291556930395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02092506632656654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020951643758529006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020927394643451377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020907171645178746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02088810223628675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020863413388280242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020862471974445206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020858742694307462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020891588173426307\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02092326694115854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020919338473524462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02090966231773121\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020907552627576126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02090258894989278\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020872150276098976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020830334848411708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02078654672349999\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020797160520769853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020810464310573887\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020796884855470894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020798077165725386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02076927509642803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020777899106846947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020774746912583294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020769748759789073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020738238529471233\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020777371369728428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02075119004082665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020739926735247133\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020714152586257573\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020720520313485247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02072490439735329\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02074322120273156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02079218144272331\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020786057523313934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020775704580433353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020752494344142853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02072158087067198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02071872658459638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020711926672485018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02070298972332166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020695914616419057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02068969913824962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02067201458660867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020685127947073056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02067508189626657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02066659629903734\n",
      "Episode average V value: 0\n",
      "epoch 28:\n",
      "Learning rate: 2.907486850152005e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5535714285714286 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5535704400527856 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00815348476311192 0.019375783673953265 0.00040816143554548036 0.020080218597315253 0.047218336869031194 6.447650492191314e-05 0.02735356578300707\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9011,  0.4502, -0.8512], device='cuda:0') tensor([ 0.5727,  0.3687, -1.1302], device='cuda:0') tensor([ 0.5671,  0.3733, -0.9993], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0707], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.019013983197510242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02247111623485883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02059257992853721\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020097278899306223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021505814904554024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020716938724810327\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021275602591534454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02079844707623124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02089148920811253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020141054689884186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020461888663997552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020927821217035805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02060479397734261\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020412253311997842\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02024233700638568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020000795090001904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02021293709772864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020584032376423294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020760464966732856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02051218426010261\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020472387263364103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020537545024934743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020214869933211862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01996181254637324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019686204550994766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019748385326984603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019619212459021634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019544986490574148\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019540903354741606\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019387152187388252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019229341996833682\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01934661344744705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019344058685061154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01947908503310816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019611602151648155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019923374090590917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019863199369209977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019959974886266767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020076457621328044\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01987757765002445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020032746678844176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020035167472934715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020296827244430358\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020210564253508406\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0202393417712301\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020123945580062048\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020114604215826795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01997356626142627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019972017965682883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019810296453845997\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019835027305547287\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019864853917776298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019865864345538324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019857447789387906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01981144403860048\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007948897142428905 0.019376313351560384 0.0006023497487040003 0.01983009554212913 0.04707888826355338 5.7728148996829984e-05 0.028237277584150434\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2806,  0.8554, -0.2355], device='cuda:0') tensor([-0.7417,  0.8004,  0.6565], device='cuda:0') tensor([-0.6478,  0.7447,  0.6111], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0790], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.019790249861433126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019764148582546423\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01977571700494451\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0198311375602273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019773174231199342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01987156263155649\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0198475699692357\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019827675059966653\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01980419770512122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01994846037700454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01996378536510159\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02001961473658199\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019988181721951714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020007459348931476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0198749313785118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019918683029096194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01995482640434344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01996393687704144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019879813934256835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01986425185955509\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01990272900891594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019819756234360355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019849384810836545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01992057972723872\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019950423053038926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020013800649411863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02009245438525216\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.020144079366469458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020245978041741722\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02022557581494885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02024700951212608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020308788955309173\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02030028515722311\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02027727646745053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02023205676972636\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020349176345570458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020280798087020265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020239439860527075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020234057102099183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020197755557740903\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020224491811488946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020189188183141277\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02016656272733149\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020149233250060315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020233790904231785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020163042854765643\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02012383607789379\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020204275804034312\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020121828337253716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020158407132254627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02006563377411415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02004614700215094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02001559900655507\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01994755052226604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02001269184349274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020006316476030735\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008173956309445202 0.020111925457604228 0.0004394607736321632 0.020165605274029077 0.04763535076379776 5.378243327140808e-05 0.02619175425893627\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6467,  0.9638, -0.0729], device='cuda:0') tensor([ 0.3272,  1.0417, -0.3106], device='cuda:0') tensor([ 0.2445,  0.9647, -0.3610], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0119], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.019938077950630233\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01997031022486851\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019926905382622477\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019967399280887223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019948555565826323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01991170701254177\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019938189901364176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019910324907302508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01994372667352393\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0199454272419464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019927222354427482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01993939449590847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019953350164955915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019979568128577537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019975844221033576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019967746712904577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01992130409517914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019897759339148877\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019900525751937594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01987517376958003\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01988381606284435\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019899277171157394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01985298069081984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019850916024719063\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019903130551801654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019935029706315704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019991418712880408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02000262754631313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01997714158395187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01998779237460436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020017299765221052\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020029361206906463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02001790573837\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020047107653092894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0200406869023236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02005009361414643\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02003638559687385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020036394545519524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020005521221189863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020027250868547227\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020050619640190167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02005082099514519\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020046572329800356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020015043075493535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0200213326678208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020030146228579272\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020018481637505782\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01998970312441248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01995437162743959\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019933378806445693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019963616970128065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019948843150319\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019923831493155852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01987696966510705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019874506146420126\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008173981393687427 0.02000809293030761 0.0004321457872283645 0.01971002861857414 0.04701827323436737 5.304568260908127e-05 0.025900109639856964\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2618, -0.8341,  0.5454], device='cuda:0') tensor([ 0.4132, -0.3956,  0.7413], device='cuda:0') tensor([ 0.3856, -0.3519,  0.7623], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0070], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.019908518844742033\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.01995153431906907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019927523144962295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019908496105489535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019885691939844054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0198616557322907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019841492874248762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019824742007254842\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019846260298841765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019830700461758593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019853166031942933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019933042784288906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019903749734663922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019919205716391452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019886201020173543\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01992121002547584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019913297652226773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019929854509871732\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01993951035548818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01994424807745073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01990881318846785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0199451062686017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019964501471272388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019993976033728416\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019996655393698496\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020065573359547503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020070973797269683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02009212074415675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020062803243156895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020054965755820924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02003928957214433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02002708417795678\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02008068818031664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020085686639908493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02012169069992538\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02012448741122568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020135962578009755\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02014125427974323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020145917695575978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020127207996346812\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020126169149889357\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020113334318291612\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020098379000022232\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020087456405433832\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020090192643554786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020068536794561876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020077697353497785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020106943503485436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020104775606060176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020103953949174816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020091678895589386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0201070107813691\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020135468736131222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02015911080895669\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020159459406090454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020191461309437286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020197083178092726\n",
      "Episode average V value: 0\n",
      "epoch 29:\n",
      "Learning rate: 2.6167381651368046e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.48214285714285715 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4821419961750068 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007833055833354592 0.021956954823341222 0.0008801949692788185 0.021089203538373114 0.04726989564672113 5.144287645816803e-05 0.027275595182785765\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2286, -0.7935,  0.6337], device='cuda:0') tensor([ 0.3633, -0.3895,  0.7414], device='cuda:0') tensor([ 0.3141, -0.4606,  0.6633], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0500], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01595776466031869\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02082237901373042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.023024647910561826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.022673816420137882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0234295475607117\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021496910532867466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020705852953214494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02082425221386883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020537228036073992\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02047802230550183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02070052930238572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020622245079182363\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02075648724109444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021003677797991605\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020879304091687555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02056253560456551\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020637999066559512\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020740631821185903\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020598179113381264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02050339491882672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020635689000190093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0210071902256459\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021129389628677983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02096897228922764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020839606521444187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02079153543887421\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021027142199239245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02121585865675043\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021358889675702743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021220856673877547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02130335006916288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02125896732710923\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0213723098388826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021347500234720557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02129739164448683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021343939913218313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02126663905224419\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021172980934501304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021300000163787535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021400605629767394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021338839605097283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02129771721687306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021291801350995013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02124583834871612\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02126919393554146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02142670824403924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021348772458203717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02128038296898551\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021367836986455113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021275814906176593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02131258034449647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021294509371121723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02127046199941098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021308381246487176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021250850036552155\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008042981528211385 0.0224619827484712 0.0005329087017162238 0.021278636616654693 0.04736433283612132 4.91856187582016e-05 0.02674951448570937\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9710, -0.3436,  0.6636], device='cuda:0') tensor([1.0642, 0.2315, 0.0105], device='cuda:0') tensor([ 0.9966,  0.2073, -0.0461], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2613], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.021208626233846953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021284096060070205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021438222586345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021387612104254536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021410974735152667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021317521988063075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021430592252088435\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02135956165589379\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021410631936709654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02134040289789311\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02124827176407732\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02119963059347018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021266178926452994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021253197492908646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021150978983542512\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021157877019086214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02114913030455671\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021202885159511044\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021182066565882916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021177065562180897\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021184882484730442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021144190367746663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02122224150941922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021180297233656824\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0211013869731687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021181566997166768\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021117410657871868\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.021098348188651615\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021105126948366876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.021065246937126896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0209991456694102\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020974594845744574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02091942636726537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020910104106502438\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020949844687165303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02089172890478056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020838502633097417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02091994773309451\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02097228617984229\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0209344221491432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020929932166904176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020918593068264706\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02090590037753945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0208925645026001\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0208564099136533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020858171367269866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020896145703640314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020843630375294367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020759712521615636\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020683241865188672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020628099600673192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02066807016809611\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020602292280621184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02064949789375948\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020593575526950788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020599168649332988\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008179997526109218 0.02078899707389064 0.0005245383533110725 0.019912890668958426 0.04733086345344782 4.296365380287171e-05 0.02739791307179257\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4721,  0.8851, -0.5339], device='cuda:0') tensor([-0.8887,  0.7699,  0.4711], device='cuda:0') tensor([-0.9791,  0.7443,  0.5304], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1199], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.020529588991184792\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02049320672923514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020443054411258932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020424405503838103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020355754337448385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02034934395915366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020289874643090896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02024866110600886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02023770822669138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020257038779683323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02033340560869468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020286412382971197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02031239724758091\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02031256733006901\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020277218467751403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02024827584622661\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020246294605587738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020323646288127682\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0203341172176262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020358150006936228\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020371746500367643\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020419085934001924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020447885899481735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0204138837517105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02038790634757188\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020355765705147195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020336653793533596\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02036019370442243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020370813954015455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020378908966253294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020365674303354862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020363313547916647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020358146004447783\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020341178518630765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02035289081635699\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02031558295831546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020306573900346597\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020275608183625782\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020292846544611234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02028262142860896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020289460759084367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02027896696230912\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02034342233501482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02041436740594472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02039023937937403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020358232980012703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02037930403084202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020382910760888825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020345370051088846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02032644724122424\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02036462294446261\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020333099228488034\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02028690737534597\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02027037543548829\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020283582165570482\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.007813043618574739 0.020507585604675114 0.0006789754100391292 0.01963841765653342 0.04809624406322837 5.4945245385169984e-05 0.02746156278462149\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2304,  0.5247, -0.1462], device='cuda:0') tensor([-0.6774,  0.3973,  0.5563], device='cuda:0') tensor([-0.5928,  0.5860,  0.6445], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.2342], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.020273642874733655\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.02025460674477958\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02022067436282226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020188565147748472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020159232966623634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020165400057658073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020150902643369113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020163556543032556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020159092406550096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020146020714574577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02018300378467123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020164907306488535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020202685020341407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020192905079090485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02016478672708248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020152967051353866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020140095425031188\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020122685387015234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02011632519262331\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020104554479300814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020113217737636375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02008955401724015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020069945181201462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020064012336746206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020062702131761565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020044502722696592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02007343053574329\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020060768221075064\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020069835790329508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02007796245736921\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02006239051370132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020058712822737385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020028038672678536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020008933413256373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020024384319938766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020021816148505647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020051246868843058\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02003162069127475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020023404896451123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020015338155216948\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02000505107110521\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020014087287967816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020023680966424696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020015704643138975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02001305888522183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02000706917943093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020003353890000485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020013281754445313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01997988169666293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019954851728149234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019947851883582255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019965345874451534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0199729274024687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019965458109579753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019932345026900805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019925912074908778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01993139181798324\n",
      "Episode average V value: 0\n",
      "epoch 30:\n",
      "Learning rate: 2.3550643486231242e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5178571428571429 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5178562181138961 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008152264883741737 0.019535290100844576 0.0006263970505242469 0.018896317280828953 0.047318792968988416 5.40192648768425e-05 0.027693836376070976\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4274, -0.5022,  0.9941], device='cuda:0') tensor([0.7374, 0.2080, 0.8796], device='cuda:0') tensor([0.8494, 0.1833, 0.8296], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0191], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01483559070361985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016640802069256704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017322183586657047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0180113910852621\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01945595143155919\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020274273223347135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02035749029545557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.02017142607494154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01967640804632762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01987018954112298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019632684391443476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019973712072155817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01968652294932777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019832387596132265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019650233716324524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019536088443904493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019599965861785452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019578228063628446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019329697800506102\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0190530909716876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01932355418072018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01951888179632299\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019292569791241256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01919735497708812\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019154532524860567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019000259433021277\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019446873602384524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019410532764306973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01937096194860122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019436249978564402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019317577359363382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019121875491691753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019020276106517724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018986809310911137\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01892411931757889\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019023300611333532\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018979349548371882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0190197690580672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018999009011074517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018978948244411084\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018921921870148763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018973574342905843\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018942010898181556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018991679349453235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018942130381172453\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01895498869387244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018938276145043596\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01883961744843637\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018888597004960317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019045867060000696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01903707044268096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01891080241224482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018871194906571815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018798553341723704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018851560769094663\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00811502601346001 0.01978189637954347 0.0006633047061186517 0.0188534704009071 0.047684258352965116 4.593248665332794e-05 0.02693311493820511\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4419,  0.8634, -0.8847], device='cuda:0') tensor([-0.0287,  0.7616, -0.9625], device='cuda:0') tensor([-0.0118,  0.6443, -0.9937], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0418], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.018797548305768047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018826746474406873\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018910139543985613\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018836196690881993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018880370947428875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018860023395787715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01880789189315718\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018875854732090937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01885281411523465\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01879334489408976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018798785995980505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018735017193478237\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018696381024912827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018679946642249055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01873630217335645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018850042239117185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018916351811954592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01889022396625086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018848911457759392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018844804700326036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018850163733641134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018894700337507765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01887442739255875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018808876858492356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018749605679962162\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018787774071480634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018741066819359737\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.0187288363042775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01874356854167427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01869269469509425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018799008898441837\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018781273651958502\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018841844910492348\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018841428888005933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01884109076043522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01877802397864751\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018791366324665538\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01876393634728028\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018902738460826185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01893696761009289\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01894717426384213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018964651137812306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018950420239615063\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01899651020627331\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018987169690533646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01898326045639887\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01902050175805513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01902374215152802\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01909904857365112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019064424480631868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01912636576177439\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019155243785930014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019162073992997592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019094569207464367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01914361701629153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019151784351433034\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008281022604554891 0.02088006369676441 0.000558009704676806 0.01943322889879346 0.047560791037976745 4.4819802045822144e-05 0.025365410425467416\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5904,  0.5870,  0.6576], device='cuda:0') tensor([-0.6615,  0.8112,  1.6938], device='cuda:0') tensor([-0.0017, -1.2995,  0.1335], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.7558], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.019120969184090397\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01917418769506725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01928392749871572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019239674661542482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019198134450520248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019198787511845544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019165698381880977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0192205131629588\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019211539920178\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01922072224401081\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019229295998574227\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01925238100021014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019195908695162276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019157100157605276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019197436319779097\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019194435742981113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0191923266077841\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019140895847535977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019117557807053383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019131800625868223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019086284096500136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019091851041405622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019048459993545614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01902278141758631\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019028375306839332\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01901419824805029\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019036393310805713\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0189959974248531\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018985687823419178\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01903645758875965\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01903902170837147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019022502514179838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019020363780810717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01905034195125046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019099881534806285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019051495884937247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019050338330354216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01902681669445346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019032889480737072\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019045258616594115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01902809774956519\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019042269497522753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01900894005183523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019000252935447895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018957781605754166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018960798451557008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01898034398559266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018944578814423747\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01897224830819242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018991908635378522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019033045784234284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01905780583562935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019047673663243066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01900873833684006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019002156880705393\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008207695444114507 0.019815175582189114 0.0006056219447345938 0.018641553734429182 0.04695900758728385 4.4558279216289523e-05 0.027672754499595612\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4557,  0.8269, -0.4689], device='cuda:0') tensor([-0.8688,  0.7259,  0.5681], device='cuda:0') tensor([-0.9619,  0.7387,  0.5742], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1142], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.018963566583445567\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.018923370281564534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018926554592173205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018928808725615538\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01896197130798306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018967357476167283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018973172648272113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018985345860346104\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01900493749786937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01898306627720218\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01899039182006349\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019006685389568574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0190195762693956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019000520644548498\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0189685200322751\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01895525401215932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018945549003458705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01892270616358056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01891669139696716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018920883784747128\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018901041253186004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01890682052060231\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018885946275501008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018881637863106808\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018913530683120006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018904250198425468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018897850977371632\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018947509459069454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01896730123268191\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018954322009205885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018950241752855534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018932508458629017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01896301319038507\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018991949794193108\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018987936314222166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018958332874618546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01896671895100875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018949841410895576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018947370093426893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018928638214854264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018917898895439926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01888774250858885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018896498834711322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01891355631508367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018911833664732914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018908403505594615\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018876435171985725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01883879616984233\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01883674789778407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0188596595379087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018890901992056487\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018906290392523346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018908727968079502\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018921386645612957\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018956446368270683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018937974050338077\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018929774178075603\n",
      "Episode average V value: 0\n",
      "epoch 31:\n",
      "Learning rate: 2.119557913760812e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.625 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.6249988839305644 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008172231422271579 0.02006799102947116 0.0006075745635826024 0.018822383494582026 0.048067041758447886 3.546737134456635e-05 0.026731905615888535\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5299, -0.4478,  1.0004], device='cuda:0') tensor([0.7815, 0.2501, 0.8022], device='cuda:0') tensor([0.8526, 0.1805, 0.8296], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0300], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01173768187355664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.020650780526921153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01936479528538055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01953757159774088\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019860675889584754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019054565406231967\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018360380378980485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019109011938174564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019005313849099623\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018859259727307492\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018748723981770302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018580949610892544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01903958011689222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018779424329598744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018406877063076806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01876848319403103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018887944546911645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019156242516696637\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01920337787671396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0192989195127868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019258199279349318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01916209274592499\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019299301402058433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019300356543950598\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019213729788445766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01936235974351756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019162825393057407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01901695713223446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01893466329951396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01885681131992627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018901815769800042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018800354234473262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01892419229183183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018997961787653027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01892158818534679\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0189366825427975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01883208007878951\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01871121089703986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018572384260722205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01879214535648417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018946654777872933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018864807878527297\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018984143929050644\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018920195871032774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018903178945873622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01900218272973122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019011658567926422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019037399902353407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01911570559426838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01907951133739617\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.019032516108911022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018951027902862072\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018894981793996797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018909305949224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018909312389565235\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008058310437947512 0.02009484636830166 0.00046211894157750067 0.0187934488048777 0.04830520049482584 3.90075221657753e-05 0.026993077397579328\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5658,  0.3485, -1.0001], device='cuda:0') tensor([ 0.1105,  0.2677, -1.1336], device='cuda:0') tensor([ 0.0811,  0.3343, -0.9849], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0015], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.018872553232266377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018919729250964308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0188935992844988\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018766448169196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01878965977596602\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018840812622503342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018852212098276904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018844556384531017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018774489497849975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018789837253876986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018708324871223533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01867916923445676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018712759603064483\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01873019001343184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018615018121809476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01871071425988011\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01875451095129168\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018792191508284217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018798188603547466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01882380126113141\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01876875866280749\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018711657845247188\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018735714471684053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018757754213762183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01880590265047633\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018724647596534673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01869449510395547\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.018704763891043235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01864519241578857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01865758405499209\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018591272985220956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018595348048055994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018598794814838907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01862542378773143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018567389742482777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018537006826482266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018538702721370086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01847295174564334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018466117830361388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0184300732842445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018534824537238346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01852891560833803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018495840122902136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018459718935735163\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018459262764081358\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018460863351830097\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018421146369382968\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018488830731560785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018510389634762276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018486591547767006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018467584186071525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018521448791700174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018467246719114788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018480642387789657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018440243384960777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018468125962425728\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00815444840490818 0.01946416394924745 0.0005651996775195584 0.018095247216522694 0.048027125928550955 4.702329635620117e-05 0.026763276821235193\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9972,  0.3660, -0.4881], device='cuda:0') tensor([ 0.8107,  0.3967, -0.8987], device='cuda:0') tensor([ 0.8985,  0.3777, -0.8722], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0357], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.018449800817521348\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018446831168623362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018419228892203342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018493380425902813\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018472309090942857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01848124982948359\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018429956405042986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018439961474712323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01838870713642488\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018434483188489253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018421360819120443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018469843889780967\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018438445066191977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018393184741338095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018338806299341603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018332954011743438\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0183240153245505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018350785255631066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018363468278135755\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018314581562664623\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01830745278152101\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018324391899277193\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018357502013926778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018332192424393486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018368710342983357\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0183773214248253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018397144542110187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018348007270475204\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018346786285040988\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018328758882442335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018301999979435303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018298940498978133\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018265882253296166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018241929474475855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018234288143816217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018228956041695693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01824288178331781\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01828443291156062\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01829004086278103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018287396257862482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01826953496688661\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018281512475757166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01828342288582012\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01825624082511204\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018242831057019827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018230314418918703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018230627200850474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01823534451686705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018256731059065917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01832646421710218\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01832799785495806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01831618193841724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018298462329515656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01832020503127013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01828619356172401\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00790119657991454 0.019505534060299395 0.0005036750529907294 0.01786925302632153 0.0479583230689168 4.2206592857837674e-05 0.026922883764375002\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7075, -0.2560, -0.4638], device='cuda:0') tensor([-0.6595, -0.7982,  0.2848], device='cuda:0') tensor([-0.7410, -0.9522,  0.4273], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0949], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01825577201085018\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.018255394042060568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018236491046013173\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01824437972200803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018237426548123922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018251890596062505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01822064426837055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018251180174816424\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018277405583787532\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018271165560681674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018256112360217177\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01825478406257918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01827016310601002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018251309166144994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01825459172264281\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01821695844573452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018225845755555716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018265300585296688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018271030045419304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018243956621046418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018216603446643373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018193673386775733\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018171284324503222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018124225097082076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018090484901957124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018087889834229525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0181201816119348\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018110488495818273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018102517387858907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018121517313245152\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01812271984820388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0181729025416511\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018200146690081746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018204563290346414\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01821788767251794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01820928062803068\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018214913403699975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01821501114434098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018235814676880027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018233389814184355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01823108284511732\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01822046380545785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018191189961661403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018193160599127175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018174857940385536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01817284706434278\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018210734177310842\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01818862699575699\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018194198284481076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01818343076218732\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018175314334104353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018163025795000773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018169780921914867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018175756226698255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0181597825191267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018149094669627504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018151172468904405\n",
      "Episode average V value: 0\n",
      "epoch 32:\n",
      "Learning rate: 1.9076021223847307e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5178571428571429 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5178562181138961 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008301765855401754 0.01855628986656666 0.000602555121819023 0.017808851038105786 0.047925938088446855 4.904569685459137e-05 0.027643003817880527\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4552,  0.8201, -0.4628], device='cuda:0') tensor([-0.9013,  0.7542,  0.6927], device='cuda:0') tensor([-0.9550,  0.6629,  0.6257], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0221], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01632508532040649\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016789873234099813\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01912481044591577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016915689170774486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016541452374723223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016147030551952345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017530991267117244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01766918832436204\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017492883401796406\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01747427882833613\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017156811995488224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01782365865074098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018677135658824544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018242158051136704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0184286175330204\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01831516432381856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018141919226550004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017895107166151756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018012954327904167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01794155024561203\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017857943962096536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018014197348325392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01797101204171057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01788304006913677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018102802822573316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01809853276150285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01816984322190346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01805313321251777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01787726554869749\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0178472140027831\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01777204885698294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017942824396110762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017728599078439\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017867242596325238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017965312702729115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018006184407118937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017917193982794927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01793108205583317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017828570475849587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017944013219999357\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017921875196895223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017890611309903087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017829818154134106\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01786073693662242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017881629913815377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017967639977994245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01794889662084533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017976244766032323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01783395304646588\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017842310941260722\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017837592439161925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017763851865186777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017754728218591313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01778935908374411\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01779880714461659\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00823058050731197 0.018892822203226387 0.0005416449981639744 0.017830695059150456 0.04767997912690043 3.479080647230148e-05 0.025212327391374856\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3527, -0.3179,  0.0912], device='cuda:0') tensor([ 0.2740,  0.0066, -0.2824], device='cuda:0') tensor([ 0.2820, -0.0006, -0.1871], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0906], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01781249754056926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017771585401488908\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017813196125657967\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01784667901943829\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0178290181129274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017835914490673222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017757157609033597\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017749166488154697\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01771764422220359\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017642855014588333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017721335280542372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01775254622861669\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01782647381137959\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017788207280673027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017937121066516116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017949686488442716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017983288106071638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018054279487415628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017955078529445705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017850474717302455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017856905817555276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017874391258305845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017859098624220474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017825251356757516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017883514911065705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017837996260532587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017883112674281203\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.017886324632299472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0179106432491194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017892363668096805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01782027748413384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01785447519917236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01788796029921452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017829459025693148\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017840477140091453\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01780865347508673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017799197409891384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01777867443154131\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01779780576520778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017827669345387067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017817841179311036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017796657455152697\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017941175249897266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01791254569557898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017920968866286177\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017883852909025055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017854880495909966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017846340416029432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01780481186733207\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017762881342479317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017758715338907372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017872980779843447\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01788975774270287\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01791625846296959\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01791535289346645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017890803465103213\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008211066571064293 0.019315823330543935 0.0005449793471998419 0.01793429036717862 0.047782561741769314 4.5463673770427703e-05 0.026255261527607217\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8392,  0.9989, -0.4245], device='cuda:0') tensor([ 0.4806,  1.0538, -0.6413], device='cuda:0') tensor([ 0.4731,  0.9993, -0.6516], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0253], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.017873677021790563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01790057037816902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017871518842204243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017840327403467634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01787258843156256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017928034912685156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017917438480378658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01794925339113013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017902863392157964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01798128233059447\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01804011920679069\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018064099519623757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018075944154813724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018093905214634207\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018125609088216036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01810596612577872\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01807510891295452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018133237152572954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018120255111119685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01812517042868187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0181023255335512\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018087507934763145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018104912508912323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018131585580530605\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01822230257999359\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01824312980512621\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018217528717676342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018217533821244535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018206784472105993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018209487733330615\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018230825919127426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018206582731034003\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018166859200178288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018137663464379495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01814193527754311\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01815820637406135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018178419799434842\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01814535212418999\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018197148862398333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01817958674587534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018171225269379542\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018153462381783222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018199598643805128\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018177425582295677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018176361860739242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018168379322632947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018152212116306677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018151598392870567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018217577028553932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018225663559468884\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01823540696802719\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01823326260620892\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018233627158527572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018230628648064153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01820237224128651\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008120706280693411 0.020722865398740395 0.0005441495674531325 0.018834461783990265 0.04820571133494377 4.296467453241348e-05 0.026169418247183784\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.5909, -0.9229,  0.7779], device='cuda:0') tensor([ 0.9898, -0.2476,  0.4403], device='cuda:0') tensor([ 0.9979, -0.2286,  0.5156], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0258], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.018200271755161975\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.018229733933891767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01822431985335394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018199377193791316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018225602490029857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018247178805936657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018281786474378333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01828592073494666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018294097442652972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018311323384011185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0183095987096934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018314556234961518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018333840407928292\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01835749688397311\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01837335414515592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018365843406047157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018359682957557525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018348939855726984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018323861277318217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018308726776382366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018298818134391194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018291982817716775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018315379215466807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018304453214238348\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018297899542609367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018263156962348148\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018274794453856893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018269410546770892\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018266734314228057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018279276241267486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01825800790040172\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018240204862790342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018246523453009023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01823173321550712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01825194144127257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018246600588033644\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018256011115184198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01823146283258288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018266869862096986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01825394322357252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01825714589362055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018256826664303213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018238985452777225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018236518092699862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018202772749006245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018203513884957903\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018177955686836174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018197365596925266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01820060176587151\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018208941962635106\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01820740112734418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018212781100705736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018197538244444925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01819492883890905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018184472099012125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01816994936981083\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018174966356484218\n",
      "Episode average V value: 0\n",
      "epoch 33:\n",
      "Learning rate: 1.7168419101462575e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5535714285714286 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5535704400527856 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008327904992736876 0.019490653584478424 0.0005052182445069775 0.018106802865862845 0.047559740774333475 4.1186437010765074e-05 0.02757059840369038\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9998,  0.4656, -0.4471], device='cuda:0') tensor([ 0.7678,  0.5262, -0.8068], device='cuda:0') tensor([ 0.8608,  0.7710, -0.7656], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0124], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.012151934206485748\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01323082246300247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017267872234461485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017946045121384993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018152432557609347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017624784105767805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01760964858390036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01749658290322663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01721449187140406\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017281754977173276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017370411256008376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017637618045598543\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017979573251472578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017626481189850777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017766294518002757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017601514716968976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017736481116122863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01770836827747616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01748986958596877\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01749292653726621\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017360063585102874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017447751071868522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017379309982061386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01757210653051044\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017427501951654753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017497174618924912\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017494721972448713\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017499284879747955\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017655332285511197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01753641560294286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017389131297681173\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017474643449531868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017603251640920085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017614583468089015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01754160705539915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017558439863259317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017581938367404112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01740242367370697\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017436803936788498\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01748866808290283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017537987879338628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017793115950312723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017817623512602822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01777390487647305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017800123188184736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01786892118431844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017832605917905028\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017707013879704324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01763370367033141\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017643641454892025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017731311998871808\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01773833725641235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017788280578685506\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017889155126694176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017878081786888416\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008129914136603475 0.02016502611991018 0.000342295382222801 0.017893827747553586 0.04803982022032142 3.469222784042358e-05 0.02705463011423126\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6957,  0.7730,  0.6403], device='cuda:0') tensor([-0.8805,  0.9255,  1.8764], device='cuda:0') tensor([-0.0045, -1.3054,  0.1241], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.9936], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01786126913077804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017844408356582794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01782775936662523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01782653123848912\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017837893968034122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01769424261243671\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017708226684547666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017675933237573563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01780443684320845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017805173684261804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017788960538829616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017758841377684527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0177873571736592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017744272770345116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017766489839506527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017755497628837498\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01783181404131522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017828844093591475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017853522369800298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017834747597851135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017827676828373332\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01776583653620698\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01775310181898524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01770770128124751\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017710914911650534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017701199037420203\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017660247322883668\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.017627015405046534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01762216949709765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01755566728770051\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01748579831671172\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01749112102527785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017520841520933455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017502959591502814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017457027044032274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017407036314221493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017367953365412202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017406430924945513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017442530158678197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017421202782585084\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01733912670116061\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017383090897280837\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01740990462290575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01741608915125113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01744979118824833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01743759971308728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017434379382643337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017362642921246146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017342574352649257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01736241022184018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017335187517832848\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017316368845632823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017314949167275287\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017276903457282666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01733123763144543\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017328223183255147\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008231683583930135 0.018279255053028465 0.0006797367964318254 0.016752007284201682 0.04809694470092654 3.096310049295425e-05 0.026487607037415727\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8345, -0.3845,  0.9124], device='cuda:0') tensor([0.9968, 0.3045, 0.4062], device='cuda:0') tensor([1.0004, 0.3272, 0.3051], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0611], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01727933742129983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017271921050074558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017213739629028835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017178493202776438\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017157749892872585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017191977095980363\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01714768322893259\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0171324835449325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017112344844456485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017182281663721724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017210067832123196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017171132223901035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017162695023027585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017129118288970655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017131534763948575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017120828685429752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01709095450375268\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017101699951635057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017090470710387214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017088432611061848\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017082948752707154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01709872425231171\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017101355422146088\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017126411724636338\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01710081645561492\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017142089158568505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01712054220266676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017107102891905226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017147725785062427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017143425383436998\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017168214166076366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017140165924745168\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017163626994451876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017192138324338243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01719829974705963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017227023598144587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017202356488509634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017184767745175494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017190843907667806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01720281473787212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017173802176979235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017229572300188456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017266626877496544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017283607073174955\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01729768177310663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01726001504494269\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0172824017327271\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01727763584399743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017314793884320858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017278819954410978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017246042996094356\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017234159784135044\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017212605644440212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017245389643260074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01723692443694326\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008301839167252183 0.01865288070891984 0.000579415230487939 0.01722650164179504 0.04787034119665623 3.671698272228241e-05 0.026882246857509017\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1364, -0.9963,  0.9302], device='cuda:0') tensor([ 0.8254, -0.3669,  0.9949], device='cuda:0') tensor([ 0.8346, -0.3797,  0.9125], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0050], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01730581520513166\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.017290771030944098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017324812324530273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01734509028256962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017368366795666442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017397740611250608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017423760802673466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017407237296379236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01740230389796789\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017402162768635803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017385718734538542\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017435497117429952\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017431450191732614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017468177586977864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0175112540281376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017531686724289813\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01755841935797621\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01753560077862427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017556760358336095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0175385669314969\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017522327195735682\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017513093338777305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01750542766451266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01748509854323378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01746052832311803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017457828144769236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017432680025656004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01745439061755261\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017462748330765724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017451624157933558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017419182711206817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017416271328294753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017399260700414594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017418401966181895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017441140533352325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0174198283084409\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01741840444009733\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017419044606332833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01741975519710238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017403893395273786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017416268580613663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01742387844177966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01742814547852165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01742011700269012\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017441816092432016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01742656456635566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01743495083609805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017441281235243966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017419937335060625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017403499952205092\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017424896848948337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017414256763026482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017401582785640603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017392713710374076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017400997345531972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017415281477709627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017410537034505978\n",
      "Episode average V value: 0\n",
      "epoch 34:\n",
      "Learning rate: 1.545157719131632e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.48214285714285715 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4821419961750068 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008096129198092968 0.019799223815789448 0.0003885805027166498 0.017759940523654223 0.04772606806084514 4.650254547595978e-05 0.02605531904567033\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8442, -0.9998, -0.0247], device='cuda:0') tensor([-0.2911, -0.9067,  0.3776], device='cuda:0') tensor([-0.3040, -0.8889,  0.1954], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0060], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016418934437549777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015951347718429234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017286451498943346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017152376046093803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017073027903421058\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016067099533285254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01688241401302909\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01723692743366377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01693026703081013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017201394391142658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01730329828393279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01730510358767653\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0175594761609458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01756900741482183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017665238923358695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01735560392909166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017265412560816294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01747012274040852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01738738224770852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01710743466909561\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017259883610580964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01719788948986491\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016950274878383978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016771391385528085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01694040026722683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016944560108897395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01675142178794852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016523685650013033\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01661238757094147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016598968826993195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016577017531933858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016649244532648783\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016575595527034415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01644239609062769\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016667287365075143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01690204330018641\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017006536615682435\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017023759613586972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017032865010350517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01690271428734478\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016887952205106655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01685985839290042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016965876530750008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016980777685107154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016832813779237094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01692399174393411\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016838476285294366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01679292004081179\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016808954705304704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016692560803559093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016665061420410028\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01675782559348\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016714843975055956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016710790798811572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01677431659020408\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008079036171082406 0.01879354464751668 0.0006726676589569251 0.016809677029959856 0.047727793022990225 3.1807303428649904e-05 0.02651737390854396\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8999, -0.3589,  0.8273], device='cuda:0') tensor([1.0319, 0.2874, 0.2588], device='cuda:0') tensor([0.9958, 0.2901, 0.1615], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1305], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016789105418692565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016768708526470916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016865120816197947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016923142874195975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016942999452456003\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017125105543845828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017079784914577466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01712454276363081\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017094193052293524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016993139898324877\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017046974975810158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01702867634053872\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016985317495091534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016895303362455583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016858608776053028\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016822549225164924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016924847968721787\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01692306812175038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016915355850285193\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016920565164613502\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01684430359225524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016889028431925638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016937206445548397\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016893259830558057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016898871447968606\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017007043426128205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017028282659612898\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.017028234226422176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017131482766542052\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017217942570743997\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017153404039410194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01723056334150553\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017273154600071863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017219754319042713\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01720393996881206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017181164987035032\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017246932398127437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017200818283676995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017185788006074815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017175800909903664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01711373180539037\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017121679034352917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017149294676922278\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01719386999178615\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017192722629859214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0171950405788361\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01715542913834546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017221964966051658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01720729868254091\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0172040336509112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017181596739717468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017136326242965547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017108617135354245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01713568271564037\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017158724692640733\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01718095199972227\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008264504965860396 0.020439424383221196 0.0009151085168632563 0.017557754684239625 0.04772346264123917 4.839529097080231e-05 0.028362226665019988\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2596, -0.5541,  0.5159], device='cuda:0') tensor([0.5331, 0.0582, 0.3719], device='cuda:0') tensor([0.4833, 0.0268, 0.4342], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0219], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.017214246547415053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017254886142781322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01724628839672672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017226578723099354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01722301495256138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01721393293148333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01724701686043173\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017219232152243094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017212290806195664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017245268449614885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017281907483789466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017272870527881568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017234178179854988\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017251006395452552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017270661764852112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017302408924428966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01730756942763239\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017323954718734533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017350631120065466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017395681822064243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017411230714452337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017394099264727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017427845849542822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017457614412125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01744061580013021\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017415919960140337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01743773469924867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017470868571261636\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017471423792460607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017488241263197764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017474817633497675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017463534894575188\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017450120684871864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01746141543197963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01748486775075634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017443867030012185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01741085184196866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01741743763272583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01745620292542433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017496665041260503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017495787988773586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017490065761773522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01746754642390521\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017453736337536017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017424230162980316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017453734945869687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017450803941254586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01743306075323667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01741998936534704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017435617950919108\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017448213737424775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01742795408032352\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0174133814123603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01743635409025582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01740566551326269\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008224552447907627 0.01999878494627774 0.00037419520314142574 0.01794432647433132 0.04698530635610223 3.224223107099533e-05 0.02779912983439863\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0976, -0.7389,  0.8206], device='cuda:0') tensor([ 0.5661, -0.1365,  1.0294], device='cuda:0') tensor([ 0.6258, -0.0161,  1.0005], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0073], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01745977165940864\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.01743958229211371\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01743356028864409\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017397775004611784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017367877971739196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017341316354855682\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01734424512905135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017361213955350247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017362406127568748\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017351672188860995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01730958751811455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01728273699200769\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017244436291944235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017233443720392698\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017284965341278404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017294452095549823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017285949976364987\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01730997628725813\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017301785456458548\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017323450114146283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017324552311275908\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01731954160670422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017308810970547234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017285299742844894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017301873731686408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017286930995598797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017297518643602582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017299272119198825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017312954622254496\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01730084705695535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017319392444155122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0172815741704595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01727655501063811\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01726145017426461\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017260866937000508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01728979837097129\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017261066193655174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017313450626107764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0173500850281822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017331573851466855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017307436452869585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017315981160893112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017322137477524986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01730197785944535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01733526739518915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017350409271447396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01737737411295001\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017365149023332405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017377504052772386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017375107373133945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0173676849611836\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017358219972550566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017370224650382224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017358461611038732\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01736343071139064\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017393822821129386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017392197517910973\n",
      "Episode average V value: 0\n",
      "epoch 35:\n",
      "Learning rate: 1.3906419472184688e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5892857142857143 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.589284661991675 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008157100215554238 0.019794406076194718 0.0003766860877221916 0.017272604598663747 0.047789691168814895 3.480766713619232e-05 0.02589656978286803\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2217,  0.7737, -0.1609], device='cuda:0') tensor([-0.6517,  0.7902,  0.5961], device='cuda:0') tensor([-0.6987,  0.7843,  0.6369], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0735], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.013872559182345867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01550236626321243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016871982685255783\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016647682693373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018646304640505047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01763395235563318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017336454937264087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017389015022975702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017422449085171574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01751909176301625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01743265219747719\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017340195171224575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0171995491354575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017275389901081486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017092883842134917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016966485673846263\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017043377017127534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01676685892528406\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016872774885847555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016957949231275252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01702306929128195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017287647873727663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017089961791761976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017242474802683486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01718544285123547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017122968084091306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01716386428708402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016911308295906535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01685499999729267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016786166896215742\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0169302825649072\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016984684252141353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01687015853006932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0169336958803553\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01706423954890361\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017002494872064778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01715431770298619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01719426657127663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017241376299580873\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017133530106447224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01711404949002634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0170277615863751\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016994390550047853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017028700401583177\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017190383262012474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017118967030251373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01705666406555696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017010000587173703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01701959742490802\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017079714475613503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017029857323839773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017073824416654997\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01700018569866129\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017121217098592975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01710850093325581\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008129279317799956 0.019070421444717794 0.00043370559375398445 0.01715579489991069 0.04719585717841983 2.4647921323776246e-05 0.02548873012396507\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8191, -0.9814,  0.3416], device='cuda:0') tensor([-0.1638, -0.7409,  0.6847], device='cuda:0') tensor([-0.0971, -0.7509,  0.8106], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0195], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01719871517788205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017154603755395664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017227713681464852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017154757086917227\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01710478220462661\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017071391063112975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017117778350862818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017188700516355047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01713982825862735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017130992685755093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017173977931710556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01715000117024651\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017093544087092714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01713186204613407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017143305689687766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017146715038807273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01712347072388195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017071443496490268\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01709177179608841\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01706404742129423\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017048557687888457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017090731540971675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017111544529151205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017122822537305654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017097845083723466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01709883009174274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017082246662771233\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.017033548232721515\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017068395270379604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01705405691735982\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017132972392977938\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01706119587271454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01718125436125756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01719956531116132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017142142440525837\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01715714784318602\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017099382697181677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01713974679249429\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01712972981729776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01717394813622909\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017174167010428693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017161030118553158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017110033995575376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01711920270117211\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017089811021772525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01709538274337061\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017099325690207463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01706521243144313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017131269342787404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01710498280202349\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01715224668719421\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017217553350281432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017214375144683224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017243948616049463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017286497802294867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01725080036917129\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008340644670650363 0.019697580951964482 0.0004272711099984008 0.017307919094339014 0.04810444566234946 3.1904779374599456e-05 0.025840589879546315\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2885, -0.0033, -0.1987], device='cuda:0') tensor([ 0.0249,  0.0689, -0.4480], device='cuda:0') tensor([ 0.0391,  0.0532, -0.2913], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0274], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.017231474199058815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01719866634640502\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01720255527411157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017228711293425392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017166479785080957\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01718069574771783\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017169493981926454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017107314506700447\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017093710076167352\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017102418743634957\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01712612929382448\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017128693965426035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017200059045480037\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017193303460876146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01718027706995501\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017181593901131463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017170320372921804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017130040357885665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01711931258527578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017082345805054275\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01706692734960567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017107427574977366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017082890375574453\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017066490003616843\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017080566640015008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017083344166827996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017073622139863635\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01706348163940066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017052542604506015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017044130259929586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017043689355481537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01705521190352304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01704863263624663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017026455056678748\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017027249135916182\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0170286400229561\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01699211805438002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017014128019884618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017011043207581948\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01697695627191801\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01696195838392892\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01695748145631856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016958818577759473\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01696292661250599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016973648252140764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01696740719835786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016976128184955707\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01696660620069937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016947035622110383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016979863754685087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016999114879032672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017004419637471947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016990368523910077\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01699726496594221\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0170168582757703\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008072749623097479 0.018889566156081856 0.0003187060464588285 0.016641647666692735 0.047060450926423074 3.065449744462967e-05 0.02629015041165985\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8594, -0.9828,  0.2718], device='cuda:0') tensor([-0.2240, -0.7731,  0.6341], device='cuda:0') tensor([-0.1885, -0.7797,  0.6951], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0151], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01701956649613892\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.017047161783372598\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01702820082341445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016996660593020567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01698288278348013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016973866216263202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01698313544156818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017006044471422316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017014066478503603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017008581482734757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017020960162438765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01702296210961014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016988617218892114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016984050351275523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017009457896884926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017029846264492898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01701562319026664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016994102969079543\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01699023796525132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016965065208756618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01695263037813326\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016982541928710702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016964616240284187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0169538019960256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01696286913155946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016968389814859687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016983611396072615\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01697949118104647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017004473313445123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016991205282494544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016997387347500236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017020419633536527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017015092919353398\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01700152672982464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016990730633177666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017005225680911926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016996246082050654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016985623728005064\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017014167710209926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0169993154548848\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016996332295278964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017000428507647786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016985274830527093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01697315245364157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016965740332365226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016961571371204277\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016978260325233904\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01698858975452155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01699044652817439\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017011085940513437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017019696179844144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01704970144863249\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017044758907070866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017057683745709557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017038448379633038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017057420219992986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01705834611156024\n",
      "Episode average V value: 0\n",
      "epoch 36:\n",
      "Learning rate: 1.251577752496622e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.4107142857142857 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.410713552297228 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008071454260963947 0.020027665922418236 0.0004182505037206283 0.017118941280059516 0.047594612542539834 3.171907365322113e-05 0.026723799946252257\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0049, -0.9915,  0.9185], device='cuda:0') tensor([ 0.6230, -0.4184,  1.0053], device='cuda:0') tensor([ 0.5463, -0.4359,  0.9993], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0209], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.017471914852244988\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014784730789769027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016953148516929813\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017330396816962294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01631744417051474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01630523802574586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015721732292265173\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015354023916491618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015684628267025137\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01648808556298415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016361808065663685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016347219555259303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016446604524762966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016197920056237353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015945025650715386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016590609590315983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016683345179688308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01651840800718393\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016949049523917206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016773555288091303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01677895198876738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016783189531791993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01666663411176867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016611302741458295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016718511746989358\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016710815941278115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016636597364374395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016594718790627898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016492876520387514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016352313329224235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016311391133240902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016452819676487707\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016532112836448933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016421120272937163\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016402375494085606\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016287188026996583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01634605588145308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016410042554935254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016496793500962337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01640755185055443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01633635524100041\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016393273385123364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016369194238752282\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016676409072430825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016631018112839003\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016574985939325486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01655767251017457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016621920683300467\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01661010243763087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0165220588642276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016518976450096288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016507919203155696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016542575736012723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016610839188581816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016671749159242168\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008345157087780535 0.019473104260861875 0.0003661917838981026 0.016696776065975426 0.04685481309890747 2.7733057737350464e-05 0.025362075861543418\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8768,  0.6079, -0.8388], device='cuda:0') tensor([ 0.5212,  0.5210, -1.0726], device='cuda:0') tensor([ 0.5337,  0.4132, -0.9989], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0726], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01670745757245828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01677814631978845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016723099707044175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016841605754670898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016825868293677493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016811700084014287\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01681745833196547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016758140803165275\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016811986233935587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01680838258172839\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016746707163399918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016689477849807312\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01667855793208468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01660264403320813\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01663190007638482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0166207196880336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016612025384538244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016629678307064275\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01659815966895594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016594550937276197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016591321580297157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01663751153390946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016659796515219656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01663068481806126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016665348642143526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016679908317578918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016725379597587475\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.016692084706621556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016699307298819934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01674901239111338\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01678943141539237\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016732230203257134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0167497000657022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016793251872416145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016760869860580122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016817678122579942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016743834213700126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01672929333547395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01670457291181241\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016661986528367503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016641156008484325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01660949213511363\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01660634438156693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016607334244657646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016633530588199694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016625533313813185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01664604535752457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016641454820389565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016644940341416843\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016616230684692267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016622403582882143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016665234576682498\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01668350076889274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016680269740392793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01666484242352196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01662668742069805\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008333335733041167 0.018815344291273503 0.00040623873405638735 0.016539545070379972 0.04761309843510389 2.5879159569740295e-05 0.02725424233544618\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0588,  0.2489, -0.1988], device='cuda:0') tensor([-0.3153,  0.2625, -0.1070], device='cuda:0') tensor([-0.2253,  0.5510, -0.1109], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0258], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016616609719921908\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016595668222612336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016595452472015663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01662379448585536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016627651889062706\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01663753616023041\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01663980048006004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016657097907745593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016651556530484446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016651980254347578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016674292057952785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016679140085029704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016695138724190334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01667560789609949\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016674196153363408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016688106077611578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016681106189935235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01667195596290202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016657847601872607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016691791096289876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016717685144692535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016697212074530825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01671529732718693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01667691174771928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016715160675279894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016722451471734946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016720201617673687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016720888009078973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016681564827671365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01670855583206195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01673087768193993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016698503840378926\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016699892692598455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016714548992913688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016677568766218998\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016679643109533723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016702928560416778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016695140340100865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016696408882875134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016687960066504342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016666079982325478\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01665257185849056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016712904423287118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016702509324957607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669879017551655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01668146746898807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01666223114937984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0166692947545808\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0166625747586497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016693254545513538\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016675368913855602\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016666562423261103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01668685434249212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016645411976929817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016641531184651056\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008174929854460061 0.01954587055882439 0.0005623895754833938 0.01673421472730115 0.04716859436035156 2.7004308998584746e-05 0.02748676942056045\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2475,  0.1584, -0.1237], device='cuda:0') tensor([-0.5799, -0.0267,  0.3820], device='cuda:0') tensor([-0.6219, -0.2454,  0.3522], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.2813], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016652774199730633\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.016690854126835124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669394669893279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669356074424619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016685155528198742\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016662059629905142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016656282616123633\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01665968196017556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016651292690593334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016637472798160014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016618877271194963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01666541422932954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01666373425466254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016694092139871906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01670013182765665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016714068728792497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016712938254850655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016728513889157567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016712583557985074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016697984863503244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016690844195561213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016674445173785697\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01666608892026949\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016656481091080134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016643661511693542\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016644567068363324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016613927857347676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016587964548059404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01657805969697182\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01660639459365987\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01660312464036829\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01659446534835007\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016605773058369973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01661321549430593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658964727803418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01659591137613421\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016600984553809033\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016584130611360957\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016572172348803985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016544924941071647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016594832251798232\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658890883497492\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01659577624099443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016606567932721524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016620812336475308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01659678916404887\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016598828556429038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658753208382788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016581686861928582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016573972030161446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658055493612886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016577714848143184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016559884232340852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016540613428529614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016546605670400425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016551541125828826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016563947738613933\n",
      "Episode average V value: 0\n",
      "epoch 37:\n",
      "Learning rate: 1.1264199772469598e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5535714285714286 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5535704400527856 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008115617679897696 0.018599808039842174 0.000508448179512925 0.016324653470423073 0.0472609677426517 3.0313387513160706e-05 0.027457479930715636\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([1.0003, 0.3140, 0.3057], device='cuda:0') tensor([ 0.9509,  0.5931, -0.2323], device='cuda:0') tensor([ 0.9999,  0.7555, -0.1006], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0635], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016318657849397924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016466156967605155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018074682137618463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.018252261784962483\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017930895793769094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017282096548350872\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0171013730652039\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017415140820149746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017643389343801472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017553248468579516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017821016928388014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01755483804218885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017284851397873245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01745483210857307\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017283509330203135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01722367700616208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01711521897574558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017127056166322693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017180914786366516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017302950272440082\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01729130164212572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01736111820656618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017153574149281793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017151558023653233\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01738221613276336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01728375370685871\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017450207844376564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017532252758327458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01749293060288176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01756000536907878\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01747770258976567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017455767447245307\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017357242577442717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0172210745619963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01725852367216869\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0171532614507287\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017119754887502024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016986012210993218\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016989704171073573\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016910142252325185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01698541805415659\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01697336160331452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016965306082437206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01705663696382985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017093585168275936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017059476694074156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01701652088112266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016999923375098862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016962423825598493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01700828137497107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01695325180953105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01697413969046683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01693386676237065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016891904889582945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016849512648721688\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008458835811819882 0.019370600243564694 0.0008202314879454207 0.016781570642720907 0.047897330164909366 2.852313965559006e-05 0.026065087573137136\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6404,  0.7721,  0.6393], device='cuda:0') tensor([-0.8383,  0.9361,  1.8303], device='cuda:0') tensor([-0.0041, -1.3137,  0.1106], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.9771], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01681462849725023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016756175425844032\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016767184359335493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016682326012745274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016619090500063504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01660103474417956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016607570232853534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016572723212377603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01664019546822399\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016611166344159562\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016573355223917674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016576150413309138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016580997980306277\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016627375283555974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016637552863297364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016590102548391817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016618663967187506\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016700744554131113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016710995987698145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016644613218873186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0166288737390784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016597396087017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016583112120546105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016532761949597845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0165793297847914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01659032729881035\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016566501362160917\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.016589540954232915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01655694815390571\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016554065036824814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016613323055869524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016614401743641434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016573502387289392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016581125608872108\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658749712406899\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016604216339780754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016577616134030825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016635728481736396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016683771988062132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01670095116874933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016770300906770258\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016766299138097403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01681746640205679\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016790995816203663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016774784366651956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016767580662285387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016761208715755288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016731517823179932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016664256090765946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01665645041207354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016671058950522052\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016641782989593946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016652263544064873\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016632085322629313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016643358210826086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016612811420752376\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008425200894474983 0.01889418434933759 0.0003609527677108417 0.016420796916820107 0.04761493840813637 2.2299818694591522e-05 0.025605896504130213\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3664, -0.3902, -0.3055], device='cuda:0') tensor([-0.3061, -0.4777,  0.2069], device='cuda:0') tensor([-0.6594, -0.2643,  0.3044], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0147], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016593619590922672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01660388461753704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016567234206104155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016540100410409667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01667530618459022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016658482613424078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016642163257051448\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01671724929039503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01671150195502883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016723448297101234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669946066693374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016678714860767437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016648577517240665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016650811328863105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01666615975300438\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016690233958419006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016681211795811477\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016665837537171598\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01665743557222856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01662032569022383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01659484915235409\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016612688767464648\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016635777852127318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016658578234544568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016641473191603105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016690543796663192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016660871941576772\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669233513651319\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016707575304751535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01676899708357586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01675093530750861\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016731731748286557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016698474039138225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016695408647080662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016678501010370616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01667221503185132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01665514078275818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016627525664014514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016665128873212746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016666985001939954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016650301327538128\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016640809690106333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01665004743494948\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016629450143178036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016604809646204147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016610124507808223\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01660767273401708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016611762201168803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016597606413253946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0165864090855234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016581553974590012\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016593837251457567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016611358712251906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01661395463474747\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01659061477056404\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008037255187053234 0.019099002281436697 0.00046332198572781637 0.016492296488955616 0.0470225336663425 2.2660322487354278e-05 0.02654538558726199\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.7492, 0.5890, 0.5717], device='cuda:0') tensor([0.6489, 0.8763, 0.1253], device='cuda:0') tensor([0.5706, 0.8145, 0.0827], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.2005], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016581881053514002\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.01658841085305472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016584132464460534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016583436559672694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016587591546244528\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016560455749457515\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016561429876584127\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016565453589567975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016570507604480974\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016549270494689346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016557058019678144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016546553369819625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016550776801747862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016575077771536866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016593617581355885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658205044076588\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016586718434619455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016638047986856218\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01664474965492683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016674135608978017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016653562985738023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01665535583130544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01663389720878444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016634538876333912\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016641023473320023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016638949289632297\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01663059565435964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01667794220313272\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0167053990369859\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016735593678114002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016737835039082626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016743373525209774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016724222145859197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01670930769980057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016727523287066302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016729433391611037\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01671321066027608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016701626756369523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016710445207990404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016719739328936233\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016731177344573318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016719547960918166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01670207582690923\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016711357787187412\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01670440945545287\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669751043347017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01670980892080015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669156799073063\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016687218458283432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01670258900966522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669857751602413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669245126961458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01668486193463656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669776873096278\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01670071218748539\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669280523575518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016696276792674325\n",
      "Episode average V value: 0\n",
      "epoch 38:\n",
      "Learning rate: 1.0137779795222638e-05\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.6607142857142857 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.6607131058694538 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008406107469461858 0.019660385609604418 0.0004608136142414878 0.017043282135389744 0.0474829141870141 2.6097536087036132e-05 0.028159800574649126\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3144,  0.9194, -0.2726], device='cuda:0') tensor([-0.7481,  0.9086,  0.6007], device='cuda:0') tensor([-0.7639,  0.8553,  0.6000], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0996], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01405582380377584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.013140147655374475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014457969857310807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016051177569251094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016379174352106122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015648864589079662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015398790409404135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015854878997844126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01619158367867823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016395026419518722\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017120676999441302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016745980643598293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016789123356246795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016616714412405614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016410266121642456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01636990576904888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01620014637002563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016079206194981564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016145748797019844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0163757664979332\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016727902729399304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016421304166674464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01638321757118627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016426078854473652\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016436358808229367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01646691970885373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01655981871740195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016562340017925534\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016612439692891078\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01679221319069189\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016861673633110672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016782378113324132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016593896067365752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0165923738142999\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658772373838084\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016465517182052594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016400530814072927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016338698594553166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016371130713784373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016366965053344354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01656077269888748\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016623726784788743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016531084453595624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016646178553323027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016788957993511433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016818811310509194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016892517935572716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016882358905773057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01690211223624224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016908359439629646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01700865669370769\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016939933380931933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01691983476285071\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01687327777648751\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01688298424799936\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008196453216020017 0.01947819733712822 0.0006201143524303916 0.0169100346500054 0.04706210070475936 2.2089287638664245e-05 0.02604964509513229\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9518,  0.7399,  0.6125], device='cuda:0') tensor([-1.0896,  0.8044,  1.8665], device='cuda:0') tensor([-0.0089, -1.3149,  0.1070], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.9921], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016885836820288134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016841915193727318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016797082305090125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016852110853197717\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01684250722691003\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016884548219772418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016915166455130744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01684217577852716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01674446374737373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016723529909315527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016695215420088783\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016771762139143834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016728919089217885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0168400380352509\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016790472998446417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016828426572381983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016856263821404198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016827782689022464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016861557860525924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016999391315297947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01693560611197932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01695322234137857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016983369525198286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017047212817398346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0170498542920945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016997549979882353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01693522885913751\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.016887202732379696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016846937461874434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01683461194541427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0168029737859743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016797894553077973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016830565337905414\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016808884036953978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01678839413460666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016704109813494922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0166810378106086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016671838194327684\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016742306700896638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01675369655005416\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01672271903522347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016709434312319155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016734694422152984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016702689506389475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016702807059304582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016700320356147418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016676017442365097\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016697326761458426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016701823775557022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016705481023601598\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669482570248939\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016675880380450658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016670362431260875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016609175581671107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016669219250630852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016634838474733574\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008365003630518912 0.01881529546296224 0.0004145183009241009 0.016377853999845683 0.04721585150435567 2.32163667678833e-05 0.025224075891543178\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8640, -0.9828,  0.2594], device='cuda:0') tensor([-0.2287, -0.7741,  0.6254], device='cuda:0') tensor([-0.2003, -0.7829,  0.6834], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0127], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016614870236639583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016646509153096255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01667308840051032\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016614527457758137\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016607177469672427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016565716762187672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01653980438223919\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016511899286952396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016465184030864662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016451599893542442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01645452862364564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0164910232771925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016517681859126547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01653507224553161\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016502428213068705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016548313989205414\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016563267326596867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016550796550059248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016596646633986224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016630410562736234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016608416007969667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016636352139581912\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016647530401474604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01668747828299862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016722711380662433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016768900802191303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016810516242669736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016756367781084122\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01674685949674024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016746385648649942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016743106911460255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016724575480638708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016766579050274656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016761918115818522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016751591426630814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016759925168176558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0167374545208377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016745834131110502\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016770849678734386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01675575857535224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016757277398756897\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016734049695063067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016738131723311577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01673525699871629\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01673416241750047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016723473743197454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016723580607678087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01672446201597734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016723005452594305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016732826113914256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016686215451873827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016657593185507427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016616767154675895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01659555608917793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016589540385558873\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008338434644043446 0.019688683410175146 0.00045477083519654117 0.016451894641388208 0.04696693721786142 1.9095167517662047e-05 0.024552581845549867\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6197, -0.2387,  0.3512], device='cuda:0') tensor([-0.2618, -0.1320,  0.8081], device='cuda:0') tensor([-0.0049, -1.3149,  0.1053], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0177], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016576761292623317\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.016572558069287518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016568771584748114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016615632880521706\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016654266066131525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01664943529912018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016636019505772145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01664413796338737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016640584895032503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01665407318590712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016627037313217807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01661145115941507\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016615596701767387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016598811492548084\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658785484597988\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01656621582712296\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016542803954573956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016523052532094247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016499218789234132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016498763046200692\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01648552050613159\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016485168458095775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016478823399201894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01647165725048501\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016507124253741016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016531701973791415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016525959377951822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016518360454688342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01652068732919283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016500305031323825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016511825463423075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01650788626875561\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01649256048649695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016473951601914855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016479615902171906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016511211212856616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01651341075648069\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01649879591353339\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01651199978756085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01650687310246383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0164953808169472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01650498499016727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016548952138633652\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016524575252416074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016506132778744475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016502863338116586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016510154920167167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016520631421132057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016547553889207946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016538937870387196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016544601922574384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016537639395159145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016547222858349656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016560844003077068\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01655582099665535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016554566890675318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016558300983975642\n",
      "Episode average V value: 0\n",
      "epoch 39:\n",
      "Learning rate: 9.124001815700374e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5178571428571429 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5178562181138961 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008120387670584024 0.019465184226166457 0.0003597660648665624 0.016506555133499204 0.047333351403474805 3.185929358005524e-05 0.024913203955627978\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9080, -0.3984, -0.5879], device='cuda:0') tensor([-0.7708, -0.9772,  0.1955], device='cuda:0') tensor([-0.8612, -0.9839,  0.2548], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0465], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01699728870557414\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01701526530086994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015864159584183385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014793580397963524\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015632451325654984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01624607106808711\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015670315007723513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015239810286503699\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01516122614711891\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015033444544921318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01522971848214064\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015066511838489937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01554608590598417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01575085099062158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01603930389370631\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015718090157153912\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015691391968478758\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015633002268495382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567492894937246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015845618164166807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016111090843363728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016069778285901806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01619933676964419\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016327374226724107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016480602642728222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016253205465996623\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01612162564348414\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016095641747279656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0161442125797757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016252087456760583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016158205149928943\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016177149015776295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016342257345502927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016347045949325453\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016278308928604164\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016333331552299636\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016420825770510745\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01646043448736183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01644055285037328\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01635699575094299\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01639569427838251\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0163806443676727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01635033121448039\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01626904899221516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016400855403669454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016357457410355193\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016263791044015905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016238198258819198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01625777412176369\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016265611895877455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01618600102275415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016137155939020917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016168956916224782\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016169590072576033\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016176492496948653\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00812988488888368 0.01911134582804516 0.0005552112903751549 0.016151874646544457 0.04744428382441401 2.3668698966503143e-05 0.02609047274244949\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.7721, -0.3824,  0.9731], device='cuda:0') tensor([0.9642, 0.3261, 0.5464], device='cuda:0') tensor([0.9997, 0.3181, 0.4709], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0117], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0161293150990137\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016178193050082664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016258768750697202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01639657030092542\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016422948963871156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016421970095356522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016439757286487514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016540879207930972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01661289885426716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016580150502487127\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658581684246308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01659167913340069\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01655906818813212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016673238937489558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016766891260409637\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0167185144560158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016691382127859988\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669119467995664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016689284266931965\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016741011472487893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016776809600938917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016795784437257533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016767488064196628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01671333038333264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016744727827608587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01672213334227377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016731793460938425\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.016822509932016314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016813735061857318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016800358814181262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016784179194057867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016735254439000768\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016686403449516593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016749589894078532\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016720182159455654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016724961741016644\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016721884934299127\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01678397196980378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016794896717062198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01679464924525012\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016812450130129473\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016773535012836138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016773536167257463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016796261552453676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01679667951590899\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01677307070871227\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016750676443796273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016778206641101624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016820853689494424\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016867073728806442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016852248019775067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016852956260375578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016866673289514588\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016895672340120713\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01689223543966584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016916524740057188\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008317215393297375 0.02142585988342762 0.0005578023215057329 0.017768792059272526 0.047857470162212846 1.7692573368549348e-05 0.02576306237094104\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3914,  0.0233, -0.9992], device='cuda:0') tensor([-0.8158, -0.3201, -0.4036], device='cuda:0') tensor([-1.0000,  0.1527, -0.5419], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0393], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.0169250448211281\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016895318458327473\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016897527918085225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016932452792652708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01690947667872212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016919915298581945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016961152127307266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016975674987357567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01692142821762159\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016927432731526013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01697005421340547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016941722243512765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016893784854374157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01688109528563089\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016872120998155923\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016843869233926008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016895272876556393\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016872973559130686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016859059852078303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016841169423798923\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016845331028705897\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016804214758345655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016783773926492922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01680388825106216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016797202824557114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01677663957009761\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01677371305975937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01678001645358382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016770171694132308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016760085849568448\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016799089746223253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016889802448338632\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01687659024667673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016861094502282552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01686347536586758\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016876717830866642\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016865490465536825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01690456342670197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01689561042831176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016914775668738672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016908922909734475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01689267595797052\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01688261087318616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016863287999010962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016849257537506074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016881064577087476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016891908617729504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01692707867737128\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01691920735562841\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016906818501931518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01689515691167523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01689333520764923\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016904517590209618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016886915821230874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016868058647873153\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00814884145744145 0.020168604313163085 0.0007570812242047396 0.016649627222679556 0.047344443548470734 1.984650641679764e-05 0.025726668192306533\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7447,  0.8223,  0.6330], device='cuda:0') tensor([-0.9642,  0.9556,  1.9091], device='cuda:0') tensor([-0.0075, -1.3172,  0.1064], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-1.0307], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016866820313827104\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.016865265068768096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016885469910088022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01688776920835664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01689595966330591\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016877267519024127\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016838216843405307\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016836412460037708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01681320740737849\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016806526812771807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01680669647378979\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016795537837393834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01680217610127544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016838616438865386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01681735788793872\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016808399280717413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016835875581592576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016844796165002843\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016849450602870176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016830416279984026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016809979344945592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016801376034721434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016777715637244017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016780601872120337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016780442839955403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016770292287994246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016793145002474474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016783519952055515\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016788207856869256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01680848610169273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016834940568024467\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016824440383608426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016829623580228544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016826513056488086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016822645421906472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016833193777170036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016833239218671758\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01683029251615466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01684925842898971\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016846737301955652\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016835747647858553\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016862937702715762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016864768826788425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016855007527080714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0168664941069851\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01688139449411601\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016880418865294834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0168610226889049\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016869871441554038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016861985114675185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016836731593304347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01682492815101449\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016834238175782817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016826423325792254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016800506093364646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01683675134144313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016835734288673847\n",
      "Episode average V value: 0\n",
      "epoch 40:\n",
      "Learning rate: 8.211601634130337e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.44642857142857145 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4464277742361174 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00840359996119514 0.020167960710357875 0.00049971175918472 0.016761639685370026 0.04642410014942289 2.8595641255378723e-05 0.02692368500493467\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3022, -0.8706,  0.3717], device='cuda:0') tensor([ 0.3454, -0.4840,  0.5588], device='cuda:0') tensor([ 0.2485, -0.5053,  0.5861], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0030], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.013932905832512511\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01586086103796131\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017575147820429668\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01832508219457749\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017106224301581582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016765326809103566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016722484192411815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017254051238220807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016744349666376723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016491484329000942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016462745039131154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016456026711104507\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0162001364868389\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016185006472311678\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01599584891529823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015875050356650416\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015855782319870747\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0162247258172382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01615346137744685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015923090083783287\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015958689223413192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0159649896644752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016100679464629234\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01601540352782683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016000417033210396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01607332028484402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016154101042751483\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01604449831315183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016163216487208375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016085808712954598\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01606015916196062\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015976472782818343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01601563531337839\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016218324172846195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016210175695134298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016223926024574696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016223564501376346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016420319372085494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016334417624335386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01628574094696281\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016340202615952225\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016232265553082385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01628026110842073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016332249297652243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01639757657159166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016329559131417478\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016313463498466158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016400666910124494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016413133168517023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0163161849991108\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01622565306493838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016277171700743116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016207542066878213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016226015572528136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01618604639197013\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008347686348948627 0.018768262773985044 0.000499224292634608 0.016167507730890065 0.04744398110359907 1.66374072432518e-05 0.02541579348500818\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8264, -0.9850,  0.3362], device='cuda:0') tensor([-0.1678, -0.7406,  0.6792], device='cuda:0') tensor([-0.1134, -0.7549,  0.8030], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0234], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016158094169989614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016159194955950855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01609386244505087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016081951099505786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016141490191135005\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016120736241656167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01612232240479386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016051013062492906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016140044431166543\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016134145378700306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01610748701209911\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016091498904235994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01609074683697115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016057018117511257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01612648885837564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01612810250655901\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016067409217803176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016020356864233243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016003987838251254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0159553082090699\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016011538669910848\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016041739724514652\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01599823105768526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015983512356900906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015985068915890428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016048810721039055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016103479014596016\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.016043604892981518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016023251944081118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015982478685689226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016020726571064105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016040366541744136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016040978604290313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015979017440599392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01607510767859855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016008299034855285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015992628415801298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016010152621933546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01597927102293978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016014173690894105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016024284865933523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0160167865571966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016010758156313767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01605792477696624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016134510149713607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01614157053359197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0161368232938179\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016111928170161098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016063654552757118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016069755789690783\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01603697782233006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016041995114903135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01604039926889617\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016088638229439914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016087278772399505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01617930004362938\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00827333101304248 0.018904048211639747 0.00045231975807473647 0.01622485720459372 0.04732665924355388 2.109312266111374e-05 0.02625643218192272\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8968,  0.4402, -0.8743], device='cuda:0') tensor([ 0.5706,  0.3452, -1.1379], device='cuda:0') tensor([ 0.5577,  0.3219, -0.9964], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0673], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016183332760221443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016158041408955832\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016171161337033075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01616592898375494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016192132839263983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016221111415021285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016257247923726036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016221519284616428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016203617059875764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016213608725437735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016216842018497026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016268604347741446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016217496137820704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016207581142791444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016213547598325845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016206626086728036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016191560405382513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016172014057121264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01625528925150219\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0162480356461235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01620886557063665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016180238738436634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01617028216686977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016191128118408254\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01620467185264216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01621945246480804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016213926337636863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016203795135919033\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016203771730227072\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01619918659271436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016158819976714565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016148329830222647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016156230611046835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01613665956243787\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0161150797045913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01607141050985977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016096212481835147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0160748616718992\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016063831604982693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016077912983267325\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01606304606076259\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01607160734843947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01607386893065294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016037566510052503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016074001726905346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016101728005121184\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01609570713227146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016087968749951526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01608427518981949\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016056055345927963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016020633839677625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01601995999198572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016011246046724006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01602492980699773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01600928282333411\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008103824045043439 0.01856602636235766 0.0004494336558345822 0.015606711760163308 0.047282344959676266 1.801525056362152e-05 0.027336837843526154\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0247, -0.0053, -0.3764], device='cuda:0') tensor([-0.3733, -0.0868, -0.2310], device='cuda:0') tensor([-0.3005,  0.0255, -0.0898], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0292], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015992672721553577\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.01599519231055479\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015979364305400312\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01602427431981816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016021228719005257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01603439578726931\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0160145905718516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01600107224925753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016001117284158393\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01602332807184818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016024343003808273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01603218048814447\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016024887775695894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01601375602070748\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016007249254420024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01597516678281638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015958395713638305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0159795401794476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01597804973131275\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015979172587350206\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01597557465124718\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01598698544991918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01598397357994882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01598079131251713\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015971555497818056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01596717385891006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015961890883913192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015976261542491266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015942465703658485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015938559460217164\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015942217721995146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015924132952997598\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015938157547475372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01596452283905819\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015940911448295517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015941567156756885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01595515505597811\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015965404413277304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01597519595716098\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015960448236931057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015932871175253032\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015913801009042397\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015936440346066397\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015921616032423955\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01593079331334388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015938584450671384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015947074774870368\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015956113866393996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01594746118719456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01594318338399638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015945058642646715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015938390578474626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015963080242741144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01595148999347455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015961001108809294\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015950521369612922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01595224555605091\n",
      "Episode average V value: 0\n",
      "epoch 41:\n",
      "Learning rate: 7.390441470717303e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.625 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.6249988839305644 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008371133777312934 0.018770287099992858 0.00035557544955736373 0.015832369301002472 0.04714922908693552 2.0983248949050904e-05 0.027778409836813806\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.7760, -0.3804,  0.9737], device='cuda:0') tensor([0.9429, 0.2574, 0.5872], device='cuda:0') tensor([0.9492, 0.2975, 0.7025], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0546], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016552965104993846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017049969613759056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01669803715345484\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015618210800716447\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017698493517107432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016649670657460338\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016796834903606582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016338466954443395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01675640509095917\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01665298679791805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01631612096668569\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016263006671107614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01629810222488247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016091523350157316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016398432221332634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0162828875876989\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016125969276793935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015861529671518063\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015737159987802656\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016020240369511562\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01600277051699185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01604379625694657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016013819486991578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015830749552050192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015925912651129893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015963045057331204\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016016304214128557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016105935521726865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01600260485117092\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015941703015145053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016052471100783314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015949250206176657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015922146208853984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0159352708180295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01586874929138474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01588910499682512\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01587700304105408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015865840647527565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015987671188017794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01616985590210081\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016235385844130625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016357172048335315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0163406166542822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01634739618336857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016550550260868522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01655248457910088\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016532477760361618\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016587666540376463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016532039607171804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01656864414560712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016532724655754782\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016683700505910743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016611154583151953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016516142020791522\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01646594050895385\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008501236624550074 0.019957964342087506 0.0004992416298337048 0.01648323054611683 0.04704405891522765 1.989511400461197e-05 0.025820078254211693\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2683,  0.9969, -0.3826], device='cuda:0') tensor([-0.1861,  0.9582, -0.3927], device='cuda:0') tensor([-0.3125,  0.9480, -0.3203], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0153], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016527417492831036\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016459448309342938\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016441696727562738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016501111465132674\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016464319407801936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016364015884806005\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016396074309631328\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016344252611613937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016287087694864668\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01626993836118625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01620858782268935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01619626866007968\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016170233430255667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016141774069859786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016173553002613878\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016208889078733645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01617953987909987\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016151639627210536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01617743147609828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01617404698083798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01624456760800329\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01622759940137638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016200426180563082\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01613909246481211\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01612807471279262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01616723637833721\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016202759203377375\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.016218788743547725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016286629895191817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016256760641494217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016267486993531463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016274469599513144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016271613916909\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01639643640660875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0164322272868666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016409552208078576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016356576648585787\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016339433588657255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016355826276691354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01639667284124863\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016333875035612705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01632586012798162\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01629657060902591\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016288932391435043\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01634616047402637\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016333425525120973\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016329714661151625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016340552777968177\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01629933653673969\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01628254228542564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016247741521220944\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016235755822260556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016235000177941942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016256568306880444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016296011775336933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01635552006815602\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008374758032150566 0.01956180070526898 0.0005506227735568246 0.016208871708251537 0.04754645828530192 1.8455810844898225e-05 0.025000370385590942\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9797, -0.3243,  0.5873], device='cuda:0') tensor([ 1.0647,  0.2167, -0.0438], device='cuda:0') tensor([ 0.9971,  0.1699, -0.0508], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.2209], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016338919831757684\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016359674070312503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016365996149838784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016347517105098363\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016391593668078182\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016423854403328664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016398654869633066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016438135179846672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01649875113464616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01650030185281204\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016479591955642855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01650613559706115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016544843615803828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016557589591377313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658564787013111\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016626963128717916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016632237064994924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016606979800065744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016564571552185547\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016555458321879865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016508043665667802\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016463087158979428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016446327546975927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016446393256462775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016467190602888638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016429028771017033\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016451559561543202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01644427559824644\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01642190634295167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01640228946547195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016392580018902026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01644513303726599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016479814050354088\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016475388601465128\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01650765832071299\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016534136418881105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016567226509107753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016562343928560135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016534185541310795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016526511676384737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016551424517045724\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016529860181940928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016527173867312086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016521879213805372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016562351361620226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016550031541045875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016533249775314528\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016529845520606684\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016567198208132242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016569175740756645\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016590520679511243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016627408675189196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016600061603001544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016571626090679806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016579821360779994\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008367794408462942 0.021912612293148413 0.0005047616023075534 0.017048551654443144 0.04694907488301396 1.99989452958107e-05 0.02474653445323929\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9999,  0.4696, -0.4458], device='cuda:0') tensor([ 0.7720,  0.5421, -0.8102], device='cuda:0') tensor([ 0.8605,  0.7757, -0.7811], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0064], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01658912197329198\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.01659434214825668\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658764264235894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016605442649763977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016582618857224975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01661708823511093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016619749239830728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016624110435060728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016626934483351688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01660048995476282\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01661456837853778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01660178193953888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01661555910156953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016613163634341347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658333431354205\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01658298340751147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01657326486847761\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016566972311947196\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016558539918442076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016541609630292435\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016535828000850936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016533560799759532\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016554503942396864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016559750137561988\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016528721916537523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01652633443653165\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01651344020144824\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016505745117406427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016489022402650017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016484218097055362\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016479416773221164\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016489330780568013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01649722094439066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01648477500097619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016491837795945312\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016493683312051366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01647912603499675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01646643012461774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016455616653066503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016420713553010228\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0163984475147441\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016388490003818233\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016396347131057268\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016418441072372454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016422553237806174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01641493210880441\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016444969931291877\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016472365763734714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01647618346551592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016455809969010422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016448158251013867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01641983981244266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016420324436019876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01643272770963835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01642538141412403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016433408526047407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016427639533532785\n",
      "Episode average V value: 0\n",
      "epoch 42:\n",
      "Learning rate: 6.651397323645573e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5178571428571429 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5178562181138961 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008364690874237567 0.019533932871185242 0.0003503236855758587 0.01595065738260746 0.04727795821800828 1.5886664390563964e-05 0.026388637328054756\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1530,  0.6232, -0.2191], device='cuda:0') tensor([-0.3113,  0.5544, -0.1520], device='cuda:0') tensor([-0.2273,  0.5554, -0.1061], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0260], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.012592712468985055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014018727337113686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014392671813429505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015200535262313982\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015407623598972957\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01579159449061586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015340320063784482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015341670439940773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01563392115044005\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015705866190708347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015841715527002257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01621265800807763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016538358229793545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016490375172228566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01623550993217914\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016287248843582347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015896909973687597\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564004528623672\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015473807652682414\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564090159566452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015593103544599323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015583039510694115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015648106014095067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015510200484034916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015489825985083977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015514358840325577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015419697494403202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015608156962867176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01544024030074934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015446707570097513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015334414052827063\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015261278350307193\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015201661926270886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015401691334547317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015414363938930725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015431245648802293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01553868774853244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015510172824843715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015460434743200569\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015494778681831021\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015398637108318004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01527662350852831\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015277481293161364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015315422761804339\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015219255218880227\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015163952126482654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015228726290690385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015304705183586554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0154430054222147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015355044142343104\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015380177409986687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015514869005598415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015458948591497552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015458377103566541\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015418871236739285\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008345936322584749 0.01778611339209601 0.0005472560737034655 0.015396490721497685 0.04742318219318986 1.7635077238082886e-05 0.027656967121642083\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8391,  0.9981, -0.4410], device='cuda:0') tensor([ 0.4894,  0.9922, -0.6717], device='cuda:0') tensor([ 0.4362,  0.9188, -0.8451], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0518], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015351325580720894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015371066622969788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015317960182415371\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01541558651581561\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015379464932010268\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01533060305572042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015326051391564363\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015391753705192154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015496859573936995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015413392367414557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01537426888843942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015343645418828869\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015325492399735558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01534308557137667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015352252695990342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015374303019659504\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01534608595847888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015454810181819753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015454717589802368\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015492757554338486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015472026979918346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015434305965403178\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015411577201740249\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015511532987071051\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0155365359836853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015535270937351799\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01555934437420623\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015536180741952824\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01547644277400135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015577722230341796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015633096542144412\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015665685899834008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564449821263693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015603653106143171\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015585116684195344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01574838549661722\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015776038089719856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01582996133996425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01581635554601828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0158541027818703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015851840789966647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015786935753196493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015837231311733813\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015874029070036495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015862527680324597\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015878418735325812\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015904937896416938\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015893556430037693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01587888580109152\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01592018699652895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015951199988362065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01596034094347954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01595323864938768\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015963683307605676\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015924873647769216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015892402712000278\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008353243145160377 0.02032768804207444 0.00035109882401229697 0.01645617244578898 0.04675875227153301 1.4784723520278931e-05 0.026387849893886595\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9503,  0.7121,  0.6369], device='cuda:0') tensor([-1.0788,  1.0802,  1.8869], device='cuda:0') tensor([-0.0050, -1.3206,  0.1041], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-1.0971], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015930460798526405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015920642662872152\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015884287630618128\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015887287816770627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015862342936541686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015846158032670817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015882099184326884\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015871345374453203\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015870995021261342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015905192934525695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015874139466051533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015848733218262256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015881756324976962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015876437843052878\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015917565080425924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01592252714529288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01593240564175681\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015937710034281568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015932476540637387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01590945356583935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0159382050680953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015924331444022288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01593457174176199\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015928667824171145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015907969245317337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015919924021977252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01594876649998722\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01595550219470309\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015940102527383714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015920054253192224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015898909352913628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015938344251085146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015929162832311883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015933815659812414\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015919037535892945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015907041316511262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015924941840499092\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01590710204482873\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01590456873782117\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015883145509685188\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015847963908154857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015832096406075354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01581780179044229\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015794276050709214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015812165586594918\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015861314457596688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01589028539189102\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015881995440595462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015878950406557932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015857839683556686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01584142455891853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01586945574834115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015866186313153192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01585906983842377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015843259526754527\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008370828876737506 0.018573908030521124 0.0006465676892148622 0.01572820775769651 0.04762503069639206 1.731971651315689e-05 0.026140253357123583\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0641,  0.3178, -0.9762], device='cuda:0') tensor([-0.3906,  0.0753, -0.9707], device='cuda:0') tensor([-0.3314,  0.0381, -0.9739], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0078], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015861755055582977\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.01586674679906561\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015864451564781067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015873541901636794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015839691311235964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015827636650639517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01581325005711814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015800820949182896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01579473780512455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01579147677664584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015758550092864407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015776741740610056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015785140261570862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015783818648627924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0158019554719816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015796752963971313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015761761905899146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015770272481854745\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01577644752263016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01577063125968224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01575194351390044\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015765917217870844\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015780162737611188\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015791918516665567\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015787309801602575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015782554299625592\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01578889136223008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015786468140318997\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015794637333999714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015796059062688605\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015779866327574183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01575527781075521\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01573597677434222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01574354911184249\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015756651577799728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015749550257897572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015749255472694262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01573469859640741\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015735259106594734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01574768739319964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01573598107247565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015732458157690726\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015720905406957076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01574185394654888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015718025320026634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01573029967999687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01571773394422939\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015720851191944274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01570890527880373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015713270900578433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01574033140910611\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015739792505413044\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01574823288268252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015749401510152212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015743075797283745\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015724272917824664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01573122692143079\n",
      "Episode average V value: 0\n",
      "epoch 43:\n",
      "Learning rate: 5.986257591281016e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5892857142857143 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.589284661991675 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00827786304289475 0.018768504961626603 0.0005492255631834268 0.015332432333379983 0.047694452725350854 1.5727847814559937e-05 0.026049559715669603\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3989, -0.9984,  0.8961], device='cuda:0') tensor([ 0.9626, -0.3237,  0.7882], device='cuda:0') tensor([ 0.9516, -0.3521,  0.7095], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0252], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01851457714413603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015790956017250817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015589581285085943\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01515271223615855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016096618440416124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015771496161404584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016783126585540317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016858025525127433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016604332828227385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01682315358064241\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016907237150301836\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016520098144947377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01715445835302528\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016950328486956774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016397422624544966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01627991123112022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016302510435552964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015975498588594757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016021589574278794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016240944343412087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016147919050935242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01620676045334249\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015964414890639593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01587016550022074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01578253907461961\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01565856250743262\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01595299551646712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015911143337790336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0158148144239781\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01579286484737639\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01589421565414116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01576598104859133\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015845619486989797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01581467259096992\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015815381875764284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015815648306333634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015722552903119597\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015692074730044657\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015557136441026404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01563938785628933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015604824882737666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015641096858652653\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015572215061037963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01570610710386789\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015695821667480982\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015656022628283372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015610355682380445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01555387958284916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015485825370828243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015504979674393932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015495274658264158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01561318859995271\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01579505212671383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01573141183083256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0157529037709188\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008317339619155973 0.019520567293511704 0.0005500930740709009 0.015805364359635858 0.04707588748633861 1.7224960029125213e-05 0.027866941943531856\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2979,  0.0208, -0.0821], device='cuda:0') tensor([-0.4663,  0.1691,  0.6612], device='cuda:0') tensor([-0.5709,  0.6336,  0.6732], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0668], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015839801245232276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015914120058280364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015869738957380797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01593151436057538\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015961070980066088\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015970491322829558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015985279429560413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015918859740147593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015905365735509096\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015884718008769245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0158358838025838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015861888665159172\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01580420103999999\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01575930629655923\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01578183281420183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015800941321220546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015799814070227132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015845497219243526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015858654781977448\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015853853481304313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01583836245117709\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015876669984668343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01587205520994229\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015893404650057858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015960402914465197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015903762218175743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015850653332092755\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015909468943697002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015928736638102837\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015865188412477867\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015813887387920816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015801916325626608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015842027486257276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01585113362306857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015887956860774186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015954096821194766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01593109185313626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015923378297841018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015889868716242553\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01597920778556046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01601432906641599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016012109178923848\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016032694360344775\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0159705537363498\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016015924330955993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01600225058710049\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01597490736809894\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01597011434652731\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016013095042674255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016045589521083804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016049753440850544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016089853306706155\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016054431277608937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0160287697350931\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016034672833330026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01606039242241886\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008391938686370849 0.0198365372098051 0.0005963079524226487 0.01634685220569372 0.04667868961021304 1.531371474266052e-05 0.02567366360500455\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.8463, -0.3820,  0.9107], device='cuda:0') tensor([0.9867, 0.2193, 0.4660], device='cuda:0') tensor([0.9848, 0.2997, 0.6175], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0509], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01604290662027548\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016046487507634707\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0160583053503574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01605373660961823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01605578691817256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01607686673301641\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016035472120249576\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016025083307585532\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016046577689660436\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01612040268738743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01609547977112675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016105001498065895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016121521275231823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01613345294383665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01613009897059871\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01611779107914281\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01615742022295308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016126933354606833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016126957135553607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016167632287741023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016201155058536303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016151259153958413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01615895099870731\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01615883992781763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01617533003464737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016193445314391118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01618077049250062\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01613639246655269\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016115651644271103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016088304922118244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016108031669399864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01606986372913983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01605603520461663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01608514051324192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016095829635179536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016048257124595462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016054535408220435\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016070808487299117\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0161123156528575\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01612300394124175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016124256174604282\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016126984605746925\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0161455622731411\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01616494367716961\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016183010703967646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016186514619035253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016176818132056014\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016163631991055683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01614483889926406\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016136273989657016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016140961425349536\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016132579211256104\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016123279058570066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01611345587408026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016104706129653895\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00833850359544158 0.019644883966073393 0.0008459648922507768 0.016170534468255938 0.04690369596332312 1.6830354928970335e-05 0.02517012723023072\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.3516, -0.9187,  0.1230], device='cuda:0') tensor([ 0.1430, -0.8269,  0.1083], device='cuda:0') tensor([ 0.1569, -0.7006,  0.2239], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0831], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.016091750568666272\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.01609652889408935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01607806241169773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01606430624188624\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01609407357440062\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01605065518166528\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016063273929965108\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016045726483210798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01606557950569642\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016084672358843047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01608083850548621\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016062349882139622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016020846965044626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016024716715270906\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016032595102811898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016004303288879158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016002103051879803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015981461438305387\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01597782334665189\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015996865707582027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01598910567894649\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016000819329753623\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016010229585572928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01602943065788662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01602175473162407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016028809828168487\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016019926944755073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016041277442127466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01603858636697473\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016056052526319715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016058318748979818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016036815058876885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01603588178137131\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016029926335387346\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016031073503383637\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016012745376366905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016017839588585794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016010128075007374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016023308143453787\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016003160507889403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01598070347101752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01598249510767408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016004878684733773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016001543834086054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01600252791749742\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015990306158350932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01597221957298115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015963824680326498\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015954468278719703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01595527515650838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015985034756682892\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015982534535130474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016007091869415364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016005139519234723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016007571166279166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016016158823472064\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01600872798357159\n",
      "Episode average V value: 0\n",
      "epoch 44:\n",
      "Learning rate: 5.387631832152914e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5178571428571429 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5178562181138961 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008172752600163221 0.018970607074908913 0.0005484223601961276 0.015731185271870344 0.04711431168019772 1.1138707399368286e-05 0.025732028579106555\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0266, -0.9916,  0.9327], device='cuda:0') tensor([ 0.7386, -0.3879,  1.0452], device='cuda:0') tensor([ 0.7798, -0.3810,  0.9735], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0098], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01403698966734939\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.012809333727798529\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01235570204961631\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.012928082077350054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014481651524288788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014887621850465183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015232578481710146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015289447729527537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015326785303100391\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015144162676814529\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015447099321531226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015683277445431385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015550004286516426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015643579338396354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01544567982631701\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015595808314780394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015796706600881675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01592240095667449\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01582214427425673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015909582272999816\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015852114264533004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015860027003318372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015934259126835687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015838450081732677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015833002115703293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015892550048744705\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015809724113133587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015838753659322503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015858608999171818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01570771830673847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015912241354170773\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016077200667091854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016044121685591512\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016099271439076735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016118610681345066\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016239057244721477\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016203997971339\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016149508824016442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016276484748024886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016204510448086594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016221250493210666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01628955706421818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016197168138311353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016168006567632533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016033340138555677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01603001663978729\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015994652102857686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015979854520453415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01603953048793806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015976151012712055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015844551391883354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015837565527106516\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015812123971415265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01581032413973975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015805081537727153\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00856564483139664 0.019341793284518644 0.0006472485509075341 0.015785109768621623 0.04706643876433372 1.5223540365695953e-05 0.02626881827879697\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.6099, -0.9567,  0.7566], device='cuda:0') tensor([ 0.9662, -0.3282,  0.4629], device='cuda:0') tensor([ 0.9805, -0.3281,  0.5864], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0596], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015816493450464413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01594040665111085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015969036513639765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015882799135286032\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01586921300859777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015896728717788158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015873377520998266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015893576450718195\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01594032944558421\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01594685211013525\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01589762136302512\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015968310857534557\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01599244779551073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01594775177811343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015874953396500104\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016010660441309586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01594460462751787\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01597929462475796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015965119767766277\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015930476210735463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01591546874498807\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015940307377478778\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015894965190397962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015957373376469405\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015959542301586933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016103913007235085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016132359353189425\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.016061965573436945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016022111739157626\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016079216288840945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016057119470448245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015985128460547116\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01598453709315932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015917025973611092\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015924051657238585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015895470940725142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015846784044099872\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015881641007672767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015897900691469492\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015898067135723275\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01588852994744364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01585366938584287\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015838123380434603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015812416045898288\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01576900771431004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015749846393758857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015793519349482664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015793309306641468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015807240875786107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015792744072824324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015838760490904113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01581830873834946\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01584691873587737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01582704669042138\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015814947870541177\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01579561518030698\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008286673716269434 0.020055168642429635 0.0004419185212245793 0.01580753715476021 0.047533558778464796 1.1855512857437134e-05 0.026529733354225756\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6954, -0.2353, -0.5236], device='cuda:0') tensor([-0.6882, -0.7611,  0.2276], device='cuda:0') tensor([-0.6903, -0.9306,  0.4467], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0913], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015769371492390907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015724940492195555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015729613148527433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015701489329814983\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015689799121636327\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015670839933491006\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015659361968313305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564638449786097\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015630521909204415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015593716608962476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015548808154317539\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015568448032286984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01554679140547878\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015565442982440194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015588791912620331\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015561084893482395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015590310371812343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015674940211149728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01566894450165236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015666189698496102\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015638890197800053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564486708617306\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015618400195123902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564560347091054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01565333582164896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015636561287941664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015642992397597817\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015619742511164882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01563209263618947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01563333625533861\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01562456107871091\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015625468157658754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015661712533062797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015670800970695998\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015687410459042875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015679204718400574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567260213787094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015691218236016803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567103174290861\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015675412000460527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015685663521609796\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567036799931616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015691688260591682\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567919943131186\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567097599442353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015679567101031217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01566128297522271\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015653676167423337\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01565142671315698\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015623274783258699\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015617891135101753\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015626780599090333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015592913342252384\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015614336709137568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015611369569082725\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008198700370267034 0.01841178380022757 0.0006400456999253948 0.015316547955386341 0.047577326130121944 1.127147674560547e-05 0.026528016761643812\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.8681, -0.9836,  0.2470], device='cuda:0') tensor([-0.2335, -0.7748,  0.6184], device='cuda:0') tensor([-0.2108, -0.7867,  0.6756], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0143], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01563761789207325\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015615835514384021\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015610647124050333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015662411624851814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015709877484208764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015709066827744197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015679563655576018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015677505707139883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0156532508120059\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015662209836664994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015638402045505064\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01562621691799054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015629541304038777\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015645523077842814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015636905365177024\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015635655972292425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015649702176610013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015654464235140126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567541734139259\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01566245239906752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015649202324016172\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564000249041099\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0156581699771523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015658572852088694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01566287975865587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01566991108578535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015680358964986305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015670658180432527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015700755726301942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015711436757729166\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0157411386722723\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015719357978314263\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01571641432429237\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01570941164313505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015689511693841092\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015677392095987192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015700035779744582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015707590139150407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01569939466788961\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015699330060526793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0156902466111797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015673388069685604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01565657326432241\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015677971593301407\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015664057471539792\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567438356048746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015670147796472886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567079603460715\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015694117766638944\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015673546815782577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015653594290786145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01565986870734399\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01566586074658411\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01565277253552763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01563868525320015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015617837578788199\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015611323709017598\n",
      "Episode average V value: 0\n",
      "epoch 45:\n",
      "Learning rate: 4.848868648937623e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5178571428571429 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5178562181138961 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008361540937796235 0.019005182035733013 0.00034831303577811923 0.01552528028935194 0.046743191577494146 1.5735067427158357e-05 0.025329693987965585\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([0.8666, 0.1901, 0.8340], device='cuda:0') tensor([0.8782, 0.6509, 0.3312], device='cuda:0') tensor([0.9097, 0.6837, 0.3259], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0388], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.013442409690469503\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015217214693418808\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.013569280324089859\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.013031689986948751\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.013550195175533493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01326739461661351\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01351502444964671\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.013364484058305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.013871736976858458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014270962265113162\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014624730262886545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01498648188620185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01525551843870845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015576029915199985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015696398432676992\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015796062476713106\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01604799625731615\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016583548417533345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016672999735605733\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016688916336796762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016624080205691002\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016654466355285336\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01661092457856425\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016668297907691105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016653323783021833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01654613491756698\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016498246790703247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01630091704964076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01613865981959663\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015973898922783083\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016123813739727422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016050366591823857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015893700842272103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015903208694676412\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015821835408282896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01583251031331235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01595486155655179\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01582779375800852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015834165887609972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015772895576406477\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015744865762806804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015732673387949862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015637809027453226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567742278778248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01563677961570153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015589516492367042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01551426982949653\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015488418835081608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015422421632664038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015509416904403932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015541996866208958\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015473478109054426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015459241923940537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015557613041263395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01549992543231282\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008323823439422996 0.019139193998184055 0.000345104024043394 0.01554184002848342 0.047140667602419854 1.3190940022468568e-05 0.025506453714333476\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2980,  0.0217, -0.0779], device='cuda:0') tensor([-0.5122, -0.1509,  0.3848], device='cuda:0') tensor([-0.6563, -0.2540,  0.3077], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.2225], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01565707523037591\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015618477224101826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015583071059732915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015668568799005585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015649155081956887\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01557420140839706\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01551786754205222\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015466544037599386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015431265369746447\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015358874392417125\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01531205834508858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015381053169250217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015304420483861655\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015283325379234462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01530944305686428\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01533018251267409\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015338470308141738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015305471945698607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01529274788418052\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015255379226679603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015233828052701374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015242825329107533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015228899317512295\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01518251377540351\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015142735958862532\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01511893769890959\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015044337872675744\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015020856349834976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014976897936932762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014980341790828343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01505049798867451\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015083201498085798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015092824069216302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015132931859573156\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015162568303388486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015122024174972968\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015073941863346665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015063759162321045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01505362300998168\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015078462947606605\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015087318220509958\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015106755673388213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01511834145923802\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015175311972243935\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015169178356882185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015198696919791687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01519052359333347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015232247626208001\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01520202612891419\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015184202929465937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015231580009041608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015208580017888673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015232478375996965\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015248482255360053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015208676465636476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015185368129633017\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008306970699690282 0.01795955852465704 0.00039432274811770186 0.014818950946442783 0.046872970025986435 1.2617811560630799e-05 0.0256496606299188\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0911,  0.4368, -0.2342], device='cuda:0') tensor([-0.3683,  0.3227, -0.1415], device='cuda:0') tensor([-0.2516,  0.1520, -0.1304], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0497], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015154427063183875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015129514049322893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01515518037169322\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015141391763373634\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015136847498432388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015158011954134474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015192465556973131\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015171159079679255\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015189989476844117\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01517827624003544\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015178774926685923\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01520287424373056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015219021110384855\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015272694908082486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015288214371712119\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01525548975205836\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015258826066403545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01529774749627486\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015274894896608132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015261721384156246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015274012415052112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01527932894773277\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01533658274837073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015365815259240292\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015350262003682943\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015314598747552505\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01531499526395962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015276350415230608\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015288608536005966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015282542325139422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015303842424588491\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015290464551015102\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015276262964938342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015275611836192023\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015306507983589417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015318509914932698\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015332872586047932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015332180658378968\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01533286177760197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015382959386107673\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015385330470186271\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01543376111873874\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01547749486985693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015467585488406134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015509517017640492\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015508745282872594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015491891495487882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015509513538047037\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015502930781804026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01552555369652854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015512260860368733\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01549166283013468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015484256947508995\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015471951266506103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015442025758590364\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008386993265710772 0.020293149534380064 0.0005928231540092383 0.01595318027352914 0.04692737630754709 1.5775397419929506e-05 0.025554913421394303\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7833, -0.9820,  0.4034], device='cuda:0') tensor([-0.1570, -0.7888,  0.6237], device='cuda:0') tensor([-0.2106, -0.7863,  0.6754], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1096], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015440215272066776\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015449665298638619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0154499506852164\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015444666250103635\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015446026401038756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015440482587868815\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015442731556666246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015443286661945978\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015474262498023491\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015513280176115458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015517613107463659\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015524365677301784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015538958699369027\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01555431311559162\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015566977711155453\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015547643205257854\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015571802289920118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015584113167155678\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015564749914559873\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015584292448834565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015590128215196954\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015574067791133466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01556709987182019\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015577827533707022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015565074259960301\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015576412940895857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01561925804111667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015595430612269649\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015602460240632126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015595757276825016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015601119769551175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015601718298647675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015594020816598905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015581350726748093\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015573242400716754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015539589019367273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015545669910979682\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015551609515206389\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015559712193179422\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015542129736831722\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015548956370250118\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015551210451984586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015566017873068317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015559566681761117\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015570399864896025\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015559270309012939\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015567402111246879\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015572465229431324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015570702075053401\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015594107824676658\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015593732353843485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015577742493726602\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015582856447764313\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01559118324563829\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015601782152680198\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015604268901308326\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015598159174318425\n",
      "Episode average V value: 0\n",
      "epoch 46:\n",
      "Learning rate: 4.363981784043861e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5535714285714286 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5535704400527856 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00848043185705319 0.02003317388612777 0.00024786221851900335 0.01608030650066212 0.046445303820073607 1.3651512563228608e-05 0.026050985783105714\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.9486,  0.7172,  0.6416], device='cuda:0') tensor([-1.0808,  1.0897,  1.8958], device='cuda:0') tensor([-0.0055, -1.3238,  0.1048], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-1.0997], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.02046881119410197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016250774160855345\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014488750120141992\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014990036841481924\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014887007657024595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01576017507748609\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01575590985354095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015619709036804529\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015702720193974215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015123170942792462\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015777308232800075\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015528890862629784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015479690886826979\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015528283085644481\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015520321836488115\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015509770617225312\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01569813329519497\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015608922811225057\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015370540181991825\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015262129248326851\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015449477421247927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015408662284225827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015392225676616609\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0153781624286677\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015343088075104688\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015378460443268219\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01566487635244374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015650905692757712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01570577677196584\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015754973376169802\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01575282289008994\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015835977406823076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015921401347563625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01583770642763162\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01566511777540048\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015601825840012342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015431232866481528\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015511566608305476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015477360926695868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015575951758202993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015483900401135528\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015522989662482388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015708880405151105\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015823657864309622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015768941536683727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015665674605744258\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015713890134874318\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01568492501327354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564213655183679\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015558096853395303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015551260415837981\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015504794167434303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0155911392813443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015483370053662378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015508959575020003\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008393672255799175 0.019260932825505735 0.0004917547514414764 0.015471142381429673 0.047117300156503915 1.1980079114437104e-05 0.024384262670762838\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.7813, -0.9837,  0.4037], device='cuda:0') tensor([-0.1548, -0.7892,  0.6213], device='cuda:0') tensor([-0.2090, -0.7858,  0.6756], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1092], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015447588660569478\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015373000914147433\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015363617322917928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01533829912774812\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015347683871233905\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01529615983122685\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015294748239092342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01527113920057971\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015255808782563286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015294860953735745\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015307629867441174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015295335849218848\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01523693243887738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015217510597546391\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015220269782187802\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015171863084384975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015207581364702042\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015238554858002965\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015282466146583157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015220719186451149\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015223416394611266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01519199024682964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015160006904467793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015172723745901017\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015154142017773766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015147577425393445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01512168082856601\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015156536973037893\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015197603340277931\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015158307716384335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015185909919399835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015183975272734636\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015184783828597647\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01515389705563985\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015168564223661375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015119355975028233\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015101035033602375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015133977976984821\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015111030193637996\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015095185926619764\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015098219545810329\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015169320500296842\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015148698768838226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015179952416844942\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015177033193305963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015171973349278582\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015207199109941396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015210930098294247\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015213041573774833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015243057012262326\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015218026309315139\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015212131224123921\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015179418035545253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015239917425862176\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01522563177706542\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01520828943460941\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008318081789184362 0.017908152476651593 0.0004923482491067261 0.014942984711378813 0.04647766094282269 9.963735938072204e-06 0.0254952422673814\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0180,  0.6019, -1.0003], device='cuda:0') tensor([-0.5004,  0.4048, -0.9107], device='cuda:0') tensor([-0.5400,  0.4730, -0.9746], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0046], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015203636593281455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01517970213618939\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015202015260285308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015172683882666526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015178140789409563\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015162335470378936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01520326679788193\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0152367945707444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015207869928174963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01518812614533267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015245536496211352\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015214432618987108\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015233984450712853\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015207630827195114\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015216147353399604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015222123270399693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015250519288302813\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015241076266529435\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01527536493113153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01528776639423146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01533535768682457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015325527200934382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015297672376160202\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015275129152331578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015272327488002191\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015279428600216555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015295766441349463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015279490886692353\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015304627038154101\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015293280356633349\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015292919658092383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015294879022551514\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01529371264185124\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01531402304076315\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015287562446736786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015336263823116696\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015377542279120927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015371750085284734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015395124011362593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015399122782698487\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0153742023874401\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015359257304257752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015344025419680952\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015366942227541012\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015360423103717828\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015374427671845468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01536400728392691\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015352614460855327\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015404814287709694\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01538017295796509\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015398676487213494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015373497222592748\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015361155354421646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015406853389716159\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015417895187721046\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008490362509153783 0.019372093290090563 0.0005392948933367734 0.015797130952123553 0.04600567926093936 1.184391975402832e-05 0.025792940665967764\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2111,  0.6948, -0.1243], device='cuda:0') tensor([-0.6722,  0.6357,  0.5823], device='cuda:0') tensor([-0.5729,  0.7296,  0.6370], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.1604], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015394278146550852\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015431609655953402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015402090108575621\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015412722038123392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015442642072080123\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01541995922105329\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015416778210884316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015422027247201408\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015438927581592921\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015462355913842483\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015456717778073259\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015440947552195305\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015443731041990502\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015422573118660323\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015429618761962208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015434925198374187\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015435409191153314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015414641667151788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01542461801882464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01542266504407895\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015453586799346587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015455579975632022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015456759689927654\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015457444579057308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015448717177217613\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015440218608731541\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015430578763586526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015436452143224979\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015437451289950782\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015449020172661495\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015431380672858333\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01543852893555146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015432178517590349\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015428244522772729\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0154293617290265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015430462298959871\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015430879171277062\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015430169102425376\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015438867251320583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015450238062072838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015473211560822259\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015474636735778669\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015473351771272383\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015461872506975418\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015454154836063936\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015440848539827442\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015434593208577246\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015428283878264568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015418815431100838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015410893634316193\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01540538197129591\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01541657010487316\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015403466532833757\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015400634624882404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015403498287226999\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015425850597636268\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015432482657022774\n",
      "Episode average V value: 0\n",
      "epoch 47:\n",
      "Learning rate: 3.927583605639475e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5178571428571429 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5178562181138961 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008508838473353535 0.019203208660008384 0.0005944914234933094 0.015542838559951633 0.04696477035805583 8.982345461845397e-06 0.02530689411633648\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2064, -0.6622,  0.2594], device='cuda:0') tensor([ 0.4528, -0.1749,  0.0561], device='cuda:0') tensor([ 0.4362, -0.1915,  0.2015], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1709], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.018907517091267638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01677153624283771\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016472796305876086\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015580002748821344\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015512836900436216\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015537241447923912\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015313032319739697\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015375004929309297\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016024252851091235\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016117945233256454\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015635562239854475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01617821257483835\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016192967420380212\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01605365340161832\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015854588977095706\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015988115012684528\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016261253811820756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01636078439934616\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016113647179438445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016271094976562178\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015987161582670908\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016062876302513737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01614046437499352\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016036971807436743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015885518161166047\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0157809983431481\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015664423560079785\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015664925825567767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015708265329222284\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015599567966570181\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015556197285511962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015640924237636175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015623316755957324\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015609346008311738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01549886943521126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015437920457815729\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015528700292787261\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015407671209027153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015435223249410759\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015420567855471745\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015507505476590862\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015474313759816585\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015462427482475798\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015730179564655767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015657631770627182\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015702853749218232\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015697866803184857\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01563485284471729\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564833074079535\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015581362209696737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015626505923747595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015592530980192794\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015590186293805076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015550248766099506\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015620344841965672\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008177604091819377 0.019491646355483682 0.0004921710986964172 0.0157240760945715 0.046731969494372604 8.547656238079072e-06 0.02443020650371909\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4856,  0.5741, -0.9955], device='cuda:0') tensor([ 0.0372,  0.4205, -1.1097], device='cuda:0') tensor([ 0.0617,  0.3112, -0.9752], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0500], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015777091305824883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015728134368264913\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015660431051815922\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015686340720818964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015713768646862632\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015659797008324056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015624739906890818\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015601062809233759\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01562524385008146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01565155928564441\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564326322980865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015613513544995714\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015640149121644475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015600352975856303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015619332685194437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564594599890562\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564174747837558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015654700491052897\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015611446582482898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01558154739473981\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015604820829198004\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015604702014984055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015569752448058005\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01559792420926403\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015652567011420614\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01566756428257704\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015684804442177114\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015698038318058553\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015735292813072975\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01568786536185132\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015713831991888583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015717260152670064\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015682257663380977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015655819096715283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015645492534774045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015615309495080868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01562131119409468\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01562244042708553\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015612143421838452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564628208377426\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01565607706396366\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015677090387797795\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015616666061788916\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015588245938106635\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015583250522872226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015603072309407546\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015587055461414256\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01559022833249595\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01560384151749671\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015594431998149033\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567186290018487\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01570236796792693\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015714951458151372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015736518562301446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015729189155896127\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015682248389572127\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008369037615600974 0.018963969871867447 0.0003966664296131057 0.015611608624458312 0.046637342769652604 9.335830807685853e-06 0.025434357192367314\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6927,  0.8042,  0.6583], device='cuda:0') tensor([-0.8883,  1.2983,  1.9671], device='cuda:0') tensor([-0.0035, -1.3239,  0.1010], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.9785], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01573095969012236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015730160066213243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01572569374418972\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015789220695145392\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015812690089451385\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01584688822627386\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01585135314628489\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015840582315002183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01582916430348565\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015816120650402044\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01585312660987945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015892794713934896\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015876970098038474\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01588265821358396\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01587507540193375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015855427020476286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01585923401156227\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015838244883183143\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015819939150490885\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015822870035373793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015813810392776788\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015812875015766933\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015824311530058446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015807236231855832\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015783500103424518\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015740597599268335\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015737473663810984\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01568942382610846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015696217556713177\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01566029680834847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01565585184076448\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015653012524646213\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564922445632638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015628566675180734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015599376764935207\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015618781989105242\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564108379280989\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015617504839019365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01560074412798578\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01559168999830317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015562662965589481\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01555274474500836\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015552920323775067\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015547604202109265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015519612225500915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015520229785863286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015534844322676303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015536443044475113\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015554317546937252\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015549084236408314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015516919505958725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015498178783929879\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015524753130092803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015500633429378421\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015499908271509969\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008332322688307614 0.018582370986463502 0.0004947065356100211 0.015190616548061371 0.046714682966470716 1.1117339134216309e-05 0.025118831926025452\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.4704,  0.8956, -0.4668], device='cuda:0') tensor([-0.8869,  0.8270,  0.5539], device='cuda:0') tensor([-0.9770,  0.8057,  0.5630], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1231], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01550036695592492\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015540668419186549\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015523858358752887\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015510215156017712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015506076606358459\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015514196862450992\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015494023106529276\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015497807468499365\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015525395330189476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015516167805404308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015500270476101734\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015479903969449803\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015479799799249964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015491418176428358\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015467999812742687\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015464493168616878\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015463071028630147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015438617343068402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015431570187462745\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015412949290590554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015420627574819852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015410995792160494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015445137636129388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01544669891737554\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015484568664702245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015477458266913244\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015448101470354145\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015459274008890394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0154410939078587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015438519605533631\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015450550381275964\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015462842503772665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01548955047990355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015521911738259304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01552374594543189\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015518021355260151\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01550560386239214\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01551443818169859\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015512173547760298\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01552220004243513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015520543684249107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015525333581240568\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015518277775964628\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01551546369588111\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015516496463171185\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015499266550414444\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015494533073731314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01549153818822875\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0154946395676121\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015476587103079016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01547309335216754\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01548139544317326\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01545397841673059\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015451066985119586\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01544598794599378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015451758390863997\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015446890105376952\n",
      "Episode average V value: 0\n",
      "epoch 48:\n",
      "Learning rate: 3.534825245075528e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.48214285714285715 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.4821419961750068 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008200987871270627 0.01934915867028758 0.0007425517295596365 0.015238239047117531 0.04711053168028593 9.247876703739167e-06 0.026389571757405066\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9964, -0.2730,  0.5011], device='cuda:0') tensor([ 1.0614,  0.2261, -0.1339], device='cuda:0') tensor([ 0.9998,  0.1513, -0.0936], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1941], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.011895245665477382\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0130182726877845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015729093527490343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014041217600202395\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014164269529283046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015025475200403619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014689603266084478\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0147798064410583\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014845024719604371\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014947061421763566\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01479378550529781\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014650912239664683\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.014800760401492445\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015038566482770774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015503207894249095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015501560976392485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015344808855112278\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01522448487913259\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015137105017399404\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015190556777330737\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015348231686013085\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015542082876587907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01592075779521163\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015879361916126475\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016079103677637048\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015900506230039347\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015762845460524776\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015618212867550375\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015671991331902443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015544530505279977\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01543428640108302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015399615177658334\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015335965773830762\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015260590091986838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01531586676377744\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015237318772253476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015188008153184622\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015333271419972573\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015266717810242136\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015166818472789601\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015157478772542947\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01512645208707976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015281775723829943\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015355351467433415\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015288969066660897\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015296386584644049\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015262788616838573\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015234905872299956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01521382928623178\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015225934762404197\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015387085065030552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015399133782081593\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01548712903221745\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015488016528820949\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015485000556259594\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008338363577611745 0.019477989068022 0.0006902473771333462 0.015513105927500874 0.04652274441346526 9.460695087909698e-06 0.027304540395271033\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0149, -0.6981,  0.8931], device='cuda:0') tensor([ 0.5170, -0.0811,  0.9825], device='cuda:0') tensor([ 0.4992, -0.1624,  0.9385], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0283], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015521047910812148\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015653169122533638\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015671939312987087\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015645860498350133\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015619175699625716\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01554047925616589\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01564008470976852\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0156261387779632\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015676451983179303\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015683957307527845\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01572197754451886\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015681416149580137\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015643113974886613\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015678117867190266\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015596317043454046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015569482456691599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015591194600594103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015570842411122434\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015545161381886864\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015504240319477738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015520436117052488\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015541140664393058\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015544314966590126\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015531418876167068\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015563646693287107\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01554300347873264\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015488072869186176\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015500807342053438\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015479218973913697\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0154640532095667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01542401869176076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015465989348206236\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015466510115080805\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015471234645859597\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015487628686241806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01545533278908112\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015427998476605502\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015438869284252272\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015411923309495281\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015379107700747966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015335135718352697\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015434568838823378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015419725547523539\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015405007838464931\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015409831474793868\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015448643260136476\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015468584677693485\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015464763944976619\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015466572029036509\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015453767488469128\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015444413798107556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015452349880760533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01547650720492013\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015479669568464008\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015473299087589662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015451322188712768\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008418852941133082 0.019420808831462636 0.000489662644919008 0.015411021739244461 0.046952634692192075 1.124400645494461e-05 0.02614147456223145\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.9998,  0.6918, -0.2697], device='cuda:0') tensor([ 0.8054,  0.7806, -0.6703], device='cuda:0') tensor([ 0.8606,  0.7702, -0.7885], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0410], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015469952362417686\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01551377269596909\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015465776499798321\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015480120086610533\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015444982241815976\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015504640941654048\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015476100466638564\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015479537840788257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015499411084197669\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015504993230003532\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015536664702033859\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015533589570999293\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01552442474917452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015511517454145684\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015525569784704669\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01551640546580814\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015547508736643876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015567531247088215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015531537196057666\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015518731612789558\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015472782917457134\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015501938448867192\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015560857405087556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01554891833318819\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015531938310577139\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015540065582794804\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015532900204157664\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015521799482004665\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015544164452576153\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01553178083285883\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015547469618485393\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015519603751650443\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015510317680309527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015519811592860526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015512698864219838\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015501286813183966\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015511995513731888\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015520616575671355\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015543297763948364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01555076023413662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015548529503193046\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015550232775774483\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015527392957295045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015527836116544876\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015528003081541371\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015535959890553884\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015537767618326091\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015520525262199712\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015519024380288708\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015514594459683834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01550290007297517\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015511756269902437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015501609703697527\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015495942490369783\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015485140721287474\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008389606729149818 0.019470886427676304 0.00029193891134855223 0.015534712242428214 0.046636045213788745 8.682280778884888e-06 0.025826635720673948\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.5250,  0.9086, -0.5494], device='cuda:0') tensor([-0.9347,  0.8200,  0.4902], device='cuda:0') tensor([-0.9975,  0.8039,  0.5081], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.1294], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015489513777302986\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015461713536063494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015443909375693827\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015416200366479898\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015424285589610218\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015403700756626228\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01540949086341038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015415447272269928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015413662418427449\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015372600674810302\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015389572650986932\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015374553075627646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015352715736383388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0153475578095373\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01533453755464892\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01530893524694774\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015286022349095065\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015340970631448129\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015337510954857142\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01537564014287147\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015357442352914131\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015377680897926273\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015377434536700806\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015394835607611646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015401032945621215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015385238652622016\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015411248321767743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01543218919576358\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015427319558491224\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01542366239666736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015407087295266257\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015414543198494765\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015401202882159062\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015385563901056432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015380952314712053\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015407728342230793\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015418926030132342\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015411078349853538\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015395559864699194\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01538646641687692\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01537577505685865\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015363607339214725\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015365536724242488\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015391321613813045\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015379351422508463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015356065013272146\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015349025761559956\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015338761343931159\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015371491922455472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015382722382809308\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015386224470420321\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01537732926442285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01540953071550752\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015386299527193786\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015380415516681201\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01537926779809157\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015374021057737991\n",
      "Episode average V value: 0\n",
      "epoch 49:\n",
      "Learning rate: 3.1813427205679753e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5178571428571429 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5178562181138961 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00825747507205233 0.018817953421734274 0.0006385141617793125 0.015069379610940814 0.04620875475555658 1.0434217751026154e-05 0.026616335282567887\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0373,  0.9034, -0.8482], device='cuda:0') tensor([-0.5611,  0.8958, -0.5353], device='cuda:0') tensor([-0.4724,  0.8946, -0.4655], device='cuda:0')\n",
      "R[0]\n",
      "tensor([0.0251], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.018152916596995458\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.017806345234728523\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015996951230422215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016757538464541238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.016178721230891015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015494291774100728\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01560651630695377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015211403344033493\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015412133463003018\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015518592370467054\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015538207274118457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015413511596206162\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015530877826241856\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015463194691590847\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0158029039700826\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015422316956877088\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015631939208415015\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015453328803917508\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015392312777299456\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015322859461108843\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015389702287773607\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015243397301269902\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015307656574796363\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015221067747377135\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01514363046321604\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015382298845479377\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015386397521099682\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015341934988216038\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015210985532565707\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015188578740452175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015248747138593572\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015386952349217609\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015441893242450074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015523773764132285\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015545434683620457\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01557035446540671\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015459964504918537\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015443759703496743\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01538981266712446\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015555798892293953\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015429877043830427\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015412145277002343\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015440284747399332\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015429040627563466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015542770353042417\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015689627059334934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015700623268662263\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015685324439632328\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015617804162525265\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015615084268566636\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015517246814075378\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015515353198314452\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015434066000622962\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015345207633979526\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015368968489194158\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008468549197074026 0.019028101219795646 0.0007872226608014899 0.015454507596790791 0.04711102209985256 7.516689598560334e-06 0.026303566111251713\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0802, -0.6253,  0.9076], device='cuda:0') tensor([0.6412, 0.0772, 1.0771], device='cuda:0') tensor([0.6569, 0.0428, 0.9902], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0197], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015505665347778372\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01547678749641625\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015415602797192746\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015498691020978934\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015442786589954738\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015390684968963238\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015418847395260702\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015384596163108026\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015418084353667736\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015471148024448472\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015426025111290943\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015454708395454767\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015470806943721388\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015577771887633103\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015670310512983374\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015738792136655494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015808262247132297\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015790230724988915\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01575121813937574\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015690422641734283\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015666084884181183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015658969509792963\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01570970740997129\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567369068837849\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015634892544605667\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015615617677528509\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015586261736572314\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015556941880474249\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015596019814934128\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015534736039543074\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015556352975289758\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01556607259266164\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015541440557401552\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015533784982258833\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015581799932054163\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015600019758874243\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015598816951795297\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01555221685483215\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015591754822443562\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015612890918287095\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01563935007854727\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015591077324651599\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015599087963531178\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01565701021905884\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01568175360094756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01574517188110154\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01577302307085274\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015775164999690675\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01574597970043253\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015721864214354248\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015769831204603367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01579337773809784\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01579092737668627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015788280373300587\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0157437960861834\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015776461944472533\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.008391210647299885 0.020653736770851538 0.0005923542878663283 0.01612251400575042 0.04676085079833865 9.041577577590942e-06 0.026245580891612916\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 False\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0439,  0.2345, -0.2128], device='cuda:0') tensor([-0.3780,  0.0798, -0.1304], device='cuda:0') tensor([-0.2995,  0.0192, -0.0737], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.0740], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.01578057588942881\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015799182353609022\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015756124841161873\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0157334822481993\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015728546851546545\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01578731584766878\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015737563409367245\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015761478037949927\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01573824393045571\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01573933647044133\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015741385269285823\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015690639622630627\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01567128625127577\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015694078844454555\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015676820323009183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01566123819648437\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015627902672955923\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0156411627719851\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015658462938303367\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01563926020963394\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01560519468325413\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015600378258051094\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015577082931694217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015610804652350613\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015621437510632259\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015632947543726603\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0156058569856051\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015613660192694797\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015605523982935304\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015588858821139421\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015572767980369056\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015599206273234866\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015601170437020986\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01558796771288175\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01556612981665494\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015545786556049348\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015546800313320279\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015528991006385594\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015536094232876267\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015527806870640695\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01551088969116317\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015479735849687617\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015503076395499662\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015496815884432432\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015473310443628421\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015495069728016073\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015498178307806651\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01548364373613188\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015507369231232183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015497619552753758\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01548760668939907\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015493645730644882\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015530926186615364\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01552614272910763\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015514023465022116\n",
      "Episode average V value: 0\n",
      "self.loss_T, self.loss_R, self.loss_gamma, self.loss_Q, self.loss_disentangle_t, self.loss_disambiguate1, self.loss_disambiguate2\n",
      "0.00832076385943219 0.018143688139272855 0.0006422134726635704 0.014998316057492047 0.04704237178340554 8.404962718486786e-06 0.024978424983099105\n",
      "self.loss_interpret/500.\n",
      "0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 -1.0 True\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.6525, -0.2480,  0.3043], device='cuda:0') tensor([-0.2549,  0.0320,  0.9472], device='cuda:0') tensor([-0.0027, -1.3253,  0.0982], device='cuda:0')\n",
      "R[0]\n",
      "tensor([-0.6616], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Average (on the epoch) training loss: 0.015536799501591744\n",
      "Episode average V value: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 0.015539885878165021\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015528007080891144\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015515381824133881\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015515826372163463\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015491833912301326\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015479726391630911\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015454898823122822\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015446793736653431\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015451759825939208\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015463443321414989\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015455317460424901\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015445569792443286\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015462340265771167\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015455410599524466\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015477097106407258\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015452491561557055\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015448129968014703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01545236882720109\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015452189238440455\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015475456357589937\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015499637783235314\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015495148308488646\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015557296688080226\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01555349916957076\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015558585306684513\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015563586648906409\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015562495421154163\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015584159750846928\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015610769492560309\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01560078202027174\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015592856723977217\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015578356806666183\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015562275446201158\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015565945313689482\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015543276324076219\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015529695195979354\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015503347221196858\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015504050182259381\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015505090120907556\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015529828121479735\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01552198954017606\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015536007245731228\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015552981801838589\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015565436717790756\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015591588124278464\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015606027336627921\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015581243498969402\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015561017865863766\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015576568848588561\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.0155894135708429\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.01556716846417499\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015555709075368846\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015569197336526945\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015551026366803703\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015554339512721173\n",
      "Episode average V value: 0\n",
      "Average (on the epoch) training loss: 0.015555800449685193\n",
      "Episode average V value: 0\n",
      "epoch 50:\n",
      "Learning rate: 2.8632084485111777e-06\n",
      "Discount factor: 0.9\n",
      "Epsilon: 1.0\n",
      "Testing score per episode (id: 0) is 0.5178571428571429 (average over 56 episode(s))\n",
      "== Mean score per episode is 0.5178562181138961 over 56 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/ctn/users/cf2794/Code/deer/examples/test_CRAR/catcher_env.py:184: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('x').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  line3 = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best neural net obtained after 38 epochs, with validation score 0.6607142857142857\n"
     ]
    }
   ],
   "source": [
    "# --- Run the experiment ---\n",
    "try:\n",
    "    os.mkdir(\"params\")\n",
    "except Exception:\n",
    "    pass\n",
    "dump(vars(parameters), \"params/\" + fname + \".jldump\")\n",
    "agent.run(parameters.epochs, parameters.steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3c23b",
   "metadata": {},
   "source": [
    "# Visualize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07d1ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35238604",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.setNetwork(fname, nEpoch=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4c458958",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent._in_episode = True\n",
    "agent._mode = 0 # Testing mode with plan_depth=0\n",
    "initState = env.reset(agent._mode)\n",
    "inputDims = env.inputDimensions()\n",
    "for i in range(len(inputDims)):\n",
    "    if inputDims[i][0] > 1:\n",
    "        agent._state[i][1:] = initState[i][1:]\n",
    "agent._Vs_on_last_episode = []\n",
    "is_terminal = False\n",
    "reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12fcd434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for i in range(100):\n",
    "    obs = env.observe()\n",
    "    plt.figure()\n",
    "    plt.imshow(np.flip(obs[0].squeeze()))\n",
    "    plt.show()\n",
    "    for i in range(len(obs)):\n",
    "        agent._state[i][0:-1] = agent._state[i][1:]\n",
    "        agent._state[i][-1] = obs[i]\n",
    "    V, action, reward = agent._step()\n",
    "    agent._Vs_on_last_episode.append(V)\n",
    "    is_terminal = env.inTerminalState()\n",
    "    if is_terminal: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5f178d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " tensor(0.5224, device='cuda:0'),\n",
       " tensor(0.5970, device='cuda:0'),\n",
       " tensor(0.8059, device='cuda:0'),\n",
       " tensor(1.0443, device='cuda:0'),\n",
       " tensor(1.1207, device='cuda:0'),\n",
       " tensor(1.0268, device='cuda:0'),\n",
       " tensor(0.8596, device='cuda:0'),\n",
       " tensor(1.3455, device='cuda:0')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent._Vs_on_last_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c8287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
