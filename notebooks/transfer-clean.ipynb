{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import hash, dump, load\n",
    "import os\n",
    "\n",
    "from deer.default_parser import process_args\n",
    "from deer.agent import NeuralAgent\n",
    "from deer.learning_algos.CRAR_torch import CRAR\n",
    "from figure8_env import MyEnv as figure8_env\n",
    "from figure8_alt1 import MyEnv as figure8_alt1\n",
    "import deer.experiment.base_controllers as bc\n",
    "\n",
    "from deer.policies import EpsilonGreedyPolicy, FixedFigure8Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure8_give_rewards = True\n",
    "nn_yaml = 'network_noconv.yaml'\n",
    "higher_dim_obs = False\n",
    "internal_dim = 10\n",
    "fname = 'figure8_alt1'\n",
    "set_network = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Defaults:\n",
    "    # ----------------------\n",
    "    # Setup Parameters (copied for convenience)\n",
    "    # ----------------------\n",
    "    figure8_give_rewards = figure8_give_rewards\n",
    "    nn_yaml = nn_yaml\n",
    "    higher_dim_obs = higher_dim_obs\n",
    "    internal_dim = internal_dim\n",
    "    fname = fname\n",
    "    \n",
    "    # ----------------------\n",
    "    # Experiment Parameters\n",
    "    # ----------------------\n",
    "    steps_per_epoch = 5000\n",
    "    epochs = 50\n",
    "    steps_per_test = 1000\n",
    "    period_btw_summary_perfs = 1\n",
    "\n",
    "    # ----------------------\n",
    "    # Temporal Processing Parameters\n",
    "    # ----------------------\n",
    "    nstep = 15\n",
    "    nstep_decay = 0.8\n",
    "    encoder_type = 'regular'\n",
    "    \n",
    "    # ----------------------\n",
    "    # Environment Parameters\n",
    "    # ----------------------\n",
    "    frame_skip = 2\n",
    "    show_rewards = False\n",
    "\n",
    "    # ----------------------\n",
    "    # DQN Agent parameters:\n",
    "    # ----------------------\n",
    "    learning_rate = 1*1E-4\n",
    "    learning_rate_decay = 1.0\n",
    "    discount = 0.9\n",
    "    epsilon_start = 1.0\n",
    "    epsilon_min = 1.0\n",
    "    epsilon_decay = 1000\n",
    "    update_frequency = 1\n",
    "    replay_memory_size = 100000 #50000\n",
    "    batch_size = 64\n",
    "    freeze_interval = 1000\n",
    "    deterministic = False\n",
    "    \n",
    "    # ----------------------\n",
    "    # Learning algo parameters\n",
    "    # ----------------------\n",
    "    # T, entropy_neighbor, entropy_random, volume, gamma, R, Q, variational\n",
    "    #loss_weights = [5E-3, 1E-3, 5E-3, 5E-3, 5E-3, 5E-3, 1.]\n",
    "    #loss_weights = [0., 0., 0., 0., 0., 0., 1., 2E-4]\n",
    "    loss_weights = [0, 0, 0, 0, 0, 0, 1., 0.]\n",
    "    #loss_weights = [5E-3, 5E-3, 5E-3, 0, 5E-3, 5E-3, 1., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = Defaults()\n",
    "with open(f'params/{fname}.p', 'wb') as f:\n",
    "    pickle.dump(parameters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end gathering data\n"
     ]
    }
   ],
   "source": [
    "if parameters.deterministic:\n",
    "    rng = np.random.RandomState(123456)\n",
    "else:\n",
    "    rng = np.random.RandomState()\n",
    "\n",
    "# --- Instantiate environment ---\n",
    "env = figure8_alt1(\n",
    "    give_rewards=figure8_give_rewards,\n",
    "    intern_dim=internal_dim,\n",
    "    higher_dim_obs=higher_dim_obs,\n",
    "    show_rewards=parameters.show_rewards,\n",
    "    nstep=parameters.nstep, nstep_decay=parameters.nstep_decay\n",
    "    )\n",
    "\n",
    "# --- Instantiate learning_algo ---\n",
    "learning_algo = CRAR(\n",
    "    env,\n",
    "    parameters.freeze_interval,\n",
    "    parameters.batch_size,\n",
    "    rng,\n",
    "    high_int_dim=False,\n",
    "    internal_dim=internal_dim, lr=parameters.learning_rate,\n",
    "    nn_yaml=nn_yaml, double_Q=True,\n",
    "    loss_weights=parameters.loss_weights,\n",
    "    nstep=parameters.nstep, nstep_decay=parameters.nstep_decay,\n",
    "    encoder_type=parameters.encoder_type\n",
    "    )\n",
    "\n",
    "if figure8_give_rewards:\n",
    "    train_policy = EpsilonGreedyPolicy(\n",
    "        learning_algo, env.nActions(), rng, 0.2,\n",
    "        consider_valid_transitions=False\n",
    "        )\n",
    "    test_policy = EpsilonGreedyPolicy(\n",
    "        learning_algo, env.nActions(), rng, 0.\n",
    "        )\n",
    "else:\n",
    "    train_policy = FixedFigure8Policy.FixedFigure8Policy(\n",
    "        learning_algo, env.nActions(), rng, epsilon=0.2,\n",
    "        height=env.HEIGHT, width=env.WIDTH\n",
    "        )\n",
    "    test_policy = FixedFigure8Policy.FixedFigure8Policy(\n",
    "        learning_algo, env.nActions(), rng,\n",
    "        height=env.HEIGHT, width=env.WIDTH\n",
    "        )\n",
    "\n",
    "# --- Instantiate agent ---\n",
    "agent = NeuralAgent(\n",
    "    env, learning_algo,\n",
    "    parameters.replay_memory_size,\n",
    "    1, parameters.batch_size, rng,\n",
    "    train_policy=train_policy, test_policy=test_policy)\n",
    "if set_network is not None:\n",
    "    agent.setNetwork(\n",
    "        f'{set_network[0]}/fname', nEpoch=set_network[1],\n",
    "        encoder_only=set_network[2]\n",
    "        )\n",
    "\n",
    "agent.run(10, 500)\n",
    "print(\"end gathering data\")\n",
    "\n",
    "# --- Bind controllers to the agent ---\n",
    "# Before every training epoch (periodicity=1), we want to print a summary of the agent's epsilon, discount and \n",
    "# learning rate as well as the training epoch number.\n",
    "agent.attach(bc.VerboseController(\n",
    "    evaluate_on='epoch', \n",
    "    periodicity=1))\n",
    "\n",
    "# Learning rate may follow a scheduler\n",
    "agent.attach(bc.LearningRateController(\n",
    "    initial_learning_rate=parameters.learning_rate, \n",
    "    learning_rate_decay=parameters.learning_rate_decay,\n",
    "    periodicity=1))\n",
    "\n",
    "# During training epochs, we want to train the agent after every [parameters.update_frequency] action it takes.\n",
    "# Plus, we also want to display after each training episode (!= than after every training) the average bellman\n",
    "# residual and the average of the V values obtained during the last episode, hence the two last arguments.\n",
    "agent.attach(bc.TrainerController(\n",
    "    evaluate_on='action', \n",
    "    periodicity=parameters.update_frequency, \n",
    "    show_episode_avg_V_value=True, \n",
    "    show_avg_Bellman_residual=True))\n",
    "\n",
    "# We wish to discover, among all versions of our neural network (i.e., after every training epoch), which one \n",
    "# has the highest validation score.\n",
    "# To achieve this goal, one can use the FindBestController along with an InterleavedTestEpochControllers. It is \n",
    "# important that the validationID is the same than the id argument of the InterleavedTestEpochController.\n",
    "# The FindBestController will dump on disk the validation scores for each and every network, as well as the \n",
    "# structure of the neural network having the best validation score. These dumps can then used to plot the evolution \n",
    "# of the validation and test scores (see below) or simply recover the resulting neural network for your \n",
    "# application.\n",
    "agent.attach(bc.FindBestController(\n",
    "    validationID=figure8_env.VALIDATION_MODE,\n",
    "    testID=None,\n",
    "    unique_fname=fname, savefrequency=5))\n",
    "\n",
    "# All previous controllers control the agent during the epochs it goes through. However, we want to interleave a \n",
    "# \"validation epoch\" between each training epoch. For each validation epoch, we want also to display the sum of all \n",
    "# rewards obtained, hence the showScore=True. Finally, we want to call the summarizePerformance method of ALE_env \n",
    "# every [parameters.period_btw_summary_perfs] *validation* epochs.\n",
    "agent.attach(bc.InterleavedTestEpochController(\n",
    "    id=figure8_env.VALIDATION_MODE, \n",
    "    epoch_length=parameters.steps_per_test,\n",
    "    periodicity=1,\n",
    "    show_score=True,\n",
    "    summarize_every=1,\n",
    "    unique_fname=fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2286, -0.2181,  0.1445, -0.3463, -0.1055, -0.1022, -0.1445, -0.3482,\n",
      "         0.4319,  0.1541]) tensor([ 0.2875, -0.3783,  0.3928, -0.2561, -0.0773, -0.4406, -0.4212, -0.1797,\n",
      "         0.7151,  0.0861]) tensor([ 0.2343, -0.2141,  0.1566, -0.3309, -0.0969, -0.1152, -0.1554, -0.3498,\n",
      "         0.4264,  0.1532])\n",
      "R[0]\n",
      "tensor([-0.0353], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0390671131759882; R = 0.0009367903624661267;                 Gamma = 0.559142674446106; Q = 0.0010826034946221626;\n",
      "Entropy Neighbor = 0.9167151342630386;                 Entropy Random = 0.7394493681788444;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0322, -0.4239, -0.3579, -0.2188, -0.2336, -0.0344, -0.1115, -0.1618,\n",
      "         0.4818,  0.1785]) tensor([ 0.0982, -0.5748, -0.1096, -0.1301, -0.2025, -0.3746, -0.3943,  0.0089,\n",
      "         0.7672,  0.1181]) tensor([ 0.0230, -0.4267, -0.3669, -0.2114, -0.2270, -0.0381, -0.1186, -0.1569,\n",
      "         0.4802,  0.1696])\n",
      "R[0]\n",
      "tensor([-0.0285], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04009600862115621; R = 0.0007360387987573632;                 Gamma = 0.5829768944978714; Q = 0.0020831229540453932;\n",
      "Entropy Neighbor = 0.9152418456077576;                 Entropy Random = 0.6510919194221496;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1709, -0.3211, -0.0546, -0.1657, -0.1378, -0.1243, -0.3167,  0.1375,\n",
      "         0.3918,  0.0191]) tensor([ 0.2329, -0.4766,  0.2012, -0.0708, -0.1039, -0.4622, -0.5950,  0.3145,\n",
      "         0.6764, -0.0491]) tensor([ 0.1715, -0.3180, -0.0426, -0.1481, -0.1158, -0.1502, -0.3598,  0.1784,\n",
      "         0.3948, -0.0073])\n",
      "R[0]\n",
      "tensor([-0.0212], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04063809584826231; R = 0.0006842943976516835;                 Gamma = 0.5798463096618652; Q = 6.280929837703298e-05;\n",
      "Entropy Neighbor = 0.8481885778903961;                 Entropy Random = 0.46489326673746106;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1770, -0.3365, -0.0466, -0.0968, -0.0246, -0.1899, -0.4266,  0.2713,\n",
      "         0.3613, -0.0380]) tensor([ 2.4122e-01, -4.9081e-01,  2.0876e-01, -3.4209e-04,  1.1659e-02,\n",
      "        -5.2581e-01, -7.0042e-01,  4.4931e-01,  6.4775e-01, -1.1008e-01]) tensor([ 0.1770, -0.3365, -0.0466, -0.0968, -0.0246, -0.1899, -0.4266,  0.2713,\n",
      "         0.3613, -0.0380])\n",
      "R[0]\n",
      "tensor([-0.0193], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.040680674217641356; R = 0.0008579157094936818;                 Gamma = 0.5900060445070267; Q = 8.081681535441022e-05;\n",
      "Entropy Neighbor = 0.8424745243787766;                 Entropy Random = 0.4143952951729298;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1615, -0.4269, -0.1771, -0.4781, -0.1352,  0.0907,  0.2936, -0.5402,\n",
      "         0.2856,  0.4488]) tensor([ 0.2236, -0.5892,  0.0572, -0.3884, -0.1070, -0.2395, -0.0067, -0.3774,\n",
      "         0.5470,  0.3813]) tensor([ 0.1496, -0.4266, -0.1860, -0.3806, -0.1470,  0.0932,  0.2250, -0.4136,\n",
      "         0.2520,  0.3711])\n",
      "R[0]\n",
      "tensor([-0.0479], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04040908201783895; R = 0.0009664705726318061;                 Gamma = 0.5955908048152924; Q = 3.971523308337055e-05;\n",
      "Entropy Neighbor = 0.8601172097921371;                 Entropy Random = 0.4104158702492714;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1456, -0.3529, -0.0865, -0.0955, -0.0528, -0.0353, -0.2421,  0.0995,\n",
      "         0.2535,  0.0379]) tensor([ 2.0814e-01, -5.1018e-01,  1.6551e-01, -4.6146e-04, -1.5565e-02,\n",
      "        -3.7289e-01, -5.2181e-01,  2.7383e-01,  5.3511e-01, -3.2511e-02]) tensor([ 0.1456, -0.3529, -0.0865, -0.0955, -0.0528, -0.0353, -0.2421,  0.0995,\n",
      "         0.2535,  0.0379])\n",
      "R[0]\n",
      "tensor([-0.0269], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04045785474032164; R = 0.0009786294572986663;                 Gamma = 0.5993567638397217; Q = 5.0987068102585906e-05;\n",
      "Entropy Neighbor = 0.867288137793541;                 Entropy Random = 0.4357510313987732;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1515, -0.3481, -0.0794, -0.1361, -0.1146, -0.0264, -0.1853,  0.0193,\n",
      "         0.2556,  0.0739]) tensor([ 0.2128, -0.5061,  0.1727, -0.0417, -0.0785, -0.3649, -0.4668,  0.1932,\n",
      "         0.5362,  0.0051]) tensor([ 0.1516, -0.3500, -0.0807, -0.1299, -0.1062, -0.0311, -0.1923,  0.0287,\n",
      "         0.2540,  0.0710])\n",
      "R[0]\n",
      "tensor([-0.0275], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04042146880179644; R = 0.0009968945293221622;                 Gamma = 0.6024278239011764; Q = 5.821382906560757e-06;\n",
      "Entropy Neighbor = 0.8735894231796265;                 Entropy Random = 0.44737837493419647;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1425, -0.3568, -0.0903, -0.1100, -0.0839, -0.0264, -0.1941,  0.0352,\n",
      "         0.2366,  0.0627]) tensor([ 0.2159, -0.5109,  0.1555, -0.0127, -0.0539, -0.3514, -0.4922,  0.2144,\n",
      "         0.5058, -0.0129]) tensor([ 0.1425, -0.3568, -0.0903, -0.1100, -0.0839, -0.0264, -0.1941,  0.0352,\n",
      "         0.2366,  0.0627])\n",
      "R[0]\n",
      "tensor([-0.0281], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.040491367928683755; R = 0.0009605370524805039;                 Gamma = 0.6034300775527954; Q = 4.86366766961055e-06;\n",
      "Entropy Neighbor = 0.8752829456329345;                 Entropy Random = 0.45850342029333113;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2775, -0.4954, -0.1583, -0.5073, -0.0582,  0.0479,  0.4357, -0.7048,\n",
      "         0.2376,  0.6126]) tensor([ 0.3376, -0.6588,  0.0723, -0.4201, -0.0284, -0.2837,  0.1354, -0.5460,\n",
      "         0.4970,  0.5452]) tensor([ 0.2961, -0.4697, -0.1196, -0.4698, -0.0357,  0.0242,  0.3838, -0.7013,\n",
      "         0.2517,  0.6146])\n",
      "R[0]\n",
      "tensor([-0.0550], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04058130426704883; R = 0.0009372444966575131;                 Gamma = 0.6039680353403092; Q = 1.0500778767621455e-06;\n",
      "Entropy Neighbor = 0.878939701795578;                 Entropy Random = 0.47125519400835036;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1435, -0.3573, -0.0914, -0.1141, -0.0864, -0.0273, -0.1940,  0.0338,\n",
      "         0.2390,  0.0639]) tensor([ 0.2055, -0.5150,  0.1601, -0.0196, -0.0496, -0.3655, -0.4750,  0.2075,\n",
      "         0.5200, -0.0056]) tensor([ 0.1434, -0.3577, -0.0917, -0.1134, -0.0854, -0.0278, -0.1945,  0.0345,\n",
      "         0.2386,  0.0637])\n",
      "R[0]\n",
      "tensor([-0.0277], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.040609766453504566; R = 0.0009151862919097766;                 Gamma = 0.6048046256303787; Q = 8.840498939406416e-07;\n",
      "Entropy Neighbor = 0.8817208042144775;                 Entropy Random = 0.4743657876253128;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.00034126740419318296\n",
      "Episode average V value: -0.0072784012265503404\n",
      "epoch 1:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/miniforge3/envs/auxrl/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:345: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:391: RuntimeWarning: invalid value encountered in divide\n",
      "  dist_matrix = dist_matrix/np.nanpercentile(dist_matrix.flatten(), 99)\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:428: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1535, -0.3471, -0.0997, -0.2279, -0.1796,  0.0454, -0.0832, -0.0746,\n",
      "         0.2726,  0.1162]) tensor([ 0.2114, -0.5072,  0.1524, -0.1348, -0.1445, -0.2949, -0.3677,  0.0974,\n",
      "         0.5512,  0.0510]) tensor([ 0.1532, -0.3428, -0.0918, -0.2028, -0.1670,  0.0300, -0.1126, -0.0482,\n",
      "         0.2704,  0.1012])\n",
      "R[0]\n",
      "tensor([-0.0305], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04058194959908724; R = 0.0008959239681717009;                 Gamma = 0.6048417918682099; Q = 1.1376452060574138e-06;\n",
      "Entropy Neighbor = 0.8878252104520797;                 Entropy Random = 0.4723686958551407;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1475, -0.3545, -0.0894, -0.1148, -0.0895, -0.0310, -0.1999,  0.0401,\n",
      "         0.2449,  0.0621]) tensor([ 0.2094, -0.5120,  0.1624, -0.0203, -0.0528, -0.3691, -0.4808,  0.2140,\n",
      "         0.5259, -0.0074]) tensor([ 0.1472, -0.3550, -0.0898, -0.1138, -0.0879, -0.0316, -0.2006,  0.0410,\n",
      "         0.2442,  0.0617])\n",
      "R[0]\n",
      "tensor([-0.0274], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.040574275977909566; R = 0.000872183550032787;                 Gamma = 0.6040996506214141; Q = 9.490008329464672e-07;\n",
      "Entropy Neighbor = 0.8892101974487304;                 Entropy Random = 0.481952199280262;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1480, -0.3530, -0.0877, -0.1143, -0.0887, -0.0326, -0.2022,  0.0436,\n",
      "         0.2454,  0.0588]) tensor([ 0.2100, -0.5106,  0.1641, -0.0198, -0.0520, -0.3707, -0.4831,  0.2176,\n",
      "         0.5265, -0.0108]) tensor([ 0.1478, -0.3534, -0.0880, -0.1135, -0.0875, -0.0331, -0.2027,  0.0443,\n",
      "         0.2449,  0.0585])\n",
      "R[0]\n",
      "tensor([-0.0272], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0405327375382185; R = 0.000850240450585261;                 Gamma = 0.6043334212303162; Q = 6.484355670863806e-07;\n",
      "Entropy Neighbor = 0.894784884095192;                 Entropy Random = 0.5012205166220665;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1477, -0.3540, -0.0913, -0.1107, -0.0872, -0.0353, -0.2032,  0.0444,\n",
      "         0.2468,  0.0599]) tensor([ 0.2213, -0.5078,  0.1550, -0.0134, -0.0573, -0.3603, -0.5012,  0.2239,\n",
      "         0.5164, -0.0155]) tensor([ 0.1477, -0.3540, -0.0913, -0.1107, -0.0872, -0.0353, -0.2032,  0.0444,\n",
      "         0.2468,  0.0599])\n",
      "R[0]\n",
      "tensor([-0.0275], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04059529627859593; R = 0.0008323584732133895;                 Gamma = 0.6057505776882172; Q = 5.957884801262025e-07;\n",
      "Entropy Neighbor = 0.8961691603660583;                 Entropy Random = 0.5067025833129882;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1487, -0.3529, -0.0896, -0.1121, -0.0886, -0.0362, -0.2031,  0.0447,\n",
      "         0.2481,  0.0595]) tensor([ 0.2108, -0.5102,  0.1623, -0.0175, -0.0519, -0.3743, -0.4839,  0.2188,\n",
      "         0.5293, -0.0100]) tensor([ 0.1487, -0.3529, -0.0896, -0.1121, -0.0886, -0.0362, -0.2031,  0.0447,\n",
      "         0.2481,  0.0595])\n",
      "R[0]\n",
      "tensor([-0.0270], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04066239514946938; R = 0.0008164665719959885;                 Gamma = 0.6066340543031693; Q = 3.510743714869591e-07;\n",
      "Entropy Neighbor = 0.9020085977315903;                 Entropy Random = 0.5291939896345138;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1493, -0.3517, -0.0923, -0.1130, -0.0918, -0.0355, -0.2021,  0.0432,\n",
      "         0.2526,  0.0621]) tensor([ 0.2008, -0.5269,  0.1499, -0.0169, -0.0328, -0.3788, -0.4981,  0.1963,\n",
      "         0.5144,  0.0106]) tensor([ 0.1493, -0.3517, -0.0923, -0.1130, -0.0918, -0.0355, -0.2021,  0.0432,\n",
      "         0.2526,  0.0621])\n",
      "R[0]\n",
      "tensor([0.0005], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04060603298246861; R = 0.0008069162785541266;                 Gamma = 0.605882148385048; Q = 3.4584557934635997e-07;\n",
      "Entropy Neighbor = 0.9026435971260071;                 Entropy Random = 0.5390523608922958;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1644, -0.3384, -0.0795, -0.1754, -0.1582,  0.0069, -0.1461, -0.0121,\n",
      "         0.2720,  0.0843]) tensor([ 0.2240, -0.4973,  0.1735, -0.0815, -0.1228, -0.3326, -0.4296,  0.1617,\n",
      "         0.5517,  0.0175]) tensor([ 0.1617, -0.3383, -0.0783, -0.1586, -0.1466, -0.0056, -0.1635,  0.0018,\n",
      "         0.2695,  0.0777])\n",
      "R[0]\n",
      "tensor([-0.0281], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04062200075387955; R = 0.0007811800595372916;                 Gamma = 0.6061068656444549; Q = 2.9409523339296583e-07;\n",
      "Entropy Neighbor = 0.9064229390621186;                 Entropy Random = 0.5523308108448982;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1755, -0.3381, -0.0874, -0.1920, -0.1799,  0.0168, -0.1134, -0.0316,\n",
      "         0.2804,  0.1114]) tensor([ 0.2457, -0.4937,  0.1602, -0.0955, -0.1513, -0.3101, -0.4151,  0.1473,\n",
      "         0.5477,  0.0399]) tensor([ 0.1721, -0.3372, -0.0835, -0.1690, -0.1669,  0.0034, -0.1360, -0.0162,\n",
      "         0.2757,  0.1022])\n",
      "R[0]\n",
      "tensor([-0.0288], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.040631717190146445; R = 0.0007644361660350114;                 Gamma = 0.6066582976579666; Q = 2.72031961777941e-07;\n",
      "Entropy Neighbor = 0.9091670808792114;                 Entropy Random = 0.5658166489601135;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2124, -0.5388, -0.2079, -0.5070, -0.0483,  0.0706,  0.4526, -0.6356,\n",
      "         0.1574,  0.5526]) tensor([ 0.2621, -0.7056,  0.0287, -0.4213, -0.0111, -0.2731,  0.1690, -0.4809,\n",
      "         0.4291,  0.4905]) tensor([ 0.2124, -0.5388, -0.2079, -0.5070, -0.0483,  0.0706,  0.4526, -0.6356,\n",
      "         0.1574,  0.5526])\n",
      "R[0]\n",
      "tensor([-0.0541], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0406646778807044; R = 0.0007512637820327654;                 Gamma = 0.6072219289541244; Q = 3.1255643381911116e-07;\n",
      "Entropy Neighbor = 0.9105303468704223;                 Entropy Random = 0.5696987555623054;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2570, -0.5198, -0.1543, -0.4459, -0.0688,  0.0657,  0.3669, -0.5719,\n",
      "         0.1622,  0.4902]) tensor([ 0.3080, -0.6852,  0.0857, -0.3594, -0.0321, -0.2782,  0.0814, -0.4134,\n",
      "         0.4348,  0.4281]) tensor([ 0.2549, -0.5073, -0.1499, -0.4578, -0.0761,  0.0658,  0.3588, -0.5665,\n",
      "         0.1812,  0.4964])\n",
      "R[0]\n",
      "tensor([-0.0520], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04069883336126805; R = 0.0007344976858003065;                 Gamma = 0.6073411304950714; Q = 3.41941240250776e-07;\n",
      "Entropy Neighbor = 0.9102191509008407;                 Entropy Random = 0.5703433242440223;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 5.248414906290577e-07\n",
      "Episode average V value: -0.001970342095196247\n",
      "epoch 2:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:293: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  abs_states[i:i+1], torch.as_tensor([action_encoding])\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:345: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:428: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1534, -0.3422, -0.0838, -0.1187, -0.1084, -0.0379, -0.1999,  0.0425,\n",
      "         0.2576,  0.0580]) tensor([ 0.2267, -0.4960,  0.1631, -0.0213, -0.0790, -0.3631, -0.4983,  0.2225,\n",
      "         0.5271, -0.0169]) tensor([ 0.1529, -0.3427, -0.0844, -0.1175, -0.1066, -0.0388, -0.2008,  0.0437,\n",
      "         0.2570,  0.0575])\n",
      "R[0]\n",
      "tensor([-0.0266], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.040675786569714545; R = 0.0007149546800646931;                 Gamma = 0.6068195993900299; Q = 6.237174925871613e-07;\n",
      "Entropy Neighbor = 0.910564215540886;                 Entropy Random = 0.5748949845433236;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1563, -0.3378, -0.0722, -0.1262, -0.1224, -0.0412, -0.1967,  0.0364,\n",
      "         0.2551,  0.0546]) tensor([ 0.2178, -0.4954,  0.1807, -0.0315, -0.0863, -0.3795, -0.4782,  0.2111,\n",
      "         0.5361, -0.0144]) tensor([ 0.1547, -0.3391, -0.0734, -0.1208, -0.1156, -0.0453, -0.2019,  0.0419,\n",
      "         0.2531,  0.0519])\n",
      "R[0]\n",
      "tensor([-0.0257], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.040716670244932175; R = 0.0006811327589093708;                 Gamma = 0.6069935175180435; Q = 5.707836830879387e-07;\n",
      "Entropy Neighbor = 0.9078774635791779;                 Entropy Random = 0.5724970350265502;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1491, -0.3425, -0.0700, -0.0961, -0.0850, -0.0702, -0.2308,  0.0715,\n",
      "         0.2416,  0.0358]) tensor([ 0.2012, -0.5173,  0.1728,  0.0007, -0.0260, -0.4127, -0.5257,  0.2257,\n",
      "         0.5041, -0.0169]) tensor([ 0.1491, -0.3425, -0.0700, -0.0961, -0.0850, -0.0702, -0.2308,  0.0715,\n",
      "         0.2416,  0.0358])\n",
      "R[0]\n",
      "tensor([0.0026], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04071970000118017; R = 0.0006704412300605327;                 Gamma = 0.6067774626016617; Q = 5.088532402837132e-07;\n",
      "Entropy Neighbor = 0.9073428336381912;                 Entropy Random = 0.570763117492199;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1502, -0.3413, -0.0698, -0.1014, -0.0995, -0.0573, -0.2130,  0.0558,\n",
      "         0.2359,  0.0429]) tensor([ 0.2019, -0.5165,  0.1732, -0.0046, -0.0405, -0.4001, -0.5087,  0.2098,\n",
      "         0.4978, -0.0094]) tensor([ 0.1495, -0.3423, -0.0705, -0.0993, -0.0962, -0.0588, -0.2145,  0.0578,\n",
      "         0.2345,  0.0419])\n",
      "R[0]\n",
      "tensor([0.0023], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04072871650010347; R = 0.0006964239931548945;                 Gamma = 0.6072778371572495; Q = 3.284096441760198e-05;\n",
      "Entropy Neighbor = 0.9058202894926071;                 Entropy Random = 0.5544657705426216;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1690, -0.3123, -0.0449, -0.1566, -0.1564, -0.0748, -0.2053,  0.0238,\n",
      "         0.2905,  0.0781]) tensor([ 0.2194, -0.4880,  0.1989, -0.0602, -0.0992, -0.4182, -0.5013,  0.1778,\n",
      "         0.5526,  0.0272]) tensor([ 0.1648, -0.3176, -0.0462, -0.1450, -0.1411, -0.0823, -0.2154,  0.0306,\n",
      "         0.2821,  0.0718])\n",
      "R[0]\n",
      "tensor([0.0032], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04055790289491415; R = 0.00080592086375691;                 Gamma = 0.6027627362012863; Q = 0.00022368558234003898;\n",
      "Entropy Neighbor = 0.9135169357061386;                 Entropy Random = 0.5723980501294136;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1090, -0.4882, -0.1943, -0.2751, -0.0171, -0.0773,  0.1002, -0.2512,\n",
      "         0.1469,  0.2862]) tensor([ 0.1675, -0.6488,  0.0480, -0.1841,  0.0207, -0.4161, -0.1772, -0.0871,\n",
      "         0.4255,  0.2166]) tensor([ 0.0841, -0.4946, -0.2072, -0.2693, -0.0240, -0.0677,  0.0996, -0.2193,\n",
      "         0.1193,  0.2556])\n",
      "R[0]\n",
      "tensor([-0.0361], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04027460923790932; R = 0.0013179987370967865;                 Gamma = 0.6007227541208268; Q = 0.0006776076256859085;\n",
      "Entropy Neighbor = 0.9113759108781815;                 Entropy Random = 0.5757232059240341;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0675, -0.3607, -0.1107, -0.2143, -0.1479, -0.0592, -0.1329, -0.0685,\n",
      "         0.1983,  0.0134]) tensor([ 0.1392, -0.5159,  0.1342, -0.1171, -0.1194, -0.3839, -0.4293,  0.1091,\n",
      "         0.4679, -0.0618]) tensor([ 0.0912, -0.3712, -0.1175, -0.2302, -0.1429, -0.0421, -0.1142, -0.0333,\n",
      "         0.1932,  0.0315])\n",
      "R[0]\n",
      "tensor([-0.0262], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.040628485932946205; R = 0.001321698350191582;                 Gamma = 0.6027189707756042; Q = 0.0007413563757213523;\n",
      "Entropy Neighbor = 0.903418075799942;                 Entropy Random = 0.575935502409935;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0148, -0.3600, -0.2566, -0.2090, -0.2484, -0.0479, -0.0832, -0.0898,\n",
      "         0.2801,  0.0309]) tensor([ 0.0668, -0.5333, -0.0151, -0.1141, -0.1918, -0.3916, -0.3805,  0.0621,\n",
      "         0.5430, -0.0160]) tensor([ 0.0153, -0.3600, -0.2568, -0.2079, -0.2478, -0.0484, -0.0835, -0.0892,\n",
      "         0.2802,  0.0316])\n",
      "R[0]\n",
      "tensor([0.0059], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04081167861074209; R = 0.0020722908414900305;                 Gamma = 0.6027307147979737; Q = 0.0014585345174109533;\n",
      "Entropy Neighbor = 0.8886407330036163;                 Entropy Random = 0.5429159680604935;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0016, -0.3554, -0.2611, -0.2287, -0.2968, -0.0196, -0.0436, -0.1031,\n",
      "         0.2437,  0.0061]) tensor([ 0.0628, -0.5118, -0.0087, -0.1351, -0.2625, -0.3589, -0.3278,  0.0702,\n",
      "         0.5247, -0.0576]) tensor([-0.0093, -0.3557, -0.2672, -0.2203, -0.2985, -0.0252, -0.0441, -0.1162,\n",
      "         0.2449,  0.0069])\n",
      "R[0]\n",
      "tensor([-0.0197], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04126799546927214; R = 0.0017458246289170348;                 Gamma = 0.6113345242738724; Q = 0.0011978140240134962;\n",
      "Entropy Neighbor = 0.8699690098762513;                 Entropy Random = 0.5081050704717636;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0885, -0.5319, -0.1216, -0.2658,  0.0735, -0.2521, -0.1217, -0.1075,\n",
      "         0.1171,  0.1126]) tensor([ 0.1494, -0.6902,  0.1226, -0.1728,  0.1112, -0.5881, -0.3904,  0.0600,\n",
      "         0.4013,  0.0375]) tensor([ 0.0934, -0.5192, -0.1070, -0.2743,  0.0712, -0.2586, -0.1405, -0.0821,\n",
      "         0.1258,  0.0978])\n",
      "R[0]\n",
      "tensor([-0.0307], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.041386634223163125; R = 0.0017831183405942284;                 Gamma = 0.6140874625444412; Q = 0.0011781544345612928;\n",
      "Entropy Neighbor = 0.861508900642395;                 Entropy Random = 0.48818334412574765;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0005511696878566603\n",
      "Episode average V value: 0.017084695280319598\n",
      "epoch 3:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:345: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:428: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0708, -0.3815, -0.3132, -0.1291, -0.3121, -0.0398, -0.0164, -0.1977,\n",
      "         0.1963,  0.0141]) tensor([-0.0153, -0.5527, -0.0735, -0.0342, -0.2555, -0.3829, -0.3171, -0.0453,\n",
      "         0.4587, -0.0332]) tensor([-0.0708, -0.3815, -0.3132, -0.1291, -0.3121, -0.0398, -0.0164, -0.1977,\n",
      "         0.1963,  0.0141])\n",
      "R[0]\n",
      "tensor([0.0070], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04141333675384522; R = 0.0019666570110130122;                 Gamma = 0.6144813226461411; Q = 0.0013595634132980193;\n",
      "Entropy Neighbor = 0.8476336225271225;                 Entropy Random = 0.46406168496608735;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0811, -0.3803, -0.3156, -0.1182, -0.3031, -0.0439, -0.0300, -0.1853,\n",
      "         0.1916,  0.0082]) tensor([-0.0252, -0.5514, -0.0762, -0.0231, -0.2464, -0.3866, -0.3301, -0.0330,\n",
      "         0.4543, -0.0397]) tensor([-0.0811, -0.3803, -0.3156, -0.1182, -0.3031, -0.0439, -0.0300, -0.1853,\n",
      "         0.1916,  0.0082])\n",
      "R[0]\n",
      "tensor([0.0072], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04147206196933985; R = 0.002118739931611344;                 Gamma = 0.6144410636425018; Q = 0.001487709172997711;\n",
      "Entropy Neighbor = 0.8357221887111664;                 Entropy Random = 0.4490662457346916;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0010, -0.5100, -0.3138, -0.3373, -0.1881, -0.0371,  0.2366, -0.3776,\n",
      "         0.1409,  0.2703]) tensor([ 0.0453, -0.6948, -0.0469, -0.2175, -0.1485, -0.3630, -0.0890, -0.1907,\n",
      "         0.3726,  0.1980]) tensor([ 0.0106, -0.5515, -0.3535, -0.3360, -0.1645, -0.0774,  0.2229, -0.3266,\n",
      "         0.1500,  0.3078])\n",
      "R[0]\n",
      "tensor([0.0037], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04155943235009909; R = 0.001988934105844237;                 Gamma = 0.6168644298315048; Q = 0.0013274874606904632;\n",
      "Entropy Neighbor = 0.822154532790184;                 Entropy Random = 0.4191120159327984;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0394, -0.4860, -0.2683, -0.3185, -0.0500, -0.0419,  0.1454, -0.3036,\n",
      "         0.1635,  0.3387]) tensor([ 0.0864, -0.6651, -0.0386, -0.2261,  0.0101, -0.3857, -0.1461, -0.1637,\n",
      "         0.4212,  0.2876]) tensor([ 0.0995, -0.5023, -0.2456, -0.2875, -0.0258, -0.0672,  0.1162, -0.2696,\n",
      "         0.1582,  0.3866])\n",
      "R[0]\n",
      "tensor([-0.0099], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04183950934559107; R = 0.002285395102459006;                 Gamma = 0.6175419642925263; Q = 0.0015731060062680626;\n",
      "Entropy Neighbor = 0.8183447673320771;                 Entropy Random = 0.41071174719929693;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1006, -0.3495, -0.3132, -0.1406, -0.3537,  0.0033,  0.0097, -0.2000,\n",
      "         0.1876, -0.0213]) tensor([-0.0357, -0.5040, -0.0625, -0.0470, -0.3199, -0.3352, -0.2778, -0.0262,\n",
      "         0.4682, -0.0853]) tensor([-0.1027, -0.3508, -0.3157, -0.1400, -0.3542,  0.0030,  0.0117, -0.2023,\n",
      "         0.1873, -0.0218])\n",
      "R[0]\n",
      "tensor([-0.0179], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04185600009560585; R = 0.002110270835459232;                 Gamma = 0.6178296496868133; Q = 0.0014924916162090086;\n",
      "Entropy Neighbor = 0.8102858235836029;                 Entropy Random = 0.3924018283486366;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0883, -0.3301, -0.2960, -0.1224, -0.3599,  0.0063, -0.0122, -0.1850,\n",
      "         0.1962, -0.0236]) tensor([-0.0230, -0.4845, -0.0448, -0.0286, -0.3262, -0.3321, -0.3000, -0.0107,\n",
      "         0.4768, -0.0879]) tensor([-0.0883, -0.3303, -0.2964, -0.1222, -0.3599,  0.0062, -0.0118, -0.1850,\n",
      "         0.1961, -0.0237])\n",
      "R[0]\n",
      "tensor([-0.0176], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04206055797636509; R = 0.002367252641939558;                 Gamma = 0.6180910845994949; Q = 0.0016209206302592065;\n",
      "Entropy Neighbor = 0.803443756699562;                 Entropy Random = 0.37782971501350404;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0280, -0.2374, -0.1987, -0.1669, -0.1184, -0.1427, -0.3207,  0.0214,\n",
      "         0.4066,  0.0947]) tensor([ 0.0283, -0.4164,  0.0700, -0.0443, -0.0821, -0.4632, -0.6332,  0.2134,\n",
      "         0.6495,  0.0142]) tensor([-0.0290, -0.2189, -0.1805, -0.1689, -0.1116, -0.1406, -0.3408,  0.0207,\n",
      "         0.4195,  0.0740])\n",
      "R[0]\n",
      "tensor([0.0129], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04203867957741022; R = 0.002334134042612277;                 Gamma = 0.6198065003156662; Q = 0.0015582643206798821;\n",
      "Entropy Neighbor = 0.7962901540994645;                 Entropy Random = 0.35830085825920105;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-5.8335e-02, -3.0045e-01, -2.6124e-01, -1.0725e-01, -3.5124e-01,\n",
      "        -4.1336e-05, -7.3373e-02, -1.2583e-01,  2.1363e-01, -1.5733e-02]) tensor([ 0.0068, -0.4552, -0.0095, -0.0128, -0.3173, -0.3381, -0.3600,  0.0490,\n",
      "         0.4944, -0.0811]) tensor([-0.0688, -0.3048, -0.2720, -0.1074, -0.3586,  0.0005, -0.0624, -0.1403,\n",
      "         0.2143, -0.0178])\n",
      "R[0]\n",
      "tensor([-0.0175], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04221819546818733; R = 0.00240164395282045;                 Gamma = 0.6212583229541778; Q = 0.0016641694041900337;\n",
      "Entropy Neighbor = 0.7990327196121216;                 Entropy Random = 0.3553801788389683;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0958, -0.2930, -0.2968, -0.1082, -0.3895,  0.0027, -0.0510, -0.1607,\n",
      "         0.2334, -0.0180]) tensor([-0.0402, -0.4647, -0.0553, -0.0121, -0.3337, -0.3402, -0.3537, -0.0070,\n",
      "         0.4952, -0.0645]) tensor([-0.0958, -0.2930, -0.2968, -0.1082, -0.3895,  0.0027, -0.0510, -0.1607,\n",
      "         0.2334, -0.0180])\n",
      "R[0]\n",
      "tensor([0.0099], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0424285049661994; R = 0.0029923127614601983;                 Gamma = 0.6223429515361786; Q = 0.002305303095228737;\n",
      "Entropy Neighbor = 0.7951739864349365;                 Entropy Random = 0.34856976494193076;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1631, -0.2348, -0.2787, -0.1950, -0.1809, -0.1407, -0.2856, -0.0736,\n",
      "         0.4513, -0.0017]) tensor([-0.1045, -0.4115, -0.0106, -0.0735, -0.1474, -0.4607, -0.5983,  0.1182,\n",
      "         0.6964, -0.0799]) tensor([-0.1607, -0.2252, -0.2685, -0.1982, -0.1776, -0.1399, -0.2947, -0.0702,\n",
      "         0.4577, -0.0118])\n",
      "R[0]\n",
      "tensor([0.0162], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.042510929979383945; R = 0.0031702713695995043;                 Gamma = 0.6217251673936844; Q = 0.0023552511920061077;\n",
      "Entropy Neighbor = 0.7919226194620133;                 Entropy Random = 0.35151296892762185;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0016744266311827232\n",
      "Episode average V value: 0.10363365258052945\n",
      "epoch 4:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 2.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 1.9998000199980002 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:322: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:345: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:428: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0322, -0.4622, -0.3447, -0.1156, -0.0932, -0.0767, -0.0692, -0.1767,\n",
      "         0.2042,  0.2460]) tensor([ 0.0242, -0.6411, -0.0807,  0.0050, -0.0529, -0.3990, -0.3892,  0.0124,\n",
      "         0.4421,  0.1671]) tensor([-0.1061, -0.4231, -0.3569, -0.1215, -0.1358, -0.0774, -0.0933, -0.2161,\n",
      "         0.2496,  0.1729])\n",
      "R[0]\n",
      "tensor([0.0032], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04271558713912964; R = 0.0031103744656720664;                 Gamma = 0.6220539962053299; Q = 0.002431794282318151;\n",
      "Entropy Neighbor = 0.7833728437423706;                 Entropy Random = 0.3441389217078686;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0736, -0.2615, -0.2630, -0.0826, -0.3922, -0.0163, -0.1237, -0.0934,\n",
      "         0.2522, -0.0206]) tensor([-0.0072, -0.4152, -0.0106,  0.0124, -0.3591, -0.3538, -0.4101,  0.0824,\n",
      "         0.5338, -0.0862]) tensor([-0.0855, -0.2663, -0.2727, -0.0826, -0.3969, -0.0153, -0.1136, -0.1080,\n",
      "         0.2510, -0.0243])\n",
      "R[0]\n",
      "tensor([-0.0150], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04270652881264687; R = 0.0030901698225643485;                 Gamma = 0.6208381398916244; Q = 0.002382581685225887;\n",
      "Entropy Neighbor = 0.7807803926467896;                 Entropy Random = 0.33884234142303465;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1223, -0.2710, -0.2928, -0.0808, -0.4064, -0.0231, -0.1084, -0.1328,\n",
      "         0.2569, -0.0442]) tensor([-0.0649, -0.4414, -0.0511,  0.0157, -0.3515, -0.3651, -0.4101,  0.0220,\n",
      "         0.5202, -0.0917]) tensor([-0.1223, -0.2710, -0.2928, -0.0808, -0.4064, -0.0231, -0.1084, -0.1328,\n",
      "         0.2569, -0.0442])\n",
      "R[0]\n",
      "tensor([0.0119], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.042371510468423364; R = 0.002392165925586596;                 Gamma = 0.6215336723327637; Q = 0.002069449225637072;\n",
      "Entropy Neighbor = 0.7843877680301666;                 Entropy Random = 0.3476557052135468;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1037, -0.2607, -0.2738, -0.0756, -0.3905, -0.0217, -0.1352, -0.1013,\n",
      "         0.2541, -0.0297]) tensor([-0.0467, -0.4379,  0.0015,  0.0484, -0.3541, -0.3445, -0.4642,  0.0978,\n",
      "         0.4923, -0.1032]) tensor([-0.1026, -0.2666, -0.2571, -0.0692, -0.3567, -0.0193, -0.1518, -0.0951,\n",
      "         0.2310, -0.0338])\n",
      "R[0]\n",
      "tensor([0.0184], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.042648980930447576; R = 0.002993107651505852;                 Gamma = 0.6223597038984299; Q = 0.0023659346048370937;\n",
      "Entropy Neighbor = 0.7766564848423004;                 Entropy Random = 0.33900885078310966;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1375, -0.2694, -0.2959, -0.0749, -0.4026, -0.0191, -0.1142, -0.1386,\n",
      "         0.2555, -0.0448]) tensor([-0.0694, -0.4220, -0.0447,  0.0197, -0.3703, -0.3561, -0.4003,  0.0367,\n",
      "         0.5379, -0.1105]) tensor([-0.1390, -0.2694, -0.2969, -0.0746, -0.4031, -0.0192, -0.1136, -0.1397,\n",
      "         0.2559, -0.0459])\n",
      "R[0]\n",
      "tensor([-0.0145], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.042483110815286634; R = 0.003100735139421886;                 Gamma = 0.6213620134592056; Q = 0.0025581887006846955;\n",
      "Entropy Neighbor = 0.7797305787801743;                 Entropy Random = 0.3449342832863331;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1532, -0.2724, -0.2987, -0.0718, -0.3883, -0.0261, -0.1292, -0.1433,\n",
      "         0.2587, -0.0533]) tensor([-0.0845, -0.4247, -0.0482,  0.0227, -0.3562, -0.3627, -0.4144,  0.0317,\n",
      "         0.5417, -0.1195]) tensor([-0.1553, -0.2730, -0.3004, -0.0716, -0.3886, -0.0261, -0.1280, -0.1448,\n",
      "         0.2586, -0.0545])\n",
      "R[0]\n",
      "tensor([-0.0148], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.042513914421200755; R = 0.0024715630908031016;                 Gamma = 0.6235487620830535; Q = 0.00212079255059507;\n",
      "Entropy Neighbor = 0.7761303228139877;                 Entropy Random = 0.343559823513031;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0653, -0.5625, -0.2396, -0.0165,  0.3270, -0.1687, -0.3237,  0.0549,\n",
      "         0.0706,  0.2823]) tensor([ 0.1230, -0.7434,  0.0170,  0.1052,  0.3740, -0.4877, -0.6284,  0.2392,\n",
      "         0.3114,  0.1904]) tensor([ 0.2186, -0.5567, -0.1640,  0.0484,  0.3448, -0.1954, -0.3843,  0.1544,\n",
      "         0.0553,  0.3619])\n",
      "R[0]\n",
      "tensor([-0.0097], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0425197022035718; R = 0.0023727539840328973;                 Gamma = 0.622762149810791; Q = 0.001990080577437766;\n",
      "Entropy Neighbor = 0.7772659808397293;                 Entropy Random = 0.34571102729439734;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1561, -0.2666, -0.3007, -0.0650, -0.3921, -0.0250, -0.1364, -0.1289,\n",
      "         0.2592, -0.0510]) tensor([-0.0976, -0.4366, -0.0603,  0.0315, -0.3373, -0.3663, -0.4367,  0.0254,\n",
      "         0.5232, -0.0997]) tensor([-0.1562, -0.2665, -0.3008, -0.0645, -0.3922, -0.0252, -0.1363, -0.1288,\n",
      "         0.2591, -0.0516])\n",
      "R[0]\n",
      "tensor([0.0115], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04262363114953041; R = 0.0032305833945574704;                 Gamma = 0.6231198204755783; Q = 0.0026849524885037683;\n",
      "Entropy Neighbor = 0.7730651671886444;                 Entropy Random = 0.34681223991513255;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0845, -0.4547, -0.2734, -0.2465, -0.1815, -0.1026,  0.0800, -0.3078,\n",
      "         0.1367,  0.2209]) tensor([-0.0120, -0.6102, -0.0382, -0.1516, -0.1524, -0.4268, -0.2148, -0.1382,\n",
      "         0.4040,  0.1446]) tensor([ 0.1257, -0.4520, -0.0997, -0.2570, -0.0092, -0.1021,  0.0770, -0.3631,\n",
      "         0.1205,  0.3544])\n",
      "R[0]\n",
      "tensor([-0.0297], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.042604027211666104; R = 0.0033398751230561173;                 Gamma = 0.6233592984676362; Q = 0.002737619196734158;\n",
      "Entropy Neighbor = 0.7731325960159302;                 Entropy Random = 0.34332298746705053;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2739, -0.3612, -0.4380, -0.2579, -0.3510,  0.0208,  0.0857, -0.3492,\n",
      "         0.2911,  0.0352]) tensor([-0.2195, -0.5404, -0.1703, -0.1376, -0.3165, -0.3026, -0.2401, -0.1592,\n",
      "         0.5285, -0.0352]) tensor([-0.2618, -0.3514, -0.4271, -0.2723, -0.3706,  0.0212,  0.0988, -0.3476,\n",
      "         0.2955,  0.0367])\n",
      "R[0]\n",
      "tensor([0.0132], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04259568000584841; R = 0.0028434051309595815;                 Gamma = 0.6246955505609513; Q = 0.0024471205386944347;\n",
      "Entropy Neighbor = 0.7710702421665192;                 Entropy Random = 0.34001503640413283;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0023788513850668096\n",
      "Episode average V value: 0.11585475664500858\n",
      "epoch 5:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:322: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:345: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:428: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1644, -0.2581, -0.3036, -0.0774, -0.4119, -0.0207, -0.1265, -0.1308,\n",
      "         0.2672, -0.0706]) tensor([-0.0849, -0.4072, -0.0581,  0.0202, -0.3869, -0.3443, -0.4291,  0.0499,\n",
      "         0.5382, -0.1423]) tensor([-0.1644, -0.2581, -0.3036, -0.0774, -0.4119, -0.0207, -0.1265, -0.1308,\n",
      "         0.2672, -0.0706])\n",
      "R[0]\n",
      "tensor([-0.0138], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04270715135335922; R = 0.0034717901558033192;                 Gamma = 0.6247943366765976; Q = 0.0027675981817737922;\n",
      "Entropy Neighbor = 0.7696245709657669;                 Entropy Random = 0.34583619925379755;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1587, -0.2338, -0.2887, -0.0882, -0.4321, -0.0209, -0.1310, -0.1302,\n",
      "         0.2836, -0.0723]) tensor([-0.1010, -0.4043, -0.0469,  0.0086, -0.3780, -0.3625, -0.4321,  0.0249,\n",
      "         0.5475, -0.1200]) tensor([-0.1587, -0.2338, -0.2887, -0.0882, -0.4321, -0.0209, -0.1310, -0.1302,\n",
      "         0.2836, -0.0723])\n",
      "R[0]\n",
      "tensor([0.0134], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04281965963542461; R = 0.0038576149391010405;                 Gamma = 0.6254570177793503; Q = 0.003170701753850153;\n",
      "Entropy Neighbor = 0.7704008709192276;                 Entropy Random = 0.34320355314016343;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1657, -0.2827, -0.1334, -0.3089, -0.2180,  0.0407,  0.0530, -0.1555,\n",
      "         0.2428,  0.3471]) tensor([ 0.2083, -0.4720,  0.1372, -0.1865, -0.1776, -0.2856, -0.2722,  0.0328,\n",
      "         0.4720,  0.2732]) tensor([-0.0380, -0.4736, -0.2685, -0.2204, -0.2393, -0.1510,  0.0903, -0.2658,\n",
      "         0.1144,  0.2581])\n",
      "R[0]\n",
      "tensor([0.0036], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04293407223373651; R = 0.003993991531897337;                 Gamma = 0.6256709846258164; Q = 0.003326161369215697;\n",
      "Entropy Neighbor = 0.7649870864152908;                 Entropy Random = 0.33549457025527957;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2662, -0.2435, -0.3530, -0.2014, -0.3715, -0.0066, -0.0579, -0.1873,\n",
      "         0.3176, -0.0456]) tensor([-0.1889, -0.3952, -0.1115, -0.1047, -0.3472, -0.3295, -0.3558, -0.0119,\n",
      "         0.5886, -0.1174]) tensor([-0.2366, -0.2555, -0.3455, -0.2257, -0.3860, -0.0065, -0.0154, -0.2172,\n",
      "         0.3143,  0.0012])\n",
      "R[0]\n",
      "tensor([-0.0157], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04282814604043961; R = 0.003878702389105456;                 Gamma = 0.6278741680383683; Q = 0.0034298888097255256;\n",
      "Entropy Neighbor = 0.7632167757749557;                 Entropy Random = 0.33686192870140075;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1842, -0.2523, -0.3180, -0.0983, -0.4584,  0.0082, -0.0643, -0.1890,\n",
      "         0.2666, -0.0810]) tensor([-0.1165, -0.4051, -0.0661, -0.0039, -0.4273, -0.3292, -0.3525, -0.0134,\n",
      "         0.5486, -0.1447]) tensor([-0.1842, -0.2523, -0.3180, -0.0983, -0.4584,  0.0082, -0.0643, -0.1890,\n",
      "         0.2666, -0.0810])\n",
      "R[0]\n",
      "tensor([-0.0126], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04300916554033756; R = 0.003812681103590876;                 Gamma = 0.6288230038881302; Q = 0.003296283533796668;\n",
      "Entropy Neighbor = 0.756504868388176;                 Entropy Random = 0.3198489596545696;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1768, -0.2806, -0.3320, -0.1022, -0.4446,  0.0265, -0.0345, -0.1969,\n",
      "         0.2392, -0.0606]) tensor([-0.1097, -0.4338, -0.0806, -0.0081, -0.4127, -0.3113, -0.3234, -0.0219,\n",
      "         0.5204, -0.1241]) tensor([-0.1844, -0.2787, -0.3354, -0.1018, -0.4485,  0.0251, -0.0341, -0.2029,\n",
      "         0.2437, -0.0639])\n",
      "R[0]\n",
      "tensor([-0.0144], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04299807718396187; R = 0.004275113177893218;                 Gamma = 0.6282519336938858; Q = 0.003651381427058368;\n",
      "Entropy Neighbor = 0.7586134918928147;                 Entropy Random = 0.3222046582698822;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1467, -0.3420, -0.2833, -0.2096, -0.3054, -0.0296, -0.0358, -0.2227,\n",
      "         0.2234,  0.0170]) tensor([-0.0932, -0.5225, -0.0125, -0.0873, -0.2693, -0.3526, -0.3604, -0.0293,\n",
      "         0.4607, -0.0573]) tensor([-0.1304, -0.3521, -0.2719, -0.2213, -0.2985, -0.0354, -0.0256, -0.2301,\n",
      "         0.2160,  0.0219])\n",
      "R[0]\n",
      "tensor([0.0132], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.042853300377726555; R = 0.003965175367338816;                 Gamma = 0.6298310610055924; Q = 0.003249524679093156;\n",
      "Entropy Neighbor = 0.7536025520563125;                 Entropy Random = 0.30965168115496633;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1946, -0.3903,  0.0044, -0.1048,  0.0987, -0.2628, -0.2327, -0.2443,\n",
      "         0.2361,  0.3460]) tensor([ 0.2615, -0.5462,  0.2425, -0.0138,  0.1340, -0.5974, -0.5012, -0.0796,\n",
      "         0.5207,  0.2674]) tensor([-0.0821, -0.3436, -0.2844, -0.2809, -0.3787, -0.0395,  0.1069, -0.3946,\n",
      "         0.2941,  0.2153])\n",
      "R[0]\n",
      "tensor([-0.0397], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04280309506505728; R = 0.004296806993545033;                 Gamma = 0.6311243009567261; Q = 0.0036292266698146705;\n",
      "Entropy Neighbor = 0.7526163413524628;                 Entropy Random = 0.2970241319537163;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2357, -0.2595, -0.3909, -0.3040, -0.2920,  0.0143, -0.0395, -0.1527,\n",
      "         0.3951, -0.0492]) tensor([-0.1830, -0.4401, -0.1199, -0.1826, -0.2573, -0.3088, -0.3607,  0.0382,\n",
      "         0.6345, -0.1199]) tensor([-0.2282, -0.2574, -0.3831, -0.3186, -0.2822,  0.0203, -0.0337, -0.1583,\n",
      "         0.3999, -0.0540])\n",
      "R[0]\n",
      "tensor([0.0174], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04285864494740963; R = 0.0043424239187443165;                 Gamma = 0.6320750313997269; Q = 0.003599221053882502;\n",
      "Entropy Neighbor = 0.741802806854248;                 Entropy Random = 0.27432973650097847;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0936, -0.2525, -0.2670, -0.1643, -0.4649,  0.0868,  0.0093, -0.1725,\n",
      "         0.2088, -0.0287]) tensor([-0.0424, -0.4280, -0.0236, -0.0673, -0.4087, -0.2574, -0.2971, -0.0190,\n",
      "         0.4669, -0.0731]) tensor([-0.1064, -0.2640, -0.2828, -0.1472, -0.4724,  0.0744,  0.0145, -0.1848,\n",
      "         0.2062, -0.0326])\n",
      "R[0]\n",
      "tensor([0.0094], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04291940153390169; R = 0.005025531440100167;                 Gamma = 0.633065781712532; Q = 0.004211342246926506;\n",
      "Entropy Neighbor = 0.7440384238958359;                 Entropy Random = 0.27211183980107306;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.003433132972513704\n",
      "Episode average V value: 0.14298421664535998\n",
      "epoch 6:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:322: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:345: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:428: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2399, -0.2849, -0.3953, -0.2971, -0.2975,  0.0149,  0.0244, -0.2391,\n",
      "         0.3615,  0.0197]) tensor([-0.1872, -0.4659, -0.1265, -0.1762, -0.2628, -0.3083, -0.2978, -0.0498,\n",
      "         0.5996, -0.0515]) tensor([-0.2332, -0.2850, -0.3947, -0.3079, -0.2835,  0.0204,  0.0224, -0.2314,\n",
      "         0.3689,  0.0125])\n",
      "R[0]\n",
      "tensor([0.0153], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04288621859997511; R = 0.005040755304333288;                 Gamma = 0.6351458985805511; Q = 0.004220619219006039;\n",
      "Entropy Neighbor = 0.7369756959676742;                 Entropy Random = 0.257257558748126;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0420, -0.3704, -0.2083, -0.2554, -0.3066, -0.0628,  0.0248, -0.2725,\n",
      "         0.1903,  0.0798]) tensor([ 0.0192, -0.5280,  0.0401, -0.1626, -0.2738, -0.4012, -0.2580, -0.1020,\n",
      "         0.4705,  0.0135]) tensor([-0.0373, -0.3674, -0.2020, -0.2599, -0.3023, -0.0595,  0.0206, -0.2653,\n",
      "         0.1899,  0.0730])\n",
      "R[0]\n",
      "tensor([-0.0232], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.043028359048068524; R = 0.004803676312498282;                 Gamma = 0.6364276651144027; Q = 0.003932509196631144;\n",
      "Entropy Neighbor = 0.7351771274805069;                 Entropy Random = 0.2553478199839592;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.4106, -0.2244,  0.2937,  0.0030,  0.1895, -0.2299, -0.4193, -0.2296,\n",
      "         0.2786,  0.3100]) tensor([ 0.4782, -0.3815,  0.5341,  0.0948,  0.2242, -0.5641, -0.6887, -0.0622,\n",
      "         0.5631,  0.2286]) tensor([-0.0387, -0.2836, -0.2527, -0.1700, -0.3447,  0.0049, -0.0130, -0.3163,\n",
      "         0.3143,  0.1792])\n",
      "R[0]\n",
      "tensor([-0.0452], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04286376963555813; R = 0.005114346988440957;                 Gamma = 0.6371885803937912; Q = 0.0042487909198680425;\n",
      "Entropy Neighbor = 0.7366801971197128;                 Entropy Random = 0.25810008612275126;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0757, -0.2433, -0.2633, -0.1318, -0.4963,  0.0859,  0.0102, -0.1778,\n",
      "         0.2124, -0.0069]) tensor([-0.0130, -0.3998, -0.0093, -0.0368, -0.4633, -0.2537, -0.2825, -0.0021,\n",
      "         0.4899, -0.0689]) tensor([-0.0941, -0.2428, -0.2765, -0.1305, -0.5074,  0.0859,  0.0196, -0.1983,\n",
      "         0.2205, -0.0104])\n",
      "R[0]\n",
      "tensor([-0.0159], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.043066694870591164; R = 0.004841264839516953;                 Gamma = 0.6381036728620529; Q = 0.004155692026572069;\n",
      "Entropy Neighbor = 0.7323867998123169;                 Entropy Random = 0.25808130902051923;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1308, -0.2429, -0.3005, -0.1323, -0.5259,  0.0929,  0.0476, -0.2446,\n",
      "         0.2292, -0.0238]) tensor([-0.0668, -0.3984, -0.0472, -0.0381, -0.4941, -0.2466, -0.2461, -0.0693,\n",
      "         0.5072, -0.0846]) tensor([-0.1317, -0.2426, -0.3009, -0.1321, -0.5267,  0.0927,  0.0479, -0.2453,\n",
      "         0.2296, -0.0249])\n",
      "R[0]\n",
      "tensor([-0.0150], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.042900967992842196; R = 0.005168150247103768;                 Gamma = 0.6385563787221908; Q = 0.004205022305744933;\n",
      "Entropy Neighbor = 0.7339686138629913;                 Entropy Random = 0.2631788474917412;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1975, -0.3636, -0.4560, -0.3003, -0.3280,  0.0727,  0.1639, -0.4003,\n",
      "         0.3435,  0.1495]) tensor([-0.1454, -0.5441, -0.1894, -0.1817, -0.2930, -0.2525, -0.1638, -0.2130,\n",
      "         0.5788,  0.0820]) tensor([-0.1914, -0.3620, -0.4532, -0.3147, -0.3213,  0.0764,  0.1718, -0.4105,\n",
      "         0.3529,  0.1577])\n",
      "R[0]\n",
      "tensor([0.0089], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0428612452596426; R = 0.005448595396999736;                 Gamma = 0.6398269037008285; Q = 0.004565362463705242;\n",
      "Entropy Neighbor = 0.7343626444339753;                 Entropy Random = 0.2616777104437351;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1901, -0.2663, -0.3260, -0.1669, -0.3737,  0.0038, -0.0792, -0.1796,\n",
      "         0.2839,  0.0107]) tensor([-0.1240, -0.4212, -0.0784, -0.0731, -0.3418, -0.3329, -0.3618, -0.0086,\n",
      "         0.5659, -0.0553]) tensor([-1.9077e-01, -2.4559e-01, -3.1656e-01, -1.8829e-01, -3.8237e-01,\n",
      "         3.7874e-04, -8.8863e-02, -1.6965e-01,  3.0790e-01,  6.2005e-03])\n",
      "R[0]\n",
      "tensor([-0.0179], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04293423103541136; R = 0.0050032820700434966;                 Gamma = 0.6402849479913711; Q = 0.004343219261732883;\n",
      "Entropy Neighbor = 0.7308017899990081;                 Entropy Random = 0.260623854637146;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1454, -0.2831, -0.0600, -0.2116, -0.3294, -0.1904, -0.0619, -0.2139,\n",
      "         0.2785,  0.2892]) tensor([ 0.2171, -0.4375,  0.1833, -0.1152, -0.3036, -0.5154, -0.3598, -0.0372,\n",
      "         0.5465,  0.2143]) tensor([ 0.2101, -0.3332, -0.1098, -0.2226, -0.3674, -0.1623,  0.0542, -0.2783,\n",
      "         0.2864,  0.3951])\n",
      "R[0]\n",
      "tensor([-0.0227], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04299776750802994; R = 0.0056322299929161095;                 Gamma = 0.6404413366317749; Q = 0.0047868023991613886;\n",
      "Entropy Neighbor = 0.7302233152389527;                 Entropy Random = 0.26088767927885054;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-1.0194e-01, -2.5932e-01, -2.7056e-01, -1.1475e-01, -4.6133e-01,\n",
      "         8.0422e-02, -1.7011e-04, -2.0338e-01,  1.9292e-01, -8.0309e-03]) tensor([-0.0380, -0.4155, -0.0185, -0.0201, -0.4283, -0.2585, -0.2915, -0.0288,\n",
      "         0.4710, -0.0713]) tensor([-0.0980, -0.2527, -0.2730, -0.1118, -0.4755,  0.0751, -0.0042, -0.1980,\n",
      "         0.2066, -0.0052])\n",
      "R[0]\n",
      "tensor([-0.0176], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04322088435292244; R = 0.005760692269715946;                 Gamma = 0.6402627264261246; Q = 0.004788009477517335;\n",
      "Entropy Neighbor = 0.7252731546163559;                 Entropy Random = 0.2544108512103558;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2567, -0.3025, -0.4044, -0.2225, -0.3733,  0.0495,  0.0446, -0.3314,\n",
      "         0.3103,  0.0291]) tensor([-0.1903, -0.4570, -0.1594, -0.1311, -0.3428, -0.2880, -0.2396, -0.1634,\n",
      "         0.5922, -0.0340]) tensor([-0.2778, -0.3292, -0.4115, -0.2310, -0.3301,  0.0479,  0.0265, -0.3269,\n",
      "         0.2913, -0.0129])\n",
      "R[0]\n",
      "tensor([-0.0209], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04329156405478716; R = 0.007439101321157068;                 Gamma = 0.6391867698431015; Q = 0.005977681117859902;\n",
      "Entropy Neighbor = 0.7211111427545548;                 Entropy Random = 0.25198967519402504;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0045223708387798975\n",
      "Episode average V value: 0.154327762940526\n",
      "epoch 7:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 0.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 0.0 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:322: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:345: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:428: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1131, -0.4682, -0.2996, -0.3168, -0.3408, -0.0966,  0.2799, -0.4762,\n",
      "         0.2940,  0.4647]) tensor([ 0.1606, -0.6496, -0.0309, -0.1990, -0.3047, -0.4243, -0.0508, -0.2873,\n",
      "         0.5256,  0.3970]) tensor([ 0.1407, -0.4914, -0.3057, -0.3576, -0.3264, -0.0756,  0.3418, -0.5162,\n",
      "         0.2913,  0.5049])\n",
      "R[0]\n",
      "tensor([0.0053], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04318473277240992; R = 0.006972488264465938;                 Gamma = 0.6390772536993027; Q = 0.005653495355858467;\n",
      "Entropy Neighbor = 0.7192538998126984;                 Entropy Random = 0.24633111676573755;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0746, -0.4287, -0.2723, -0.2203, -0.3663, -0.0593,  0.1917, -0.3597,\n",
      "         0.1950,  0.4005]) tensor([ 0.1239, -0.6040, -0.0365, -0.1270, -0.3090, -0.4047, -0.1115, -0.2127,\n",
      "         0.4509,  0.3545]) tensor([-0.0012, -0.4341, -0.2725, -0.2269, -0.3989, -0.1208,  0.1652, -0.3675,\n",
      "         0.1803,  0.3370])\n",
      "R[0]\n",
      "tensor([-0.0009], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04328707204759121; R = 0.007533834468078567;                 Gamma = 0.6376252219676971; Q = 0.006011946471524425;\n",
      "Entropy Neighbor = 0.716526435136795;                 Entropy Random = 0.24254164388775826;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2567, -0.2552, -0.3062, -0.1848, -0.2427, -0.0276, -0.1489, -0.1748,\n",
      "         0.2954, -0.0440]) tensor([-0.1998, -0.4350, -0.0390, -0.0622, -0.2077, -0.3479, -0.4672,  0.0161,\n",
      "         0.5359, -0.1219]) tensor([-0.2667, -0.2787, -0.3294, -0.1723, -0.2374, -0.0393, -0.1517, -0.1810,\n",
      "         0.2947, -0.0399])\n",
      "R[0]\n",
      "tensor([0.0142], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04359799161553383; R = 0.008932410792214796;                 Gamma = 0.6376381530761719; Q = 0.006876171564654214;\n",
      "Entropy Neighbor = 0.7044031860828399;                 Entropy Random = 0.2286021443158388;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1268, -0.2876, -0.3052, -0.2014, -0.4125,  0.1218,  0.0487, -0.2231,\n",
      "         0.1938, -0.0065]) tensor([-0.0763, -0.4640, -0.0648, -0.1053, -0.3557, -0.2226, -0.2563, -0.0727,\n",
      "         0.4514, -0.0510]) tensor([-0.1278, -0.2891, -0.3108, -0.2234, -0.4007,  0.1281,  0.0531, -0.2174,\n",
      "         0.2016, -0.0013])\n",
      "R[0]\n",
      "tensor([0.0052], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04368091234564781; R = 0.009144066742563154;                 Gamma = 0.6371126929521561; Q = 0.006809929660201305;\n",
      "Entropy Neighbor = 0.7043411258459091;                 Entropy Random = 0.22724556374549865;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1660, -0.5000, -0.2963, -0.4168, -0.3126, -0.0549,  0.3999, -0.5566,\n",
      "         0.3001,  0.5244]) tensor([ 0.2306, -0.6569, -0.0578, -0.3272, -0.2852, -0.3861,  0.0942, -0.3889,\n",
      "         0.5622,  0.4608]) tensor([ 0.1898, -0.4926, -0.2887, -0.4125, -0.2549, -0.0431,  0.3648, -0.5361,\n",
      "         0.3267,  0.5083])\n",
      "R[0]\n",
      "tensor([-0.0360], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0442465206682682; R = 0.010141188919427805;                 Gamma = 0.6375435121059417; Q = 0.007882895936782007;\n",
      "Entropy Neighbor = 0.6929007663726806;                 Entropy Random = 0.21715666845440865;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0968, -0.2889, -0.2888, -0.1902, -0.3810,  0.1352,  0.0488, -0.2152,\n",
      "         0.1781,  0.0491]) tensor([-0.0469, -0.4726, -0.0158, -0.0669, -0.3425, -0.1900, -0.2838, -0.0215,\n",
      "         0.4099, -0.0215]) tensor([-0.0687, -0.2388, -0.2695, -0.1891, -0.3495,  0.1356,  0.0118, -0.1978,\n",
      "         0.2420,  0.1245])\n",
      "R[0]\n",
      "tensor([0.0105], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04425260871648788; R = 0.010233720218995586;                 Gamma = 0.6369186761379242; Q = 0.007599843786068959;\n",
      "Entropy Neighbor = 0.6898939304351807;                 Entropy Random = 0.20993589198589324;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1352, -0.4951, -0.2991, -0.3832, -0.3068, -0.1143,  0.3279, -0.5250,\n",
      "         0.3225,  0.5025]) tensor([ 0.1821, -0.6698, -0.0648, -0.2938, -0.2520, -0.4616,  0.0264, -0.3812,\n",
      "         0.5802,  0.4610]) tensor([ 0.0492, -0.5259, -0.3344, -0.2606, -0.3107, -0.1600,  0.2198, -0.4264,\n",
      "         0.2354,  0.4402])\n",
      "R[0]\n",
      "tensor([-0.0052], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.044200914345681665; R = 0.009582907915115357;                 Gamma = 0.6362815047502518; Q = 0.007381947575457161;\n",
      "Entropy Neighbor = 0.6863693345785141;                 Entropy Random = 0.2050029395222664;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1169, -0.2719, -0.3119, -0.1065, -0.4981,  0.0648,  0.0255, -0.2489,\n",
      "         0.2281, -0.0028]) tensor([-0.0514, -0.4260, -0.0596, -0.0128, -0.4662, -0.2745, -0.2674, -0.0736,\n",
      "         0.5071, -0.0643]) tensor([-0.1169, -0.2719, -0.3119, -0.1065, -0.4981,  0.0648,  0.0255, -0.2489,\n",
      "         0.2281, -0.0028])\n",
      "R[0]\n",
      "tensor([-0.0162], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0446817819699645; R = 0.01159401546738809;                 Gamma = 0.6365353124141693; Q = 0.008532424769946374;\n",
      "Entropy Neighbor = 0.6807187153100968;                 Entropy Random = 0.20328888460993766;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0635, -0.4090, -0.2980,  0.0274, -0.1269, -0.1221, -0.2277, -0.0145,\n",
      "         0.2387,  0.2436]) tensor([ 0.1237, -0.5844, -0.0300,  0.1497, -0.0860, -0.4437, -0.5494,  0.1805,\n",
      "         0.4785,  0.1633]) tensor([ 0.1193, -0.4180, -0.2686,  0.0760, -0.0878, -0.1210, -0.2882,  0.0626,\n",
      "         0.2070,  0.2101])\n",
      "R[0]\n",
      "tensor([0.0068], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04431710489094257; R = 0.010378675914020278;                 Gamma = 0.6358444112539291; Q = 0.007904166063875891;\n",
      "Entropy Neighbor = 0.6779258642196655;                 Entropy Random = 0.1962637601494789;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0143, -0.2342, -0.2088, -0.1918, -0.3323,  0.1186, -0.0462, -0.0665,\n",
      "         0.2015,  0.1108]) tensor([ 0.0619, -0.4200,  0.0654, -0.0672, -0.2921, -0.2066, -0.3759,  0.1274,\n",
      "         0.4326,  0.0379]) tensor([-0.0443, -0.2763, -0.2558, -0.2186, -0.3254,  0.1407,  0.0071, -0.1335,\n",
      "         0.1804,  0.0702])\n",
      "R[0]\n",
      "tensor([0.0100], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04440264983475208; R = 0.010047091547981836;                 Gamma = 0.6338277243375778; Q = 0.007787154653866309;\n",
      "Entropy Neighbor = 0.6696906331777572;                 Entropy Random = 0.19059269474446774;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.0072439975838235115\n",
      "Episode average V value: 0.20429297422147746\n",
      "epoch 8:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 4.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 3.9996000399960003 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:322: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:345: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:428: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1095, -0.2807, -0.3081, -0.1091, -0.4811,  0.0648,  0.0232, -0.2456,\n",
      "         0.2209,  0.0011]) tensor([-0.0442, -0.4350, -0.0560, -0.0154, -0.4489, -0.2745, -0.2693, -0.0706,\n",
      "         0.4999, -0.0606]) tensor([-0.1095, -0.2807, -0.3081, -0.1091, -0.4811,  0.0648,  0.0232, -0.2456,\n",
      "         0.2209,  0.0011])\n",
      "R[0]\n",
      "tensor([-0.0170], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0447517713829875; R = 0.011125648298708256;                 Gamma = 0.6347776871919631; Q = 0.008461621734779328;\n",
      "Entropy Neighbor = 0.6666777740716934;                 Entropy Random = 0.18714740991592407;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1198, -0.4233, -0.3736, -0.0899, -0.2125, -0.0529, -0.1037, -0.1496,\n",
      "         0.2103,  0.1090]) tensor([-0.0616, -0.6003, -0.1061,  0.0320, -0.1739, -0.3749, -0.4268,  0.0434,\n",
      "         0.4493,  0.0319]) tensor([-0.1142, -0.4379, -0.3779, -0.1039, -0.2077, -0.0493, -0.0795, -0.1678,\n",
      "         0.2036,  0.1202])\n",
      "R[0]\n",
      "tensor([0.0089], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.044701697170734404; R = 0.010136034434544854;                 Gamma = 0.6351995817422866; Q = 0.00789181528496556;\n",
      "Entropy Neighbor = 0.66387049472332;                 Entropy Random = 0.18602284736931324;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.2042, -0.2945, -0.3194, -0.1708, -0.2616, -0.0623, -0.1527, -0.1780,\n",
      "         0.3119,  0.0345]) tensor([-0.1462, -0.4657, -0.0852, -0.0759, -0.2076, -0.4022, -0.4443, -0.0299,\n",
      "         0.5779, -0.0171]) tensor([-0.2421, -0.2676, -0.3039, -0.1723, -0.2331, -0.0284, -0.1567, -0.2045,\n",
      "         0.3004, -0.0171])\n",
      "R[0]\n",
      "tensor([0.0056], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04488476085662842; R = 0.011055255029990803;                 Gamma = 0.6335562611818314; Q = 0.008501178342616185;\n",
      "Entropy Neighbor = 0.6531773844957351;                 Entropy Random = 0.1730897832661867;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2772, -0.3528, -0.0717, -0.2747,  0.0612, -0.0438, -0.0453, -0.3493,\n",
      "         0.3792,  0.3900]) tensor([ 0.3276, -0.5291,  0.1589, -0.1855,  0.1176, -0.3883, -0.3361, -0.2081,\n",
      "         0.6413,  0.3399]) tensor([ 0.3121, -0.3943, -0.0566, -0.3847,  0.0489, -0.0782,  0.0627, -0.4200,\n",
      "         0.3813,  0.4208])\n",
      "R[0]\n",
      "tensor([-0.0176], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.045325693786144254; R = 0.01136523671238683;                 Gamma = 0.6343404068946839; Q = 0.008374696217477322;\n",
      "Entropy Neighbor = 0.6495364710092545;                 Entropy Random = 0.17059913308918476;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0985, -0.4764, -0.2820, -0.3854, -0.2076,  0.0045,  0.3510, -0.4452,\n",
      "         0.1808,  0.4674]) tensor([ 0.1526, -0.6393, -0.0407, -0.2963, -0.1711, -0.3373,  0.0663, -0.2844,\n",
      "         0.4542,  0.4044]) tensor([ 0.0100, -0.4377, -0.3127, -0.3731, -0.2044,  0.0949,  0.2911, -0.3553,\n",
      "         0.1429,  0.3678])\n",
      "R[0]\n",
      "tensor([-0.0377], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.045318145640194415; R = 0.012046692423056811;                 Gamma = 0.6339302568435669; Q = 0.00908475667773746;\n",
      "Entropy Neighbor = 0.6457220135927201;                 Entropy Random = 0.16867656816542148;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1120, -0.3858, -0.3039, -0.0621, -0.2169, -0.1199, -0.1608, -0.1358,\n",
      "         0.2004,  0.1693]) tensor([-0.0428, -0.5389, -0.0614,  0.0315, -0.1820, -0.4548, -0.4379,  0.0333,\n",
      "         0.4836,  0.0966]) tensor([-0.1493, -0.3620, -0.3170, -0.0853, -0.2421, -0.1034, -0.1555, -0.1571,\n",
      "         0.2299,  0.1212])\n",
      "R[0]\n",
      "tensor([-0.0246], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04511800948530435; R = 0.01165183095744578;                 Gamma = 0.6321282430887222; Q = 0.008838941372698172;\n",
      "Entropy Neighbor = 0.6406347179412841;                 Entropy Random = 0.16765902033448218;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1467, -0.2471, -0.1032, -0.3459, -0.1264,  0.1776,  0.0036, -0.0458,\n",
      "         0.1723,  0.2414]) tensor([ 0.1854, -0.4415,  0.1673, -0.2220, -0.0830, -0.1488, -0.3199,  0.1403,\n",
      "         0.3992,  0.1660]) tensor([-0.0066, -0.4480, -0.2695, -0.1327, -0.2730, -0.1028,  0.0600, -0.2391,\n",
      "         0.1042,  0.3258])\n",
      "R[0]\n",
      "tensor([-0.0011], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04526959647983313; R = 0.011228069354139733;                 Gamma = 0.6325255966186524; Q = 0.008698756028315983;\n",
      "Entropy Neighbor = 0.6375083820819855;                 Entropy Random = 0.16522198973596097;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0259, -0.2792, -0.2213, -0.1650, -0.4098,  0.0671, -0.0157, -0.1225,\n",
      "         0.1531, -0.0038]) tensor([ 0.0458, -0.4343,  0.0264, -0.0663, -0.3814, -0.2588, -0.3222,  0.0575,\n",
      "         0.4183, -0.0740]) tensor([-0.0260, -0.2824, -0.1968, -0.2081, -0.3642,  0.0955, -0.0050, -0.1233,\n",
      "         0.1238, -0.0141])\n",
      "R[0]\n",
      "tensor([-0.0192], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04531521286815405; R = 0.011383803476637694;                 Gamma = 0.6326010887622833; Q = 0.008623590733739547;\n",
      "Entropy Neighbor = 0.6337517465353012;                 Entropy Random = 0.1656189598888159;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.2512, -0.4248, -0.1407,  0.0817,  0.0449, -0.1195, -0.4155,  0.2517,\n",
      "         0.1265,  0.1495]) tensor([ 0.3085, -0.6026,  0.1316,  0.2068,  0.0908, -0.4412, -0.7343,  0.4503,\n",
      "         0.3660,  0.0648]) tensor([ 0.2493, -0.4238, -0.1399,  0.0760,  0.0386, -0.1175, -0.4101,  0.2482,\n",
      "         0.1257,  0.1432])\n",
      "R[0]\n",
      "tensor([0.0026], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04520663670450449; R = 0.010743765520572197;                 Gamma = 0.6325644867420197; Q = 0.008710607183573301;\n",
      "Entropy Neighbor = 0.6348466430902481;                 Entropy Random = 0.16692591850459576;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0839, -0.2650, -0.2728, -0.1183, -0.4539,  0.0530, -0.0250, -0.1720,\n",
      "         0.2049, -0.0060]) tensor([-0.0305, -0.4448,  0.0036,  0.0057, -0.4168, -0.2716, -0.3588,  0.0266,\n",
      "         0.4394, -0.0765]) tensor([-0.0393, -0.2728, -0.2402, -0.1404, -0.4196,  0.0646, -0.0312, -0.1250,\n",
      "         0.1754,  0.0048])\n",
      "R[0]\n",
      "tensor([0.0168], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04507406439632177; R = 0.011017375425202772;                 Gamma = 0.6320167096853256; Q = 0.008658702948305291;\n",
      "Entropy Neighbor = 0.6358115423917771;                 Entropy Random = 0.16700297185778618;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.008584466652420814\n",
      "Episode average V value: 0.28222723859808496\n",
      "epoch 9:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 4.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 3.9996000399960003 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:322: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:345: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:428: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.1325, -0.2739, -0.3136, -0.2175, -0.1781,  0.0057, -0.1095, -0.1646,\n",
      "         0.3489,  0.0490]) tensor([-0.0668, -0.4298, -0.0695, -0.1254, -0.1451, -0.3305, -0.3863,  0.0021,\n",
      "         0.6327, -0.0183]) tensor([-0.1477, -0.3040, -0.3236, -0.1705, -0.1425, -0.0409, -0.1509, -0.1586,\n",
      "         0.3329,  0.0709])\n",
      "R[0]\n",
      "tensor([-0.0244], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.045297746263444426; R = 0.01169893319538096;                 Gamma = 0.6318807172775268; Q = 0.009433930134633556;\n",
      "Entropy Neighbor = 0.6373021242618561;                 Entropy Random = 0.1662583377957344;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0892, -0.2717, -0.2768, -0.1218, -0.4500,  0.0590, -0.0159, -0.1777,\n",
      "         0.1966, -0.0067]) tensor([-0.0253, -0.4275, -0.0244, -0.0271, -0.4167, -0.2799, -0.3062, -0.0029,\n",
      "         0.4752, -0.0702]) tensor([-0.0897, -0.2716, -0.2769, -0.1216, -0.4502,  0.0588, -0.0158, -0.1781,\n",
      "         0.1968, -0.0072])\n",
      "R[0]\n",
      "tensor([-0.0171], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.044892915062606335; R = 0.010517391230911017;                 Gamma = 0.6317274941205978; Q = 0.00852630711637903;\n",
      "Entropy Neighbor = 0.6389511680603027;                 Entropy Random = 0.16691365303099157;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 1.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1758, -0.3548, -0.1835,  0.1521, -0.0093, -0.1071, -0.4568,  0.2466,\n",
      "         0.1807,  0.2595]) tensor([ 0.2353, -0.5252,  0.0515,  0.2497,  0.0540, -0.4470, -0.7453,  0.3976,\n",
      "         0.4439,  0.1987]) tensor([ 0.1611, -0.1832, -0.1344, -0.0057, -0.3035,  0.0078, -0.3140,  0.1935,\n",
      "         0.2623,  0.1634])\n",
      "R[0]\n",
      "tensor([-0.0034], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04493813195079565; R = 0.012035450187104288;                 Gamma = 0.6306867625713348; Q = 0.009388667721184902;\n",
      "Entropy Neighbor = 0.6350346903800964;                 Entropy Random = 0.16541124995052814;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0071, -0.2654, -0.1902, -0.2561, -0.3055,  0.1308, -0.0460, -0.0556,\n",
      "         0.1594,  0.0009]) tensor([ 0.0383, -0.4526,  0.0856, -0.1313, -0.2652, -0.1948, -0.3748,  0.1384,\n",
      "         0.3907, -0.0715]) tensor([ 0.0072, -0.2398, -0.1543, -0.3039, -0.2502,  0.1380, -0.0857,  0.0010,\n",
      "         0.1744, -0.0009])\n",
      "R[0]\n",
      "tensor([0.0098], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.045205150030553344; R = 0.012988577237119898;                 Gamma = 0.6307130192518234; Q = 0.009722029906348325;\n",
      "Entropy Neighbor = 0.6288594031929969;                 Entropy Random = 0.16023274952173233;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0842, -0.2652, -0.2652, -0.1408, -0.4360,  0.0437, -0.0431, -0.1464,\n",
      "         0.2073, -0.0222]) tensor([-0.0208, -0.4214, -0.0126, -0.0459, -0.4027, -0.2949, -0.3319,  0.0283,\n",
      "         0.4864, -0.0861]) tensor([-0.0847, -0.2652, -0.2655, -0.1405, -0.4364,  0.0434, -0.0431, -0.1470,\n",
      "         0.2074, -0.0226])\n",
      "R[0]\n",
      "tensor([-0.0165], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04505024472624063; R = 0.011976017185428645;                 Gamma = 0.6299614586830139; Q = 0.009515486562624574;\n",
      "Entropy Neighbor = 0.628195858836174;                 Entropy Random = 0.16295176784694196;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0529, -0.2604, -0.2428, -0.1584, -0.4137,  0.0613, -0.0554, -0.1052,\n",
      "         0.2015, -0.0152]) tensor([ 0.0088, -0.4180,  0.0103, -0.0631, -0.3795, -0.2776, -0.3437,  0.0693,\n",
      "         0.4799, -0.0794]) tensor([-0.0608, -0.2596, -0.2490, -0.1532, -0.4208,  0.0596, -0.0524, -0.1166,\n",
      "         0.2057, -0.0153])\n",
      "R[0]\n",
      "tensor([-0.0177], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04516125749796629; R = 0.011565943035762758;                 Gamma = 0.6301819393634797; Q = 0.009025739881617484;\n",
      "Entropy Neighbor = 0.6244575462341309;                 Entropy Random = 0.15919727033376693;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0793, -0.2644, -0.2454, -0.1524, -0.2851, -0.0381, -0.0696, -0.2346,\n",
      "         0.2906,  0.1275]) tensor([-0.0240, -0.4443,  0.0234, -0.0306, -0.2494, -0.3605, -0.3936, -0.0423,\n",
      "         0.5282,  0.0518]) tensor([-0.1277, -0.2655, -0.2758, -0.1620, -0.2588, -0.0430, -0.0908, -0.2151,\n",
      "         0.3054,  0.0806])\n",
      "R[0]\n",
      "tensor([0.0120], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.045037282578647135; R = 0.012445017722900957;                 Gamma = 0.6293272248506546; Q = 0.009530596449796576;\n",
      "Entropy Neighbor = 0.6241795978546143;                 Entropy Random = 0.16241898107528688;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0851, -0.2627, -0.2645, -0.1456, -0.4238,  0.0542, -0.0489, -0.1421,\n",
      "         0.2119, -0.0218]) tensor([-0.0108, -0.4157, -0.0179, -0.0476, -0.3970, -0.2711, -0.3543,  0.0376,\n",
      "         0.4791, -0.0919]) tensor([-0.0851, -0.2627, -0.2645, -0.1456, -0.4238,  0.0542, -0.0489, -0.1421,\n",
      "         0.2119, -0.0218])\n",
      "R[0]\n",
      "tensor([-0.0179], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04508788201957941; R = 0.01273139024025295;                 Gamma = 0.6302787592411041; Q = 0.009783315117820166;\n",
      "Entropy Neighbor = 0.622348727107048;                 Entropy Random = 0.16010497418045996;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0983, -0.2432, -0.0908, -0.2738, -0.2114,  0.0831, -0.1892,  0.1734,\n",
      "         0.1495, -0.0051]) tensor([ 0.1512, -0.4091,  0.1632, -0.1755, -0.1721, -0.2555, -0.4686,  0.3450,\n",
      "         0.4255, -0.0748]) tensor([-0.0106, -0.2641, -0.1546, -0.2624, -0.2508,  0.1009, -0.1010,  0.0193,\n",
      "         0.1314, -0.0284])\n",
      "R[0]\n",
      "tensor([-0.0239], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.045353624194860456; R = 0.013794258235197048;                 Gamma = 0.6297504880428314; Q = 0.01046766759257298;\n",
      "Entropy Neighbor = 0.6180158741474152;                 Entropy Random = 0.16008324667811394;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1784, -0.3195, -0.1297, -0.1901, -0.3167, -0.0982,  0.0173, -0.3337,\n",
      "         0.3102,  0.3705]) tensor([ 0.2406, -0.4756,  0.1171, -0.0995, -0.2847, -0.4381, -0.2679, -0.1641,\n",
      "         0.5893,  0.3052]) tensor([ 0.3466, -0.3181, -0.0126, -0.1965, -0.2023, -0.1776, -0.0210, -0.3317,\n",
      "         0.3496,  0.5193])\n",
      "R[0]\n",
      "tensor([-0.0298], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04559858480095863; R = 0.014506453842390328;                 Gamma = 0.6303259966373443; Q = 0.010639374828082509;\n",
      "Entropy Neighbor = 0.6100954277515411;                 Entropy Random = 0.1555155944377184;                 Volume = 0.0; VAE = 0.0\n",
      "Average (on the epoch) training loss: 0.00960331153110601\n",
      "Episode average V value: 0.2891133290141821\n",
      "epoch 10:\n",
      "Learning rate: 0.0001\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.2\n",
      "Testing score per episode (id: 0) is 94.0 (average over 1 episode(s))\n",
      "== Mean score per episode is 93.99060093990602 over 1 episodes ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:322: UserWarning: You passed a edgecolor/edgecolors ('k') for an unfilled marker ('+').  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.\n",
      "  ax.scatter(\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:345: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/Users/chingfang/Code/deer/examples/test_CRAR/figure8_alt1.py:428: RuntimeWarning: All-NaN axis encountered\n",
      "  ylim_max = np.nanmax(self._separability_tracking)*1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.1181, -0.3761, -0.1856, -0.0931, -0.0191, -0.0682, -0.2359, -0.1067,\n",
      "         0.2745,  0.2470]) tensor([ 0.1848, -0.5311,  0.0561, -0.0017,  0.0173, -0.4049, -0.5110,  0.0601,\n",
      "         0.5577,  0.1748]) tensor([ 0.1154, -0.4213, -0.2006, -0.0326,  0.1066, -0.0968, -0.3602,  0.0506,\n",
      "         0.2277,  0.1987])\n",
      "R[0]\n",
      "tensor([-0.0369], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.045643136650323865; R = 0.014920905178587417;                 Gamma = 0.6302621161937714; Q = 0.011004713690374047;\n",
      "Entropy Neighbor = 0.6091972035169602;                 Entropy Random = 0.16026164031028747;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0029, -0.2363, -0.1013, -0.4533, -0.1663,  0.1144, -0.1421,  0.0844,\n",
      "         0.2041, -0.1038]) tensor([ 0.0644, -0.4008,  0.1455, -0.3535, -0.1361, -0.2108, -0.4342,  0.2578,\n",
      "         0.4702, -0.1775]) tensor([ 0.0025, -0.2497, -0.0998, -0.5026, -0.1181,  0.1361, -0.1280,  0.0940,\n",
      "         0.1943, -0.1034])\n",
      "R[0]\n",
      "tensor([-0.0274], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.0456780639141798; R = 0.014748061858175789;                 Gamma = 0.6308450638055801; Q = 0.01118595651909709;\n",
      "Entropy Neighbor = 0.6069612275362015;                 Entropy Random = 0.15899979062378405;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "0 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0799, -0.3678, -0.3087,  0.0936, -0.0279, -0.0780, -0.3754, -0.0114,\n",
      "         0.2360,  0.1629]) tensor([-0.0153, -0.5352, -0.0800,  0.1883,  0.0307, -0.4161, -0.6623,  0.1355,\n",
      "         0.5031,  0.1036]) tensor([-0.0416, -0.5147, -0.3762,  0.1785,  0.1506, -0.1708, -0.4534,  0.1111,\n",
      "         0.1732,  0.2306])\n",
      "R[0]\n",
      "tensor([-0.0047], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.045575411468744276; R = 0.01703326645528432;                 Gamma = 0.6307224037647248; Q = 0.012274065618752501;\n",
      "Entropy Neighbor = 0.6048705714941025;                 Entropy Random = 0.15807892243564128;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "3 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.0539, -0.4410, -0.3257,  0.0514, -0.0855, -0.1465, -0.2625,  0.0140,\n",
      "         0.2324,  0.3494]) tensor([ 0.1148, -0.6166, -0.0614,  0.1736, -0.0435, -0.4673, -0.5810,  0.2064,\n",
      "         0.4722,  0.2662]) tensor([ 7.1465e-02, -4.3471e-01, -3.0060e-01, -3.8493e-04, -1.2746e-01,\n",
      "        -1.7841e-01, -2.1553e-01, -4.5853e-02,  2.5713e-01,  3.7255e-01])\n",
      "R[0]\n",
      "tensor([0.0034], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04564801128953695; R = 0.01679862318834057;                 Gamma = 0.6302765834331513; Q = 0.011797053195536136;\n",
      "Entropy Neighbor = 0.6001991321444511;                 Entropy Random = 0.1556842769086361;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([ 0.3353, -0.4133, -0.0300, -0.3227, -0.2645, -0.3354,  0.0873, -0.3972,\n",
      "         0.3401,  0.5235]) tensor([ 0.3937, -0.5697,  0.2171, -0.2333, -0.2334, -0.6758, -0.1923, -0.2284,\n",
      "         0.6209,  0.4572]) tensor([ 0.3657, -0.4014,  0.0241, -0.3074, -0.1609, -0.3602,  0.0248, -0.4211,\n",
      "         0.3649,  0.5658])\n",
      "R[0]\n",
      "tensor([-0.0292], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.04592937768995762; R = 0.01852304318221286;                 Gamma = 0.6313124493360519; Q = 0.01326598228898365;\n",
      "Entropy Neighbor = 0.5967214722633362;                 Entropy Random = 0.1549587285667658;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "2 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0852, -0.3089, -0.2210, -0.1931, -0.3256,  0.0725, -0.0252, -0.1416,\n",
      "         0.1140, -0.0432]) tensor([-0.0248, -0.4688,  0.0296, -0.0977, -0.2902, -0.2657, -0.3109,  0.0304,\n",
      "         0.3917, -0.1100]) tensor([-0.0819, -0.3130, -0.2380, -0.1579, -0.3385,  0.0581, -0.0370, -0.1384,\n",
      "         0.1256, -0.0281])\n",
      "R[0]\n",
      "tensor([-0.0218], grad_fn=<SelectBackward0>)\n",
      "LOSSES\n",
      "T = 0.046243696443736555; R = 0.018488127643766346;                 Gamma = 0.6316634036302566; Q = 0.012748503811541013;\n",
      "Entropy Neighbor = 0.5908406972885132;                 Entropy Random = 0.1533635333031416;                 Volume = 0.0; VAE = 0.0\n",
      "Printing a few elements useful for debugging:\n",
      "actions_val[0], rewards_val[0], terminals_val[0]\n",
      "1 0.0 0.0\n",
      "Es[0], TEs[0], Esp_[0]\n",
      "tensor([-0.0283, -0.2009, -0.0625, -0.1074, -0.1276,  0.0347, -0.1850, -0.2573,\n",
      "         0.2070,  0.1255]) tensor([ 0.0481, -0.3574,  0.1722, -0.0114, -0.1006, -0.2874, -0.4789, -0.0868,\n",
      "         0.4754,  0.0447]) tensor([-0.1093, -0.2602, -0.2224, -0.0746, -0.2570,  0.0226, -0.1467, -0.2341,\n",
      "         0.2264,  0.1304])\n",
      "R[0]\n",
      "tensor([-0.0352], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(\"params\")\n",
    "except Exception:\n",
    "    pass\n",
    "dump(vars(parameters), \"params/\" + fname + \".jldump\")\n",
    "#agent.gathering_data=False\n",
    "if set_network is not None:\n",
    "    agent.setNetwork(\n",
    "        f'{set_network[0]}/fname', nEpoch=set_network[1],\n",
    "        encoder_only=set_network[2]\n",
    "        )\n",
    "agent.run(parameters.epochs, parameters.steps_per_epoch)\n",
    "\n",
    "# --- Show results ---\n",
    "basename = \"scores/\" + fname\n",
    "scores = load(basename + \"_scores.jldump\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.setNetwork(f'{fname}/fname', nEpoch=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent._in_episode = True\n",
    "agent._mode = 0 # Testing mode with plan_depth=0\n",
    "initState = env.reset(agent._mode)\n",
    "inputDims = env.inputDimensions()\n",
    "\n",
    "for i in range(len(inputDims)):\n",
    "    if inputDims[i][0] > 1:\n",
    "        agent._state[i][1:] = initState[i][1:]\n",
    "agent._Vs_on_last_episode = []\n",
    "is_terminal = False\n",
    "reward = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for i in range(100):\n",
    "    obs = env.observe()\n",
    "    _obs = obs[0].reshape((env.WIDTH, env.HEIGHT))\n",
    "    plt.figure()\n",
    "    plt.imshow(np.flip(_obs.squeeze()))\n",
    "    plt.show()\n",
    "    for i in range(len(obs)):\n",
    "        agent._state[i][0:-1] = agent._state[i][1:]\n",
    "        agent._state[i][-1] = obs[i]\n",
    "    V, action, reward, _ = agent._step()\n",
    "    print(action)\n",
    "    agent._Vs_on_last_episode.append(V)\n",
    "    is_terminal = env.inTerminalState()\n",
    "    if is_terminal: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "obs = env.observe()\n",
    "_obs = obs[0].reshape((env.WIDTH, env.HEIGHT))\n",
    "_obs = np.flip(_obs.squeeze())\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "im = ax.imshow(np.zeros(_obs.shape))\n",
    "\n",
    "def init():\n",
    "    plt.cla()\n",
    "    im = ax.imshow(_obs)\n",
    "    return [im]\n",
    "\n",
    "def animate(i, *args, **kwargs):\n",
    "    plt.cla()\n",
    "    obs = env.observe()\n",
    "    _obs = obs[0].reshape((env.WIDTH, env.HEIGHT))\n",
    "    _obs = np.flip(_obs.squeeze())\n",
    "    im = ax.imshow(_obs)\n",
    "    for i in range(len(obs)):\n",
    "        agent._state[i][0:-1] = agent._state[i][1:]\n",
    "        agent._state[i][-1] = obs[i]\n",
    "        V, action, reward, _ = agent._step()\n",
    "        agent._Vs_on_last_episode.append(V)\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, init_func=init, \n",
    "     frames=100, blit=False, repeat=True)\n",
    "ani.save(f'figs/{fname}/behavior.gif', writer=\"ffmpeg\", fps = 15)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
